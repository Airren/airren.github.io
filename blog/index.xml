<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Blog on ByteGopher</title>
    <link>https://airren.github.io/blog/</link>
    <description>Recent content in Blog on ByteGopher</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 01 Apr 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://airren.github.io/blog/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>「Raft」 The Raft Consensus Algorithm</title>
      <link>https://airren.github.io/blog/raft/</link>
      <pubDate>Thu, 01 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://airren.github.io/blog/raft/</guid>
      <description>12 123 https://raft.github.io/
https://www.infoq.com/presentations/raft-consensus-algorithm/
https://www.geeksforgeeks.org/raft-consensus-algorithm/
https://www.hashicorp.com/resources/raft-consul-consensus-protocol-explained</description>
    </item>
    
    <item>
      <title></title>
      <link>https://airren.github.io/blog/1_cryptography/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://airren.github.io/blog/1_cryptography/</guid>
      <description>对称加密 非对称加密 RSA 由于计算非常复杂，只适用于小数据加密。
HTTPS 非对称加密+对称加密
mTLS 数字证书 数字证书的颁发过程一般为： 用户首先产生自己的密钥对，并将公共密钥以及部分个人身份信息传送给认证中心。认证中心在核实身份后，执行一些必要的步骤，以确认请求确实是由用户发送来的。然后，认证中心将发给用户一个数字证书。该证书内包含用户的个信息和他的公钥信息。同时还附有认证中心的签名信息。
加密通信 Alice [Decode message by Alice&amp;rsquo;s private key] &amp;lt;&amp;mdash;- send message &amp;mdash; [message encrypted with Alice&amp;rsquo;s public key] Bob
公钥加密，私钥解密
数字签名 Bob 给Alice发送的文件需要携带数字签名。
Bob使用自己的私钥 以及文件的哈希值， 通过签名算法 计算出 数字签名
Alice 收到文件后， 通过文件哈希值，Bob的数字签名，以及Bob的公钥 进行签名验证
数字签名主要有以下三个作用：认证，确认收到的数据的身份信息；防止抵赖，文件一旦签名后不能反悔；防止篡改，保证文件在传输过程中的完整性。
比特币其实就是数字签名
X.509 数字证书 证书版本信息
证书的序列号，每个证书都有一个唯一的证书序列号
证书所使用的签名算法；
证书的发行机构名称，命名规则一般采用X.500格式；
证书的有效期，现在通用的证书一般采用UTC时间格式，它的计时范围1950-2049；
证书所有人的名称，命名规则一般采用X.500格式；
证书所有人的公开密钥；
证书发行者对证书的签名；
Openssl 创建一个 root certificates 和 private key 用来为服务签署 certificates
1openssl req -x509 -sha256 -nodes -days 365 -newkey rsa:2048 -subj &amp;#39;/O=example Inc.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://airren.github.io/blog/3_intel_sgx/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://airren.github.io/blog/3_intel_sgx/</guid>
      <description>SGX
概述 https://www.intel.com/content/www/us/en/developer/tools/software-guard-extensions/overview.html
https://blog.quarkslab.com/overview-of-intel-sgx-part-1-sgx-internals.html
Intel Software Guard Extensions(Intel SGX) 保护选定的代码和数据不被泄露的和修改。开发者可以把应用程序划分到CPU强化的enclave中或者内存中可执行的保护区域，即使在受攻击的平台中也可以提高安全性。使用这种新的应用层可信执行环境，开发者能够启用身份和记录隐私，安全浏览和数据保护(DRM)或者任何需要安全存储机密或者保护数据的高保障安全应用场景中。
机密性和完整性， 即使在OS、BIOS、VMM或者SMM层存在特权恶意软件的情况下也可以保证安全。 低学习曲线，和父应用程序类似的OS编程模型，并且在主CPU上执行 远程认证 远程部分能够认证一个应用程序的enclave的身份，并且安全的将密钥、凭据和敏感数据提供为enclave 最小的可能攻击面， CPU边界成为攻击面外围，所有的数据、内存、外围之外的IO都是加密的。 最小攻击面的硬件辅助可信执行环境。
intel SGX保护的应用程序 Intel SGX应用程序由两个部分组成： 不可信代码和可信Enclave. 开发者可以创建一对多的可信enclave用来支持分布式体系结构。
常用应用有密钥，专有算法，生物识别数据和CSR生成等。
程序运行时， Intel SGX指令在一个特定的保护内存区域中创建和执行enclave，该区域有由开发者定义的受限入口和出口函数。能够防止数据泄露。在CPU范围中的enclave和数据运行在一个clean的环境中， enclave数据写入到磁盘会被加密，并且校验其完整性。
上图中的流程
Application由可信和不可信部分构成 App运行和创建evclave， enclave放入到可信内存中 可信函数被调用，执行会转换到enclave中 enclave可以访问所有进程数据，外部要访问enclave数据被禁止 可信函数返回enclave数据 对enclave有未授权的访问和内存侦听是有可能的
认证Enclave和加密数据 当前，ODM(原始设备制造上)和ISV(独立软件提供商) 通常在制造时或通过无法以机密方式证明XXX。
Intel SGX使用enclave之间本地认证或者第三方远程认证的方式来保证应用程序没有受到破坏。
应用程序受保护的部分会加载到一个Enclave，它的代码和数据都会收到监测。会发送一个请求到远端服务器，用来验证这个Enclave是否是可靠的Intel 处理器生成的。 如果认证了Enclave的身份，远端就会信任Enclave并安全的提供密钥，凭证和数据.
Intel SGX 包括一个生成CPU和Enclave特定“密封密钥”的指令。密钥能够用来安全的存储和取回可鞥你需要保存在磁盘中的敏感信息。
Intel SGX 实现新的安全模型 Intel SGX 是在很多公司、大学的安全研究人员以及政府安全机构的支持下创建的，上百家ISV与Intel合作，使用Intel SGX来保护关键任务应用程序。
Set up SGX develop environment Install SGX driver
Install SGX SDK
Install SGX PSW
直接按照官方文档依次安装上述3个组件</description>
    </item>
    
    <item>
      <title></title>
      <link>https://airren.github.io/blog/crypto_openvpn/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://airren.github.io/blog/crypto_openvpn/</guid>
      <description>Reference https://www.cyberciti.biz/faq/ubuntu-20-04-lts-set-up-openvpn-server-in-5-minutes/
https://github.com/Nyr/openvpn-install/blob/master/openvpn-install.sh</description>
    </item>
    
    <item>
      <title></title>
      <link>https://airren.github.io/blog/k8s_1_pod/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://airren.github.io/blog/k8s_1_pod/</guid>
      <description>从底层技术角度看，Pod内不同容器之间共享存储和一些namespace。
PID namespace: Pod中不同应用程序看拿到的其他进程的ID。Sidecar 模式下只能看到一个进程？
Network Namespace: Pod 中的多个容器具有相同的网络配置，共享一个端口范围。
IPC Namespace： Pod中的多个容器能够使用SystemV IPC 或 POSIX消息队列进行通信。
UTS Namespace: Pod中的多个容器共享一个主机名。
在Kubernetes的网络模型中，每台服务器上的容器有自己独立的IP段。
为了实现这一目标，重点解决一下两点：
各台服务器上的容器IP段不能重叠，所以需要某种IP段分配机制，为各台机器分配独立的IP段。 从某个Pod发出的流量到达所在的机器的Host上时，机器网络层应当根据目标IP地址，将流量转发到目标机器的能力。 综上，两个能力： IP地址分配和Route.
容器之间直接通信，不需要额外的NAT。
Pod to Pod 所有的Pod之间要保证3层网络的联通性
Pod to Service Servcie 总共有4种类型，其中组常用的就是Cluster IP. 这种类型的Service会分配一个仅集群内可以访问的虚拟IP。
Kubernetes通过kube-proxy组件实现Service Cluster IP的功能。kube-proxy 是一个daemonset，通过复杂的iptables/IPVS 规则在Pod和Service之间进行各种过滤和NAT.
Pod到集群外 从Pod内部到集群外的流量，Kubernetes会通过SNAT来处理。
Kubernets 默认的组网方案是bridge，CNI主要是用来解决容器的跨机通信。典型的跨机通信方案有bridge和overlay。
创建Pod时候，首先会创建一个pause容器。占用一个 linux的network namespace。Pod内的其他容器共享这个network namespace。此时，只有一个lo设备。 CNI负责初始化pause container 中的网络设备。
kubernetes主机内组网&amp;amp;跨节点组网 kubernetes 经典的主机内组网模型是veth pair+bridge。
跨机通信一般是bridge + overlay。 vxlan
downward API 通过HostAlias修改pod中的/etc/host(Pod在host network下不支持)
Pod的隔离中 network namspce 是最先创建的，如果ns使用了host模式，则uts也会使用host模式。
Pause扮演PID 1的角色，并在子进程成为“孤儿进程”时，通过wait() 收割这些僵尸子进程。</description>
    </item>
    
    <item>
      <title></title>
      <link>https://airren.github.io/blog/linux_zero_copy/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://airren.github.io/blog/linux_zero_copy/</guid>
      <description>https://www.jianshu.com/p/a6c6f47a5ef7
https://blog.csdn.net/weixin_42096901/article/details/103017044
https://blog.csdn.net/weixin_39406430/article/details/123715072
http://t.zoukankan.com/yangyongjie-p-14576216.html
https://zhuanlan.zhihu.com/p/430848775
https://blog.csdn.net/weixin_42340926/article/details/126211173</description>
    </item>
    
    <item>
      <title></title>
      <link>https://airren.github.io/blog/multipass_network/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://airren.github.io/blog/multipass_network/</guid>
      <description>LXC Set proxy
1sudo lxc config set core.proxy_https http://username:password@&amp;lt;IP&amp;gt;:&amp;lt;port&amp;gt;/ LXC
https://www.linode.com/docs/guides/beginners-guide-to-lxd-reverse-proxy/
https://www.digitalocean.com/community/tutorials/how-to-install-and-configure-lxd-on-ubuntu-20-04
SDEWAN - direct connect Edge-1
1# PREROUTTING 2sudo iptables -I PREROUTING -d 10.10.70.49/32 -p tcp -m tcp --dport 6443 -j DNAT --to-destination 10.96.0.1:443 -t nat Hub
1# PREROUTTING 2 3sudo iptables -I PREROUTING --destination 10.95.62.68/32 -p esp -j DNAT --to-destination 10.233.108.10 -t nat 4sudo iptables -I PREROUTING --destination 10.95.62.68/32 -p udp --dport 4500 -j DNAT --to-destination 10.233.108.10:4500 -t nat 5sudo iptables -I PREROUTING --destination 10.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://airren.github.io/blog/network_virtualization/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://airren.github.io/blog/network_virtualization/</guid>
      <description>1title: Linux Network Virtualization Network Namespace In order to provide the isolation, Linux has 6 namespaces to split the different resources, shown as follows:
Namespace Description Mount Namespace File system mount point CLONE_NEWNET UTS Namespace Hostname CLONE_NETUTS IPC Namespace POSIX process messaging queue CLONE_NEWIPC PID Namespace Process PID number namespace CLONE_NEWPID Network Namespace IP address/Port/Router/IPtables CLONE_NEWNS User Namespace User isolation CLONE_NEWUSER For the process, if they want to use the resources of the Namespace, they should enter the namespace first.</description>
    </item>
    
    <item>
      <title>「网络」网络基础</title>
      <link>https://airren.github.io/blog/network_base/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://airren.github.io/blog/network_base/</guid>
      <description>What is the network layer? Network-to-network connections are what make the Internet possible. The &amp;ldquo;network layer&amp;rdquo; is the part of the Internet communications process where these connections occur, by sending packets of data back and forth between different networks, In the 7-layer OSI model, the network layer is layer 3. The Internet Protocol(IP) is one of the main protocols used at this layer, along with several other protocols for routing, resting and encryption.</description>
    </item>
    
    <item>
      <title>【Linux】 Systemd</title>
      <link>https://airren.github.io/blog/linux_systemd/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://airren.github.io/blog/linux_systemd/</guid>
      <description>1# 通过Pid获取对应的service 2systemd status &amp;lt;Pid&amp;gt; </description>
    </item>
    
    <item>
      <title>Basic of client-go</title>
      <link>https://airren.github.io/blog/k8s_source_code_3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://airren.github.io/blog/k8s_source_code_3/</guid>
      <description>The repositories The Ku
The Client Library&amp;ndash; k8s.io/client-go k8s.io/client-go is a typical web service client library that supports all API types that are officially part of Kubernetes. It can be used to execute the usual REST verbs.
Create Get List Update Delete Patch Watch For each Kubernetes 1.x.y release, there is a client-go release with a matching tag kubernetes-1.x.y.
Most of your code that speaks to Kubernetes APIs will use tools/clientcmd/ to set up a client from a kubeconfig file, and kubernetes/ for the actual Kubernetes API clients.</description>
    </item>
    
    <item>
      <title>Cloud Native</title>
      <link>https://airren.github.io/blog/CloudNative/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://airren.github.io/blog/CloudNative/</guid>
      <description>4C8G 70%-80% 虚拟化浪费掉了
裸金属
2001 VMware虚拟化技术
2006 AWS推出EC2服务
2010 Openstack社区成立。 虚拟化技术，管理操作系统
2011.04 第一个 开源PaaS平台 CloudFoundry
2013.03 开源Docker发布。 操作系统之上的应用容器化。
2014.06 Google 发布Kubernetes, 应用编排
2015.07 Google 宣布成立CNCF基金会
Building sustainable ecosystems for cloud native software.
IaaS Infrastructure-as-a-service 基础设施即服务
PaaS Platform as a service
SaaS Software as a service
CaaS container as a service
优势 ：
稳定性： 几个9 SLA 0.999 年宕机时间
弹性扩展
安全性
成本
易用性
IDC
单体架构
集群架构阶段（单集群，同时只有一个实例提供服务）
分布式架构阶段（负载均衡，同时提供服务）
微服务架构， 以业务天然分库
ServiceMesh： 网格化架构
RPC 远程调用/ Gateway 负载均衡-&amp;gt; 服务与IP映射 facade pattern ： 真正想做一件事，对外暴露统一访问接口：负载均衡、协议抓换、用户鉴权</description>
    </item>
    
    <item>
      <title>cross complile</title>
      <link>https://airren.github.io/blog/openwrt_cross_compile/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://airren.github.io/blog/openwrt_cross_compile/</guid>
      <description>openWRT Cross compile 1export STAGING_DIR=/home/airren/openwrt/staging_dir/toolchain-x86_64_gcc-8.4.0_musl 2 3 4export TOOLCHAIN_DIR=$STAGING_DIR 5export TOOLCHAIN_PATH=$TOOLCHAIN_DIR/bin 6export CXX=$TOOLCHAIN_PATH/g++-uc 7export AR=$TOOLCHAIN_PATH/x86_64-openwrt-linux-musl-ar 8export CXXFLAGS=&amp;#34;-O2&amp;#34; 9 10 11export CROSSCOMPILE_PATH=$TOOLCHAIN_DIR/usr 12# export CFLAGS=&amp;#34;-I$CROSSCOMPILE_PATH/jhhhhinclude&amp;#34; 13 14 15export LDCFLAGS=&amp;#34;-L$TOOLCHAIN_DIR/usr/lib -lz&amp;#34; 16export LD_LIBRARY_PATH=$TOOLCHAIN_DIR/usr/lib 17export PATH=$TOOLCHAIN_PATH:$PATH 1./autogen.sh --build=x86_64-pc-linux-gnu --host=i486-openwrt-linux 2./autogen.sh --build=x86_64-pc-linux-gnu --host=x86_64-openwrt-linux 3 4make CC=i486-openwrt-linux-gcc LD=i486-openwrt-linux-ld 5make CC=x86_64-openwrt-linux-gcc LD=x86_64-openwrt-linux-ld build openwrt in a docker
1apt update 2apt install -y git wget build-essential gawk gcc-multilib flex git gettext libncurses5-dev libssl-dev python3-distutils rsync unzip zlib1g-dev 3 4apt update 5apt install build-essential ccache ecj fastjar file g++ gawk \ 6gettext git java-propose-classpath libelf-dev libncurses5-dev \ 7libncursesw5-dev libssl-dev python python2.</description>
    </item>
    
    <item>
      <title>Device Plugin</title>
      <link>https://airren.github.io/blog/k8s_device_plugin/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://airren.github.io/blog/k8s_device_plugin/</guid>
      <description>GitHub: Intel Device plugins for Kubernetes
Device Plugins Device Plugins
Use the Kubernetes device plugin framework to implement plugins for GPUs, NICs, FPGAs, InfiniBand, and similar resources that require vendor-specific setup.
Instead of customizing the code for Kubernetes itself, vendors can implements a device plugin that you deploy either manually or as a DaemonSet. The targeted device include GPUs, high-performance NICs, FPGAs, InfiniBand adapters, and other similar computing resources that may require vendor specific initialization and setup.</description>
    </item>
    
    <item>
      <title>Dockerfile</title>
      <link>https://airren.github.io/blog/docker_dockerfile/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://airren.github.io/blog/docker_dockerfile/</guid>
      <description>Dockerfile 中的entrypoint 和CMD的区别
1CMD executable param1 param2 # 不用使用这种shell表示法，1 号进程为shell 2CMD [&amp;#34;executable&amp;#34;,&amp;#34;param1&amp;#34;,&amp;#34;param2&amp;#34;] EntryPoint 和CMD都可以在执行的时候被覆盖。
组合使用ENTRYPOINT和CMD, ENTRYPOINT指定默认的运行命令, CMD指定默认的运行参数. 例子如下:
1FROM ubuntu:trusty 2ENTRYPOINT [&amp;#34;/bin/ping&amp;#34;,&amp;#34;-c&amp;#34;,&amp;#34;3&amp;#34;] 3CMD [&amp;#34;localhost&amp;#34;] docker 会把CMD的命令拼接到Entrypoint之后</description>
    </item>
    
    <item>
      <title>Extend Disk Space without shutdown</title>
      <link>https://airren.github.io/blog/linux-ubuntu-lvm/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://airren.github.io/blog/linux-ubuntu-lvm/</guid>
      <description>We have a sever for code test, but with the test case growth, the Disk space is not enough for use.
Fortunately, we use ubuntu LVM to manage the Disk.
1fdisk /dev/sdb 1pvdisplay https://gyazo.com/40b3c078d6bb755f9cca318b3c28b2cf
1vgextend ubuntu-vg /dev/sdc1 1vgdisplay 1lvdisplay 1lvextend -l +100%FREE /dev/ubuntu-vg/ubuntu-lv 2resize2fs /dev/ubuntu-vg/ubuntu-lv Multipass extend VM disk size.
Multipass uses qemu to create the VM instance. So you can modify the qemu image manually to change the VM disk size.</description>
    </item>
    
    <item>
      <title>How to Create a go project for Cloud Native</title>
      <link>https://airren.github.io/blog/project_go/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://airren.github.io/blog/project_go/</guid>
      <description>Dockerfile Use Makefile to compiling and buid docker images </description>
    </item>
    
    <item>
      <title>Intel AMXAV</title>
      <link>https://airren.github.io/blog/intel_spx_AMX/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://airren.github.io/blog/intel_spx_AMX/</guid>
      <description>Introduce SIMD 单指令数据-&amp;gt; VNNI/INT8
Intrinsics for Intel(R) Advanced Matrix Extension Instructions Intel Advanced Matrix Extension is a new 64-bit programming paradigm consisting of two components:
A set of 2-dimensional registers(tiles) representing sub-arrays from a larger 2-dimensional memory image Am accelerator that is able to operate on tiles; the first implementation of this accelerator is called TMUL(tile matrix multiply unit) Intrinsic for Intel Advanced Matrix Extension AMX-BF16 Instructions This intrinsic supports tile computational operations on bfloat16 number.</description>
    </item>
    
    <item>
      <title>IPSec</title>
      <link>https://airren.github.io/blog/network_ipsec/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://airren.github.io/blog/network_ipsec/</guid>
      <description>IPsec is a group of networking protocols used for setting up secure encrypted connections, such VPNs, across publicly shared networks.
What is IPsec IPsec is a group of protocols that are used together to set up encrypted connections between devices. It helps keep data send over public networks secure. IPsec is often used to set up VPNs, and it works by encrypting IP packets, along with authenticating the source where the packets come from.</description>
    </item>
    
    <item>
      <title>iptables</title>
      <link>https://airren.github.io/blog/network_iptables/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://airren.github.io/blog/network_iptables/</guid>
      <description>防火墙 逻辑上，防火墙可以分为主机防火墙和网络防火墙。主机防火墙针对单个主机进行防护；网络防火墙往往处于网络入口或者边缘，针对网络入口进行防护，服务于防火墙背后的本地局域网。
物理上，防火墙可以分为硬件防火墙和软件防火墙。硬件防火墙在硬件级别实现部分防火墙功能，另一部分基于软件实现，性能高，成本高；软件防火墙应用软件处理逻辑运行于通用计算平台之上的防火墙，性能低，成本低。
iptables/netfilter iptables其实不是真正的防火墙，可以把它理解陈伟一个客户端代理，用户通过iptables这个代理，将用户的安全设定执行到对应的“安全框架”中，这个“安全框架”才是真正的防火墙， 这个框架的名字叫netfilter。
netfilter才是防火墙真正的安全框架，位于内核空间。iptables其实是一个命令行工具， 位于用户空间，我们使用iptables这个工具操作真正的框架netfilter。
netfilter/iptables组成的linux平台下的包过滤防火墙，是免费的，具有以下功能：
网络地址转换(NAT, Network Address Translate) 数据包内容修改 数据包过滤(防火墙功能) 我们虽然可以使用service iptables start启用iptables服务，但其实准确的来说iptables并没有一个守护进程，不能算是真正意义上的服务，而算是内核提供的功能。
iptables是按照规则(rules)来办事的, rules 就是我们预定义的条件。规则一般定义为“如果数据包头符合这样的条件，就这样处理这个数据包”。规则存储在内核空间的信息包过滤表中。这些规则分别指定了源地址、目的地址、传输协议(如TCP、UDP、ICMP)和服务类型(如HTTP、FTP和SMTP)等。当数据包与规则匹配时，iptables就根据规则所定义的方法来处理这些数据包， 如放行(accept)、拒绝(reject)和丢弃(drop)等。配置防火墙主要工作就是添加、修改和删除这些规则。
ewctl
hubDevice Objcet true 默认hub</description>
    </item>
    
    <item>
      <title>Istio MultiCluster</title>
      <link>https://airren.github.io/blog/4_istio_multicluster/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://airren.github.io/blog/4_istio_multicluster/</guid>
      <description>Multicluster Replicated Control Plane is an uses case to enable communication between two service in difference service mesh without using Ingress and can enable mutual TLS between the service.
Istio 1.8 Upgrade Notes
Multicluster .global Stub Domain Deprecation As part of this release, Istio has switched to a new configuration for multi-primary (formerly “replicated control planes”). The new configuration is simpler, has fewer limitations, and has been thoroughly tested in a variety of environments.</description>
    </item>
    
    <item>
      <title>K8s Groups and Versions and Kinds</title>
      <link>https://airren.github.io/blog/k8s_1_GVK/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://airren.github.io/blog/k8s_1_GVK/</guid>
      <description>Groups and Versions An API Group in Kubernetes is simply a collection of related functionality. Each group has one or more versions,
Kinds and Resources Each API group-version contains one or more API types, which we call Kinds.
A resource is simply a use of Kind in the API. Often, there&amp;rsquo;s a one-to-one maping between Kinds and resources. For intance, the pods resource crooesponds to the Pod Kind. However, sometimes, the same Kind may be returned by multiple resources.</description>
    </item>
    
    <item>
      <title>K8s network</title>
      <link>https://airren.github.io/blog/k8s_network/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://airren.github.io/blog/k8s_network/</guid>
      <description>容器网络 每一个容器都可以有一个自己独立的网络栈，这个独立的网络栈是基于Linux的Network Namespace实现的。
这个独立的网络栈包含了： Network Interface、Loopback Device、Routing Table和IPtables规则。对于一个进程来说，这些要素就构成了它发起和响应网络请求的基本环境。
容器可以使用自己独立的网络栈(创建属于自己的Network Namespace)，也可以直接使用Host的网络栈(不创建Network Namespace)。
1# Uset -net=host to share the host network 2docker run -d -net=host --name nginx-host nginx 直接使用Host的网络栈可以提供良好的网络性能，但是不可避免的会引入网络资源共享的问题，比如端口冲突。大多数应用场景下，我们希望容器能够有自己独立的IP地址和端口，即有自己独立的Namespace。
这个时候，就会出现一个问题，在这个被隔离的容器进程中如何与其他的Network Namespace里的容器进程进行交互呢。
一般我们如果希望两台主机之间的通信，直接用网线把这两台主机连接起来即可；而如果是多台主机之间通信我们可以将其连接在同一台交换机上。
在Linux系统中，能够起到虚拟交换机作用的虚拟网络设备是Bridge，是二层网络设备。主要功能是根据MAC地址来将数据包转发到网桥的不同Port上。
为了实现上述目的，docker项目会在Host上创建一个docker0的网桥，凡是连接在docker0网桥上的容器，就相当于在同一个二层网络。
接下来就是如何把容器连接到docker0网桥上，这就需要veth pair的虚拟设备了。veth pair创建出来以后总是以两张虚拟网卡veth peer的形式成对出现的。并且从其中一个peer发出的数据包可以直接出现在与之对应的另一个peer上，即使veth pair的两端不在同一个Network Namespace 中。因此，veth pair常常用作连接不同Network Namespace的网线。</description>
    </item>
    
    <item>
      <title>K8s 源码阅读 -- 环境搭建</title>
      <link>https://airren.github.io/blog/k8s_source_code_1_contribute/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://airren.github.io/blog/k8s_source_code_1_contribute/</guid>
      <description>Branch Strategy Fork K8s 源码， 并从自己的仓库中clone到本地。设置Upstream， 跟踪K8s源码的更新
Kubernetes Project 使用标准的Github &amp;ldquo;Fork and Pull&amp;rdquo; workflow。在git中，个人Fork的仓库应该设置为&amp;quot;origin&amp;quot;, 而原始项目的仓库成为&amp;quot;upstream&amp;quot;。为了保证个人分支(origin)和上游(upstream)更新保持一致，需要在你的本地仓库中完成以下设置。
Adding Upstream 增加upstream 作为一个remote，并且配置为不可以push。
1git remote add upstream https://github.com/kubernetes/kubernetes.git 2git remote set-url --push upstream no_push 设置完成后可以通过git remote -v 检查remote的配置情况。
Keeping Your Fork in sync Fetch all the changes from upstream and &amp;ldquo;rebase&amp;rdquo; them on your local master branch. 这将保证你的本地仓库与上游项目保持同步。Push the local changes to your remote master.
1git fetch upstream 2git checkout master 3git rebase upstream/master 4git push You should do this minimally before creating a new branch to work on you feature or fix.</description>
    </item>
    
    <item>
      <title>K8s 源码阅读 4</title>
      <link>https://airren.github.io/blog/k8s_source_code_4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://airren.github.io/blog/k8s_source_code_4/</guid>
      <description>Short Names and Categories Like native resources, custom resources might have long resources names. CRs can have short names as well.
Again, kubectl learns about short names via discovery information.
1apiVersion: apiextensions.k8s.io/v1beta1 2kind: CustomResourcesDefinition 3metadata: 4	name: ats.cnat.programming-kubernetes.info 5spec: 6	... 7	shortNames: 8	- at Further, CRs&amp;ndash;as any other resources&amp;ndash;can be part of categories. The most common use is the all category, as in kubectl get all. Is lists all user-facing resources in a cluster, like pods and services.</description>
    </item>
    
    <item>
      <title>K8s 源码阅读 5 Automating Code Generation</title>
      <link>https://airren.github.io/blog/k8s_source_code_5/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://airren.github.io/blog/k8s_source_code_5/</guid>
      <description>Calling the Generators Usually, the code generators are called in mostly the same way in every controller project.
Here, all means to call all four standard code generators for CRs.
deepcopy-gen
Generate func(t *T)DeepCopy() *T and func(t *T)DeepCopyInfo(*T) method.
client-gen
Creates typed client sets
informer-gen
Creates informers for CRs that offer an event-base interface to react to changes of CRs on the server.
lister-gen
Creates lister for CRs that offer a read-only caching layer for GET and LIST request.</description>
    </item>
    
    <item>
      <title>K8s 源码阅读 6 Solutions for Writing Operators</title>
      <link>https://airren.github.io/blog/k8s_source_code_6/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://airren.github.io/blog/k8s_source_code_6/</guid>
      <description>Following sample-controller Bootstraping Business Logic We are now in the position to implement the business logic of the custom controller. That is, we implement the state transitions between the three phases&amp;ndash;form PhasePending to PhaseRuning to PhaseDone&amp;ndash;in controller.go.
processNextWorkItem() processNextWorkItem() bool will read a single work item off the workquque and attempt to process it, by calling the syncHandler.
1func (c *Controller) processNextWorkItem() bool{ 2 obj, shutdowon := c.workqueue.Get() 3 4 if shutdown{ 5 return false 6 } 7 8 // We wrap this block in a func so we can defer c.</description>
    </item>
    
    <item>
      <title>K8s 源码阅读7</title>
      <link>https://airren.github.io/blog/k8s_source_code_7/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://airren.github.io/blog/k8s_source_code_7/</guid>
      <description>In this chapter we&amp;rsquo;ll discuss the operational aspects of controllers and operators, showing you how to package them, walking you through best practices for running controllers in production, and making sure that your extension points don&amp;rsquo;t break your Kubernetes cluster, security, or performance-wise.
Lifecycle Management and Packaging Let&amp;rsquo;s start with the low-hanging fruit: packaging and delivering your controllers so that a user can install it in a straightforward manner.
Packaging: The Challenge While Kubernetes defines resources with manifest, typically written in YAML, a low-level interface to declare the state of resources, these manifest files have shortcoming.</description>
    </item>
    
    <item>
      <title>Kube Config 控制多个集群</title>
      <link>https://airren.github.io/blog/5_kube_config/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://airren.github.io/blog/5_kube_config/</guid>
      <description>https://www.cnblogs.com/zhaobowen/p/13963343.html
https://zhuanlan.zhihu.com/p/169746514
https://kubernetes.io/docs/tasks/access-application-cluster/configure-access-multiple-clusters/
https://juejin.cn/post/6968129599070797837
1export KUBECONFIG git blame</description>
    </item>
    
    <item>
      <title>Kubernetes API Basic</title>
      <link>https://airren.github.io/blog/k8s_source_code_2_api_basic/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://airren.github.io/blog/k8s_source_code_2_api_basic/</guid>
      <description>Controller and Operator In this section you&amp;rsquo;ll learn about controllers and operators in Kubernetes and how they work.
The API server has the following core responsibilities:
To serve the Kubernetes API. This API is used cluster-internally by the master components, the worker nodes, and you Kubernetes-native apps, as well as externally by clients such as kubectl. To proxy cluster components, such as the Kubernetes dashboard, or stream logs, services ports, or serve kubectl exec sessions.</description>
    </item>
    
    <item>
      <title>Linux Network Command</title>
      <link>https://airren.github.io/blog/network_command/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://airren.github.io/blog/network_command/</guid>
      <description>nc Netcat(or nc) is a command-line utility that reads and write data across network connections, using the TCP or UDP protocols. It is one of the most powerful tools in the network and system administrators arsenal, and it as considered as a Swiss army knife of networking tools.
Netcat is cross-platform, and it&amp;rsquo;s available for Linux, macOS, Windows , and BSD. You can use Netcat to debug and monitor network connections, scan for open ports, transfer data, as a proxy and more.</description>
    </item>
    
    <item>
      <title>Linux socket</title>
      <link>https://airren.github.io/blog/linux_socket/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://airren.github.io/blog/linux_socket/</guid>
      <description>Internet domain socket Unix domain socket You can forward the unix domain socket with the -R option of the ssh command.
1ssh -R remote_socket:local_socket https://github.com/nikhilroxtomar/Multiple-Client-Server-Program-in-C-using-fork</description>
    </item>
    
    <item>
      <title>Mac Init</title>
      <link>https://airren.github.io/blog/Mac_init/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://airren.github.io/blog/Mac_init/</guid>
      <description>HomeBrew 1/bin/bash -c &amp;#34;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)&amp;#34; 1brew install wget 2 3brew install go Software Chrome
Typora
Istat Menus
Alfred
Dash
Wireshark
Sublime
Modify Keys settings -&amp;gt; Keyboard -&amp;gt; modifyKeys
Tools 1apt install vim git tmux golang Vim 1# ~/.vimrc 2cat &amp;lt;&amp;lt;EOF| tee -a ~/.vimrc 3set nu 4syntax on 5inoremap jj &amp;lt;ESC&amp;gt; 6 7 8set fileencodings=utf-8,ucs-bom,gb18030,gbk,gb2312,cp936 9set termencoding=utf-8 10set encoding=utf-8 11 12&amp;#34; show existing tab with 4 spaces width 13set tabstop=4 14&amp;#34; when indenting with &amp;#39;&amp;gt;&amp;#39;, use 4 spaces width 15set shiftwidth=4 16&amp;#34; On pressing tab, insert 4 spaces 17set expandtab 18 19EOF oh my zsh 1sudo apt install zsh 2sh -c &amp;#34;$(wget https://raw.</description>
    </item>
    
    <item>
      <title>Make</title>
      <link>https://airren.github.io/blog/linux_make/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://airren.github.io/blog/linux_make/</guid>
      <description>The marker - means ignore the err of this line command
@ only prints the result of command.</description>
    </item>
    
    <item>
      <title>multus</title>
      <link>https://airren.github.io/blog/k8s_network_multus/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://airren.github.io/blog/k8s_network_multus/</guid>
      <description>https://github.com/k8snetworkplumbingwg/multus-cn
Multus CNI enables attaching multiple netwrok interface to pods in Kubernets.
Multus CNI is a container nerwork interface plugin for Kubernets that enables attaching multiple network interfaces to pods. Typicaly, in Kubernetes each pod only has one network interface (apart from a loopback) &amp;ndash; with Multus you can create a multi-homed pod that has multiple interface. This is accomplished by Multus acting as a &amp;ldquo;meta-plugin&amp;rdquo;, a CNI plugin that can call multiple other CNI plugins.</description>
    </item>
    
    <item>
      <title>OAuth 2.0</title>
      <link>https://airren.github.io/blog/OAuth/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://airren.github.io/blog/OAuth/</guid>
      <description>OAuth 2.0 </description>
    </item>
    
    <item>
      <title>OpenVPN Setup</title>
      <link>https://airren.github.io/blog/network_openvpn/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://airren.github.io/blog/network_openvpn/</guid>
      <description>Configuration Server side Server.conf
1# /etc/openvpn/server/server.conf 2local 10.0.0.230 3port 1194 4proto udp 5dev tun 6ca ca.crt 7cert server.crt 8key server.key 9dh dh.pem 10auth SHA512 11tls-crypt tc.key 12topology subnet 13client-config-dir /etc/openvpn/ccd # bind ip with client name 14route 192.166.0.0 255.255.255.0 # route add to server side 15push &amp;#34;route 192.167.0.0 255.255.255.0&amp;#34; # route add to client side 16server 10.8.0.0 255.255.255.0 17push &amp;#34;redirect-gateway def1 bypass-dhcp&amp;#34; 18ifconfig-pool-persist ipp.txt 19push &amp;#34;dhcp-option DNS 10.0.0.1&amp;#34; 20keepalive 10 120 21cipher AES-256-CBC 22user nobody 23group nogroup 24persist-key 25persist-tun 26verb 4 # log level, 1-11, bigger more details 27crl-verify crl.</description>
    </item>
    
    <item>
      <title>OS memory</title>
      <link>https://airren.github.io/blog/os_memory/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://airren.github.io/blog/os_memory/</guid>
      <description>What is the maximum size of the stack?
It depends on your operating system. On Windows, the typical maximum size for a stack is 1MB, whereas it is 8MB on a typical modern Linux, although those values are adjustable in various ways. If the sum of your stack variables (including low-level overhead such as return addresses, stack-based arguments, return value placeholders, and alignment bytes) in the entire call stack exceeds that limit, you get a stack overflow, which typically takes down your program without any chance at recovery.</description>
    </item>
    
    <item>
      <title>Performance profiling</title>
      <link>https://airren.github.io/blog/linux_perf/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://airren.github.io/blog/linux_perf/</guid>
      <description>Linux Performance Counter Hardware Event CPU
Performance Monitor Unit
Instruction retired Processor clock cycles Cache
Software Event Software counter/tracepoint
Page fault process context Tracepints is the hook in the Linux kernel. 在特定代码执行的时候会被触发。
1ls /sys/kernel/debug/tracing/events ![image-20221201151615697](/Users/airren/Library/Application Support/typora-user-images/image-20221201151615697.png)
If the machine not a baremetal, it can&amp;rsquo;t collect hardware event. For example in a esxi VM.
Request
LLC-load-misses Instructions Cycles The ODMS containes now:
Dashboard consists of 12 panels based on following metrics:</description>
    </item>
    
    <item>
      <title>PKCS11</title>
      <link>https://airren.github.io/blog/crypto_pkcs11/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://airren.github.io/blog/crypto_pkcs11/</guid>
      <description>PKCS#11 Terminology Cryptoki Cryptoki(Cryptographic Token Interfaces) is a library(dll or so file) that is provided by the cryptographic device vendors. It contains an implementation of the PLCS#11 C header files. Every cryptographic device vendor provides its own PKCS#11 complaint library. Applications has to load this library in order to access the cryptographic device.
Slots Slots are the logical partitions in the cryptographic device. In case of HSMs, there could be hundreds or more slots are available while in the case of smart cards, there could be only on slot available.</description>
    </item>
    
    <item>
      <title>Redis</title>
      <link>https://airren.github.io/blog/redis_preview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://airren.github.io/blog/redis_preview/</guid>
      <description>bitmap
背景知识 文件：
​ 数据可以存在文件里，通过grep awk 查找文件。
​ 如果文件变大，10M -&amp;gt; 1T , 查找会变慢。全量扫描IO。
数据库：（受限于IO）
​ mysql 存储， 存储分块，可以通过索引直接获取datapage中的数据。
索引也是数据块
二级索引，给索引建立索引
表很大，如果连接比较少，读 如果命中索引，查询还是毫秒级别
如果并发很大（足够大），如果每个查询的数据都是独立的，会收到吞吐的限制。
Redis+数据库：（内存与磁盘的折中方案）
nosql -&amp;gt; key vale
短域名-&amp;gt; 长域名，计数
关联表的数据也放置在value中。只关注每条记录自身。
基于内存的
worker 单线程
6.x IO threads
value 是有类型的 string、list、set、hash、zset；且每种类型有自己的本地方法。
数据向计算移动
计算向数据移动
连接池：
socket list 线程池：
可以使用一个线程去处理连接池中的连接（nio，多路复用，epoll） 内存数据库：（受限于成本）
Hana https://bytedance.feishu.cn/docs/doccnwV2ZxHYiLagaPOQSZ3ldlr
常识：s&amp;lt;- ms &amp;lt;-us &amp;lt;-ns
硬盘：
带宽、吞吐：百兆，1-2G pci-e/ nvme 3G/s
寻址时间 ms
内存:
寻址时间 ns redis 安装 http://db-engines.com
http://redis.io
编译安装</description>
    </item>
    
    <item>
      <title>strongswan</title>
      <link>https://airren.github.io/blog/2_strongswan/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://airren.github.io/blog/2_strongswan/</guid>
      <description>When reading/adjusting any StrongSwan configurations, remember these important words:
left is local to the machine it&amp;rsquo;s stated on; right is remote in the same manner
So, on the server side, left is local to the server and on the client side, left is local to that client.
check the X509 cert details
1openssl x509 -text -noout -in /etc/ipsec.d/private/sunKey.pem ​
Ubuntu Set up IPsec Tunnel 1docker run --rm -d -i --network host --name cnf --user root -v /home/ubuntu/entrypoint.</description>
    </item>
    
    <item>
      <title>StrongWAN configure with CNF.</title>
      <link>https://airren.github.io/blog/2_strongwan_NAT_travalse/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://airren.github.io/blog/2_strongwan_NAT_travalse/</guid>
      <description>Download the material
1wget -r -N -nd http://sdewan.sh.intel.com:8888/ipsec-demo/ modify the node selector in cnf-1.yaml and cnf-2.yaml respectively. Create 2 pod on different node with host network.
1 nodeSelector: 2 # change to the specific node 3 kubernetes.io/hostname: node Copy cert to the CNF Pod.
Find the container id for cnf-1 and cnf-2.
1# For cnf-1, copy sunCert to it 2docker cp ./cert/caCert.pem $(kubectl describe po cnf-1|grep docker:|awk -F / &amp;#39;{print $3}&amp;#39;):/etc/ipsec.</description>
    </item>
    
    <item>
      <title>Unix Init</title>
      <link>https://airren.github.io/blog/Linux_init/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://airren.github.io/blog/Linux_init/</guid>
      <description>Tools 1apt install vim git tmux golang Vim 1# ~/.vimrc 2cat &amp;lt;&amp;lt;EOF | tee -a ~/.vimrc 3set nu 4syntax on 5inoremap jj &amp;lt;ESC&amp;gt; 6 7 8set fileencodings=utf-8,ucs-bom,gb18030,gbk,gb2312,cp936 9set termencoding=utf-8 10set encoding=utf-8 11 12&amp;#34; show existing tab with 4 spaces width 13set tabstop=4 14&amp;#34; when indenting with &amp;#39;&amp;gt;&amp;#39;, use 4 spaces width 15set shiftwidth=4 16&amp;#34; On pressing tab, insert 4 spaces 17set expandtab 18 19EOF oh my zsh 1sudo apt install -y zsh 2sh -c &amp;#34;$(wget https://raw.</description>
    </item>
    
    <item>
      <title>User Kuberbuilder to create a CRD operator</title>
      <link>https://airren.github.io/blog/k8s_operator/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://airren.github.io/blog/k8s_operator/</guid>
      <description>Develop Environment Kind kind is a tool for running local Kubernetes clusters using Docker container &amp;ldquo;nodes&amp;rdquo;. kind was primarily designed for testing Kubernetes itself but may be used for local development or CI.
1kind load docker-image --name &amp;lt;kind-cluster-name&amp;gt; --nodes &amp;lt;node-name&amp;gt; &amp;lt;image-name&amp;gt;:latest Certmangaer 1helm repo add jetstack https://charts.jetstack.io 2helm repo update 3helm install \ 4 cert-manager jetstack/cert-manager \ 5 --namespace cert-manager \ 6 --create-namespace \ 7 --version v1.10.1 \ 8 --set installCRDs=true Question</description>
    </item>
    
    <item>
      <title>VPC</title>
      <link>https://airren.github.io/blog/network_VPC/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://airren.github.io/blog/network_VPC/</guid>
      <description></description>
    </item>
    
    <item>
      <title>What is VLAN and Virtual Network Interface</title>
      <link>https://airren.github.io/blog/network_VLAN/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://airren.github.io/blog/network_VLAN/</guid>
      <description>In our day-to-day life, we have seen LAN and WAN architectures mostly because we have to deal with only one IP address on one interface. We either connect our system with LAN cable or with WiFi.
In this article, we will discuss the VLAN and how to create the VLAN on the Ubuntu server, but let first understand what is VLAN and why we use VLAN.
What is VLAN Virtual Local Area Network(VLAN) is a logical concept of breaking large broadcast domains into small domains.</description>
    </item>
    
    <item>
      <title>What is VXLAN</title>
      <link>https://airren.github.io/blog/network_VXLAN/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://airren.github.io/blog/network_VXLAN/</guid>
      <description></description>
    </item>
    
    <item>
      <title>怎么成为K8s的Contributor</title>
      <link>https://airren.github.io/blog/k8s_contributer/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://airren.github.io/blog/k8s_contributer/</guid>
      <description>Important Doc
Contributor Cheat Sheet 加入SIG SIG(Special Interest Groups) 是Kubernetes社区中关注特定模块的永久组织。
作为刚参与社区的开发者，可以从sig/app, sig/node, sig/scheduling 这几个SIG开始。
KEP KEP(Kubernetes Enhancement Proposal)。对于功能和API的修改都需要先在kubernetes/enhancements仓库对应SIG的目录下提交Proposal才能实施。所有的Proposal都必须经过讨论，通过社区SIG Leader的批准。
很多不熟悉Kubernetes工作流的开发者会在社区中直接提交一个包含API改动的commit，但是如果这类commit没有对应的KEP 是不会被社区合入的。
项目设计 所有进入开发状态的功能都会有一个非常详细的KEP。KEP有一个详细的模板，设计是非常规范的。我们再日常的开发中也可以使用类似的格式写设计文档或者技术文档。
最近几年新实现的功能都会有着比较详细的KEP文档
分布式协作 Kubernetes 中所有的社区会议都会使用Zoom录制，并上传到Youtube。大多数的讨论和交流也对会再对应的issue和PR中。
每个提交的PR都要通过2K以上的成员的review以及几千个单元测试、集成测试、端到端测试以及扩展性测试，这些测定共同保证了项目的稳定性。
kubernetes/test-infra 项目中包含了Kubernetes的测试基础配置。 很多端到端的测试都会启动Kubernetes集群，并在真实的环境中测试代码的逻辑，这些测试可能一次会执行几十分钟，并且有一定概率出现Flaky。
影响力 提高个人和公司在开源社区的影响力，也是参与社区的重要目的。
对个人来说，参与开源项目可以快速理解项目的实现原理以及工作流程。如果想要在未来从事相关的工作，参与开源项目一定是加分项。
对公司来说，参与开源项目可以提高公司在开源社区的话语权，提高公司的技术影响力。足够的话语权也会让开源社区在关键需求上有较快的支持，减少与社区代码的分叉，降低维护成本，并满足公司内部的需求。
操作指南 参与开源项目并不一定要从非常复杂的功能或者Proposal开始。任何一个对代码库有利的PR都是值得提交的。修复代码中的typo 或者静态检查错误，作为最开始的工作是没有任何问题的。这能够帮我们快速热身。不过在熟悉了kubernetes的提交流程之后就没有必要做类似的提交了，以为所有的提交都需要Reviewer和Approver的批准，我们应该尽可能的做有意义的变动，减少他们的工作量。
从阅读源码开始 我们可以从自己熟悉的模块入手，了解该模块的实现原理，在阅读代码的过程中，我们很容易发现源代码中的一些typo和缺陷，这个时候就可以提交PR修复这些问题。
从静态检查开始 .golint_failures 文件中忽略了几百个Package中的静态检查，你可以在其中选择合适的Package作为成为Kubernetes贡献者的而第一步。
从项目管理开始 也可以选择Kubernetes的项目管理， sig/release.
选取第一个kubernetes问题 issue 列表
使用tag过滤问题 “good first issue” “help wanted” 这些标签表明了对新手非常友好。有时候问题也会被打上错误标签，也许是技术难度被低估了。
TODO 搜索代码库里的TODO。
Go 语言的开发规范、分布式社区的治理方式
代码需要每天都看，留出专门的时间来查看Kubernetes的源码，对它的核心组件的实现看看，构建一下, 测试一下，修一下Bug，typo等。
一般半年之后，你就可以熟悉基础项目，并且开始贡献代码。
当你已经和团队协作的很熟悉，就会自然承接一些子任务，然后团队就会赋予你写的权限，这样就可以顺理成章的成为Kubernetes的committer。这个时候你就是这个子项目的maintainer了
TODO 加入 Kubenetes Slack Channle 加入邮件列表 加入SIG 参加社区会议 提issue 如何提交PR</description>
    </item>
    
    <item>
      <title>自控力</title>
      <link>https://airren.github.io/blog/Book_WillPower/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://airren.github.io/blog/Book_WillPower/</guid>
      <description>自控力
The WillPower Instinct
“意志力学科”这门课汇集了心理学、经济学、神经学、医学领域关于自控的最新洞见，告诉人们如何改变旧习惯，培养健康的新习惯、克服拖延、抓住重点、管理压力。阐述了为何人们会在诱惑前屈服，以及怎样才能抵挡住诱惑。此外，它还提出了理解自控局限的重要性，以及培养意志力的最佳决策。
对于意志力科学的理解有助于培养自控力，让人们更有精力追逐最重要的东西。自控的策略有助于人们抵制各种各样的诱惑。
为了成功做到自控，你必须知道自己为何失败 提高自控力的最有效途径在于，弄清自己如何失控、为何失控。意识到自己有多容易失控，并非意味着你是一个失败者。恰恰相反，这将有助于你避开意志力失效的陷阱。研究表明，自诩为意志坚定的人反而最容易在诱惑面前失控。因为他们无法预测自己在何时何地、会由于何种原因失控。他们在面对挫折时更容易吃惊，在陷入困境时更容易放弃。
自知之明是自控的基础。认识到自己意志力存在问题，则是自控的关键。
当我们屈从于诱惑或者拖着不该做的事时，是什么拖了我们的后腿？是哪些致命的错误？更重要的是，我们如何寻找机会，避免来犯同样的错误。我们怎样从失败中汲取经验，为成功铺平道路？
这些行为虽不完美，却是人之常态。每个人都在以某种方式抵制诱惑、癖好、干扰和拖延。这不是个体的弱点或个人的不足，而是普遍的经验，是人所共有的状态。
理论固然好，但是数据更重要。
沉迷于电视剧不能自拔
总是幻想或者希望自己和主角处于同样的状态，同样可以随心所欲的处理各种困境。更不想进一步打破自己的幻想，不想回归现实。可事实却是，越沉浸于其中，却又距离故事中的主角远了一步。这个世界上有太多看不完的故事，不是每个故事都需要去读，选择重要的，选择真正有意义，有营养的文化饕餮。</description>
    </item>
    
    <item>
      <title>高并发负载均衡</title>
      <link>https://airren.github.io/blog/high_concurrency_lb/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://airren.github.io/blog/high_concurrency_lb/</guid>
      <description>高并发，负载均衡，高可用
不要因为技术而技术, 软件工程学需要分层解耦
应用层 1# $$ current process pid 2cd /proc/$$/fd 0 stdin
1 stdout
2 stderr
1# 8 is the name of the file descriptor, &amp;lt;&amp;gt; in and out direction 2exec 8&amp;lt;&amp;gt; /dev/tcp/www.baidu.com/80 3# exec 8&amp;lt;&amp;amp; - 4# &amp;amp; represent the argument is a fd 5echo -e &amp;#34;GET / HTTP/1.0\n&amp;#34; &amp;gt;&amp;amp; 8 传输层 </description>
    </item>
    
  </channel>
</rss>
