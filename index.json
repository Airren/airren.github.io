[{"categories":null,"contents":" 不要吝啬你的批评与感悟，敬请留言，我们一起进步。\n如果你有过以下问题，欢迎阅读文章，提出意见与建议\ngo mod 怎么使用？ GOPATH是什么？ GO111MODULE=\u0026quot;\u0026quot; 这个参数决定了什么？ go get、go download 有什么区别？ import到底import的什么东西？ 依赖管理工具 用过Java 的同学都知道，对依赖的管理经历了从原始的手动引入jar包，到使用maven等自动化管理工具去引入第三方依赖的过程，从而可以使用别人已经开发好的优秀工具。如果使用过Python的同学可能会熟练的使用pip install 第三方的工具包。Java 和Python的第三方工具包都是集中式管理的，使用maven 或者是pip 都是从对应的管理中心下载更新依赖。当然还有 npm、yarn、gradle等其他语言的依赖版本工具。\n在go语言中，第三方依赖的管理工具经过了一个漫长的发展过程。在GO1.11 发布之前govendor、dep等工具百花齐放。直到go mod 出现，开始一统天下。go 的依赖非常简单粗暴，只要依赖源码就可以了。例如：\n1import \u0026#34;github.com/jinzhu/gorm\u0026#34; github.com/jinzhu/gorm 就是gorm的GitHub项目路径。\nGOPATH时期 Go 在1.11 之前使用GOPATH模式进行依赖的管理。安装部署go环境，使用go 进行开发的时候强制被要求要设置GOPATH（当然安装过程中也会默认指定$GOPATH=~/go）。 要在GOPATH路径下新建 /src /bin /pkg文件夹。\n1➜ ~/go 2├── bin # 存储go编译生成的二进制可执行文件，一般会把该路径配置到PATH中,PATH=$PATH:$GOPATH/bin 3├── pkg # 存储预编译的目标文件，以加快后续的编译速度 4└── src # 存储Go的源代码，一般以$GOPATH/src/github.com/foo/bar的路径存放 1➜ ~ go env |grep GOPATH 2GOPATH=\u0026#34;/Users/bytedance/go\u0026#34; 在这种模式下，如果使用go get 拉取外部依赖会自动下载并安装到$GOPATH/src 目录下。\n这种模式下，go get没有版本管理的概念，无法处理依赖不同版本的问题，因为同一个依赖都存在同一个路径下面。\n在Go官方还没有推出Go Modules 的时候，go的依赖管理工具可谓是百花齐放，例如 govendor， dep，但是最终Go Modules发布，平息了诸侯割据的局面。\nGO Modules Go1.11 开始推出Go Modules ,Go1.13开始不再推荐使用GOPATH。意思就是说你可以在任何路径下存放你的Go源码文件, 不用再像以前一样非得放到$GOPATH/src中。 每一个go项目 都是一个 Modules。vgo 是Go Modules的前身。\n在Go Modules环境下出现了一个很重要的环境变量GO111MODULE\n1➜ ~ go env 2GO111MODULE=\u0026#34;auto\u0026#34; # 当为 aotu 模式时候如果当前目录中有go.mod则为GO Module模式 3GOPROXY=\u0026#34;https://proxy.golang.org,direct\u0026#34; 4GONOPROXY=\u0026#34;\u0026#34; 5GOSUMDB=\u0026#34;sum.golang.org\u0026#34; 6GONOSUMDB=\u0026#34;\u0026#34; 7GOPRIVATE=\u0026#34;\u0026#34; 如果要对go 的环境变量进行设置，可以使用\n1go env -w GO111MODULE=on # 设置go 环境变量 2go env -u # 恢复初始设置 GO111MODULE GO111MODULE 这个环境变量是用来作为使用Go Modules 的开关。可以说这个变量是历史产物，很有肯能会在将来Go的新版本中去除掉。\n1GO111MODULE=\u0026#34;auto\u0026#34; # 只要项目包含了go.mod 文件的话就启用Go modules， 在Go1.11-1.14 中是默认值 2GO111MODULE=\u0026#34;on\u0026#34; # 启用Go Modules 3GO111MODULE=\u0026#34;off\u0026#34; # 禁用Go Modules， 对老的项目进行兼容 GOPROXY GOPROXY 是Go Modules的代理，可以通过镜像站点快速拉取（很多公司都会设置自己的镜像站点），可以设置多个代理。\n1GOPROXY=\u0026#34;https://proxy.golang.org,direct\u0026#34; direct的意思是如果通过代理获取不到go get 就会通过源地址直接去抓取\ngo mod 创建Go Modules的基本命令\n1➜ ~ go mod 2Go mod provides access to operations on modules. 3 4Note that support for modules is built into all the go commands, 5not just \u0026#39;go mod\u0026#39;. For example, day-to-day adding, removing, upgrading, 6and downgrading of dependencies should be done using \u0026#39;go get\u0026#39;. 7See \u0026#39;go help modules\u0026#39; for an overview of module functionality. 8# 所有的go commands 都支持 modules。 9Usage: 10 11 go mod \u0026lt;command\u0026gt; [arguments] 12 13The commands are: 14 15 download download modules to local cache 16 edit edit go.mod from tools or scripts 17 graph print module requirement graph 18 init initialize new module in current directory 19 tidy add missing and remove unused modules 20 vendor make vendored copy of dependencies 21 verify verify dependencies have expected content 22 why explain why packages or modules are needed 23 24Use \u0026#34;go help mod \u0026lt;command\u0026gt;\u0026#34; for more information about a command. go mod init\n在当前目录初始化一个新的module， 就是说将该目录下的工程文件初始化为一个Go Module.\n如果当前目录在GOPATH中，这条命令无需传入参数，参数默认为 GOPATH/src 到该目录的相对路径。\n1➜ demo pwd 2/Users/bytedance/go/src/github.com/airren/demo # 当前路径 3➜ demo go mod init 4go: creating new go.mod: module github.com/airren/demo 5➜ demo ls 6go.mod 7➜ demo cat go.mod 8module github.com/airren/demo 9 10go 1.14 11➜ demo 如果当前目录不在GOPATH中，要手动指定module的名字\n1➜ gotest pwd 2/Users/bytedance/Desktop/gotest 3➜ gotest go mod init # 如果不在GOPATH路径下 4go: cannot determine module path for source directory /Users/bytedance/Desktop/gotest (outside GOPATH, module path must be specified) 5 6Example usage: 7 \u0026#39;go mod init example.com/m\u0026#39; to initialize a v0 or v1 module 8 \u0026#39;go mod init example.com/m/v2\u0026#39; to initialize a v2 module 9 10Run \u0026#39;go help mod init\u0026#39; for more information. 11➜ gotest go mod init github.com/airren/gotest 12go: creating new go.mod: module github.com/airren/gotest 13➜ gotest cat go.mod 14module github.com/airren/gotest 15 16go 1.14 go mod download\ngo mod download 命令会把package下载到 GOPATH/pkg/mod路径下，下载时要指定版本可以用@latest。可以任意路径下使用go mod download\n1➜ jinzhu pwd 2/Users/bytedance/go/pkg/mod/github.com/jinzhu 3➜ jinzhu ls 4gorm@v1.9.11-0.20190912141731-0c98e7d712e2 inflection@v1.0.0 5gorm@v1.9.12 now@v1.0.1 6inflection@v0.0.0-20180308033659-04140366298a now@v1.1.1 7➜ jinzhu go mod download -x github.com/jinzhu/gorm@v1.9.8 # 要指定版本 8➜ jinzhu ls 9gorm@v1.9.11-0.20190912141731-0c98e7d712e2 inflection@v1.0.0 10gorm@v1.9.12 now@v1.0.1 11gorm@v1.9.8 now@v1.1.1 12inflection@v0.0.0-20180308033659-04140366298a 13➜ jinzhu cd gorm@v1.9.8 vendor\ngo mod vendor会在项目中创建一个vendor文件夹。在编译时，可以使用 -mod=vendor ，使用代码主目录文件夹下vendor目录满足依赖获取，go build -mod=vendor。此时，go build 忽略go.mod 中的依赖，（这里仅使用代码root目录下的vendor其他地方的将忽略）\n1GOFLAGS=-mod=vendor` 设置顶级vendor作为依赖 `go env -w GOFLAGS=\u0026#34;-mod=vendor\u0026#34;` 进行设置。 取消 `go env -w GOFLAGS=\u0026#34;-mod=\u0026#34; import import 导入的是文件存储的相对路径（不能使用绝对路径）或者是Modules Name，并不是package的name，但是在调用Function的时候使用的是package的name。\nimport 首先会从$GOROOT中寻找，然后从$GOPATH/src 中寻找，如果是以./ 或者 ../ 开头的import 直接去对应的相对路径寻找。\nimport 时候是不区分大小写的，所以在go项目中folder的name尽量是小写，可以有下划线_, 但是packagename一定不能有 _，否则golint会有提示。\n举个例子🌰文件结构如图所示\n1gotest 2├── format_print 3│ └── colorprintpath.go # 文件名并不影响 import 4└── sdemo 5 ├── demo.go colorprintpath.go\n1package colorprintfile // 调用方法时候通过package name 调用 2import \u0026#34;fmt\u0026#34; 3// NewPirnt is the new format print 公开方法要有注释 4func NewPrint(content string) { 5\tfmt.Printf(\u0026#34;This is the content: %v \\n\u0026#34;, content) 6} demo.go 调用上述方法\n1package main 2import \u0026#34;../format_print\u0026#34; // import 使用的是相对路径 3func main(){ 4\tcolorprintfile.NewPrint(\u0026#34;hello\u0026#34;)\t// 调用package中的公开方法 5} 如果使用了go mod， 在项目文件下有了go.mod, 文件中会有\n1module github.com/airren/gotest 此时就不能使用相对路径引用package, 要通过modules的方式引用\n1package main 2import \u0026#34;github.com/airren/gotest/format_print\u0026#34; 3func main(){ 4\tcolorprintfile.NewPrint(\u0026#34;hello\u0026#34;)\t// 调用package中的公开方法 5} go get 可以在任意路径下执行go get\n用于从远程代码仓库(github, gitlab,gogs)上下载并安装代码包\n支持的代码版本控制系统有: Git , Mercurial(hg)，SVN, Bazaar\n指定的代码包会被下载到$GOPATH中包含的第一个工作区的src目录中，然后再安装\n常用参数\n1-d # 只执行下载动作，而不执行安装动作 2-fix # 在下载代码包后先执行修正动作，而后再进行编译和安装 3-u # 利用网络来更新已有的代码包及其依赖包 4-x # 显示过程 例如使用go get 获取 gorm。 通过-x 参数可以展示详细的过程。\n1➜ ~ go get -u -x github.com/jinzhu/gorm 2cd . 3git clone -- https://github.com/jinzhu/gorm /Users/bytedance/go/src/github.com/jinzhu/gorm 4cd /Users/bytedance/go/src/github.com/jinzhu/gorm 5git submodule update --init --recursive 6cd /Users/bytedance/go/src/github.com/jinzhu/gorm 7git show-ref 8cd /Users/bytedance/go/src/github.com/jinzhu/gorm 9git submodule update --init --recursive 10cd /Users/bytedance/go/src/github.com/jinzhu/inflection 11git config remote.origin.url 12cd /Users/bytedance/go/src/github.com/jinzhu/inflection 13git pull --ff-only 14cd /Users/bytedance/go/src/github.com/jinzhu/inflection 15git submodule update --init --recursive 16cd /Users/bytedance/go/src/github.com/jinzhu/inflection 17git show-ref 18cd /Users/bytedance/go/src/github.com/jinzhu/inflection 19git submodule update --init --recursive 20WORK=/var/folders/pz/w7jm4wm933lcspm82kff26600000gn/T/go-build644292157 如果在具有go.mod 的项目的文件夹下使用go get , 会将对应的依赖以及版本写入go.mod, go.sum 是自动生成的，具体介绍可以查看https://studygolang.com/articles/25658\n1➜ gotest cat go.mod 2module github.com/airren/gotest 3 4go 1.14 5➜ gotest cat go.sum 6cat: go.sum: No such file or directory 7➜ gotest go get -u github.com/jinzhu/gorm/ # 拉取gorm 8go: github.com/jinzhu/gorm upgrade =\u0026gt; v1.9.12 9➜ gotest cat go.mod 10module github.com/airren/gotest 11 12go 1.14 13 14require github.com/jinzhu/gorm v1.9.12 // indirect # 新增依赖， 未被使用或者间接使用会有 indirect 15➜ gotest cat go.sum 16github.com/denisenkom/go-mssqldb v0.0.0-20191124224453-732737034ffd/go.mod h1:xbL0rPBG9cCiLr28tMa8zpbdarY27NDyej4t/EjAShU= 17github.com/erikstmartin/go-testdb v0.0.0-20160219214506-8d10e4a1bae5/go.mod h1:a2zkGnVExMxdzMo3M0Hi/3sEU+cWnZpSni0O6/Yb/P0= 18github.com/go-sql-driver/mysql v1.4.1/go.mod h1:zAC/RDZ24gD3HViQzih4MyKcchzm+sOG5ZlKdlhCg5w= 19github.com/golang-sql/civil v0.0.0-20190719163853-cb61b32ac6fe/go.mod h1:8vg3r2VgvsThLBIFL93Qb5yWzgyZWhEmBwUJWevAkK0= 20github.com/golang/protobuf v1.2.0/go.mod h1:6lQm79b+lXiMfvg/cZm0SGofjICqVBUtrP5yJMmIC1U= 21github.com/jinzhu/gorm v1.9.12 h1:Drgk1clyWT9t9ERbzHza6Mj/8FY/CqMyVzOiHviMo6Q= 22github.com/jinzhu/gorm v1.9.12/go.mod h1:vhTjlKSJUTWNtcbQtrMBFCxy7eXTzeCAzfL5fBZT/Qs= 23github.com/jinzhu/inflection v1.0.0 h1:K317FqzuhWc8YvSVlFMCCUb36O/S9MCKRDI7QkRKD/E= 24github.com/jinzhu/inflection v1.0.0/go.mod h1:h+uFLlag+Qp1Va5pdKtLDYj+kHp5pxUVkryuEj+Srlc= 25github.com/jinzhu/now v1.0.1/go.mod h1:d3SSVoowX0Lcu0IBviAWJpolVfI5UJVZZ7cO71lE/z8= 26github.com/lib/pq v1.1.1/go.mod h1:5WUZQaWbwv1U+lTReE5YruASi9Al49XbQIvNi/34Woo= 27github.com/mattn/go-sqlite3 v2.0.1+incompatible/go.mod h1:FPy6KqzDD04eiIsT53CuJW3U88zkxoIYsOqkbpncsNc= 28golang.org/x/crypto v0.0.0-20190308221718-c2843e01d9a2/go.mod h1:djNgcEr1/C05ACkg1iLfiJU5Ep61QUkGW8qpdssI0+w= 29golang.org/x/crypto v0.0.0-20190325154230-a5d413f7728c/go.mod h1:djNgcEr1/C05ACkg1iLfiJU5Ep61QUkGW8qpdssI0+w= 30golang.org/x/crypto v0.0.0-20191205180655-e7c4368fe9dd/go.mod h1:LzIPMQfyMNhhGPhUkYOs5KpL4U8rLKemX1yGLhDgUto= 31golang.org/x/net v0.0.0-20180724234803-3673e40ba225/go.mod h1:mL1N/T3taQHkDXs73rZJwtUhF3w3ftmwwsq0BUmARs4= 32golang.org/x/net v0.0.0-20190404232315-eb5bcb51f2a3/go.mod h1:t9HGtf8HONx5eT2rtn7q6eTqICYqUVnKs3thJo3Qplg= 33golang.org/x/sys v0.0.0-20190215142949-d0b11bdaac8a/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY= 34golang.org/x/sys v0.0.0-20190412213103-97732733099d/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs= 35golang.org/x/text v0.3.0/go.mod h1:NqM8EUOU14njkJ3fqMW+pc6Ldnwhi/IjpwHt7yyuwOQ= 36google.golang.org/appengine v1.4.0/go.mod h1:xpcJRLb0r/rnEns0DIKYYv+WjYCduHsrkT7/EB5XEv4= 不要吝啬你的批评与感悟，敬请留言，我们一起进步。\n参考资料 https://github.com/golang/go/wiki/Modules\nhttps://blog.golang.org/using-go-modules\nhttps://juejin.im/post/5e57537cf265da57584da62b\nhttps://learnku.com/go/t/39086\nhttps://studygolang.com/articles/25658\n","date":"August 4, 2020","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/note_go/1_go_modules/","summary":"不要吝啬你的批评与感悟，敬请留言，我们一起进步。\n如果你有过以下问题，欢迎阅读文章，提出意见与建议\ngo mod 怎么使用？ GOPATH是什么？ GO111MODULE=\u0026quot;\u0026quot; 这个参数决定了什么？ go get、go download 有什么区别？ import到底import的什么东西？ 依赖管理工具 用过Java 的同学都知道，对依赖的管理经历了从原始的手动引入jar包，到使用maven等自动化管理工具去引入第三方依赖的过程，从而可以使用别人已经开发好的优秀工具。如果使用过Python的同学可能会熟练的使用pip install 第三方的工具包。Java 和Python的第三方工具包都是集中式管理的，使用maven 或者是pip 都是从对应的管理中心下载更新依赖。当然还有 npm、yarn、gradle等其他语言的依赖版本工具。\n在go语言中，第三方依赖的管理工具经过了一个漫长的发展过程。在GO1.11 发布之前govendor、dep等工具百花齐放。直到go mod 出现，开始一统天下。go 的依赖非常简单粗暴，只要依赖源码就可以了。例如：\n1import \u0026#34;github.com/jinzhu/gorm\u0026#34; github.com/jinzhu/gorm 就是gorm的GitHub项目路径。\nGOPATH时期 Go 在1.11 之前使用GOPATH模式进行依赖的管理。安装部署go环境，使用go 进行开发的时候强制被要求要设置GOPATH（当然安装过程中也会默认指定$GOPATH=~/go）。 要在GOPATH路径下新建 /src /bin /pkg文件夹。\n1➜ ~/go 2├── bin # 存储go编译生成的二进制可执行文件，一般会把该路径配置到PATH中,PATH=$PATH:$GOPATH/bin 3├── pkg # 存储预编译的目标文件，以加快后续的编译速度 4└── src # 存储Go的源代码，一般以$GOPATH/src/github.com/foo/bar的路径存放 1➜ ~ go env |grep GOPATH 2GOPATH=\u0026#34;/Users/bytedance/go\u0026#34; 在这种模式下，如果使用go get 拉取外部依赖会自动下载并安装到$GOPATH/src 目录下。\n这种模式下，go get没有版本管理的概念，无法处理依赖不同版本的问题，因为同一个依赖都存在同一个路径下面。\n在Go官方还没有推出Go Modules 的时候，go的依赖管理工具可谓是百花齐放，例如 govendor， dep，但是最终Go Modules发布，平息了诸侯割据的局面。","tags":null,"title":"「Go」依赖管理 Go Modues/ GOPATH"},{"categories":null,"contents":" 如何用go实现一个简单的并行任务\nGolang并发 1package main 2 3import ( 4\t\u0026#34;fmt\u0026#34; 5\t\u0026#34;sync\u0026#34; 6) 7 8var wg sync.WaitGroup 9 10func printer(ch chan int) { 11\tfor i := range ch { 12\tfmt.Printf(\u0026#34;Received %d \u0026#34;, i) 13\t} 14\twg.Done() // 15} 16 17// main is the entry point for the program. 18func main() { 19\tc := make(chan int) 20\tgo printer(c) 21\twg.Add(1) 22 23\t// Send 10 integers on the channel. 24\tfor i := 1; i \u0026lt;= 10; i++ { 25\tc \u0026lt;- i 26\t} 27 28\tclose(c) 29\twg.Wait() 30} 正常情况下goroutine的结束过程是不可控制的。\n存在这么一种情况，主程序已经结束了，但是主程序中新激活的goroutine并没有运行完。主程序一旦结束，主程序中的goroutine也就结束了。\n1import ( 2\t\u0026#34;fmt\u0026#34; 3\t\u0026#34;time\u0026#34; 4) 5 6func main() { 7 8\tgo func() { 9\tfor index := 0; index \u0026lt; 10; index++ { 10\tfmt.Print(index, \u0026#34; \u0026#34;) 11\ttime.Sleep(time.Second * 1) 12\t} 13\t}() 14 15\tfmt.Println(\u0026#34;end\u0026#34;) 16} 17// 运行结果为 18// end 匿名函数中的代码并没有运行,使用sync.WaitGroup修改代码如下\n1package main 2 3import ( 4\t\u0026#34;fmt\u0026#34; 5\t\u0026#34;sync\u0026#34; 6\t\u0026#34;time\u0026#34; 7) 8 9var wg sync.WaitGroup 10 11func main() { 12\twg.Add(1) // 表示等待一个 goroutine运行结束 13\tgo func() { 14\tfor index := 0; index \u0026lt; 10; index++ { 15\tfmt.Print(index, \u0026#34; \u0026#34;) 16\ttime.Sleep(time.Second*1) 17\t} 18\twg.Done() 19\t}() 20 21\twg.Wait() 22\tfmt.Println(\u0026#34;end\u0026#34;) 23} 24// 运行结果为 25// 0 1 2 3 4 5 6 7 8 9 end 当wg.Add(1)，且有两个执行速度不一样的线程时候\n1func main() { 2\twg.Add(1) 3\tgo func() { 4\tfor index := 0; index \u0026lt; 10; index++ { 5\tfmt.Print(index, \u0026#34; \u0026#34;) 6\ttime.Sleep(time.Second*1) 7\t} 8\twg.Done() 9\t}() 10 11\tgo func() { 12\tfor index := 0; index \u0026lt; 10; index++ { 13\tfmt.Print(index, \u0026#34;+ \u0026#34;) 14\ttime.Sleep(time.Second*10) 15\t} 16\twg.Done() 17\t}() 18 19\twg.Wait() 20\tfmt.Println(\u0026#34;end\u0026#34;) 21} 22// 运行结果为 23// 0+ 0 1 2 3 4 5 6 7 8 9 1+ end sycc.WaitGroup 有三个方法\nAdd()用来设置或者添加需要等待完成的goroutine的数量， Add(2) 或者两次调用Add(1)表示要等待两个goroutine完成\nDone()在goroutine真正完成之前调用本方法来表示goroutine已经完成了，会对等待计数器的值减一。 Done()的数目一定要与Add()的数量一致,否则会造成永久阻塞而出现死锁。fatal error: all goroutines are asleep - deadlock!\nWait() 在等待计数器减为0之前，Wait() 会一直阻塞当前的goroutine。\n简单的协程池 开辟固定数量的协程池处理任务，通过chan 传递Task。\n1package main 2 3import ( 4\t\u0026#34;fmt\u0026#34; 5\t\u0026#34;sync\u0026#34; 6\t\u0026#34;sync/atomic\u0026#34; 7\t\u0026#34;time\u0026#34; 8) 9 10var ( 11\tcount int64 12\twg = sync.WaitGroup{} 13\tch = make(chan int) // no buffer chan need consume first 14) 15 16func main() { 17 18\t// total task N 19\tconst N = 1000 20 21\t// build a pool with 5 goroutine, every goroutine deal the data form the chan 22\tfor i := 0; i \u0026lt; 5; i++ { 23\twg.Add(1) 24\tgo func() { 25\tdefer wg.Done() 26\tfor val := range ch { 27\tcount2 := atomic.AddInt64(\u0026amp;count, 1) 28\t\u0026lt;-time.After(100 * time.Millisecond) 29\tfmt.Printf(\u0026#34;%vvar: %v\\n\u0026#34;, count2, val) // count2 is a new local variable 30\t} 31\t}() 32\t} 33 34\tfmt.Println(\u0026#34;\u0026gt;\u0026gt;\u0026gt; Start Work\u0026#34;) 35\tstartAt := time.Now() 36 37\t// task producer 38\tfor i := 0; i \u0026lt; N; i++ { 39\tch \u0026lt;- i 40\t} 41 42\tclose(ch) // need to close the chan first, or lead to deadlock due to all goroutines are asleep. 43\twg.Wait() 44 45\tfmt.Println(\u0026#34;\u0026gt;\u0026gt;\u0026gt; Finished\u0026#34;) 46\ttotalTime := time.Now().Sub(startAt) 47\tfmt.Printf(\u0026#34;Total time is %v, total task: %v, avg time: %v\u0026#34;, totalTime, count, totalTime/time.Duration(N)) 48} 1\u0026gt;\u0026gt;\u0026gt; Finished 2Total time is 20.359523649s, total task: 1000, avg time: 20.359523ms 如果数据处理的量远远小于开辟的协程池的数量无疑是资源的浪费，但是每次都复用协程，减少了协程创建和销毁的开销\n动态协程池 当每一个任务来临的时候创建一个协程，创建的协程的最大数量由有容量的chan 控制\n1package main 2 3import ( 4\t\u0026#34;fmt\u0026#34; 5\t\u0026#34;sync\u0026#34; 6\t\u0026#34;sync/atomic\u0026#34; 7\t\u0026#34;time\u0026#34; 8) 9 10var ( 11\tcount int64 12\twg = sync.WaitGroup{} 13\tconcurCh = make(chan bool, 5) 14) 15 16func main() { 17\t// total task N 18\tconst N = 1000 19 20\tfmt.Println(\u0026#34;\u0026gt;\u0026gt;\u0026gt; Start Work\u0026#34;) 21\tstartAt := time.Now() 22 23\tfor i := 0; i \u0026lt; N; i++ { 24\twg.Add(1) 25\tgo func(val int) { 26\tdefer func() { 27\t\u0026lt;-concurCh 28\twg.Done() 29\t}() 30\tconcurCh \u0026lt;- true 31\tcount2 := atomic.AddInt64(\u0026amp;count, 1) 32\t\u0026lt;-time.After(100 * time.Millisecond) 33\tfmt.Printf(\u0026#34;%2d var: %v\\n\u0026#34;, count2, val) 34\t}(i) 35\t} 36 37\twg.Wait() 38\tdefer close(concurCh) 39\tfmt.Println(\u0026#34;\u0026gt;\u0026gt;\u0026gt; Finished\u0026#34;) 40\ttotalTime := time.Now().Sub(startAt) 41\tfmt.Printf(\u0026#34;Total time is %v, total task: %v, avg time: %v\u0026#34;, totalTime, count, totalTime/time.Duration(N)) 42} 1\u0026gt;\u0026gt;\u0026gt; Finished 2Total time is 20.392798952s, total task: 1000, avg time: 20.392798ms 需要不断地创建和销毁goroutine可能会造成额外的开销\n实际测试下来这两种写法的性能差别不是很大。\nGoroutine 的资源开销非常小，要避免过渡的滥用。特别是在并发请求的时候，如果Goroutine设置的过多很容易把下游打挂\n1func TestConcurrency(t *testing.T) { 2\tids := make([]int, 0) 3\tfor i := 0; i \u0026lt; 100; i++ { 4\tids = append(ids, i) 5\t} 6 7\twork := func(i, j int) { 8\t\u0026lt;-time.After(1 * time.Second) 9\tprintln(i) 10 11\t} 12 13\tblchan := make(chan int, 10) 14 15\tstartAt := time.Now() 16\twg := sync.WaitGroup{} 17\tfor i, v := range ids { 18\twg.Add(1) 19\tblchan \u0026lt;- 1 20\tgo func(i, j int) { 21\tdefer wg.Done() 22\twork(i, j) 23\t\u0026lt;- blchan 24\t}(i, v) 25\t} 26\twg.Wait() 27\tclose(blchan) 28\tprintln(time.Now().Sub(startAt).Round(time.Second).String()) 29} ","date":"August 5, 2020","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/note_go/8_go_concurrency/","summary":"如何用go实现一个简单的并行任务\nGolang并发 1package main 2 3import ( 4\t\u0026#34;fmt\u0026#34; 5\t\u0026#34;sync\u0026#34; 6) 7 8var wg sync.WaitGroup 9 10func printer(ch chan int) { 11\tfor i := range ch { 12\tfmt.Printf(\u0026#34;Received %d \u0026#34;, i) 13\t} 14\twg.Done() // 15} 16 17// main is the entry point for the program. 18func main() { 19\tc := make(chan int) 20\tgo printer(c) 21\twg.Add(1) 22 23\t// Send 10 integers on the channel.","tags":["Go"],"title":"「Go」并发实现"},{"categories":null,"contents":"context.Context用来设置截止日期、同步信号，传递请求相关值的结构体。上下文与Goroutine有非常密切的关系。\n1type Context interface{ 2 Deadline()(deadline time.Time, ok bool) 3 Done() \u0026lt;-chan struct{} 4 Err() error 5 Value(key interface{}) interface{} 6} context.Context有四个方法：\nDeadline() 返回context.Context被取消时间，也就是完成工作的截止日期；\nDone() 返回一个channel，这个channel 会在当前工作完成或者上下文被取消后关闭，多次调用Done方法返回的是同一个channel；\nErr() 返回context.Context 结束的原因，它只会在Done返回的Channel被关闭时才会返回非空的值\n如果 context.Context 被取消，会返回Canceled错误；\n如果 context.Context 超时，会返回DeadlineExceeded错误；\nValue 从context.Context 中获取键对应的值。对同一个上下文来说，多次调用value并传入相同的key会返回相同的结果，该方法用来传递请求特定的数据。\n1func main() { 2\tctx := context.Background() // new empty context 3 4\tctx = context.WithValue(ctx, \u0026#34;org\u0026#34;, \u0026#34;ali\u0026#34;) 5\tctx, _ = context.WithCancel(ctx) 6\tctx, _ = context.WithDeadline(ctx, time.Now().Add(10*time.Second)) 7\tctx, _ = context.WithTimeout(ctx, time.Second) 8 9} 参考文档：\nhttps://draveness.me/golang/docs/part3-runtime/ch06-concurrency/golang-context/\n","date":"August 11, 2020","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/note_go/7_go_context/","summary":"context.Context用来设置截止日期、同步信号，传递请求相关值的结构体。上下文与Goroutine有非常密切的关系。\n1type Context interface{ 2 Deadline()(deadline time.Time, ok bool) 3 Done() \u0026lt;-chan struct{} 4 Err() error 5 Value(key interface{}) interface{} 6} context.Context有四个方法：\nDeadline() 返回context.Context被取消时间，也就是完成工作的截止日期；\nDone() 返回一个channel，这个channel 会在当前工作完成或者上下文被取消后关闭，多次调用Done方法返回的是同一个channel；\nErr() 返回context.Context 结束的原因，它只会在Done返回的Channel被关闭时才会返回非空的值\n如果 context.Context 被取消，会返回Canceled错误；\n如果 context.Context 超时，会返回DeadlineExceeded错误；\nValue 从context.Context 中获取键对应的值。对同一个上下文来说，多次调用value并传入相同的key会返回相同的结果，该方法用来传递请求特定的数据。\n1func main() { 2\tctx := context.Background() // new empty context 3 4\tctx = context.WithValue(ctx, \u0026#34;org\u0026#34;, \u0026#34;ali\u0026#34;) 5\tctx, _ = context.WithCancel(ctx) 6\tctx, _ = context.WithDeadline(ctx, time.Now().Add(10*time.Second)) 7\tctx, _ = context.","tags":["Go"],"title":"「Go」context"},{"categories":null,"contents":" NRI 目前看来主要是对CPU 实现更加细粒度的控制。\nHistory and Background\nVarious extension mechanisms over the years\nOCI hooks\ncustom actions executed at various container lifecycle events runc , cri-o ? Runtime wrapper using runtime classes\nCustom actions implemented by custom runtime wrapper a bit of kludge runc/crun/etc.. containers/cri-o NRI\ncustom actions at pod or container creation/stop containerd NRI evolution\nSubject of this presentation? What is NRI\nNRI: Node resource interface, a common framework for\nPlugging extensionsinto OCI-compatible runtimes\nImplementing custom container configuration logic\ncommon\nplugins work identically i supported runtimes Support present in commonly used runtimes framework\nmultiple NRI pieces collectively achieve NRI\u0026rsquo;s goal pluggable extensions\nAlter behavior without runtime modifications Custom logic\nYour cluster, you plugin, your rules within the allowed boundaries imposed by NRI plumbing to enforce how containers are configured\nInitially, during container creation Subsequently, by container updates Potentially, in response to some external events =\u0026gt; you cluster, you plugin, your rules\nwithin the allowed boundaries imposed by NRI How Does it work?\nWhat can it do?\nWrite An NRI Plugin\nCPU管理的现状 k8s的cpu manger 完成节点测的cpu资源分配和隔离(core pinning and isolation). 处理流程\n发现机器cpu的拓扑 上报k8s机器的可用资源 分配资源供workload运行 追踪pod的资源分配情况。 kubelet 将系统的CPU分为两个资源池\nexclusive pool： 同时只有一个任务可以分配到cpu share pool： 多个进程分配到cpu 原生的K8s cpumanger 目前只提供静态的CPU分配策略。 当K8s创建一个pod后，pod会被分类为一个Qos\nGuaranteed Burstable BestEffort 并且kubelet允许管理员通过-reserved-cpus指定保留的CPU提供给系统进程或者kube 守护进程。保留的这部分资源主要给系统进程使用。可以作为共享池分给非guranteed 的pod容器。 但是guaranteed 类pod无法分配这些cpus。\n目前K8s的节点侧依据cpuManger的分配策略来分配 numa node的cpuset， 能够做到\n容器分配到一个numa node上 容器分配到一组共享的numa node上。 cpuManger当前限制：\n最大numa node数量不能大于8，防止state explosion 策略只支持静态分配cpuset，未来会支持在容器生命周期内动态调整cpuset 调度器不感知节点上的拓扑信息。 对于线程布局（thread placement）的应用，防止物理核的共享和邻居干扰。 CPUmanger 当前不支持。 POD CPU limit Node Resource Interface containerd 主要工作在平台(docker or k8s)和更底层的 runtime (runc , kata)之间。containerd提供容器进程的管理， 镜像的管理，文件系统快照以及元数据和依赖管理。\nNRI plugin: 节点资源接口插件，管理cgroups 和拓扑\nNRI可以用来解决批量计算，延迟敏感性服务的性能问题， 以满足服务SLA/SLO,优先级等用户需求。 例如性能需求， 通过将容器的CPU分配统一NUMA node，来保证numa内的内存调用。除了NUMA，还有CPU，L3 cache 等资源拓扑亲和性。\n当前kubelet的实现的是通过cpumanager 的处理对象只能是guaranteed 类的pod， topologyManger 通过cpuManager提供的hints实现资源分配。\nkubelet 当前也不适合处理多种需求的扩展，因为在kubelet增加细粒度的资源分配会导致kubelet 和CRI的界限越来越模糊。\n而NRI，则是在CRI同期生命周期间做调用，适合做 resource pinning 和节点的拓扑感知。并且在CRI内部做插件定义和迭代，可以做到上层 kubenetes 以最小的代价来适配变化。\n在容器的生命周期中，CNI/NRI插件能够注入容器初始化进程的Create和start之间：\nCreate-\u0026gt; NRI-\u0026gt; Start\n以官方例子 clearfs： 在启动容器前， 依据Qos类型调用cgroup命令，cpu.cfs_quota_us为-1 表示不设上限。\nNRI直接控制cgroup，所以有更底层的资源分配方式。 不过越接近底层，处理逻辑越复杂。\nWhy NRI:\n支持定制化扩展，kubelet 可以直接载入扩展配置，无需修改自身代码\n通过与CRI交互，kubelet 可以将部分复杂的CPU分配需求下方到 runtime 来处理。\n应用程序如何独占一个CPU？\nNUMA 简介？\ndocker -\u0026gt; containerd -\u0026gt; runc?\nhttps://www.modb.pro/db/462537\nhttps://zhuanlan.zhihu.com/p/490585683\n","date":"December 12, 2022","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/blog/cloudnative_nri/","summary":"NRI 目前看来主要是对CPU 实现更加细粒度的控制。\nHistory and Background\nVarious extension mechanisms over the years\nOCI hooks\ncustom actions executed at various container lifecycle events runc , cri-o ? Runtime wrapper using runtime classes\nCustom actions implemented by custom runtime wrapper a bit of kludge runc/crun/etc.. containers/cri-o NRI\ncustom actions at pod or container creation/stop containerd NRI evolution\nSubject of this presentation? What is NRI\nNRI: Node resource interface, a common framework for","tags":null,"title":"K8s Cpu 调度管理的现状与限制"},{"categories":null,"contents":"Prometheus Intro Prometheus 是SoundCloud开源的系统监控和报警工具集。通过Prometheus可以进行时序数据的采集、监控和报警。\n时序数据模型 Time Series Data Model Metric 是一个对时序指标的统称，例如.：http_requests_total - the total number of HTTP requests received，就可以称为一条Metric\n在Prometheus 中每一个时序序列(time-series)都是由于Metric Name 和Lable{Key-Value}组成的\n例如：\n1http_request_total{url=\u0026#34;/ping\u0026#34;,status=200} Metric Name： http_request_total 在Prometheus中Metric Name只能由大小写字母、数字、下划线、冒号组成，且不能以数字开头，对应正则为[a-zA-Z_:][a-zA-Z0-9_:]*。冒号保留，会在定义规则的时候使用。\nLabel Name: host 和status都属于Label. 在Prometheus中Label Name只能由大小写字母、数字、下划线组成，且不能以数字开头，对应的正则为[a-zA-Z_][a-zA-Z0-9_]*。一般_开头的Labels保留位系统内部使用。\nNotation\nGiven a metric name and a set of labels, time series are frequently identified using this notion:\n1\u0026lt;Metric Name\u0026gt;{\u0026lt;Label Name\u0026gt;=\u0026lt;Label Value\u0026gt;,...} For example, a time series with the mertric name api_http_request_total and the label method=\u0026quot;POST\u0026quot; and handler=\u0026ldquo;message\u0026rdquo;` could be written like this. This is the same notation that OpenTSDB uses.\n1api_http_request_total{method=\u0026#34;POST\u0026#34;, handler=\u0026#34;/messages\u0026#34;} 2node_cpu_seconds_total{cpu=\u0026#34;2\u0026#34;,mode=\u0026#34;system\u0026#34;} 1\u0026lt;--- metric name------\u0026gt;\u0026lt;-----lable set------\u0026gt;\u0026lt;-timestamp -\u0026gt;\u0026lt;-value-\u0026gt; 2node_cpu_seconds_total{cpu=\u0026#34;2\u0026#34;,mode=\u0026#34;system\u0026#34;}@1434417560938 195721.31 3# timestamp 是毫秒级时间戳 4# value 有且只有一个 float64 __ 作为前缀标签，只能在系统内部使用。 Prome底层实现指标名称是以__name__=\u0026lt;metric name\u0026gt;形式存储的，以下两种表达方式是相同的。\n1api_http_request_total{method=\u0026#34;POST\u0026#34;, handler=\u0026#34;/messages\u0026#34;} 2{__name_=api_http_request_total, method=\u0026#34;POST\u0026#34;, handler=\u0026#34;/messages\u0026#34;} Component 所有基础组件的安装都基于Docker。\nPrometheus 1docker pull prom/prometheus 2docker run -d -p 9090:9090 --name prometheus prom/prometheus 安装完成后可以访问9090端口，可以看到Prometheus管理页面。如下图为查询go_routines的情况。\n查询当前数据：\n1GET http://devbox:9090/api/v1/query?query=go_goroutines\u0026amp;time=1610127237.659 查询历史数据：\n1GET http://devbox:9090/api/v1/query_range?query=go_goroutines\u0026amp;start=1610126024.257\u0026amp;end=1610126924.257\u0026amp;step=3 配置/etc/prometheus/prometheus.yaml\n1# my global config 2global: 3\t# 拉取target的默认时间间隔 4 scrape_interval: 15s # Set the scrape interval to every 15 seconds. Default is every 1 minute. 5 evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute. 执行Rule的时间间隔 6 # scrape_timeout is set to the global default (10s). 拉取超时时间 7 8# Alertmanager configuration 9alerting: 10 alertmanagers: 11 - static_configs: 12 - targets: 13 # AlertManager ip:port 可以配置多个 14 # - alertmanager:9093 15 16# Load rules once and periodically evaluate them according to the global \u0026#39;evaluation_interval\u0026#39;. 17rule_files: 18 # - \u0026#34;first_rules.yml\u0026#34; # 规则配置文件 19 # - \u0026#34;second_rules.yml\u0026#34; 20 21# A scrape configuration containing exactly one endpoint to scrape: 22# Here it\u0026#39;s Prometheus itself. 23scrape_configs: 24 # The job name is added as a label `job=\u0026lt;job_name\u0026gt;` to any timeseries scraped from this config. 25 - job_name: \u0026#39;prometheus\u0026#39; 26 # metrics_path defaults to \u0026#39;/metrics\u0026#39; 27 # scheme defaults to \u0026#39;http\u0026#39;. 28 static_configs: 29 - targets: [\u0026#39;localhost:9090\u0026#39;] 30 - job_name: \u0026#39;pushgateway\u0026#39; 31 # metrics_path defaults to \u0026#39;/metrics\u0026#39; 32 # scheme defaults to \u0026#39;http\u0026#39;. 33 static_configs: 34 - targets: [\u0026#39;10.x.x.115:9091\u0026#39;] 35 - job_name: \u0026#39;alertmanager\u0026#39; 36 # metrics_path defaults to \u0026#39;/metrics\u0026#39; 37 # scheme defaults to \u0026#39;http\u0026#39;. 38 static_configs: 39 - targets: [\u0026#39;10.x.x.115:9093\u0026#39;] PushGateway 1docker pull prom/pushgateway 2docker run -d --restart=always --name pushgateway -p 9091:9091 prom/pushgateway AlertManager 1docker run -d --restart=always --name alertmanager -p 9093:9093 prom/alertmanager 配置\nWebHook Test\n1import SimpleHTTPServer 2import SocketServer 3 4PORT = 5001 5 6class ServerHandler(SimpleHTTPServer.SimpleHTTPRequestHandler): 7 8 def do_POST(self): 9 content_len = int(self.headers.getheader(\u0026#39;content-length\u0026#39;, 0)) 10 post_body = self.rfile.read(content_len) 11 print post_body 12 self.send_response(200) 13 self.end_headers() 14 15Handler = ServerHandler 16 17httpd = SocketServer.TCPServer((\u0026#34;\u0026#34;, PORT), Handler) 18 19print \u0026#34;serving at port\u0026#34;, PORT 20httpd.serve_forever() Prometheus 数据类型 Metric Type These are currently only differentiated in the client libraries and in the wire protocol. The prometheus server does not yet make user of the type information and flattens all data into untyped time series.\nCounter A counter is a cumulative metric that represents a single monotonically increasing counter whose value can only increase or be reset to zero on restart. For example, you can use a counter to represent the number of requests served, tasks completed, or errors.\n只增不减，计数器\nCounter类型的指标相当于一个计数器，只增不减。除非Prometheus Client重启，将重新计数。例如：http_request_total。\n例如：node_cpu_seconds_total{cpu=\u0026quot;0\u0026quot;,mode=\u0026quot;system\u0026quot;}\n原始指标\nrate()获取增长率\nrate始终大于0\ntopk() 获取top k数据\nGauge A gauge is a metric that represents a single numerical value that can arbitrarily go up and down.\nGauges are typically used for measured values like temperatures or current memory usage, but also \u0026ldquo;counts\u0026rdquo; that can go up and down, like the number of concurrent requests.\nGauge 相当于一个仪表盘，可增可减，是一个瞬时值。 例如：node_memory_MemFree（主机当前空闲的内容大小）、node_memory_MemAvailable（可用内存大小）都是Gauge类型的监控指标。\n原始指标\ndelta() 在一定时间内的差异 每个点与过去2h的差异\nderiv()计算样本线性回归模型\npredict_linear(node_memory_MemFree_bytes[10h], 4*3600) 预测未来4h的指标情况\nHistogram A histogram samples observations (usually things like request durations or response sizes) and counts them in configurable buckets. It also provides a sum of all observed values.\n柱状图，用于观察结果采样，分组及统计。例如： 请求持续时间。是对一段时间内的数据进行采样，并能够对其指定区间以及总数进行统计。需要根据区间计算。\nHistogram指标直接反应了在不同区间内样本的个数，区间通过标签le进行定义。\nSummary Similar to a histogram, a summary samples observations (usually things like request durations and response sizes). While it also provides a total count of observations and a sum of all observed values, it calculates configurable quantiles over a sliding time window.\n类似Histogram, 用于表示一段时间内的数据采样结果，不是临时算出来的，结果早已存储。\n长尾问题\n如果大多数API请求都维持在100ms的响应时间范围内，而个别请求的响应时间需要5s，那么就会导致某些WEB页面的响应时间落到中位数的情况，而这种现象被称为长尾问题。\n为了区分是平均的慢还是长尾的慢，最简单的方式就是按照请求延迟的范围进行分组。例如，统计延迟在0~10ms之间的请求数有多少而10~20ms之间的请求数又有多少。通过这种方式可以快速分析系统慢的原因。Histogram和Summary都是为了能够解决这样问题的存在，通过Histogram和Summary类型的监控指标，我们可以快速了解监控样本的分布情况。\n数据存入Prome 存入Prom的点会自动添加Instance\u0026amp;job 两个tag\n实际打点 数据存入Prom后会自动加上 instance \u0026amp; job 两个tag\nPromQL PromQL是Prom的数据查询DSL(Domain Specified Language)语言。\n结果类型：\nType Desc Demo 瞬时数据（Instant Vector） 包含一组TimeSeries，每个时序只有一个点 http_request_total 区间数据（Range Vector） 包含一组TimeSeries, 每个时序有多个点 http_request_total[5m] 纯量数据（Scalar） 只有一个数据，没有Time Series count(http_request_total) 查询方式\n1logback_events_total{level=\u0026#34;info\u0026#34;} 查询支持正则匹配\n1http_request_total{code!=\u0026#34;200\u0026#34;} # code != 200 2http_request_total{code=~\u0026#34;2..\u0026#34;} # code = 2xx 3http_request_total{code!~\u0026#34;2..\u0026#34;} # code != 2xx 其他查询\n1# 取整 2floor(avg(http_request_total{code=\u0026#34;200\u0026#34;})) 3ceil(avg(http_request_total{code=\u0026#34;200\u0026#34;})) 4# 查看每秒数据 5rate(http_request_total[5m]) 6 7#模糊查询： level=\u0026#34;inxx 8logback_events_total{level=~\u0026#34;in..\u0026#34;} 9logback_events_total{level=~\u0026#34;in.*\u0026#34;} 聚合查询：\n1# count 2count(logback_event_total) 3# sum 4sum(logback_event_total) 5# avg 6avg(logback_event_total) 7# topk 8topk(2, logback_events_total) 9 10# irate 如查询过去5分钟的平均值 11irate( logback_events_total[5m]) Reference https://www.jianshu.com/p/93c840025f01\nhttps://yunlzheng.gitbook.io/prometheus-book/parti-prometheus-ji-chu/promql/prometheus-promql-operators-v2\nhttps://prometheus.io/docs/concepts/data_model/#notation\n","date":"December 11, 2021","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/component/TimeSeries/prometheus_intro/","summary":"Prometheus Intro Prometheus 是SoundCloud开源的系统监控和报警工具集。通过Prometheus可以进行时序数据的采集、监控和报警。\n时序数据模型 Time Series Data Model Metric 是一个对时序指标的统称，例如.：http_requests_total - the total number of HTTP requests received，就可以称为一条Metric\n在Prometheus 中每一个时序序列(time-series)都是由于Metric Name 和Lable{Key-Value}组成的\n例如：\n1http_request_total{url=\u0026#34;/ping\u0026#34;,status=200} Metric Name： http_request_total 在Prometheus中Metric Name只能由大小写字母、数字、下划线、冒号组成，且不能以数字开头，对应正则为[a-zA-Z_:][a-zA-Z0-9_:]*。冒号保留，会在定义规则的时候使用。\nLabel Name: host 和status都属于Label. 在Prometheus中Label Name只能由大小写字母、数字、下划线组成，且不能以数字开头，对应的正则为[a-zA-Z_][a-zA-Z0-9_]*。一般_开头的Labels保留位系统内部使用。\nNotation\nGiven a metric name and a set of labels, time series are frequently identified using this notion:\n1\u0026lt;Metric Name\u0026gt;{\u0026lt;Label Name\u0026gt;=\u0026lt;Label Value\u0026gt;,...} For example, a time series with the mertric name api_http_request_total and the label method=\u0026quot;POST\u0026quot; and handler=\u0026ldquo;message\u0026rdquo;` could be written like this.","tags":null,"title":"「Prom」Prometheus 安装及使用简介"},{"categories":null,"contents":"12 123 https://raft.github.io/\nhttps://www.infoq.com/presentations/raft-consensus-algorithm/\nhttps://www.geeksforgeeks.org/raft-consensus-algorithm/\nhttps://www.hashicorp.com/resources/raft-consul-consensus-protocol-explained\n","date":"April 1, 2021","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/blog/raft/","summary":"12 123 https://raft.github.io/\nhttps://www.infoq.com/presentations/raft-consensus-algorithm/\nhttps://www.geeksforgeeks.org/raft-consensus-algorithm/\nhttps://www.hashicorp.com/resources/raft-consul-consensus-protocol-explained","tags":["Raft"],"title":"「Raft」 The Raft Consensus Algorithm"},{"categories":null,"contents":"动态规划：\n子问题 状态定义 DP方程 ","date":"September 17, 2020","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/DataStruct/ds_dp/","summary":"动态规划：\n子问题 状态定义 DP方程 ","tags":[""],"title":"数据结构与算法动态规划"},{"categories":null,"contents":"https://www.cnblogs.com/-flq/p/9519276.html https://www.cnblogs.com/xuwujing/archive/2020/02/29/12385903.html\nhttps://www.elastic.co/guide/en/elasticsearch/client/go-api/current/index.html https://www.jianshu.com/p/6e28c967d872\n","date":"September 9, 2020","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/component/NoSQL/ElasticSearch/elasticsearch_aggregation/","summary":"https://www.cnblogs.com/-flq/p/9519276.html https://www.cnblogs.com/xuwujing/archive/2020/02/29/12385903.html\nhttps://www.elastic.co/guide/en/elasticsearch/client/go-api/current/index.html https://www.jianshu.com/p/6e28c967d872","tags":[""],"title":"post"},{"categories":null,"contents":"查询语句\nquery bool must exist \u0026ldquo;exists\u0026rdquo;: { \u0026ldquo;field\u0026rdquo;: \u0026ldquo;name\u0026rdquo; } 判断字段是否存在 must_not match \u0026ldquo;match\u0026rdquo;: { \u0026ldquo;tweet\u0026rdquo;: \u0026ldquo;elasticsearch\u0026rdquo; } 匹配字符串中是否包含 should Filter 简单查询 查询某个字段是否存在或者是否为null 1curl -H \u0026#39;Content-type: application/json\u0026#39; -XPOST \u0026#39;http://ip:9200/alert_group/_search\u0026#39; -d 1{ 2 \u0026#34;query\u0026#34;: { 3 \u0026#34;bool\u0026#34;: { 4 \u0026#34;must\u0026#34;: { // must_not 5 \u0026#34;exists\u0026#34;: { 6 \u0026#34;field\u0026#34;: \u0026#34;name\u0026#34; // 必须存在该字段，且该字段不为null 7 } 8 } 9 } 10 } 11} 空查询（empty search） {}在功能上等价于使用 match_all 查询， 正如其名字一样，匹配所有文档：\n1curl -X GET \u0026#34;localhost:9200/_search?pretty\u0026#34; -H \u0026#39;Content-Type: application/json\u0026#39; -d\u0026#39; 2{ 3 \u0026#34;query\u0026#34;: { 4 \u0026#34;match_all\u0026#34;: {} 5 } 6} 7\u0026#39; Match 1GET /_search 2{ 3 \u0026#34;query\u0026#34;: { 4 \u0026#34;match\u0026#34;: { 5 \u0026#34;tweet\u0026#34;: \u0026#34;elasticsearch\u0026#34; 6 } 7 } 8} 复合查询 组合多条件查询。elasticsearch提供bool来实现这种需求；\n主要参数： must：文档 必须 匹配这些条件才能被包含进来。 must_not：文档 必须不 匹配这些条件才能被包含进来。 should：如果满足这些语句中的任意语句，或的关系，将增加 _score ，否则，无任何影响。它们主要用于修正每个文档的相关性得分。 filter：必须 匹配，但它以不评分、过滤模式来进行。这些语句对评分没有贡献，只是根据过滤标准来排除或包含文档。\n一个 bool 语句 允许在你需要的时候组合其它语句，无论是 must 匹配、 must_not 匹配还是 should 匹配，同时它可以包含不评分的过滤器（filters）：\n1{ 2 \u0026#34;bool\u0026#34;: { 3 \u0026#34;must\u0026#34;: { \u0026#34;match\u0026#34;: { \u0026#34;tweet\u0026#34;: \u0026#34;elasticsearch\u0026#34; }}, 4 \u0026#34;must_not\u0026#34;: { \u0026#34;match\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;mary\u0026#34; }}, 5 \u0026#34;should\u0026#34;: { \u0026#34;match\u0026#34;: { \u0026#34;tweet\u0026#34;: \u0026#34;full text\u0026#34; }}, 6 \u0026#34;filter\u0026#34;: { \u0026#34;range\u0026#34;: { \u0026#34;age\u0026#34; : { \u0026#34;gt\u0026#34; : 30 }} } 7 } 8} 了找出信件正文包含 business opportunity 的星标邮件，或者在收件箱正文包含 business opportunity 的非垃圾邮件：\nshoule在与must或者filter同级时，默认是不需要满足should中的任何条件的，此时我们可以加上minimum_should_match 参数，来达到我们的目的，即上述代码改为：\n1{ 2 \u0026#34;bool\u0026#34;: { 3 \u0026#34;must\u0026#34;: { \u0026#34;match\u0026#34;: { \u0026#34;email\u0026#34;: \u0026#34;business opportunity\u0026#34; }}, 4 \u0026#34;should\u0026#34;: [ 5 { \u0026#34;match\u0026#34;: { \u0026#34;starred\u0026#34;: true }}, 6 { \u0026#34;bool\u0026#34;: { 7 \u0026#34;must\u0026#34;: { \u0026#34;match\u0026#34;: { \u0026#34;folder\u0026#34;: \u0026#34;inbox\u0026#34; }}, 8 \u0026#34;must_not\u0026#34;: { \u0026#34;match\u0026#34;: { \u0026#34;spam\u0026#34;: true }} 9 }} 10 ], 11 \u0026#34;minimum_should_match\u0026#34;: 1 12 } 13} Term 精确查询\n1GET /forum/article/_search 2{ 3 \u0026#34;query\u0026#34;: { 4 \u0026#34;constant_score\u0026#34;: { 5 \u0026#34;filter\u0026#34;: { 6 \u0026#34;bool\u0026#34;: { 7 \u0026#34;must\u0026#34; : [ 8 {\u0026#34;term\u0026#34; : {\u0026#34;tag_cnt\u0026#34; : 1}}, 9 {\u0026#34;terms\u0026#34; : {\u0026#34;tag\u0026#34; : [\u0026#34;java\u0026#34;]}} 10 ] 11 } 12 } 13 } 14 } 15} 嵌套查询 如果doc中有个字段是Object Array， 通过其中的一个Object 查询\n1{ 2 \u0026#34;query\u0026#34;: { 3 \u0026#34;nested\u0026#34;: { 4 \u0026#34;path\u0026#34;: \u0026#34;tags\u0026#34;, // 字段名 5 \u0026#34;query\u0026#34;: { 6 \u0026#34;bool\u0026#34;: { 7 \u0026#34;must\u0026#34;: [ 8 { 9 \u0026#34;term\u0026#34;: { 10 \u0026#34;tags.key\u0026#34;: \u0026#34;k1\u0026#34; // 查找tags 中包含object{key:k1,val:v1}的所有doc 11 } 12 }, 13 { 14 \u0026#34;term\u0026#34;: { 15 \u0026#34;tags.val\u0026#34;: \u0026#34;v1\u0026#34; 16 } 17 } 18 ] 19 } 20 } 21 } 22 } 23} 1{ 2 \u0026#34;query\u0026#34;: { 3 \u0026#34;nested\u0026#34;: { 4 \u0026#34;path\u0026#34;: \u0026#34;tags\u0026#34;, 5 \u0026#34;query\u0026#34;: { 6 \u0026#34;bool\u0026#34;: { 7 \u0026#34;must\u0026#34;: [ 8 { 9 \u0026#34;term\u0026#34;: { 10 \u0026#34;tags.key\u0026#34;: \u0026#34;$psm\u0026#34; 11 } 12 }, 13 { 14 \u0026#34;terms\u0026#34;: { 15 \u0026#34;tags.val\u0026#34;:[ \u0026#34;v1\u0026#34;,\u0026#34;v2\u0026#34;] // 查询多个值 16 } 17 } 18 ] 19 } 20 } 21 } 22 }, 23 \u0026#34;sort\u0026#34;: [ 24 { 25 \u0026#34;created_at\u0026#34;: { 26 \u0026#34;order\u0026#34;: \u0026#34;desc\u0026#34; 27 } 28 } 29 ] 30} 在排序的过程中，只能使用可排序的属性进行排序。那么可以排序的属性有哪些呢？\n数字 日期 嵌套查询的效率相对是比较低的，如果数据量非常大的情况下就会出现慢查询的问题\n1//按照条件新建一个index 作为测试数据使用 2POST _reindex 3{ 4 \u0026#34;source\u0026#34;: { 5 \u0026#34;index\u0026#34;: \u0026#34;usernested\u0026#34;, 6 \u0026#34;query\u0026#34;: { 7 \u0026#34;nested\u0026#34;: { 8 \u0026#34;path\u0026#34;: \u0026#34;tags\u0026#34;, 9 \u0026#34;query\u0026#34;: { 10 \u0026#34;bool\u0026#34;: { 11 \u0026#34;must\u0026#34;: [ 12 { 13 \u0026#34;term\u0026#34;: { 14 \u0026#34;tags.brand\u0026#34;: \u0026#34;c55fd643-1333-4647-b898-fb3e5e4e6d67\u0026#34; 15 } 16 }, 17 { 18 \u0026#34;term\u0026#34;: { 19 \u0026#34;tags.site\u0026#34;: \u0026#34;163\u0026#34; 20 } 21 } 22 ] 23 } 24 } 25 } 26 } 27 }, 28 \u0026#34;dest\u0026#34;: { 29 \u0026#34;index\u0026#34;: \u0026#34;new_usernested\u0026#34; 30 } 31} 1//根据条件更新一个 nested的文档 2GET usernested/_update_by_query 3{ 4 \u0026#34;query\u0026#34;: { 5 \u0026#34;nested\u0026#34;: { 6 \u0026#34;path\u0026#34;: \u0026#34;tags\u0026#34;, 7 \u0026#34;query\u0026#34;: { 8 \u0026#34;bool\u0026#34;: { 9 \u0026#34;must\u0026#34;: [ 10 { 11 \u0026#34;term\u0026#34;: { 12 \u0026#34;tags.brand\u0026#34;: \u0026#34;c55fd643-1333-4647-b898-fb3e5e4e6d67\u0026#34; 13 } 14 }, 15 { 16 \u0026#34;term\u0026#34;: { 17 \u0026#34;tags.site\u0026#34;: \u0026#34;163\u0026#34; 18 } 19 } 20 ] 21 } 22 } 23 } 24 }, 25 \u0026#34;script\u0026#34;: { 26 \u0026#34;inline\u0026#34;: \u0026#34;for(e in ctx._source.tags){e.brand = \u0026#39;test2\u0026#39;;}\u0026#34; //更新nested字段 27 //\u0026#34;inline\u0026#34;:\u0026#34;ctx._source.userid = \u0026#39;testid\u0026#39;\u0026#34; //更新普通字段 28 } 29} 通过_source字段中的include和exclude来指定返回结果包含哪些字段，排除哪些字段 1{ 2 \u0026#34;_source\u0026#34;:{ 3 \u0026#34;include\u0026#34;:[ 4 \u0026#34;policyNo\u0026#34;, 5 \u0026#34;policyRelationNo\u0026#34;, 6 \u0026#34;policyStatus\u0026#34; 7 ], 8 \u0026#34;exclude\u0026#34;:[ 9 \u0026#34;salesType\u0026#34; 10 ] 11 }, 12 \u0026#34;query\u0026#34;: { 13 \u0026#34;bool\u0026#34;: { 14 \u0026#34;must\u0026#34;: [ 15 { 16 \u0026#34;term\u0026#34;: { 17 \u0026#34;policyRelationNo\u0026#34;: \u0026#34;KR01435021\u0026#34; 18 } 19 } 20 ], 21 \u0026#34;should\u0026#34;: [], 22 \u0026#34;must_not\u0026#34;: [] 23 } 24 }, 25 \u0026#34;from\u0026#34;: 0, 26 \u0026#34;size\u0026#34;: 10 27} 1 2{ 3\t\u0026#34;_shards\u0026#34;: { 4\t\u0026#34;total\u0026#34;: 5, 5\t\u0026#34;successful\u0026#34;: 5, 6\t\u0026#34;failed\u0026#34;: 0 7\t}, 8\t\u0026#34;hits\u0026#34;: { 9\t\u0026#34;total\u0026#34;: 19, 10\t\u0026#34;max_score\u0026#34;: 11.391884, 11\t\u0026#34;hits\u0026#34;: [ 12\t{ 13\t\u0026#34;_index\u0026#34;: \u0026#34;search4policy-msad-dev3_20200520000000\u0026#34;, 14\t\u0026#34;_type\u0026#34;: \u0026#34;policy-msad-dev3\u0026#34;, 15\t\u0026#34;_id\u0026#34;: \u0026#34;4407038\u0026#34;, 16\t\u0026#34;_score\u0026#34;: 11.391884, 17\t\u0026#34;_source\u0026#34;: { 18\t\u0026#34;policyRelationNo\u0026#34;: \u0026#34;KR01435021\u0026#34;, 19\t\u0026#34;policyNo\u0026#34;: \u0026#34;B609120319\u0026#34;, 20\t\u0026#34;policyStatus\u0026#34;: 11 21\t} 22\t}, 23\t{ 24\t\u0026#34;_index\u0026#34;: \u0026#34;search4policy-msad-dev3_20200520000000\u0026#34;, 25\t\u0026#34;_type\u0026#34;: \u0026#34;policy-msad-dev3\u0026#34;, 26\t\u0026#34;_id\u0026#34;: \u0026#34;4407046\u0026#34;, 27\t\u0026#34;_score\u0026#34;: 10.713255, 28\t\u0026#34;_source\u0026#34;: { 29\t\u0026#34;policyRelationNo\u0026#34;: \u0026#34;KR01435021\u0026#34;, 30\t\u0026#34;policyNo\u0026#34;: \u0026#34;B609120323\u0026#34;, 31\t\u0026#34;policyStatus\u0026#34;: 11 32\t} 33\t} 34\t] 35\t}, 36\t\u0026#34;took\u0026#34;: 5, 37\t\u0026#34;timed_out\u0026#34;: false 38} 参考资料：\nhttps://blog.csdn.net/weixin_33831196/article/details/85860371?utm_medium=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.add_param_isCf\u0026depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.add_param_isCf\nhttps://blog.csdn.net/u012934325/article/details/106971482/\nhttps://blog.csdn.net/qq_35393693/article/details/80143287\nhttps://segmentfault.com/a/1190000020245240\n*https://www.jianshu.com/p/c377477df7fc\nhttps://blog.csdn.net/qq_32165041/article/details/83715134\nhttps://www.jianshu.com/p/2abd2e344dcb\n","date":"September 7, 2020","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/component/NoSQL/ElasticSearch/elasticsearch_query/","summary":"查询语句\nquery bool must exist \u0026ldquo;exists\u0026rdquo;: { \u0026ldquo;field\u0026rdquo;: \u0026ldquo;name\u0026rdquo; } 判断字段是否存在 must_not match \u0026ldquo;match\u0026rdquo;: { \u0026ldquo;tweet\u0026rdquo;: \u0026ldquo;elasticsearch\u0026rdquo; } 匹配字符串中是否包含 should Filter 简单查询 查询某个字段是否存在或者是否为null 1curl -H \u0026#39;Content-type: application/json\u0026#39; -XPOST \u0026#39;http://ip:9200/alert_group/_search\u0026#39; -d 1{ 2 \u0026#34;query\u0026#34;: { 3 \u0026#34;bool\u0026#34;: { 4 \u0026#34;must\u0026#34;: { // must_not 5 \u0026#34;exists\u0026#34;: { 6 \u0026#34;field\u0026#34;: \u0026#34;name\u0026#34; // 必须存在该字段，且该字段不为null 7 } 8 } 9 } 10 } 11} 空查询（empty search） {}在功能上等价于使用 match_all 查询， 正如其名字一样，匹配所有文档：\n1curl -X GET \u0026#34;localhost:9200/_search?pretty\u0026#34; -H \u0026#39;Content-Type: application/json\u0026#39; -d\u0026#39; 2{ 3 \u0026#34;query\u0026#34;: { 4 \u0026#34;match_all\u0026#34;: {} 5 } 6} 7\u0026#39; Match 1GET /_search 2{ 3 \u0026#34;query\u0026#34;: { 4 \u0026#34;match\u0026#34;: { 5 \u0026#34;tweet\u0026#34;: \u0026#34;elasticsearch\u0026#34; 6 } 7 } 8} 复合查询 组合多条件查询。elasticsearch提供bool来实现这种需求；","tags":["ElasticSearch"],"title":"「ElasticSearch」 ElasticSearch 简单查询"},{"categories":null,"contents":"Slice的坑 1numList := make([]int, 10) 2// 产生的numList会存入10个0， 如果继续append 数据会导致numList的数据超过10 Slice 扩容\n1func TestSliceExtend(t *testing.T) { 2\tcapacity := 0 3\tlist := make([]int, 0) 4\tfor i := 0; i \u0026lt; 4096; i++ { 5\tlist = append(list, i) 6\tif capacity != cap(list) { 7\ttimes := float64(cap(list)) / float64(capacity) 8\tdiffer := cap(list) - capacity 9\tcapacity = cap(list) 10\tif times == 2.0 { 11\tfmt.Printf(\u0026#34;capacity is: %d \\t times: %.2f \\n\u0026#34;, capacity, times) 12\t} else { 13\tfmt.Printf(\u0026#34;capacity is: %d \\t times: %.2f \\t differ: %d \\n\u0026#34;, capacity, times, differ) 14\t} 15\t} 16\t} 17} ","date":"September 2, 2020","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/note_go/5.3_go_slice/","summary":"Slice的坑 1numList := make([]int, 10) 2// 产生的numList会存入10个0， 如果继续append 数据会导致numList的数据超过10 Slice 扩容\n1func TestSliceExtend(t *testing.T) { 2\tcapacity := 0 3\tlist := make([]int, 0) 4\tfor i := 0; i \u0026lt; 4096; i++ { 5\tlist = append(list, i) 6\tif capacity != cap(list) { 7\ttimes := float64(cap(list)) / float64(capacity) 8\tdiffer := cap(list) - capacity 9\tcapacity = cap(list) 10\tif times == 2.0 { 11\tfmt.Printf(\u0026#34;capacity is: %d \\t times: %.","tags":[""],"title":"「Go」slice"},{"categories":null,"contents":"\rGit 数据存储的基本概念 WorkSpace: 工作区，编辑修改文件的区域\nIndex/Stage: 暂存区， 未提交修改\nRepository： 本地仓库\nRemote： 远程仓库\n我们使用编辑器写代码的区域就是WorkSpace, 执行git add fileName之后，就将修改的文件提交到了暂存区，执行git commmit -m \u0026quot;update fineName\u0026quot; 之后就将修改提交到了本地版本库。最后使用 git push 将修改提交到远程仓库。\nGit 常用操作 配置用户名以及邮箱 设置\n1git config --global user.Name \u0026#34;name\u0026#34; 2git config --global user.email \u0026#34;xxx@outlook.com\u0026#34; 查看\n1git config user.name 2git config user.email 初始化Git仓库 git init 1git init fileName 2# or 不指定路径，默认为当前路径 3git init 初始化仓库后，会生成一.git的隐藏文件夹\n建立裸仓库\n1git init --bare bare_repo 对比正常git仓库normal_repo与bare_repo的目录结构发现，在normal_repo/.git 文件夹中的文件直接出现在了bare_repo 中\n切换分支。\n在一个裸仓库中执行git命令会提示this operation must be run in a work tree。因为裸仓库是没有工作区的，只会记录git提交的历史信息，git log可以查看提交历史，但是没有办法进行版本回退或者切分分支的操作。\n但是可以通过hooks建立一个单独存放源码的文件夹，将git仓库与项目源码分离存放。远程仓库往这个repo的推送更新会更新源码文件夹的内容。可以看一下这个技巧在Hexo部署中的实战.\n切换branch 切换本地的branch\n切换到远程branch 到本地\n切换commit 多次commit合并为一个commit 1git rebase -i \u0026lt;commitId\u0026gt; commitId是不需要被合并的一次commit， 是需要合并的commit的上一个commitId。\n修改commit信息 修改历史commit信息：同上\n修改最新的一次commit的信息\n1git commit --amend \u0026#34;message\u0026#34; rebase和merge的区别 git rebase 撤销\ngit \u0026ndash;abort/\u0026ndash;continue\n1git reflog 2 3git reset --hard \u0026lt;commit id\u0026gt; git stash 的使用 git stash用于临时保存和恢复修改, 可以跨分支\n在未add之前才能执行git stash\ngit stash [save] [message] 保存，save为可选项，message为本次保存的注释\ngit stash list 所有保存的记录列表\ngit stash pop stash@{num} 恢复，num是可选项，通过git stash list可查看具体值。只能恢复一次\ngit stash apply stash@{num} 恢复，num是可选项，通过git stash list可查看具体值。可回复多次\ngit stash drop stash@{num} 删除某个保存，num是可选项，通过git stash list可查看具体值\ngit stash clear 删除所有保存\n1git branch -a # 查看所有的分支 2git branch # 查看当前使用分支(结果列表中前面标*号的表示当前使用分支) 3git checkout {$branchName} # 切换分支 1git config --global init.defaultBranch main 需要解决的问题\ngit stash 是保存在了哪里 git reset \u0026amp; git revert git rebase git init \u0026amp; git init -bare、 解决冲突 git commit \u0026ndash;amend https://www.jianshu.com/p/699ed86028c2\nhttps://www.liaoxuefeng.com/wiki/896043488029600/900004590234208\ngitignore只能忽略未track的文件\nGit 知识积累\nhttps://zhuanlan.zhihu.com/p/147356242\nhttps://www.jianshu.com/p/e5b13480479b\nhttps://www.cnblogs.com/rainbowk/p/10932322.html\n","date":"August 26, 2020","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/tips/git_stage_repo/","summary":"Git 数据存储的基本概念 WorkSpace: 工作区，编辑修改文件的区域\nIndex/Stage: 暂存区， 未提交修改\nRepository： 本地仓库\nRemote： 远程仓库\n我们使用编辑器写代码的区域就是WorkSpace, 执行git add fileName之后，就将修改的文件提交到了暂存区，执行git commmit -m \u0026quot;update fineName\u0026quot; 之后就将修改提交到了本地版本库。最后使用 git push 将修改提交到远程仓库。\nGit 常用操作 配置用户名以及邮箱 设置\n1git config --global user.Name \u0026#34;name\u0026#34; 2git config --global user.email \u0026#34;xxx@outlook.com\u0026#34; 查看\n1git config user.name 2git config user.email 初始化Git仓库 git init 1git init fileName 2# or 不指定路径，默认为当前路径 3git init 初始化仓库后，会生成一.git的隐藏文件夹\n建立裸仓库\n1git init --bare bare_repo 对比正常git仓库normal_repo与bare_repo的目录结构发现，在normal_repo/.git 文件夹中的文件直接出现在了bare_repo 中\n切换分支。\n在一个裸仓库中执行git命令会提示this operation must be run in a work tree。因为裸仓库是没有工作区的，只会记录git提交的历史信息，git log可以查看提交历史，但是没有办法进行版本回退或者切分分支的操作。","tags":[""],"title":"「Git」 Git 工作区\u0026暂存区\u0026本地仓库\u0026远程仓库以及基本操作"},{"categories":null,"contents":"HTTP简介 HTTP协议（HyperText Transfer Protocol， 超文本传输协议），是一个基于TCP/IP通信协议来传输数据。是用于从服务器传输超文本到本地浏览器的协议。HTTP使用同一资源标识符（Uniform Resource Identifiers, URL）来传输数据和建立连接。\nHTTP协议工作于客户端-服务端（C-S）架构上。浏览器作为HTTP客户端通过URL向服务端发送请求，并获得返回数据。\nHTTP特点：\nHTTP是无连接的： 无连接的含义是限制每次连接只处理一个请求。服务器处理完客户的请求，并收到客户的应答后，即断开连接。\nHTTP是无状态的： HTTP是无状态协议。无状态是指协议对于事务处理灭有记忆能力。缺少状态意味着如果后续处理需要前面的信息，则它必须重传，这样可能导致每次传输的数据量增大。\nHTTP是媒体独立的： 任何数据类型都可以通过HTTP发送，客户端以及服务器要指定相同的MIME-type类型。媒体类型通常通过 HTTP 协议，由 Web 服务器告知浏览器的，更准确地说，是通过 Content-Type 来表示的。例如：Content-Type：text/HTML。通常只有广泛应用的格式才会获得一个 MIME Type，如果是某个客户端自己定义的格式，一般只能以 application/x- 开头。\nWeb-Browser \u0026lt;===\u0026gt; HTTP Server \u0026lt;===\u0026gt; CGI(Common GateWay Interface) Program \u0026lt;==\u0026gt;Database\n客户端请求消息 请求消息包括以下格式：请求行（request line）、请求头部（header）、空行和请求数据四个部分组成\n服务器响应消息 响应也由四个部分组成，分别是：状态行、消息报头、空行和响应正文。\n不带Body 的请求 1# 请求消息 2GET /health HTTP/1.1 3Host: 127.0.0.1:8080 4User-Agent: curl/7.65.3 5Accept: */* 6 7# 返回消息 8HTTP/1.1 200 OK 9Content-Type: text/plain; charset=utf-8 10Date: Sat, 22 Aug 2020 17:56:22 GMT 11Content-Length: 2 12 13ok 带Body的请求 1# 请求消息 2GET /health?val=123 HTTP/1.1 3Host: localhost:8080 4User-Agent: curl/7.65.3 5Accept: */* 6Content-Type: text/plain 7Content-Length: 9 8 9body test 10 11# 返回消息 12HTTP/1.1 200 OK 13Content-Type: text/plain; charset=utf-8 14Date: Sat, 22 Aug 2020 18:17:14 GMT 15Content-Length: 7 16 17ok: 123 Http9种请求 http定义了9中请求动作，来表明对Request-URI指定的资源进行不同的操作方式。是一种http协议的使用规范。\nHTTP1.0 定义了三种请求方法： GET, POST 和 HEAD方法。\nHTTP1.1 新增了六种请求方法：OPTIONS、PUT、PATCH、DELETE、TRACE 和 CONNECT 方法。\nMethod Intro 使用约束 幂等性 GET 向特定资源发起请求。 只是获取数据，并不会对数据造成修改 幂等 POST 向特定资源提交数据进行进行处理请求（例如提交表单或者创建文件），请求数据类型： multipart/form-data**或 application/x-www-form-urlencoded 一般是创建一个新的实体（例如新增一个员工信息） PUT 向指定资源位置上传最新的内容 一般是更新一个已有实体（更新员工信息） DELETE 请求删除Request-URI所标识的资源 删除资源（删除某个员工信息） PATCH 对PUT的补充，默认是以x-www-form-urlencoded的contentType 用来更新部分资源 HEAD 向服务器请求与GET一致的响应，响应体不返回，响应头返回 幂等 OPTIONS 返回服务其针对特定资源所支持的HTTP请求方法，发送*测试服务器的功能性 TRACE 回显服务器收到的请求，主要用于测试或者诊断 提供一种方法来测试当一个请求发生的时候，服务器通过网络收到的内容。所以它会返回你发送的内容。 CONNECT HTTP/1.1协议中预留给能够将连接改为管道方式的代理服务器。 虽然HTTP的请求方式有9种，但是我们在实际应用中常用的也就是get和post，其他请求方式也都可以通过这两种方式间接的来实现。\nGET 和 POST的区别 GET POST 幂等性 GET和HEAD请求是幂等的 ，被称为安全方法。不会对服务端的信息产生修改 非幂等的，可能会修改服务器的资源 Url 请求数据附加在在URL中，以\u0026quot;?\u0026ldquo;链接URL和请求数据，多个参数使用\u0026amp;连接。URL编码采用ASCII编码，所有的非ASCII字符都要在编码后传输。可以保存为浏览器书签 请求数据在Body中 传输数据大小 在HTTP规范中对地址栏的长度和传输数据的大小没有限制，但是，特定的浏览器和服务端对URL的长度有限制。使用GET请求时候，传输数据会受到URL长度的限制。 传输数据大小理论上不受限制 安全性 GET请求会把信息暴露在地址栏，可能会通过浏览器缓存或者历史记录暴露信息。GET请求提交的数据还可能造成Cross-site request frogery攻击，即利用网站对用户标识的信任欺骗用户的浏览器发送HTTP请求给目标站点 不存在上述问题 HTTP 响应头信息 应答头 说明 Allow 服务器支持哪些请求方法（如GET、POST等）。 Content-Encoding 文档的编码（Encode）方法。只有在解码之后才可以得到Content-Type头指定的内容类型。利用gzip压缩文档能够显著地减少HTML文档的下载时间。Java的GZIPOutputStream可以很方便地进行gzip压缩，但只有Unix上的Netscape和Windows上的IE 4、IE 5才支持它。因此，Servlet应该通过查看Accept-Encoding头（即request.getHeader(\u0026quot;Accept-Encoding\u0026quot;)）检查浏览器是否支持gzip，为支持gzip的浏览器返回经gzip压缩的HTML页面，为其他浏览器返回普通页面。 Content-Length 表示内容长度。只有当浏览器使用持久HTTP连接时才需要这个数据。如果你想要利用持久连接的优势，可以把输出文档写入 ByteArrayOutputStream，完成后查看其大小，然后把该值放入Content-Length头，最后通过byteArrayStream.writeTo(response.getOutputStream()发送内容。 Content-Type 表示后面的文档属于什么MIME类型。Servlet默认为text/plain，但通常需要显式地指定为text/html。由于经常要设置Content-Type，因此HttpServletResponse提供了一个专用的方法setContentType。 Date 当前的GMT时间。你可以用setDateHeader来设置这个头以避免转换时间格式的麻烦。 Expires 应该在什么时候认为文档已经过期，从而不再缓存它 Last-Modified 文档的最后改动时间。客户可以通过If-Modified-Since请求头提供一个日期，该请求将被视为一个条件GET，只有改动时间迟于指定时间的文档才会返回，否则返回一个304（Not Modified）状态。Last-Modified也可用setDateHeader方法来设置。 Location 表示客户应当到哪里去提取文档。Location通常不是直接设置的，而是通过HttpServletResponse的sendRedirect方法，该方法同时设置状态代码为302。 Refresh 表示浏览器应该在多少时间之后刷新文档，以秒计。除了刷新当前文档之外，你还可以通过setHeader(\u0026quot;Refresh\u0026quot;, \u0026quot;5; URL=http://host/path\u0026quot;)让浏览器读取指定的页面。 注意这种功能通常是通过设置HTML页面HEAD区的＜META HTTP-EQUIV=\u0026quot;Refresh\u0026quot; CONTENT=\u0026quot;5;URL=http://host/path\u0026quot;＞实现，这是因为，自动刷新或重定向对于那些不能使用CGI或Servlet的HTML编写者十分重要。但是，对于Servlet来说，直接设置Refresh头更加方便。 注意Refresh的意义是\u0026quot;N秒之后刷新本页面或访问指定页面\u0026rdquo;，而不是\u0026quot;每隔N秒刷新本页面或访问指定页面\u0026quot;。因此，连续刷新要求每次都发送一个Refresh头，而发送204状态代码则可以阻止浏览器继续刷新，不管是使用Refresh头还是＜META HTTP-EQUIV=\u0026quot;Refresh\u0026quot; ...＞。 注意Refresh头不属于HTTP 1.1正式规范的一部分，而是一个扩展，但Netscape和IE都支持它。 Server 服务器名字。Servlet一般不设置这个值，而是由Web服务器自己设置。 Set-Cookie 设置和页面关联的Cookie。Servlet不应使用response.setHeader(\u0026quot;Set-Cookie\u0026quot;, ...)，而是应使用HttpServletResponse提供的专用方法addCookie。参见下文有关Cookie设置的讨论。 WWW-Authenticate 客户应该在Authorization头中提供什么类型的授权信息？在包含401（Unauthorized）状态行的应答中这个头是必需的。例如，response.setHeader(\u0026quot;WWW-Authenticate\u0026quot;, \u0026quot;BASIC realm=＼\u0026quot;executives＼\u0026quot;\u0026quot;)。 注意Servlet一般不进行这方面的处理，而是让Web服务器的专门机制来控制受密码保护页面的访问（例如.htaccess）。 HTTP 状态码 当浏览者访问一个网页时，浏览者的浏览器会向网页所在服务器发出请求。当浏览器接收并显示网页前，此网页所在的服务器会返回一个包含HTTP状态码的信息头（server header）用以响应浏览器的请求。\nHTTP状态码（HTTP Status Code）\n200 - 请求成功 301 - 资源（网页等）被永久转移到其它URL 404 - 请求的资源（网页等）不存在 500 - 内部服务器错误 HTTP状态码分类 HTTP状态码由三个十进制数字组成，第一个十进制数字定义了状态码的类型，后两个数字没有分类的作用。HTTP状态码共分为5种类型：\n分类 分类描述 1** 信息，服务器收到请求，需要请求者继续执行操作 2** 成功，操作被成功接收并处理 3** 重定向，需要进一步的操作以完成请求 4** 客户端错误，请求包含语法错误或无法完成请求 5** 服务器错误，服务器在处理请求的过程中发生了错误 HTTP状态码列表:\n状态码 状态码英文名称 中文描述 100 Continue 继续。客户端应继续其请求 101 Switching Protocols 切换协议。服务器根据客户端的请求切换协议。只能切换到更高级的协议，例如，切换到HTTP的新版本协议 200 OK 请求成功。一般用于GET与POST请求 201 Created 已创建。成功请求并创建了新的资源 202 Accepted 已接受。已经接受请求，但未处理完成 203 Non-Authoritative Information 非授权信息。请求成功。但返回的meta信息不在原始的服务器，而是一个副本 204 No Content 无内容。服务器成功处理，但未返回内容。在未更新网页的情况下，可确保浏览器继续显示当前文档 205 Reset Content 重置内容。服务器处理成功，用户终端（例如：浏览器）应重置文档视图。可通过此返回码清除浏览器的表单域 206 Partial Content 部分内容。服务器成功处理了部分GET请求 300 Multiple Choices 多种选择。请求的资源可包括多个位置，相应可返回一个资源特征与地址的列表用于用户终端（例如：浏览器）选择 301 Moved Permanently 永久移动。请求的资源已被永久的移动到新URI，返回信息会包括新的URI，浏览器会自动定向到新URI。今后任何新的请求都应使用新的URI代替 302 Found 临时移动。与301类似。但资源只是临时被移动。客户端应继续使用原有URI 303 See Other 查看其它地址。与301类似。使用GET和POST请求查看 304 Not Modified 未修改。所请求的资源未修改，服务器返回此状态码时，不会返回任何资源。客户端通常会缓存访问过的资源，通过提供一个头信息指出客户端希望只返回在指定日期之后修改的资源 305 Use Proxy 使用代理。所请求的资源必须通过代理访问 306 Unused 已经被废弃的HTTP状态码 307 Temporary Redirect 临时重定向。与302类似。使用GET请求重定向 400 Bad Request 客户端请求的语法错误，服务器无法理解 401 Unauthorized 请求要求用户的身份认证 402 Payment Required 保留，将来使用 403 Forbidden 服务器理解请求客户端的请求，但是拒绝执行此请求 404 Not Found 服务器无法根据客户端的请求找到资源（网页）。通过此代码，网站设计人员可设置\u0026quot;您所请求的资源无法找到\u0026quot;的个性页面 405 Method Not Allowed 客户端请求中的方法被禁止，本来应该用PUT，结果用POST请求就会报这个错误。 406 Not Acceptable 服务器无法根据客户端请求的内容特性完成请求 407 Proxy Authentication Required 请求要求代理的身份认证，与401类似，但请求者应当使用代理进行授权 408 Request Time-out 服务器等待客户端发送的请求时间过长，超时 409 Conflict 服务器完成客户端的 PUT 请求时可能返回此代码，服务器处理请求时发生了冲突 410 Gone 客户端请求的资源已经不存在。410不同于404，如果资源以前有现在被永久删除了可使用410代码，网站设计人员可通过301代码指定资源的新位置 411 Length Required 服务器无法处理客户端发送的不带Content-Length的请求信息 412 Precondition Failed 客户端请求信息的先决条件错误 413 Request Entity Too Large 由于请求的实体过大，服务器无法处理，因此拒绝请求。为防止客户端的连续请求，服务器可能会关闭连接。如果只是服务器暂时无法处理，则会包含一个Retry-After的响应信息 414 Request-URI Too Large 请求的URI过长（URI通常为网址），服务器无法处理 415 Unsupported Media Type 服务器无法处理请求附带的媒体格式 416 Requested range not satisfiable 客户端请求的范围无效 417 Expectation Failed 服务器无法满足Expect的请求头信息 500 Internal Server Error 服务器内部错误，无法完成请求 501 Not Implemented 服务器不支持请求的功能，无法完成请求 502 Bad Gateway 作为网关或者代理工作的服务器尝试执行请求时，从远程服务器接收到了一个无效的响应 503 Service Unavailable 由于超载或系统维护，服务器暂时的无法处理客户端的请求。延时的长度可包含在服务器的Retry-After头信息中 504 Gateway Time-out 充当网关或代理的服务器，未及时从远端服务器获取请求 505 HTTP Version not supported 服务器不支持请求的HTTP协议的版本，无法完成处理 content-type Content-Type（内容类型），一般是指网页中存在的 Content-Type，用于定义网络文件的类型和网页的编码，决定浏览器将以什么形式、什么编码读取这个文件。\nContent-Type 标头告诉客户端实际返回的内容的内容类型。\n语法格式：\n1Content-Type: text/html; charset=utf-8 2Content-Type: multipart/form-data; boundary=something 实例：\n常见的媒体格式类型如下：\ntext/html ： HTML格式 text/plain ：纯文本格式 text/xml ： XML格式 image/gif ：gif图片格式 image/jpeg ：jpg图片格式 image/png：png图片格式 以application开头的媒体格式类型：\napplication/xhtml+xml ：XHTML格式 application/xml： XML数据格式 application/atom+xml ：Atom XML聚合格式 application/json： JSON数据格式 application/pdf：pdf格式 application/msword ： Word文档格式 application/octet-stream ： 二进制流数据（如常见的文件下载） application/x-www-form-urlencoded ： 中默认的encType，form表单数据被编码为key/value格式发送到服务器（表单默认的提交数据的格式） 另外一种常见的媒体格式是上传文件之时使用的：\nmultipart/form-data ： 需要在表单中进行文件上传时，就需要使用该格式 HTTP content-type 对照表\n","date":"August 21, 2020","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/blog/http_introducton/","summary":"HTTP简介 HTTP协议（HyperText Transfer Protocol， 超文本传输协议），是一个基于TCP/IP通信协议来传输数据。是用于从服务器传输超文本到本地浏览器的协议。HTTP使用同一资源标识符（Uniform Resource Identifiers, URL）来传输数据和建立连接。\nHTTP协议工作于客户端-服务端（C-S）架构上。浏览器作为HTTP客户端通过URL向服务端发送请求，并获得返回数据。\nHTTP特点：\nHTTP是无连接的： 无连接的含义是限制每次连接只处理一个请求。服务器处理完客户的请求，并收到客户的应答后，即断开连接。\nHTTP是无状态的： HTTP是无状态协议。无状态是指协议对于事务处理灭有记忆能力。缺少状态意味着如果后续处理需要前面的信息，则它必须重传，这样可能导致每次传输的数据量增大。\nHTTP是媒体独立的： 任何数据类型都可以通过HTTP发送，客户端以及服务器要指定相同的MIME-type类型。媒体类型通常通过 HTTP 协议，由 Web 服务器告知浏览器的，更准确地说，是通过 Content-Type 来表示的。例如：Content-Type：text/HTML。通常只有广泛应用的格式才会获得一个 MIME Type，如果是某个客户端自己定义的格式，一般只能以 application/x- 开头。\nWeb-Browser \u0026lt;===\u0026gt; HTTP Server \u0026lt;===\u0026gt; CGI(Common GateWay Interface) Program \u0026lt;==\u0026gt;Database\n客户端请求消息 请求消息包括以下格式：请求行（request line）、请求头部（header）、空行和请求数据四个部分组成\n服务器响应消息 响应也由四个部分组成，分别是：状态行、消息报头、空行和响应正文。\n不带Body 的请求 1# 请求消息 2GET /health HTTP/1.1 3Host: 127.0.0.1:8080 4User-Agent: curl/7.65.3 5Accept: */* 6 7# 返回消息 8HTTP/1.1 200 OK 9Content-Type: text/plain; charset=utf-8 10Date: Sat, 22 Aug 2020 17:56:22 GMT 11Content-Length: 2 12 13ok 带Body的请求 1# 请求消息 2GET /health?","tags":["Http"],"title":"「HTTP」HTTP 9 种请求方式"},{"categories":null,"contents":" 学好一个框架或者一门语言，最好的方法就是要学会看官方的Document。几乎所有的博客只是把自己对官方文档的理解重新加工整理出来而已，增加了自己的主管想法。\n刚入门的时候面对英文文档可能一头雾水，但是当你坚持下来，你会发现，这些官方文档写的要比那些博客好的多，表述精确的多。\n以后我的文章会主要参考官方文档展开介绍，顺带加一点自己的理解\nGitHub\nOfficial Document\n1. Gin 简介 The fastest full-featured web freamwork for Go. Crystal clear.\n快 支持中间件 Crash还原 JSON验证 路由分组 错误日志收集 模板渲染 可扩展 2. 快速用Gin搭建一个Web服务 1go get -u github.com/gin-gonic/gin # install Gin 2 3mkdir gin_demo \u0026amp;\u0026amp; cd gin_demo 4 5vi main.go main.go的内容如下\n1package main 2 3import ( 4\t\u0026#34;net/http\u0026#34; 5\t\u0026#34;github.com/gin-gonic/gin\u0026#34; 6 7) 8 9func main(){ 10\tr := gin.Default() 11 12\tr.GET(\u0026#34;/ping\u0026#34;, func(c *gin.Context){ 13\tc.JSON(200, gin.H{ 14\t\u0026#34;message\u0026#34;:\u0026#34;pong\u0026#34;, 15\t}) 16\t}) 17 18\tr.GET(\u0026#34;/health\u0026#34;, func(c *gin.Context){ 19\tc.String(http.StatusOK, \u0026#34;ok\u0026#34;) 20\t}) 21\tr.Run() 22} 然后初始化GoModule, 运行项目\n1go mod init xxx/xxx/gin_demo 2 3go run main.go 如上图所示，一个简单的web服务就搭建成功了\n测试一下访问情况\n服务端日志\n由于gin.Default() 返回的gin.Engine (router)自带Logger中间件，所以可以在日志中看到具体的请求与响应情况。看一眼源码\n1// Default returns an Engine instance with the Logger and Recovery middleware already attached. 2func Default() *Engine { 3\tdebugPrintWARNINGDefault() 4\tengine := New() 5\tengine.Use(Logger(), Recovery()) 6\treturn engine 7} Gin 项目目录 1├─ Project Name 2│ ├─ config //配置文件 3│ ├── ... 4│ ├─ controller //控制器层，验证提交的数据，将验证完成的数据提交给service 5│ ├── ... 6│ ├─ service //业务层， 只完成业务逻辑得开发，不进行数据库的操作 7│ ├── ... 8│ ├─ repository //数据库操作层 dal/ dao; 数据库操作层，写，多表插入，多表查询，不写业务代码 9│ ├── ... 10│ ├─ model //数据库ORM 11│ ├── ... 12│ ├─ entity //实体 写返回数据的结构体。写controller层方法参数验证的结构体 13│ ├── ... 14│ ├─ proto //proto文件 写 gRPC 的 *.pb.go 文件。 15│ ├── ... 16│ ├─ router //路由 17│ ├── middleware //路由中间件 （鉴权，日志，异常捕获） 18│ ├── ... 19│ ├── ... 20│ ├─ util //工具类，项目通用的工具包 21│ ├── ... 22│ ├─ vendor //扩展包 第三方依赖，通常使用go mod 管理 23│ ├── ... 24│ ├─ main.go //入口文件 参考资料：\nhttps://cloud.tencent.com/developer/article/1490384\n","date":"August 21, 2020","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/blog/gin_overview/","summary":"学好一个框架或者一门语言，最好的方法就是要学会看官方的Document。几乎所有的博客只是把自己对官方文档的理解重新加工整理出来而已，增加了自己的主管想法。\n刚入门的时候面对英文文档可能一头雾水，但是当你坚持下来，你会发现，这些官方文档写的要比那些博客好的多，表述精确的多。\n以后我的文章会主要参考官方文档展开介绍，顺带加一点自己的理解\nGitHub\nOfficial Document\n1. Gin 简介 The fastest full-featured web freamwork for Go. Crystal clear.\n快 支持中间件 Crash还原 JSON验证 路由分组 错误日志收集 模板渲染 可扩展 2. 快速用Gin搭建一个Web服务 1go get -u github.com/gin-gonic/gin # install Gin 2 3mkdir gin_demo \u0026amp;\u0026amp; cd gin_demo 4 5vi main.go main.go的内容如下\n1package main 2 3import ( 4\t\u0026#34;net/http\u0026#34; 5\t\u0026#34;github.com/gin-gonic/gin\u0026#34; 6 7) 8 9func main(){ 10\tr := gin.Default() 11 12\tr.GET(\u0026#34;/ping\u0026#34;, func(c *gin.Context){ 13\tc.","tags":null,"title":"「Gin」Gin入门"},{"categories":null,"contents":"https://docs.mongodb.com/manual/reference/bson-types/\nhttp://bsonspec.org/\nhttps://www.mongodb.com/json-and-bson\nhttps://www.educba.com/json-vs-bson/\\\nhttps://www.geeksforgeeks.org/difference-between-json-and-bson/\n","date":"August 20, 2020","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/component/DataBase/mongo/bson/","summary":"https://docs.mongodb.com/manual/reference/bson-types/\nhttp://bsonspec.org/\nhttps://www.mongodb.com/json-and-bson\nhttps://www.educba.com/json-vs-bson/\\\nhttps://www.geeksforgeeks.org/difference-between-json-and-bson/","tags":["Bson"],"title":"「Mongo」Bson vs Json"},{"categories":null,"contents":"1. Go语言介绍 1.1 Go 语言特点 静态类型、编译型的开源语言\n静态类型是指要明确变量的类型，或者编译器可以推导出变量的类型。要么在变量类型旁边指定变量的那个类型，要么是可以推导出变量类型。\n编译型是指要编译成机器语言。\n1package main 2func main(){ 3 // Declare the type of the variable 4 var num1 int = 1; 5 // Deduce the type of the variable 6 num2 :=2 7} 脚本化的语法，支持多种范式编程\n函数式\u0026amp;面向对象\n原生、给力的并发编程支持\n注意： 原生支持和函数库支持的区别\n1.2 Go语言的优势和劣势 优势\n脚本化的语法 静态类型+编译型，程序运行速度有保障 原生的支持并发编程 - 降低开发、维护成本；程序可以更好的执行 劣势\n语法糖并没有Python和Ruby那么多- 1成是开发时间，9成维护时间 目前的程序运行速度还不及c，但是目前已经赶超了C++和Java 第三方库函数暂时不像绝对主流的编程语言那样多 1.3 Go开发环境 Linux 下的安装 FreeBSD Linux Windows 32bit - 64bit\nLinux 下的设置方法\n有四个环境变量需要设置： GOROOT、GOPATH、GOBIN以及PATH\n需要设置到某一个profile文件中\nOS X-\u0026gt; ~/.bash_profile(单一用户) 或者 /etc/profile（所有用户）\nMac 安装Golang 所有开发默认使用Mac环境，使用brew可以安装并管理go多个版本\n1brew install go # 安装go最新版本 1go version # 查看go版本 安装路径\nBrew 可以用来管理多版本的Go，安装指定版本1.14\n1brew install go@1.14 安装路径\n1/usr/local/Cellar/go@1.14/1.14.9 切换go的版本到1.14, 这个地方具体的操作需要根据homebrew的具体版本进行操作\n1brew unlink go 2brew link --overwrite go@1.14 1.4 关键环境变量 GOROOT 该环境变量的值应该为Go语言的当前安装目录\nGOPATH 该环境变量为Go语言工作区的集合\ngo 1.12 版本中支持 go mod , 不再强制将项目源码放置到Src目录中。\nGOBIN 是你想存放Go程序的可执行文件的目录\n1export GOROOT=/usr/local/go # 一般不需要设置 2export GOPATH=~/go # 默认为~/go 3export GOBIN=$GOPATH/bin # 默认为~/go/bin PATH: 为了方便使用Go语言命令和Go程序的可执行文件，需要追加其值，如\n1export PATH=$PATH:$GOBIN 2 3source profileName # 使修改生效 任意目录 go version\n如果使用交叉编译(Cross compile)则需要设置GOOS环境变量\n2. 基本规则 2.1 工作区和GOPATH 工作区是放置Go源码文件的目录\n一般情况下，Go源码文件都需要存放到工作区中\n但对于命令源码文件来说，这不是必须的\n每个工作区的结构都类似下图所示\n1/home/username/golib: 2\tsrc/ # 用于存放源码文件、以代码包为组织形式 3\tpkg/ # 用于存放归档文件（名称以.a）为后缀的文件 - 所有归档文件都会被存放到该目录下的平台相关目录中，同样以代码包为组织形式 4\tbin/ # 用于存放当前工作区中Go程序的可执行文件---GOBIN 5\t# 1. 当环境变量GOBIN已有效设置时，该目录会变的无意义 6\t# 2. 当GOPATH的值中包含多个工作区的路径时候，必须设置GOBIN，否则无法成功安装Go程序的可执行文件。 平台相关目录 pkg/darwin_amd64\n两个隐含的Go语言环境变量： GOOS和GOARCH\nGOOS：操作系统\nGOARCH:计算架构\n平台相关目录是以$GOOS_$GOARCH为命名方式，如linux_amd64\n\u0026lt;工作区目录\u0026gt;/pkg/\u0026lt;平台相关目录\u0026gt;/\u0026lt;一级代码包\u0026gt;/\u0026lt;二级代码包\u0026gt;/\u0026lt;末级代码包\u0026gt;.a 2.1 源码文件的分类和含义 GO源码文件 名称以.go为后缀，内容以Go语言代码组织的文件 多个Go源码文件是需要用代码包组织起来的\n分三类\n命令源码文件、库源码文件 - go语言程序\n测试源码文件- 辅助源码文件\n命令源码文件 声明自己属于main代码包 包含无参数声明和结果声明的main函数 被安装后，相应的可执行文件会被存放到GOBIN指向的目录或者\u0026lt;当前工作区目录\u0026gt;/bin下\n命令源码文件是Go程序的入口，但是不建议把程序都写在一个文件中\n注意： 同一个代码包中强烈不建议直接包含多个命令源码文件\n库源码文件 不具备命令源码文件的两个特征的源码文件\n被安装后，相应的归档文件会被存放到\u0026lt;当前工作目录\u0026gt;/pkg/\u0026lt;平台相关目录\u0026gt;下\n测试源码文件 不具备命令源码文件那两个特征的源码文件\n名称以_test.go为后缀\n其中至少有一个函数的名称以Test或Benchmark为前缀\n并且，该函数接受一个类型为*testing.T或*testing.B的参数\n1// 功能测试函数 2func TestFind(t *testing.T){ 3 // 省略若干条语句 4} 5 6// 基准测试函数或性能测试函数 7func BenchmarkFind(b *testing.B){ 8 // 省略若干条语句 9} 2.3 代码包的相关知识 代码包的作用 编译和归档Go成语的最基本单位\n代码划分、集结和依赖的有效组织形式，也是权限控制的辅助手段\n代码包的规则 一个代码包实际上就是一个由导入路径代表的目录\n导入路径即\u0026lt;工作区目录\u0026gt;/src或\u0026lt;工作区目录\u0026gt;/pkg/\u0026lt;平台相关目录\u0026gt;之下的某段子路径\n例如：代码包hypermind.cn可以对应于\n/home/username/golib/src/hypermind.cn\n(其中，/home/username/golib 是一个工作区目录)\n代码包的声明 每个源码文件必须声明其所属的代码包\n同一个代码包中的所有源码文件声明的代码包应该是相同的\n代码包声明与代码包导入路径的区别 代码包声明语句中的包名称应该是该代码包的导入路径的最右子路径\n例如 hypermind.cn/pkgtool -\u0026gt; package pkgtool\n代码包的导入 代码包导入语句中使用的包名称应该与其导入路径一致，例如\nflag、fmt、strings\n1import ( 2\t\u0026#34;flag\u0026#34; 3 \u0026#34;fmt\u0026#34; 4 \u0026#34;strings\u0026#34; 5) 代码包的导入方法 带别名的导入 1import str \u0026#34;strings\u0026#34; 2str.HasPrefix(\u0026#34;abc\u0026#34;,\u0026#34;a\u0026#34;) 本地化的导入 1import . \u0026#34;strings\u0026#34; 2HasPrefix(\u0026#34;abc\u0026#34;,\u0026#34;a\u0026#34;) 仅仅初始化 1import _ \u0026#34;strings\u0026#34; 2// 仅仅执行代码包中的初始化函数 代码包的初始化 代码包初始化函数即：无参数声明和结果声明的init函数 init函数可以被声明在任何文件中，且可以有多个 init 函数的执行时机\u0026mdash;单一代码包内 对所有全局变量进行求值\u0026mdash;-\u0026raquo;\u0026raquo;\u0026gt;执行所有init函数\n单个代码包内多个init函数的执行顺序是不确定的\ninit 函数的执行时机\u0026mdash;不同代码包之间 执行被导入的代码包中init函数\u0026mdash;\u0026ndash;\u0026raquo;\u0026raquo; 执行导入它的那个代码包的init函数\n导入顺序 A -\u0026gt; B -\u0026gt; C\ninit 的执行顺序 C B A\n注意： 我们不应该对在同一个代码包中被导入的多个代码包的init函数的执行顺序作出假设！\ninit函数的执行时机\u0026mdash;-所有涉及到的代码包 每一个init函数只会被执行一次\n3. 命令基础 1go run 2go build 和 go install 3go get 3.1 go run 用于运行命令源码文件 只能接受一个命令源码文件以及若干个库源码文件作为文件参数 其内部操作步骤是： 先编译源码文件再运行； 源文件\u0026ndash;compile(放入临时文件夹)\u0026ndash;\u0026gt;1可执行文件2. 归档文件 示例\nhttps://github.com/hyper-carrot/goc2p\nds命令和psd命令\nds命令的源码文件goc2p/src/helper/ds/showds.go 用于显示指定目录的目录结构\npds命令的源码文件goc2p/src/helper/ds/showpds.go 用于显示指定代码包的依赖关系\ngo run 常用标记的使用\n1-a # 强制编译相关代码，不论他们的编译结果是否已是最新的 2-n # 打印编译过程中所需运行的命令，但不会真正执行他们 3-p -n # 并行编译，其中n为并行的数量 n为逻辑核的数量 4-v # 列出被编译代码包的名称 5-a -v # 列出所有被编译的代码包的名称 1.4 版本后不包含Go语言自带的标准库的代码包 6-work # 显示编译时创建的临时工作目录的路径，并且不删除它 7-x # 打印编译过程中所需的命令，并执行他们 注意与-n的区别 3.2 go build 用于编译源码文件或代码包\n编译非命令源码文件不会产生任何执行结果(只是检查语法的有效性)\n编译命令源码文件会在该命令的执行目录中生成一个可执行文件\n执行该命令且不追加任何参数时，他会试图把当前目录作为代码包并编译\n执行该命令且以代码包的导入路径作为参数时，改代码包及其依赖会被编译\n（-a 标记后所有涉及到的代码包都会被重新编译 ）\n执行该命令以若干源码文件作为参数时，只有这些文件会被编译（如果缺少依赖会编译错误）\n例如： /Users/airren/go/src/github.com/airren/day01/helloworld/main.go\n如果对main.go进行编译，\n可以直接在hello word路径下执行go build 或者再任意路径执行go build github.com/airren/day01/helloworld， 项目的路径是从$GOPATH/src后开始写起 编译生成的可执行文件在执行go build的当前路径下。\n1go build -o hello # 指定编译后的文件名 3.3 go install 先执行 go build 后copy\n用于编译并安装代码包或源码文件 安装代码包会在当前工作区的 pkg/\u0026lt;平台相关目录\u0026gt;下生成归档文件 安装命令源码文件会在当前工作区的bin目录或$GOBIN目录下生成可执行文件 执行该命令且不追加任何参数时，它会试图把当前目录作为代码包并安装 执行该命令且以代码包的导入路径作为参数时，该代码包及其依赖会被安装 执行改命令且以命令源码文件以及相关库源码文件作为参数时，只有这些文件会被编译并安装 代码包安装之后，在pkg中会有 .a 文件, 在其他的代码中就可以引入已经安装的代码包\n3.4 go get 用于从远程代码仓库(github, gitlab,gogs)上下载并安装代码包 受支持的代码版本控制系统有: Git , Mercurial(hg)，SVN, Bazaar 指定的代码包会被下载到$GOPATH中包含的第一个工作区的src目录中，然后再安装 1go get -x github.com/go-errors/errors go get常用标记的使用\n1-d # 只执行下载动作，而不执行安装动作 2-fix # 在下载代码包后先执行修正动作，而后再进行编译和安装 3-u # 利用网络来更新已有的代码包及其依赖包 4-x # 显示过程 3.5 godoc 1go get golang.org/x/tools/cmd/godoc 4. 跨平台编译 交叉编译\n默认我们go build的可执行文件都是当前操作系统可执行的文件，如果我想在windows下编译一个linux下可执行文件，那需要怎么做呢？\n只需要指定目标操作系统的平台和处理器架构即可：\n1SET CGO_ENABLED=0 // 禁用CGO 2SET GOOS=linux // 目标平台是linux 3SET GOARCH=amd64 // 目标处理器架构是amd64 使用了cgo的代码是不支持跨平台编译的\n然后再执行go build命令，得到的就是能够在Linux平台运行的可执行文件了。\nMac 下编译 Linux 和 Windows平台 64位 可执行程序：\n1CGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build 2CGO_ENABLED=0 GOOS=windows GOARCH=amd64 go build Linux 下编译 Mac 和 Windows 平台64位可执行程序：\n1CGO_ENABLED=0 GOOS=darwin GOARCH=amd64 go build 2CGO_ENABLED=0 GOOS=windows GOARCH=amd64 go build Windows下编译Mac平台64位可执行程序：\n1SET CGO_ENABLED=0 2SET GOOS=darwin 3SET GOARCH=amd64 4go build t\n","date":"August 20, 2020","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/note_go/1_go_basic_cmd/","summary":"1. Go语言介绍 1.1 Go 语言特点 静态类型、编译型的开源语言\n静态类型是指要明确变量的类型，或者编译器可以推导出变量的类型。要么在变量类型旁边指定变量的那个类型，要么是可以推导出变量类型。\n编译型是指要编译成机器语言。\n1package main 2func main(){ 3 // Declare the type of the variable 4 var num1 int = 1; 5 // Deduce the type of the variable 6 num2 :=2 7} 脚本化的语法，支持多种范式编程\n函数式\u0026amp;面向对象\n原生、给力的并发编程支持\n注意： 原生支持和函数库支持的区别\n1.2 Go语言的优势和劣势 优势\n脚本化的语法 静态类型+编译型，程序运行速度有保障 原生的支持并发编程 - 降低开发、维护成本；程序可以更好的执行 劣势\n语法糖并没有Python和Ruby那么多- 1成是开发时间，9成维护时间 目前的程序运行速度还不及c，但是目前已经赶超了C++和Java 第三方库函数暂时不像绝对主流的编程语言那样多 1.3 Go开发环境 Linux 下的安装 FreeBSD Linux Windows 32bit - 64bit\nLinux 下的设置方法\n有四个环境变量需要设置： GOROOT、GOPATH、GOBIN以及PATH","tags":["Go"],"title":"「Go」Go的安装以及介绍"},{"categories":null,"contents":"1. Docker 安装ElasticSearch 1docker search elasticsearch 1docker pull elasticsearch # 默认会拉取 latest 版本 2docker pull elasticsearch:6.8.11 # https://hub.docker.com/ 版本查找 3docker images # 查看本地images 1 docker run -d --name elasticserarch_1 -p 9200:9200 -p 9300:9300 elasticsearch:6.8.11 1docker ps 1curl http://devbox:9200/ 2. docker 安装Cerebro 1docker search cerebro # test 1docker pull lmenezes/cerebro 1docker run -d -p 9002:9000 \\ 2--restart=unless-stopped \\ 3--name cerebro \\ 4-v /etc/localtime:/etc/localtime \\ 5-v cerebro:/opt/cerebro \\ 6-h cerebro \\ 7lmenezes/cerebro 86f036de7c87672903c88f6590d40d052e8c7b79767e410e35b1f2162c268b63f docker run 参数说明\nhttps://www.runoob.com/docker/docker-run-command.html?ivk_sa=1023345p\n访问http://ip:9002 并配置集群\n配置完成后点击 connect, 下图中已经建立好两个Index\n1docker run -id https://www.runoob.com/docker/docker-run-command.html https://blog.csdn.net/qq_19381989/article/details/102781663\n1curl ","date":"August 18, 2020","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/component/NoSQL/ElasticSearch/elasticsearch_install/","summary":"1. Docker 安装ElasticSearch 1docker search elasticsearch 1docker pull elasticsearch # 默认会拉取 latest 版本 2docker pull elasticsearch:6.8.11 # https://hub.docker.com/ 版本查找 3docker images # 查看本地images 1 docker run -d --name elasticserarch_1 -p 9200:9200 -p 9300:9300 elasticsearch:6.8.11 1docker ps 1curl http://devbox:9200/ 2. docker 安装Cerebro 1docker search cerebro # test 1docker pull lmenezes/cerebro 1docker run -d -p 9002:9000 \\ 2--restart=unless-stopped \\ 3--name cerebro \\ 4-v /etc/localtime:/etc/localtime \\ 5-v cerebro:/opt/cerebro \\ 6-h cerebro \\ 7lmenezes/cerebro 86f036de7c87672903c88f6590d40d052e8c7b79767e410e35b1f2162c268b63f docker run 参数说明","tags":[""],"title":"「ElasticSearch」ElasticSearch安装"},{"categories":null,"contents":"","date":"August 17, 2020","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/component/MessageQueue/kafka_install/","summary":"","tags":["Mongo"],"title":"「Kafka」Kafka安装"},{"categories":null,"contents":"\r","date":"August 17, 2020","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/component/NoSQL/ElasticSearch/logstash_install/","summary":"\r","tags":["ElasticSearch"],"title":"「LogStash」LogStash安装"},{"categories":null,"contents":"mongo 基本数据类型 Type bosun.E type E struct { Key string Value interface{} } E represents a BSON element for a D. It is usually used inside a D. bosun.D type D []E D is an ordered representation of a BSON document. This type should be used when the order of the elements matters, // such as MongoDB command documents. If the order of the elements does not matter, an M should be used instead. // // Example usage: // // bson.D{{\u0026ldquo;foo\u0026rdquo;, \u0026ldquo;bar\u0026rdquo;}, {\u0026ldquo;hello\u0026rdquo;, \u0026ldquo;world\u0026rdquo;}, {\u0026ldquo;pi\u0026rdquo;, 3.14159}} bosun.M type M map[string]interface{} // M is an unordered representation of a BSON document. This type should be used when the order of the elements does not // matter. This type is handled as a regular map[string]interface{} when encoding and decoding. Elements will be // serialized in an undefined, random order. If the order of the elements matters, a D should be used instead. // // Example usage: // // bson.M{\u0026ldquo;foo\u0026rdquo;: \u0026ldquo;bar\u0026rdquo;, \u0026ldquo;hello\u0026rdquo;: \u0026ldquo;world\u0026rdquo;, \u0026ldquo;pi\u0026rdquo;: 3.14159}. bosun.A type A []interface{} // An A is an ordered representation of a BSON array. // // Example usage: // // bson.A{\u0026ldquo;bar\u0026rdquo;, \u0026ldquo;world\u0026rdquo;, 3.14159, bson.D{{\u0026ldquo;qux\u0026rdquo;, 12345}}} 设置某个字段的值\n1setValue := bson.E{Key: \u0026#34;$set\u0026#34;, Value: bson.D{{\u0026#34;end_at\u0026#34;, alert.CreatedAt}}}) 2 ? bson.E{Key: \u0026#34;$set\u0026#34;, Value: bson.D{{\u0026#34;end_at\u0026#34;, alert.CreatedAt}}}) 3\tupdate = append(update, bson.E{Key: \u0026#34;$inc\u0026#34;, Value: bson.D{bson.E{Key:\u0026#34;count\u0026#34;, Value: 1}}}) filter 1filter = make(bson.D, 0) 2filter = $or 1{\u0026#34;key1\u0026#34;:1,\u0026#34;$or\u0026#34;:[{\u0026#34;key2\u0026#34;:2},{\u0026#34;key3\u0026#34;:2}] 1filter:= bson.D{ 2 {\u0026#34;key1\u0026#34;,1}, 3 {\u0026#34;$or\u0026#34;:[]interface{ 4 bson.M{\u0026#34;key2\u0026#34;:2}, 5 bson.M{\u0026#34;key3\u0026#34;:2}, 6 }} 7} The query should be equivalent to the following in the mongo console\n1db.mycollection.find{{\u0026#34;key1\u0026#34;:1,\u0026#34;$or\u0026#34;:[{\u0026#34;key2\u0026#34;:2},{\u0026#34;key3\u0026#34;:2}]}} if you\u0026rsquo;d rather wish to use unordered maps, it would be like this\n1pipeline := bson.M{ 2 \u0026#34;key1\u0026#34;:1; 3 \u0026#34;$or\u0026#34;:[]interface{ 4 bson.M{\u0026#34;key2\u0026#34;:2}, 5 bson.M{\u0026#34;key3\u0026#34;:2}, 6 } 7} other example\n1findQuery := bson.M{ 2 \u0026#34;key1\u0026#34;:1, 3} 4 5orQuery:= []bson.M{} 6orQuery= append(orQuery, bson.M{\u0026#34;key2\u0026#34;:2}, bson.M{\u0026#34;key3\u0026#34;:2}) 7 8findquery[\u0026#34;$or\u0026#34;] = orQuery 9result := []interface{} 10err := mongo.DB.C(\u0026#34;collectionName\u0026#34;).find(findQuery).All(\u0026amp;result) ","date":"August 17, 2020","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/component/DataBase/mongo/mongo_go_sdk/","summary":"mongo 基本数据类型 Type bosun.E type E struct { Key string Value interface{} } E represents a BSON element for a D. It is usually used inside a D. bosun.D type D []E D is an ordered representation of a BSON document. This type should be used when the order of the elements matters, // such as MongoDB command documents. If the order of the elements does not matter, an M should be used instead.","tags":["Mongo"],"title":"「Mongo」Mongo golang sdk"},{"categories":null,"contents":"RRD(Round Robin Database) RRD 数据库在创建的时候就已经定义好了大小，当存储空间满了之后，又从头开始覆盖旧的数据，适用于存储和时间序列相关的数据。RRD的大小可控，且不用维护。\nA specialized storage system known as a Round Robin Database allows one to store large amounts of series information such as temperatures, network bandwidth, and stock prices with a constant disk footprint. It does this by taking advantage of changing needs for precision. As we will see later, the \u0026ldquo;round-robin \u0026quot; part comes from the basic data structure used to store data points: circular lists.\n参考资料：\n[https://jawnsy.wordpress.com/2010/01/08/round-robin-databases/#:~:text=A%20specialized%20storage%20system%20known,of%20changing%20needs%20for%20precision.](https://jawnsy.wordpress.com/2010/01/08/round-robin-databases/#:~:text=A specialized storage system known,of changing needs for precision.)\nhttps://www.docs4dev.com/docs/zh/opentsdb/2.3/reference/api_http-query-index.html\n","date":"August 10, 2020","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/component/TimeSeries/tsdb_argot/","summary":"RRD(Round Robin Database) RRD 数据库在创建的时候就已经定义好了大小，当存储空间满了之后，又从头开始覆盖旧的数据，适用于存储和时间序列相关的数据。RRD的大小可控，且不用维护。\nA specialized storage system known as a Round Robin Database allows one to store large amounts of series information such as temperatures, network bandwidth, and stock prices with a constant disk footprint. It does this by taking advantage of changing needs for precision. As we will see later, the \u0026ldquo;round-robin \u0026quot; part comes from the basic data structure used to store data points: circular lists.","tags":["TSDB"],"title":"「TSDB」术语"},{"categories":null,"contents":"思想和身体至少有一个在路上\n不要做一个行尸走肉\n如果一件事做不到100分，那和没做有什么分别\n抬头看路，低头做事\n","date":"August 9, 2020","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/life/nice_day/","summary":"思想和身体至少有一个在路上\n不要做一个行尸走肉\n如果一件事做不到100分，那和没做有什么分别\n抬头看路，低头做事","tags":[""],"title":"「坚持」 做好每一件事"},{"categories":null,"contents":"用户和用户组 groups 1groups \u0026lt;user1\u0026gt; \u0026lt;user2\u0026gt; \u0026lt;user3\u0026gt; # 查看当前用户所属的用户组 ","date":"August 9, 2020","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/linux/user/","summary":"用户和用户组 groups 1groups \u0026lt;user1\u0026gt; \u0026lt;user2\u0026gt; \u0026lt;user3\u0026gt; # 查看当前用户所属的用户组 ","tags":[""],"title":"「Linux」 user"},{"categories":null,"contents":"Hexo 安装 https://hexo.io/zh-cn/docs/\n安装Node.js\n安装Git\n安装Hexo\n1sudo npm install -g hexo-cli 如果在mac中安装报/usr/lib/node_modules/的操作权限问题，执行以下命令。\n1sudo chown -R `whoami` /usr/local/lib/node_modules 初始化项目\n1hexo init blog 创建完成后，当前目录下会有一个xx_blog的文件夹，具体的文件夹查询官网hexo.io\nHexo 部署到Nginx \u0026amp; Github.io 开发机 在自己写Blog的Pc上安装插件\n1yarn add hexo-deployer-git 服务器 在即将部署的服务器上执行以下操作\n1yum install git 2 3useradd -m git # 创建一个git用户，用来运行git服务 4 # 新建git用户并非必要，但是为了安全起见，还是用git用户单独来运行git服务 5 6passwd git 设置PC到服务器的git用户免密登录\n1# 生成ssh密钥 2ssh-keygen 3# 将公钥添加到server 4ssh-copy-id git@serverIp 在服务器上初始化一个Git仓库\n1mkdir -p /var/repo 2ca /var/repo 3git init --bare blog.git # --bare 初始化一个裸仓库，裸仓库没有工作区，只为共享而存在 4chown -R git:git blog.git ​ 配置Git hooks\n1mkdir /var/repo/blog.git/hooks 2vi post-receive ​ 写入以下内容\n1#!/bin/sh 2git --work-tree=/var/www/blog --git-dir=/home/git/byte_gopher_blog.git checkout -f 3# /var/www/blog 是部署目录。 每次push完成之后 ​ 增加可执行权限\n1chmod +x /var/repo/blog.git/hooks/post-receive 禁用git用户的shell登录权限\n1vi /etc/passwd 2# git❌1001:1001:,,,:/home/git:/bin/bash 3 git❌1001:1001:,,,:/home/git:/usr/bin/git-shell 最后再禁用\n部署nginx\n创建需要的代理文件夹\n1mkdir -p /home/www/hexo #创建目录 2chown -R git:git /home/www/hexo # 增加git用户权限 修改nginx配置/etc/nginx/nginx.conf\n1 server { 2 listen 80 default_server; 3 listen [::]:80 default_server; 4 server_name _; 5 root /home/www/hexo; 6 7 include /etc/nginx/default.d/*.conf; 8 9 location / { 10 } 11 12 error_page 404 /404.html; 13 location = /40x.html { 14 } 15 16 error_page 500 502 503 504 /50x.html; 17 location = /50x.html { 18 } 19 } 配置hexo _config.yml\n1# URL 2## If your site is put in a subdirectory, set url as \u0026#39;http://yoursite.com/child\u0026#39; and root as \u0026#39;/child/\u0026#39; 3url: https://www.bytegopher.com # 为了避免不必要的麻烦此处设置根域名 \u0026amp; 根目录 4root: / 5 6# Deployment branch: gh-pages # branch name, whaterver\n发布Blog\n写完博客之后直接发布就可以更新到Nginx服务器\u0026amp; Github.io\n1hexo clean \u0026amp; hexo d -g ?\nConfig md conf 1title: Hello Hexo！ 2layout: post 3subtitle: \u0026#34;hello word, welcome\u0026#34; 4date: 2020-07-26 01:09:53 5author: \u0026#34;Airren\u0026#34; 6catalog: true 7header-img: \u0026#34;post-bg-js-module.jpg\u0026#34; 8tags: 9 - Life _config.yml 1# Hexo Configuration 2## Docs: https://hexo.io/docs/configuration.html 3## Source: https://github.com/hexojs/hexo/ 4 5# Site 6title: ByteGopher 7subtitle: To Be A Lean Developer! 8author: Airren 9language: en 10timezone: Asia/Shanghai 11 12# URL 13## If your site is put in a subdirectory, set url as \u0026#39;http://yoursite.com/child\u0026#39; and root as \u0026#39;/child/\u0026#39; 14url: https://www.bytegopher.com 15root: / 16permalink: :year/:month/:day/:title/ 17permalink_defaults: 18 19#Custom Setting Start 20 21# Site settings 22SEOTitle: ByteGopher | Airren 23header-img: img/home-bg.jpg 24email: renqiqiang@outlook.com 25description: \u0026#34;ByteGopher\u0026#34; 26keyword: \u0026#34;ByteGopher, Airren\u0026#34; 27 28 29# SNS settings 30# RSS: false 31# weibo_username: Demonbane 32# zhihu_username: Demonbane 33github_username: Airren 34twitter_username: Airrenz 35facebook_username: Airrenz 36linkedin_username: 强-任-b8a3b4103 37 38# Build settings 39anchorjs: true # if you want to customize anchor. check out line:181 of `post.html` 40 41 42# Disqus settings 43disqus_username: bytegopher 44 45# Duoshuo settings 46# duoshuo_username: kaijun 47# Share component is depend on Comment so we can NOT use share only. 48# duoshuo_share: true # set to false if you want to use Comment without Sharing 49 50 51# Analytics settings 52# Baidu Analytics 53ba_track_id: 4cc1f2d8f3067386cc5cdb626a202900 54# Google Analytics 55ga_track_id: \u0026#39;UA-49627206-1\u0026#39; # Format: UA-xxxxxx-xx 56ga_domain: bytegopher.com 57 58 59# Sidebar settings 60sidebar: true # whether or not using Sidebar. 61sidebar-about-description: \u0026#34;Hi, welcome!\u0026#34; 62sidebar-avatar: ./img/avatar.jpg # use absolute URL, seeing it\u0026#39;s used in both `/` and `/about/` 63 64 65# Featured Tags 66featured-tags: true # whether or not using Feature-Tags 67featured-condition-size: 1 # A tag will be featured if the size of it is more than this condition value 68 69 70# Friends 71friends: [ 72 { 73 title: \u0026#34;Kaijun\u0026#39;s Blog\u0026#34;, 74 href: \u0026#34;http://blog.kaijun.rocks\u0026#34; 75 },{ 76 title: \u0026#34;Hux Blog\u0026#34;, 77 href: \u0026#34;http://huangxuan.me\u0026#34; 78 }, 79] 80 81 82#Custom Setting End 83 84 85 86# Directory 87source_dir: source 88public_dir: public 89tag_dir: tags 90archive_dir: i_dont_wanna_use_default_archives 91category_dir: categories 92code_dir: downloads/code 93i18n_dir: :lang 94skip_render: 95 96# Writing 97new_post_name: :title.md # File name of new posts 98default_layout: post 99titlecase: false # Transform title into titlecase 100external_link: true # Open external links in new tab 101filename_case: 0 102render_drafts: false 103post_asset_folder: true 104relative_link: false 105future: true 106highlight: 107 enable: true 108 line_number: true 109 auto_detect: true 110 tab_replace: 111 112# Category \u0026amp; Tag 113default_category: uncategorized 114category_map: 115tag_map: 116 117# Date / Time format 118## Hexo uses Moment.js to parse and display date 119## You can customize the date format as defined in 120## http://momentjs.com/docs/#/displaying/format/ 121date_format: YYYY-MM-DD 122time_format: HH:mm:ss 123 124# Pagination 125## Set per_page to 0 to disable pagination 126per_page: 10 127pagination_dir: page 128 129# Extensions 130## Plugins: https://hexo.io/plugins/ 131## Themes: https://hexo.io/themes/ 132theme: huxblog 133 134# Deployment 135## Docs: https://hexo.io/docs/deployment.html 136deploy: 137 type: git 138 repo: 139 github: https://github.com/Airren/airren.github.io 140 alios: git@hongkong:/home/git/blog.git 141 branch: gh-pages 142 143index_generator: 144 per_page: 3 ##首頁默认10篇文章标题 如果值为0不分页 145archive_generator: 146 per_page: 10 ##归档页面默认10篇文章标题 147 yearly: true ##生成年视图 148 monthly: true ##生成月视图 149tag_generator: 150 per_page: 10 ##标签分类页面默认10篇文章 151category_generator: 152 per_page: 10 ###分类页面默认10篇文章 Hexo Write Page 1hexo new page --path about/me \u0026#34;About me\u0026#34; 1INFO Created: ~/Desktop/ByteGopher/airren_blog/source/about/me.md Post 1hexo new post -p web/https_tips \u0026#34;HTTPS Tips\u0026#34; 1INFO Created: ~/Desktop/ByteGopher/airren_blog/source/_posts/web/https_tips.md reference：\nhttps://xdlrt.github.io/2016/02/18/2016-02-18/ https://www.lagou.com/lgeduarticle/40391.html https://juejin.im/post/5ab47e48f265da23805991dc https://blog.csdn.net/weixin_42646103/article/details/105181586?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param\u0026depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param https://zhuanlan.zhihu.com/p/158678677 https://oakland.github.io/2016/05/02/hexo-%E5%A6%82%E4%BD%95%E7%94%9F%E6%88%90%E4%B8%80%E7%AF%87%E6%96%B0%E7%9A%84post/ https://www.jianshu.com/p/e20deec143b1\n参考资料\nhttps://www.jianshu.com/p/e1ccd49b4e5d\n","date":"August 7, 2020","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/tips/hexo_create/","summary":"Hexo 安装 https://hexo.io/zh-cn/docs/\n安装Node.js\n安装Git\n安装Hexo\n1sudo npm install -g hexo-cli 如果在mac中安装报/usr/lib/node_modules/的操作权限问题，执行以下命令。\n1sudo chown -R `whoami` /usr/local/lib/node_modules 初始化项目\n1hexo init blog 创建完成后，当前目录下会有一个xx_blog的文件夹，具体的文件夹查询官网hexo.io\nHexo 部署到Nginx \u0026amp; Github.io 开发机 在自己写Blog的Pc上安装插件\n1yarn add hexo-deployer-git 服务器 在即将部署的服务器上执行以下操作\n1yum install git 2 3useradd -m git # 创建一个git用户，用来运行git服务 4 # 新建git用户并非必要，但是为了安全起见，还是用git用户单独来运行git服务 5 6passwd git 设置PC到服务器的git用户免密登录\n1# 生成ssh密钥 2ssh-keygen 3# 将公钥添加到server 4ssh-copy-id git@serverIp 在服务器上初始化一个Git仓库\n1mkdir -p /var/repo 2ca /var/repo 3git init --bare blog.git # --bare 初始化一个裸仓库，裸仓库没有工作区，只为共享而存在 4chown -R git:git blog.","tags":["Hexo"],"title":"「Hexo」 搭建部署"},{"categories":null,"contents":"HBase 简介 OpensTSDB支持多种底层存储，例如HBase、Cassandra。\nHBase是分布式列存储系统，其底层依赖HDFS分布式文件系统。HBase是参考Google BigTable模型开发的，本质上是一个典型的KV存储，适用于海量结构化数据的存储。\nHBase的优点：\n集群部署，横向扩展方便 容错性高，相同的数据会复制多份，放到不同的节点上 同等硬件，相比传统数据库支持的数量级高 吞吐能力强，写入量高 不足：\n只支持单行的事务 查询方式： 只能通过RowKey进行查询或者扫描 HBase 和HDFS的关系？ 全面事务 ","date":"August 7, 2020","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/component/TimeSeries/hbase_introduction/","summary":"HBase 简介 OpensTSDB支持多种底层存储，例如HBase、Cassandra。\nHBase是分布式列存储系统，其底层依赖HDFS分布式文件系统。HBase是参考Google BigTable模型开发的，本质上是一个典型的KV存储，适用于海量结构化数据的存储。\nHBase的优点：\n集群部署，横向扩展方便 容错性高，相同的数据会复制多份，放到不同的节点上 同等硬件，相比传统数据库支持的数量级高 吞吐能力强，写入量高 不足：\n只支持单行的事务 查询方式： 只能通过RowKey进行查询或者扫描 HBase 和HDFS的关系？ 全面事务 ","tags":["Hbase"],"title":"「HBase」 简介"},{"categories":null,"contents":"Test Test 1go test --bench ./ 5s Code coverage 1go test -cover Profile 引发性能问题的原因，=执行时间过长、内存占用过多，以及意外堵塞。\n在测试时保存并输出相关数据，进行初次评估 在运行阶段通过web接口获得实时数据，分析一段时间内的健康状况 1go test -run NONE -bench . -memprofile mem.out -cpuprofile cpu.out net/http 服务开启debug 端口\n1go tool pprof http://10.152.50.69:9452/debug/pprof/profile\\?second\\=60 -alloc_space\npprof 常用指令\nWeb\n","date":"August 6, 2020","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/note_go/11_go_testprofile/","summary":"Test Test 1go test --bench ./ 5s Code coverage 1go test -cover Profile 引发性能问题的原因，=执行时间过长、内存占用过多，以及意外堵塞。\n在测试时保存并输出相关数据，进行初次评估 在运行阶段通过web接口获得实时数据，分析一段时间内的健康状况 1go test -run NONE -bench . -memprofile mem.out -cpuprofile cpu.out net/http 服务开启debug 端口\n1go tool pprof http://10.152.50.69:9452/debug/pprof/profile\\?second\\=60 -alloc_space\npprof 常用指令\nWeb","tags":null,"title":"「Go」pprof"},{"categories":null,"contents":"UNIX 时间戳 Unix时间戳（英文为Unix epoch, Unix time, POSIX time 或 Unix timestamp）是指格林威治时间1970年01月01日00时00分00秒(北京时间1970年01月01日08时00分00秒)起至现在的总秒数。\n类型 位数 Timestamp Time 秒级 10 1596646807 2020-08-06 01:00:07 毫秒级 13 1596646807000 2020-08-06 01:00:07 Unix时间戳（英文为Unix epoch, Unix time, POSIX time 或 Unix timestamp）\n是从1970年1月1日（UTC/GMT的午夜）开始所经过的秒数，不考虑闰秒。\n","date":"August 6, 2020","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/note_go/5.3go_time/","summary":"UNIX 时间戳 Unix时间戳（英文为Unix epoch, Unix time, POSIX time 或 Unix timestamp）是指格林威治时间1970年01月01日00时00分00秒(北京时间1970年01月01日08时00分00秒)起至现在的总秒数。\n类型 位数 Timestamp Time 秒级 10 1596646807 2020-08-06 01:00:07 毫秒级 13 1596646807000 2020-08-06 01:00:07 Unix时间戳（英文为Unix epoch, Unix time, POSIX time 或 Unix timestamp）\n是从1970年1月1日（UTC/GMT的午夜）开始所经过的秒数，不考虑闰秒。","tags":["Go"],"title":"「Go」时间"},{"categories":null,"contents":"什么是HTTPS 申请免费SSL 七牛云免费SSL申请 Nginx 部署设置https vi /etc/nginx/nginx.conf\n1 server { 2 listen 443 ssl http2 default_server; 3 listen [::]:443 ssl http2 default_server; 4 server_name www.bytegopher.com; # bind the domain name 5 root /var/www/hexo; 6 index index.html index.htm; 7 8 ssl_certificate /etc/nginx/bytegopher.com/bytegopher.com.crt; # absolute path of certificate 9 ssl_certificate_key /etc/nginx/bytegopher.com/bytegopher.com.key; # absolute path of certificate 10 ssl_session_timeout 5m; 11 ssl_protocols TLSv1.1 TLSv1.2; 12 ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4:!DH:!DHE; 13 ssl_prefer_server_ciphers on; 14 15 # Load configuration files for the default server block. 16 include /etc/nginx/default.d/*.conf; 17 18 19 error_page 404 /404.html; 20 location = /40x.html { 21 } 22 23 error_page 500 502 503 504 /50x.html; 24 location = /50x.html { 25 } 26 } 27 28 # 如果是http请求则自动转换为https 29 server { 30 listen 80; 31 server_name www.bytegopher.com; 32 rewrite ^(.*) https://$server_name$1 permanent; 33 } SSL 状态检测 状态检测 如何查看一个网站的非https请求 chrome 调试模式的console 中会输出非https请求\n","date":"July 31, 2020","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/blog/https_tips/","summary":"什么是HTTPS 申请免费SSL 七牛云免费SSL申请 Nginx 部署设置https vi /etc/nginx/nginx.conf\n1 server { 2 listen 443 ssl http2 default_server; 3 listen [::]:443 ssl http2 default_server; 4 server_name www.bytegopher.com; # bind the domain name 5 root /var/www/hexo; 6 index index.html index.htm; 7 8 ssl_certificate /etc/nginx/bytegopher.com/bytegopher.com.crt; # absolute path of certificate 9 ssl_certificate_key /etc/nginx/bytegopher.com/bytegopher.com.key; # absolute path of certificate 10 ssl_session_timeout 5m; 11 ssl_protocols TLSv1.1 TLSv1.2; 12 ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4:!DH:!DHE; 13 ssl_prefer_server_ciphers on; 14 15 # Load configuration files for the default server block.","tags":["HTTPS"],"title":"「HTTPS」 Tips"},{"categories":null,"contents":"搭建静态资源服务器 静态资源文件夹\n1/root/file Nginx 配置\nvi /etc/nginx/nginx.conf\n1location /file { # 这个file 跟资源路径的名字没有半毛钱关系，可以不同 2\talias /root/file; # 静态资源的绝对路径 3\tautoindex on; # 自动创建目录 4} 为了提高文件的传输效率，降低带宽浪费，可以开启gzip压缩\n1gzip on; 2gzip_minPlength 1; # 小于1字节不压缩， 3gzip_comp_level 2; # 压缩级别为2 4gzip_types taxt/plain applicaton/x-javascripts txt/css application/xml image/jpeg image/gif image/png; # 压缩文件类型 重启nginx服务\n1nginx -s reload 2# or 3systemctl restart nginx.service 通过浏览器访问资源\n此时还有很多小伙伴大概率会遇到403 Forbidden， 试过将资源文件夹设置为777 -R 权限或者chown -R nginx:nginx file。But, still doesn\u0026rsquo;r work。\n目前的解决方法是将/etc/nginx/nginx.conf 中的user 设置为root 。\n1# user nginx 2user root ","date":"July 31, 2020","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/blog/nginx_tips/","summary":"搭建静态资源服务器 静态资源文件夹\n1/root/file Nginx 配置\nvi /etc/nginx/nginx.conf\n1location /file { # 这个file 跟资源路径的名字没有半毛钱关系，可以不同 2\talias /root/file; # 静态资源的绝对路径 3\tautoindex on; # 自动创建目录 4} 为了提高文件的传输效率，降低带宽浪费，可以开启gzip压缩\n1gzip on; 2gzip_minPlength 1; # 小于1字节不压缩， 3gzip_comp_level 2; # 压缩级别为2 4gzip_types taxt/plain applicaton/x-javascripts txt/css application/xml image/jpeg image/gif image/png; # 压缩文件类型 重启nginx服务\n1nginx -s reload 2# or 3systemctl restart nginx.service 通过浏览器访问资源\n此时还有很多小伙伴大概率会遇到403 Forbidden， 试过将资源文件夹设置为777 -R 权限或者chown -R nginx:nginx file。But, still doesn\u0026rsquo;r work。\n目前的解决方法是将/etc/nginx/nginx.conf 中的user 设置为root 。","tags":["Nginx","Tips"],"title":"「Nginx」 Tips"},{"categories":null,"contents":"常用配置 vi ~/vimrc\n1set nu 2syntax on 3inoremap jj \u0026lt;ESC\u0026gt; # ues \u0026lt;jj\u0026gt; instead of \u0026lt;ESC\u0026gt; Vim 相关配置以及快捷键设置 .vimrc 1\u0026#34; Vim 的默认寄存器和系统剪贴板共享 2set clipboard+=unnamed 3\u0026#34; select模式下复制，文本选中时，按下Ctrl+C，即可复制 4if has(\u0026#34;clipboard\u0026#34;) 5 vnoremap \u0026lt;C-C\u0026gt; \u0026#34;+y 6endif 7 8set nu 9 10syntax on 11inoremap jj \u0026lt;ESC\u0026gt; vim模式 normal \u0026mdash;按v进入\u0026mdash;\u0026gt; visual\nnormal \u0026ndash;\u0026gt; instert\ninsert\ncommand\n快捷键 (normal) 移动 命令 功能 shift + 6 切换行首 shift + 4 切换到行尾 gg 跳转到首行行首 shift+g 跳转到末行行首 w 下一个单词 b 上一个单词 e 移动到词尾 删除 命令 功能 x 向后删除一个字符 X 向前删除一个字符 nx 连续向后删除n个字符 dd 删除当前行 ndd 删除光标所在的连续向下n行 d1G 删除光标所在到第一行所有的数据 dG 删除光标所在到最后一行的所有数据 dw 删除光标之后的单词剩余部分。 d$ 删除光标之后的该行剩余部分。 删除包含特定字符的行\n:g 表示 全文搜索字符串，然后在匹配的行上执行一个命令\n:%g/搜索的正则表达式/要执行的命令\n1# 删除包含abc的行 2:%g/abc/d 3 4# 删除不包含abc的行 5:%g!/abc/d 6# 删除不包含abc的行，未测试 7:v/abc/d 剪切 首先进入visual模式，可以使用 hjkl进行选择， 然后使用以下 命令操作\nv -\u0026gt; 进入普通 visual\nV（shift+v） -\u0026gt; 进入visual Line\nCtrl+v \u0026mdash;-\u0026gt; visual block， shift+i 块模式下插入\n命令 功能 d 剪切 y 复制 p 黏贴 ^ 选中当前行当行首 $ 选中当前行到行尾 复制 命令 功能 y visual 模式下复制 block yaw 复制光标所在的单词 yw 复制光标所在位置到当前单词结束 yy 复制当前行 nyy 复制光标所在的连续向下n行 y^ 复制当前到行首 y$ 复制当前到行尾 yG 复制到文档结尾（nyG，ynG）？ 粘贴 命令 功能 p 粘贴光标后(或者光标所在下一行) P 粘贴在光标前（或者光标所在上行） 编辑类指令 命令 功能 . 重复前一个动作 u 撤销前一个动作 Undo Ctrl + r 重做前一个动作 Redo 查找 在normal模式下按下/即可进入查找模式，输入要查找的字符串并按下回车。 Vim会跳转到第一个匹配。按下n查找下一个，按下N查找上一个。\nVim查找支持正则表达式，例如/vim$匹配行尾的\u0026quot;vim\u0026quot;。 需要查找特殊字符需要转义，例如/vim\\$匹配\u0026quot;vim$\u0026quot;。\n大小写敏感查找\n在查找模式中加入\\c表示大小写不敏感查找，\\C表示大小写敏感查找。例如：\n1/foo\\c 将会查找所有的\u0026quot;foo\u0026quot;,\u0026quot;FOO\u0026quot;,\u0026quot;Foo\u0026quot;等字符串。\n大小写敏感配置\nVim 默认采用大小写敏感的查找，为了方便我们常常将其配置为大小写不敏感：\n1\u0026#34; 设置默认进行大小写不敏感查找 2set ignorecase 3\u0026#34; 如果有一个大写字母，则切换到大小写敏感查找 4set smartcase 将上述设置粘贴到你的~/.vimrc，重新打开Vim即可生效\n查找当前单词\n在normal模式下按下*即可查找光标所在单词（word）， 要求每次出现的前后为空白字符或标点符号。例如当前为foo， 可以匹配foo bar中的foo，但不可匹配foobar中的foo。 这在查找函数名、变量名时非常有用。\n按下g*即可查找光标所在单词的字符序列，每次出现前后字符无要求。 即foo bar和foobar中的foo均可被匹配到。\n查找与替换 :s（substitute）命令用来查找和替换字符串。语法如下：\n1:{作用范围}s/{目标}/{替换}/{替换标志} 例如:%s/foo/bar/g会在全局范围(%)查找foo并替换为bar，所有出现都会被替换（g）\n作用范围\n作用范围分为当前行、全文、选区等等。\n当前行：\n1:s/foo/bar/g 全文：\n1:%s/foo/bar/g 选区，在Visual模式下选择区域后输入:，Vim即可自动补全为 :'\u0026lt;,'\u0026gt;。\n1:\u0026#39;\u0026lt;,\u0026#39;\u0026gt;s/foo/bar/g 2-11行：\n1:5,12s/foo/bar/g 当前行.与接下来两行+2：\n1:.,+2s/foo/bar/g 替换标志\n上文中命令结尾的g即是替换标志之一，表示全局global替换（即替换目标的所有出现）。 还有很多其他有用的替换标志：\n空替换标志表示只替换从光标位置开始，目标的第一次出现：\n1:%s/foo/bar i表示大小写不敏感查找，I表示大小写敏感：\n1:%s/foo/bar/i 2# 等效于模式中的\\c（不敏感）或\\C（敏感） 3:%s/foo\\c/bar c表示需要确认，例如全局查找\u0026quot;foo\u0026quot;替换为\u0026quot;bar\u0026quot;并且需要确认：\n1:%s/foo/bar/gc 回车后Vim会将光标移动到每一次\u0026quot;foo\u0026quot;出现的位置，并提示\n1replace with bar (y/n/a/q/l/^E/^Y)? 按下y表示替换，n表示不替换，a表示替换所有，q表示退出查找模式， l表示替换当前位置并退出。^E与^Y是光标移动快捷键\n翻页 整页翻页 ctrl-f ctrl-b f就是forword b就是backward\n翻半页 ctrl-d ctlr-u d=down u=up\n滚一行 ctrl-e ctrl-y\nzz 让光标所杂的行居屏幕中央 zt 让光标所杂的行居屏幕最上一行 t=top zb 让光标所杂的行居屏幕最下一行 b=bottom\n参考链接\nhttps://www.cnblogs.com/huxinga/p/7942194.html\nhttps://harttle.land/2015/11/07/vim-cursor.html\n","date":"July 31, 2020","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/blog/vim_tips/","summary":"常用配置 vi ~/vimrc\n1set nu 2syntax on 3inoremap jj \u0026lt;ESC\u0026gt; # ues \u0026lt;jj\u0026gt; instead of \u0026lt;ESC\u0026gt; Vim 相关配置以及快捷键设置 .vimrc 1\u0026#34; Vim 的默认寄存器和系统剪贴板共享 2set clipboard+=unnamed 3\u0026#34; select模式下复制，文本选中时，按下Ctrl+C，即可复制 4if has(\u0026#34;clipboard\u0026#34;) 5 vnoremap \u0026lt;C-C\u0026gt; \u0026#34;+y 6endif 7 8set nu 9 10syntax on 11inoremap jj \u0026lt;ESC\u0026gt; vim模式 normal \u0026mdash;按v进入\u0026mdash;\u0026gt; visual\nnormal \u0026ndash;\u0026gt; instert\ninsert\ncommand\n快捷键 (normal) 移动 命令 功能 shift + 6 切换行首 shift + 4 切换到行尾 gg 跳转到首行行首 shift+g 跳转到末行行首 w 下一个单词 b 上一个单词 e 移动到词尾 删除 命令 功能 x 向后删除一个字符 X 向前删除一个字符 nx 连续向后删除n个字符 dd 删除当前行 ndd 删除光标所在的连续向下n行 d1G 删除光标所在到第一行所有的数据 dG 删除光标所在到最后一行的所有数据 dw 删除光标之后的单词剩余部分。 d$ 删除光标之后的该行剩余部分。 删除包含特定字符的行","tags":["Tips","Vim"],"title":"「Vim」 Tips"},{"categories":null,"contents":"2020.06.21 上海 - 兰州 早上上海出发，下午16点到达兰州，然后到神州租车取上我们的战车——7座的科帕奇。虽然是七座，但是最后一排的空间小的可怜🤕。其实本来是想租一个霸道/路虎之类的，奈何第一次使用一嗨租车不让租高端车型。或许因为我们出游的时间是是个淡季，又或许是因为疫情的影响，这几天租车特别便宜。科帕奇只有360左右每天（含全险），现在看了一眼都600+每天了。同期的霸道只要600左右每天，现在1000+（没租上霸道感觉错过了一个亿）。\n开上战车，寻了个离机场最近的美食街吃个拉面，必须是地道的牛肉拉面，便奔向曹家堡机场去与小伙伴回合。200+ 公里伴随着晴雨莫测的天气开了大约两个半小时。\n夜宿西宁，吃肉去~\n2020.06.22 西宁-青海湖 青海湖，最大的盐水湖。门票太贵了，没有进景区，好像景区内也没啥可看的(滑稽)。在附近转了转，风景也不错，湖边的游客也很多，还和白牦牛拍了合照。\n有点阴天，云特别的低，但不像南方的阴雨天那样沉闷。空气中夹杂着山顶融化的雪水的气息。草地上点缀着些许的小黄花。\n2020.06.25 门源-达坂山 既当金山之后第二段难开的山路，九曲十八弯。\n达坂山观景台，收费5元/车。可以听停车休息一会。山顶的风甚是凛冽。\n","date":"July 28, 2020","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/life/graduated-travel/","summary":"2020.06.21 上海 - 兰州 早上上海出发，下午16点到达兰州，然后到神州租车取上我们的战车——7座的科帕奇。虽然是七座，但是最后一排的空间小的可怜🤕。其实本来是想租一个霸道/路虎之类的，奈何第一次使用一嗨租车不让租高端车型。或许因为我们出游的时间是是个淡季，又或许是因为疫情的影响，这几天租车特别便宜。科帕奇只有360左右每天（含全险），现在看了一眼都600+每天了。同期的霸道只要600左右每天，现在1000+（没租上霸道感觉错过了一个亿）。\n开上战车，寻了个离机场最近的美食街吃个拉面，必须是地道的牛肉拉面，便奔向曹家堡机场去与小伙伴回合。200+ 公里伴随着晴雨莫测的天气开了大约两个半小时。\n夜宿西宁，吃肉去~\n2020.06.22 西宁-青海湖 青海湖，最大的盐水湖。门票太贵了，没有进景区，好像景区内也没啥可看的(滑稽)。在附近转了转，风景也不错，湖边的游客也很多，还和白牦牛拍了合照。\n有点阴天，云特别的低，但不像南方的阴雨天那样沉闷。空气中夹杂着山顶融化的雪水的气息。草地上点缀着些许的小黄花。\n2020.06.25 门源-达坂山 既当金山之后第二段难开的山路，九曲十八弯。\n达坂山观景台，收费5元/车。可以听停车休息一会。山顶的风甚是凛冽。","tags":null,"title":"「毕业旅行」青甘自驾"},{"categories":null,"contents":"遇见你是最美好的开始 未来的我们会过的更好 世间美好 与你我环环相扣 https://themify.me/themify-icons https://themes.gohugo.io/dot-hugo-documentation-theme/\n","date":"December 29, 2018","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/life/married/","summary":"遇见你是最美好的开始 未来的我们会过的更好 世间美好 与你我环环相扣 https://themify.me/themify-icons https://themes.gohugo.io/dot-hugo-documentation-theme/","tags":null,"title":"「Love」我们结婚了"},{"categories":null,"contents":"CAP定律 CAP 按照美国著名科学家 Eric Brewer 在 2000 年提出的理论，当技术架构从集中式架构向分布式架构演进，会遇到 “CAP 定律”的瓶颈。 CAP 说明一个数据处理系统不能同时满足一致性，可用性和分区容错性这三个需求。\nCAP永远不可能同时满足，最多只能同时满足两个，提高其中任意两者的同时，必然要牺牲第三者。 所以，好的系统是根据具体应用，来决定如何在三者之间进行取舍。\n####Consistency 一致性—— 读操作是否总能读到前一个写操作的结果，即是说在分布式环境中，多点读出的数据内容是否相容。 ####Partition Tolerance* 分区容错性——数据的分区特性，对系统性能的影响程度 ####Availiability 可用性——访问数据的性能\nhttps://www.cnblogs.com/frank2015/p/9554180.html\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/6.824/CAP%E5%AE%9A%E5%BE%8B/","summary":"CAP定律 CAP 按照美国著名科学家 Eric Brewer 在 2000 年提出的理论，当技术架构从集中式架构向分布式架构演进，会遇到 “CAP 定律”的瓶颈。 CAP 说明一个数据处理系统不能同时满足一致性，可用性和分区容错性这三个需求。\nCAP永远不可能同时满足，最多只能同时满足两个，提高其中任意两者的同时，必然要牺牲第三者。 所以，好的系统是根据具体应用，来决定如何在三者之间进行取舍。\n####Consistency 一致性—— 读操作是否总能读到前一个写操作的结果，即是说在分布式环境中，多点读出的数据内容是否相容。 ####Partition Tolerance* 分区容错性——数据的分区特性，对系统性能的影响程度 ####Availiability 可用性——访问数据的性能\nhttps://www.cnblogs.com/frank2015/p/9554180.html","tags":null,"title":""},{"categories":null,"contents":"LXC Set proxy\n1sudo lxc config set core.proxy_https http://username:password@\u0026lt;IP\u0026gt;:\u0026lt;port\u0026gt;/ LXC\nhttps://www.linode.com/docs/guides/beginners-guide-to-lxd-reverse-proxy/\nhttps://www.digitalocean.com/community/tutorials/how-to-install-and-configure-lxd-on-ubuntu-20-04\nSDEWAN - direct connect Edge-1\n1# PREROUTTING 2sudo iptables -I PREROUTING -d 10.10.70.49/32 -p tcp -m tcp --dport 6443 -j DNAT --to-destination 10.96.0.1:443 -t nat Hub\n1# PREROUTTING 2 3sudo iptables -I PREROUTING --destination 10.95.62.68/32 -p esp -j DNAT --to-destination 10.233.108.10 -t nat 4sudo iptables -I PREROUTING --destination 10.95.62.68/32 -p udp --dport 4500 -j DNAT --to-destination 10.233.108.10:4500 -t nat 5sudo iptables -I PREROUTING --destination 10.95.62.68/32 -p udp --dport 500 -j DNAT --to-destination 10.233.108.10:500 -t nat 6 7 8 9 10 11sudo iptables -I PREROUTING --destination 10.95.62.119/32 -p esp -j DNAT --to-destination 10.233.65.140 -t nat 12sudo iptables -I PREROUTING --destination 10.95.62.119/32 -p udp --dport 4500 -j DNAT --to-destination 10.233.65.140:4500 -t nat 13sudo iptables -I PREROUTING --destination 10.95.62.119/32 -p ud --dport 500 -j DNAT --to-destination 10.233.65.140:500 -t nat 14 15sudo iptables -I PREROUTING --destination 10.95.62.119/32 -p tcp --dport 4500 -j DNAT --to-destination 10.233.65.140:4500 -t nat 16sudo iptables -I PREROUTING --destination 10.95.62.119/32 -p tcp --dport 500 -j DNAT --to-destination 10.233.65.140:500 -t nat 17 18 19 20 21sudo iptables -D POSTROUTING -d 10.154.142.12/32 -j SNAT --to-source 10.154.142.7 -t nat 22 23sudo iptables -I POSTROUTING -d 192.168.0.8/32 -j SNAT --to-source 10.20.0.118 -t nat 24 25sudo iptables -I POSTROUTING -d 10.20.0.118/32 -j SNAT --to-source 192.169.0.4 -t nat 26 27 28192.169.0.4/32 === 10.20.0.118/32 remove mark of the client\n1# modify config new nodus with sdewan -\u0026gt; test failed -\u0026gt; test host direct mode 4 1 2conn localtodevice1-Conndevice1 3 left=192.168.0.1 4 right=%any 5 leftsubnet=192.168.0.1/32 6 rightsourceip=192.168.0.5 7 rightsubnet=192.168.0.5/32 8 ikelifetime=3h 9 lifetime=1h 10 margintime=9m 11 keyingtries=%forever 12 dpdaction=restart 13 dpddelay=30s 14 leftauth=pubkey 15 rightauth=pubkey 16 leftcert=/etc/ipsec.d/certs/localtodevice1_public.pem 17 leftsendcert=yes 18 rightsendcert=yes 19 auto=start 20 leftid=\u0026#34;CN=sdewan-controller-base\u0026#34; 21 rightid=\u0026#34;CN=device-device-1-cert\u0026#34; 22 leftupdown=/etc/updown 23 keyexchange=ikev2 24 mark=30 25 esp=aes128-sha256-modp3072,aes256-sha256-modp3072 26 ike=aes128-sha256-modp3072,aes256-sha256-modp3072 27 type=tunnel 1conn localtodevice1-Conndevice1 2 left=%any 3 right=10.95.62.217 4 rightsubnet=192.168.0.1/32 5 # rightsubnet=10.233.108.12/32 6 leftsourceip=%config 7 ikelifetime=3h 8 lifetime=1h 9 margintime=9m 10 keyingtries=%forever 11 dpdaction=restart 12 dpddelay=30s 13 leftauth=pubkey 14 rightauth=pubkey 15 leftcert=/etc/ipsec.d/certs/localtodevice1_public.pem 16 leftsendcert=yes 17 rightsendcert=yes 18 auto=start 19 leftid=\u0026#34;CN=device-device-1-cert\u0026#34; 20 rightid=\u0026#34;CN=sdewan-controller-base\u0026#34; 21 leftupdown=/usr/lib/ipsec/_updown iptables 22 keyexchange=ikev2 23 esp=aes128-sha256-modp3072,aes256-sha256-modp3072 24 ike=aes128-sha256-modp3072,aes256-sha256-modp3072 25 type=tunnel ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/blog/multipass_network/","summary":"LXC Set proxy\n1sudo lxc config set core.proxy_https http://username:password@\u0026lt;IP\u0026gt;:\u0026lt;port\u0026gt;/ LXC\nhttps://www.linode.com/docs/guides/beginners-guide-to-lxd-reverse-proxy/\nhttps://www.digitalocean.com/community/tutorials/how-to-install-and-configure-lxd-on-ubuntu-20-04\nSDEWAN - direct connect Edge-1\n1# PREROUTTING 2sudo iptables -I PREROUTING -d 10.10.70.49/32 -p tcp -m tcp --dport 6443 -j DNAT --to-destination 10.96.0.1:443 -t nat Hub\n1# PREROUTTING 2 3sudo iptables -I PREROUTING --destination 10.95.62.68/32 -p esp -j DNAT --to-destination 10.233.108.10 -t nat 4sudo iptables -I PREROUTING --destination 10.95.62.68/32 -p udp --dport 4500 -j DNAT --to-destination 10.233.108.10:4500 -t nat 5sudo iptables -I PREROUTING --destination 10.","tags":null,"title":""},{"categories":null,"contents":"Service Mesh 浅析\nIstio的自我救赎\nhttps://github.com/cloudnativebooks/cloud-native-istio/tree/master/chapter-files/security\n云原生架构的三驾马车\nKubenetes， Service Mesh , Serverless\nServcie Mesh 超时重试\n16年概念提出。\n技术选型？\nServiceMesh 的相关概念\nService Mesh的起源\n微服务架构的特性\n围绕业务构建团队 康威定律-\u0026gt; 团队结构决定了产品结构\n去中心化的数据管理\n团队层面： 内聚，独立业务开发，没有依赖\n产品层面： 服务彼此独立，独立部署，没有依赖\n访问量决定部署实例的数量\n银弹理论-\u0026gt; 人月神话 没有任何一种技术可以完美的解决软件开发中的问题。\n空间换时间 or 时间换空间\n微服务架构带来的缺点\n服务间网络通信问题\n分布式计算的8个谬论\n网络是可靠的 网络延时是0 很难会把网络相关的需求考虑到我们的设计中。分布式系统中，网络问题是一个重要问题。\n如何管理和控制网络通信\n辅助注册、发现\n路由，流量转移\n弹性能力 熔断超时重试\n安全\n可观测性\nPatten： Service Mesh\n阶段一： 控制逻辑与业务逻辑耦合\n阶段二： 公共库：流控，重试 （人力，时间学习，语言蚌绑定，平台相关，代码侵入）\n阶段三：代理模式， 功能简陋Nginx\n阶段四： Sidecar 模式 2013-2105\n阶段五： Service Mesh 2016-2017\n​ Service MeshV2 2018\n《What\u0026rsquo;s service mesh? And why do I need one?》\nData plane\nService Mesh产生的原因\nService Mesh的核心功能\nIstio\n流量控制 路由，熔断，超时重试\n安全\n可观测性\nService Mesh 的主要功能\n流量控制： 路由， 流量转移，超时重试，熔断， 故障注入， 流量镜像\n策略： 流量限制， 黑白名单\n网络安全：授权以及身份认证\n可观测性： 指标手机和展示，日志收集， 分布式追踪\nKubernetes：\n解决容器编排与调度问题， 本质上是管理应用生命周期， 调度器\nIngress ？k\nServcie Mesh:\n解决服务网络通信问题，本质上是管理服务通信(代理)\n标准\nUDPA（Universal Data Plane API） 统一的数据平面API\nenvoy\nCloud Native Computing Foundation\n应用层-\u0026gt; SMI-\u0026gt; 控制平面 -\u0026gt; UDPA-\u0026gt; 数据平面\nSMI(Service Mesh Interface)\nenvoy xDS 协议\nAWS： app mesh\nIstio 入门 Istio 是一个完全开源的服务网格， 作为透明的一怎\n服务网格产品\nIstio 希腊语，杨帆起航\nkubernetes 希腊语，舵手\n数据平面，控制平面\nlyft ？\n轻松构建服务网格，\n灰度发布\n蓝绿部署\nAB测试\n流量 安全 策略 可观测性\nMixer 废弃，转移到envoy中\nGoogle ： Istio, gRPC，Kubernetes\n性能问题加重\n易用性\n解耦 要让步于 取舍\nMVP理论 《 精益创业》\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/cloudnative/Istio/1-Istio/","summary":"Service Mesh 浅析\nIstio的自我救赎\nhttps://github.com/cloudnativebooks/cloud-native-istio/tree/master/chapter-files/security\n云原生架构的三驾马车\nKubenetes， Service Mesh , Serverless\nServcie Mesh 超时重试\n16年概念提出。\n技术选型？\nServiceMesh 的相关概念\nService Mesh的起源\n微服务架构的特性\n围绕业务构建团队 康威定律-\u0026gt; 团队结构决定了产品结构\n去中心化的数据管理\n团队层面： 内聚，独立业务开发，没有依赖\n产品层面： 服务彼此独立，独立部署，没有依赖\n访问量决定部署实例的数量\n银弹理论-\u0026gt; 人月神话 没有任何一种技术可以完美的解决软件开发中的问题。\n空间换时间 or 时间换空间\n微服务架构带来的缺点\n服务间网络通信问题\n分布式计算的8个谬论\n网络是可靠的 网络延时是0 很难会把网络相关的需求考虑到我们的设计中。分布式系统中，网络问题是一个重要问题。\n如何管理和控制网络通信\n辅助注册、发现\n路由，流量转移\n弹性能力 熔断超时重试\n安全\n可观测性\nPatten： Service Mesh\n阶段一： 控制逻辑与业务逻辑耦合\n阶段二： 公共库：流控，重试 （人力，时间学习，语言蚌绑定，平台相关，代码侵入）\n阶段三：代理模式， 功能简陋Nginx\n阶段四： Sidecar 模式 2013-2105\n阶段五： Service Mesh 2016-2017\n​ Service MeshV2 2018","tags":null,"title":""},{"categories":null,"contents":"What is Service Mesh(服务网格) https://jimmysong.io/blog/why-do-you-need-istio-when-you-already-have-kubernetes/\nUPF\n2 次链接\n1 控制面 ip register step 1-4\nhub 公有网络直连接， 给edge pod分配全局IP，cluster api server CRD controller 监视CRs \u0026ndash;\u0026gt; kube cofig\n2 数据面\nhub-device connection\nhub 桥接\nIPSec configuration -\u0026gt; 2 次分发\nSNAT-\u0026gt; DNAT IP 地址可能重合\n测试环境部署 4 cluster\n物理机 4 nuc\n10.239.241.255 \u0026ndash; hub\nswitch 交换机\nkubectl get iphost\nkubectl describe iphost hubdevice1\nkubectl get\nspce:\npubkry\nconn_type\nproposal 加解密\nmark route base VPN\nmode: start\nremote_sourceIP: 虚拟IP\n私钥。公钥，CA\nremote： %any 接受所有外部链接\ntype: VTI-based\nIPsec -\u0026gt; Interface + policy\nkubectl describe\ncnf pod : openwrt 大部分网络 default pod\nSNET\nIPsec tunnel -》 点对点， 实际上应该是点对 域名\n路由 hub 路由正常的main table\nIP router、rule 、table\n自己配置一个表号， 某些情景下使用IP rule。\n所有的CR 类型，IPsec，firewall，\ntcpdump\nscc -》 overlay controller\nsdewan- system or default\nrsync -\u0026gt; deploy resource\nscc -\u0026gt; use rsync to deploy the CRs , 所有的call log，204，ok\nmongo 存储注册内容，\ntest-scc\nIPtables\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/cloudnative/Kubernates/k8s-Istio-Envoy/","summary":"What is Service Mesh(服务网格) https://jimmysong.io/blog/why-do-you-need-istio-when-you-already-have-kubernetes/\nUPF\n2 次链接\n1 控制面 ip register step 1-4\nhub 公有网络直连接， 给edge pod分配全局IP，cluster api server CRD controller 监视CRs \u0026ndash;\u0026gt; kube cofig\n2 数据面\nhub-device connection\nhub 桥接\nIPSec configuration -\u0026gt; 2 次分发\nSNAT-\u0026gt; DNAT IP 地址可能重合\n测试环境部署 4 cluster\n物理机 4 nuc\n10.239.241.255 \u0026ndash; hub\nswitch 交换机\nkubectl get iphost\nkubectl describe iphost hubdevice1\nkubectl get\nspce:\npubkry\nconn_type\nproposal 加解密\nmark route base VPN","tags":null,"title":""},{"categories":null,"contents":"","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/cloudnative/Linux/curl/","summary":"","tags":null,"title":""},{"categories":null,"contents":"TCP 的有限状态机\nCLOSED CLOSED\nSYN_SENT LISTENING\n​ SYN_RECEIVED\nESTABLISHED ESTABLISHED\nnetfilter: Frame\niptables: 数据报文过滤\n防火墙： 硬件/软件\n规则： 匹配标准和处理办法\n默认规则：\n​ 关闭\n匹配标准：\nIP:源IP， 目标IP\nTCP: SPORT, DPORT SYN=1,FIN=0,RST=0,ACK=0\nUDP:SPORT, DPORT\nICMP: icmp-type\n规则在内核空间\n内核空间的TCPIP的协议栈上，开放给用户空间中的iptables API。\n内核空间的工作框架：\n用户空间的管理工具： system call\n参考 openBSD\nLinux 2.0：ipfw/firewall\nLinux 2.2： ipchain/firewall Linux 2.4 ： iptables/netfilter\n1：07\n1/proc/sys/net/ipv4/ip_forward 路由决策发生在数据包到达网卡， 送到TCPIP协议栈上的那一刻。 然后先发生路由决策\nnetfilter 补充在tcp ip协议上的3个hook function。\n多个规则，自上而下，逐个检查，\n不做拒绝或者放行策略\n4： 刚刚进入本机网卡，还没有到达路由表。（地址转换k\u0026rsquo;k）\n5： 即将离开本机的时候，路由决策做出之后。\n规则链\nPREROUTING\nINPUT\nFORWARD\nOUTPUT\nPOSTROUTING\nfilter：过滤 表\nINPUT/ OUTPUT/ FORWARD\nnat: 地址转换 表\nPREROUTING/ POSTROUTING/OUTPUT\nredirect : 本机重定向\nmangle 修改报文首部 拆开修改，封装\nPREROUTING\nINPUT\nFORWARD\nOUTPUT\nPOSTROUTING\nraw 原始格式\nPREROUTING/OUTPUT\nchain的优先次序\n4表5链k\n500条规则\n自定义链只能被默认链调用才可以生效（return), 如果没有别任何一条队则匹配到应该有返回机制。\n不能删除非空链。 用户可以删除自定义的空链，默认链不能被删除。\n每一条规则都有两个内置的计数器，\n一个用来记录被匹配到的报文个数\n被匹配的报文大小之和。\n匹配标准和处理动作\n标准：\n1iptables [-t TABLE] COMMAND CHAIN [num] 匹配标准 -j 处理办法 通用匹配\n1-s, --src 源IP 2-d, --dst , 目标地址 3-p {tcp |udp | icmp} 4-i Interface, 指定数据报文流入接口 prerouting，input，forward 5-o interface， 指定数据报文流出的接口 output, postrouting, forward 6 7 8-j jump 9ACCEPT 10DROP 11REJECT 12 13连接状态 扩展匹配： 依赖扩展功能/user/lib/iptables\n隐含扩展，不用特别指明由哪一个模块进行扩展，因为此时使用-p{tcp | udp |icmp}\n显示扩展，必须指明由哪一个模块进行扩展， 使用-m完成此功能，\n网络访问控制\nDDOS\nnetfilter，\n在用户层通过iptables 对netfilter进行控制管理。\nRedirect 是针对本机的， 本机产生的数据包转到 localhost的某个端口， 适合用redirect，会比DNAT效率高一点，而外部地址只能用DNAT了。\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/cloudnative/Linux/iptables/","summary":"TCP 的有限状态机\nCLOSED CLOSED\nSYN_SENT LISTENING\n​ SYN_RECEIVED\nESTABLISHED ESTABLISHED\nnetfilter: Frame\niptables: 数据报文过滤\n防火墙： 硬件/软件\n规则： 匹配标准和处理办法\n默认规则：\n​ 关闭\n匹配标准：\nIP:源IP， 目标IP\nTCP: SPORT, DPORT SYN=1,FIN=0,RST=0,ACK=0\nUDP:SPORT, DPORT\nICMP: icmp-type\n规则在内核空间\n内核空间的TCPIP的协议栈上，开放给用户空间中的iptables API。\n内核空间的工作框架：\n用户空间的管理工具： system call\n参考 openBSD\nLinux 2.0：ipfw/firewall\nLinux 2.2： ipchain/firewall Linux 2.4 ： iptables/netfilter\n1：07\n1/proc/sys/net/ipv4/ip_forward 路由决策发生在数据包到达网卡， 送到TCPIP协议栈上的那一刻。 然后先发生路由决策\nnetfilter 补充在tcp ip协议上的3个hook function。\n多个规则，自上而下，逐个检查，\n不做拒绝或者放行策略\n4： 刚刚进入本机网卡，还没有到达路由表。（地址转换k\u0026rsquo;k）\n5： 即将离开本机的时候，路由决策做出之后。\n规则链\nPREROUTING\nINPUT\nFORWARD\nOUTPUT","tags":null,"title":""},{"categories":null,"contents":"","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/cloudnative/Linux/jq/","summary":"","tags":null,"title":""},{"categories":null,"contents":"查看端口的占用情况\n1netstat -atunlp 2 3# 用来查看系统当前网络状态信息， 包括端口、连接情况等 4# -t: TCP端口 5# -u: UDP端口 6# -l: 仅显示监听Socket LISTEN状态的Socket 7# -p: 显示进程标识符和程序名称，每一个socket都属于一个程序 8# -n: 不进行DNS解析 9# -a: 显示所有连接的端口 10 11 12 13 14lsof 15# 列出当前系统打开文件(list open files) 16# -i:[num] 指定端口 1nslookup # 域名解析 2host 3dig ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/cloudnative/Linux/port/","summary":"查看端口的占用情况\n1netstat -atunlp 2 3# 用来查看系统当前网络状态信息， 包括端口、连接情况等 4# -t: TCP端口 5# -u: UDP端口 6# -l: 仅显示监听Socket LISTEN状态的Socket 7# -p: 显示进程标识符和程序名称，每一个socket都属于一个程序 8# -n: 不进行DNS解析 9# -a: 显示所有连接的端口 10 11 12 13 14lsof 15# 列出当前系统打开文件(list open files) 16# -i:[num] 指定端口 1nslookup # 域名解析 2host 3dig ","tags":null,"title":""},{"categories":null,"contents":"","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/cloudnative/Linux/route/","summary":"","tags":null,"title":""},{"categories":null,"contents":"mwan3\n单线多拨\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/cloudnative/Linux/wan3/","summary":"mwan3\n单线多拨","tags":null,"title":""},{"categories":null,"contents":"","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/cloudnative/Linux/%E8%BF%9B%E7%A8%8B%E6%97%A5%E5%BF%97/","summary":"","tags":null,"title":""},{"categories":null,"contents":"","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/cloudnative/Linux/%E8%BF%9B%E7%A8%8B%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F/","summary":"","tags":null,"title":""},{"categories":null,"contents":"1 docker run -d -p 27017:27017 --name mongo_4_4_2 mongo:4.4.2 mongosh 命令行client https://docs.mongodb.com/mongodb-shell/install\n1If you need to have node@14 first in your PATH run: 2 echo \u0026#39;export PATH=\u0026#34;/usr/local/opt/node@14/bin:$PATH\u0026#34;\u0026#39; \u0026gt;\u0026gt; ~/.zshrc 3 4For compilers to find node@14 you may need to set: 5 export LDFLAGS=\u0026#34;-L/usr/local/opt/node@14/lib\u0026#34; 6 export CPPFLAGS=\u0026#34;-I/usr/local/opt/node@14/include\u0026#34; mongo doc\nhttps://mongoing.com/docs/tutorial/query-documents.html\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/component/DataBase/mongo/mongo_install/","summary":"1 docker run -d -p 27017:27017 --name mongo_4_4_2 mongo:4.4.2 mongosh 命令行client https://docs.mongodb.com/mongodb-shell/install\n1If you need to have node@14 first in your PATH run: 2 echo \u0026#39;export PATH=\u0026#34;/usr/local/opt/node@14/bin:$PATH\u0026#34;\u0026#39; \u0026gt;\u0026gt; ~/.zshrc 3 4For compilers to find node@14 you may need to set: 5 export LDFLAGS=\u0026#34;-L/usr/local/opt/node@14/lib\u0026#34; 6 export CPPFLAGS=\u0026#34;-I/usr/local/opt/node@14/include\u0026#34; mongo doc\nhttps://mongoing.com/docs/tutorial/query-documents.html","tags":null,"title":""},{"categories":null,"contents":"","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/DataStruct/02_complication/","summary":"","tags":null,"title":""},{"categories":null,"contents":"","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/DataStruct/03_array_link_jump/","summary":"","tags":null,"title":""},{"categories":null,"contents":"","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/DataStruct/04_stack_queue/","summary":"","tags":null,"title":""},{"categories":null,"contents":"","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/DataStruct/05_ds_hash_map/","summary":"","tags":null,"title":""},{"categories":null,"contents":"","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/DataStruct/ds_heap/","summary":"","tags":null,"title":""},{"categories":null,"contents":"13th May 2022 Hi, June, this class, I hope you could help me to correct the typo and grammar and make the sentence I have made much more like a native speaker. I would appreciate it if you could help me. The sentences here are the answer about the first class. The first phase is about my hometown, the second is about my name, the third is about my job, and last but not least is about my electronic devices.\nHi, I am Airren. I come from China in Shanghai City, the city is currently under lockdown due to the COVID-19.\nI am not a native inhabitant(citizen) of Shanghai. I went here to work right after I graduated from my master\u0026rsquo;s courses and got my master\u0026rsquo;s degree, I got my first job in Shanghai. Till now, I still work in Shanghai but changed my position.\nMy hometown is Shandong province, north of China, Jinan City. It is an average town surrounded by mountains and it\u0026rsquo;s abundant with spring water. The water comes out from the underground to the surface. It is like a machine(water pump) that brings the water to the ground, nonstop. What magic it is. The most famous spring water is named Baotu spring. And the spring pool is fed by underwater limestone water through three outlets. It\u0026rsquo;s beautiful and magical. Nature really does its magic.\nNext, I want to talk something about my name, Airren. My Chinese last name is Ren, so I combined the Air and Ren to Airren. Someday, I found it is a game\u0026rsquo;s character name, and the game is \u0026lsquo;All Start Tower Defense.\u0026rsquo; Airren is a 5-star summoner and ground-type unit based on Eren Yeager from the series Attack on Titan. He can only be obtained from the Hero Summon. Airren is not Airen, not a typo. Airen as a name for boys is a Hebrew name, and the name Airen means \u0026ldquo;mountain of strength.\u0026rdquo; I think Airren contains Airen, so Airren is better for me. That\u0026rsquo;s how I got my name.\nAnd then, Let\u0026rsquo;s talk something about my work. I am a software developer working in Intel now. Intel is a global processor vendor. My work focus on Cloud Native Network research. This is a fundamental function for most applications\u0026rsquo; backend. The application in our smart-Phone is the Frontend Part. The service has a lot of remote servers(computers) to run the backend application to make it work. I worked in Intel for about half a year. Before joining Intel, I worked in ByteDance for two years after graduation. The work I did in ByteDance focused on Time Series Data Management. From the name, you can know that Time Series Data is a kind of data combined with time. For example, the temperature of a day is different with the time changes. The specific time and the temperature of this time assembled a record. This record is time-series data. In ByteDance, the online users\u0026rsquo; number, the hot video playtimes, or advertisements playtimes, and all this record can be Time Series Data. They collect the time series data and analysis to predict the peak workloads and keep the application\u0026rsquo;s stability. So every time you open TikTok, it will feed some exciting videos. Sometimes the application will be crashed due to a random error, but it won\u0026rsquo;t suffer for a long time. It always gets normal quickly. We can create a Trending list through the Time-series Data to show the hot discussion.\nWhat\u0026rsquo;s more, maybe because I work with a computer every day to programming, I like to try a different kind of electric device. I am an Apple user. I have an iPhone, iPad, MacBook, and flex headphones. I have different types of computers, such as a Surface Laptop(portable computer) and several Intel NUCs(mini PC). And I have assembled a Desktop Computer by myself. I bought a motherboard, CPU, memory modules, disk, and a power supply on an online shop like amazon or Shopee(In China is Taobao or JD). I also have a Nintendo Switch. I\u0026rsquo;d like to play the game on the switch on the weekend, some like the Super Mario series. And then, I have a NAS dedicated for storage which is not a docking station. A docking station is an extended device for a computer. But NAS, like a low-power computer, runs 24 hours every day, and with ample storage disk, all my computers can access the NAS to read or write the data. NAS is a home data share center.\nThis is the first time I have taken this kind of class. Before this class, I rarely talked in English but always read some English content about computer science on tech websites, such as stack overflow, Github, and Linux foundation. I am taking this class want to speak more, and at the same time, I want to correct my pronunciation and accent. Most of the time, I don\u0026rsquo;t know how to express the thought in my brain, organize the sentence, and speak that out. I think with your help, I will learn to munch more words and speak fluently, and finally, I can think in English and speak out everything in my mind without getting stuck.\n15/16/17th May 2022 Talk about my self-introduction.\n18th May 2022\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/English-learning/2022-05-13/","summary":"13th May 2022 Hi, June, this class, I hope you could help me to correct the typo and grammar and make the sentence I have made much more like a native speaker. I would appreciate it if you could help me. The sentences here are the answer about the first class. The first phase is about my hometown, the second is about my name, the third is about my job, and last but not least is about my electronic devices.","tags":null,"title":""},{"categories":null,"contents":"Thanks, Anj. I love your class, you are full of passion and patience. You are an excellent and professional teacher. , I think you have magic in the class. When I take your class, you can take all of my attention. I think you are very popular on this platform, your class is very hard to reserve.\nI have worked from home since two months ago.\nengoo.com/en/materials\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/English-learning/2022-05-17/","summary":"Thanks, Anj. I love your class, you are full of passion and patience. You are an excellent and professional teacher. , I think you have magic in the class. When I take your class, you can take all of my attention. I think you are very popular on this platform, your class is very hard to reserve.\nI have worked from home since two months ago.\nengoo.com/en/materials","tags":null,"title":""},{"categories":null,"contents":"18th May 2022 Yesterday, I am sorry heard you External Solid State Drive is corrupted. Is name correct, or Mobile Solid State Storage, or external hard driver, which one is usual. SSD, the short name is often used in China, so do Philippine? I remember that you bought it from Shopee. It\u0026rsquo;s may be a China brand.\nThe electronic device in Chinese brand I only suggest HUAWEI, XIAOMI, VIVO, HONOR, and Lenovo. The electronic device with a famous brand will may more stable and have much better service after it sold. some extend device，a brand name UGREEN is better choice.\nFor a storage device, stability is much important the than the size. Larger size can storage much data, but if you device corrupted, you will lose all of you data.\nThrough the picture you shared with me yesterday, I found a similar device like that.\nThis is External SSD. It have a type-c interface with fast speed more than 100MB/s. It\u0026rsquo;s light and handy, but you should take a type-c cable with it, or else you can\u0026rsquo;t connect it with you computer or mobile phone. Cell phone or smart phone, which word you use usually or what is different between it, we can talk in next class.\nThere three kind of Type-c cable(at least on endpoint is type-C interface). First one is Type-C to Type-C，second is Type-C to Type-A, Type-A is a very common usb interface in various kind of electronic device. The last one, is Type-C to a multifunction interface, it can be Type-A or Type-C, it depend on you use case.\nOk, turn back. If you device is similar to it, you can check on the end of you device, are there two screws on the top or on the bottom as is shown in the following picture.\nMake sure you device is out of warranty period，and or the seller do not mind you tear down(disassemble) it. If you don\u0026rsquo;t care the warranty. You can follow me.\nIf you cannot see the screws, There maybe a plastic paper cover on the end, you can try to remove it. After you use screw tools to screw the screws out, and remove the bottom case, or the top case. You can get a electronic board like that.\nIn the red square there is the solid state disk with M.2 interface, the black on is M.2 Jack. In the right-top picture pane you can see the SSD.\nM.2 SSD have 4 kind of size. The common size is 2242 and 2280. You can check which one is you disk\u0026rsquo;s size.\nYou can remove you SSD from the type adaptor.\nNow you know you External SDD consist of two parts, one is the type-c adaptor(maybe named that), and another is the M.2 SSD.\nI don\u0026rsquo;t know what happened to you external SSD. It you have a computer with M.2 interface, this interface usually on the mother board, you can connect to M.2 SSD to you computer directly to check if it is normal.\nor else, you can only by a M.2 to type-C adaptor, and move you SSD to the new adaptor, If you are lucky, it will be work. It it works normally, it proves that you old type-C adaptor is broken.\nIf it doesn\u0026rsquo;t work, maybe you SSD is broken.\nM.2-To-Type-C adaptor is cheaper than a SSD. In China, a M.2 to Type-C adaptor is about 40 RMB, same to 308 PHP.\nI suggest to a computer repair shop to check if your SSD is still work normal，it the SSD is OK, you can only by a M.2-To-Type-C adaptor with a case. Yours is with aluminium alloy, it looks beautiful.\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/English-learning/2022-05-18/","summary":"18th May 2022 Yesterday, I am sorry heard you External Solid State Drive is corrupted. Is name correct, or Mobile Solid State Storage, or external hard driver, which one is usual. SSD, the short name is often used in China, so do Philippine? I remember that you bought it from Shopee. It\u0026rsquo;s may be a China brand.\nThe electronic device in Chinese brand I only suggest HUAWEI, XIAOMI, VIVO, HONOR, and Lenovo.","tags":null,"title":""},{"categories":null,"contents":"Today，Let\u0026rsquo;s talk something about computer\nAll the computers that are developed are not the same, they have different designs and features. Some computers have a very high capacity as well as working speed; however, some are slow. Depending on the requirements, computers are being developed.\nDepending upon the internal structure, and applicability, the computer system is categorized as follows −\nMainframe Computer It is high capacity and costly computer. It is largely used by big organizations where many people can use it simultaneously.\nSuper Computer This category of computer is the fastest and also very expensive. A typical supercomputer can solve up to ten trillion individual calculations per second.\nWorkstation Computer The computer of this category is a high-end and expensive one. It is exclusively made for complex work purposes.\nPersonal Computer (PC) It is a low-capacity computer developed for single users.\nPersonal computers can be split into Desktop computers, laptops, mini PC, and tablets.\nLaptop computer (notebook) It is a handy computer that can be easily carried anywhere.\nTablet and Smartphone Modern technology has advanced further. It has helped develop computers that are pocket-friendly. Tablets and smartphones are the best examples of such computers.\nNext, we can talk something about the Operate System. Such as window, Linux(Ubuntu or CentsOS, or fedra, or Arch linux).\nWindows is very expensive, one of my compute is Windows 11. I bought the license from Taobao(like Shopee), it\u0026rsquo;s much cheaper than the official store. When I in university, that time, I didn\u0026rsquo;t have income. I use the hacked windows, it\u0026rsquo;s free.\nAnd, I am not a Windows office suit user, It\u0026rsquo;s expensive, In China, the company named JiaShan Software, the have a production similar to Office that is WPS. It has enough compatibility with Windows Office Document, Powerpoint, and Excel. It\u0026rsquo;s an all-in-one software. You can use WPS to edit the file with the suffix .doc , .ppt, exl, and so on,\nIn Ubuntu, there is also a free Version Office software, name Libra Office(I don\u0026rsquo;t know is it the spell correct). I rarely used the ubuntu with a desktop, I just use a command-line user.\ninsufficient preparation\n13th May 2022 Teacher June\nbacklog A number of people have been employed to deal with the backlog of work. trending Shortly after the semi-finals, she became a trending topic on Chinese social media and she became famous quickly around the world. Hot discussion R\u0026amp;D Research \u0026amp; development Trail class comment: He likes to talk with me, but unfortunately our conversations are very limited. He has some difficulty understanding some works but especially when talking a bit fast. I enjoy having Ren in my class.\nSelf-introduction/Job/hometown/electric device 14th May 2022 Teacher June\nInternet Addiction:\nWhat‘s your opinion about Internet Addiction?\nHave you ever been addicted to the internet?\nHave you been scammed before?\nAre you a victim of fake news?\nWhat should we do to keep our personal data safe?\nIn my opinion, Internet online games are something that you can\u0026rsquo;t reject by yourself. Once you drop in, you can\u0026rsquo;t stop doing that.\nAnd TikTok, the feeding video platform, is another kind of Internet drug, while using the TikTok, I don\u0026rsquo;t know what about the next video, so I expect the next video, and wait to get funny with it. and my brain will produce a lot of dopamine to make me feel happy.\nAbout 4 years ago, when the TikTok became popular, I have been addicted to TikTok for a while(about 3 months). I can stop myself to swap to the next video. And I also played Tencent\u0026rsquo;s mobile games, such as mobile Legend and PUBG Mobile. But I haven\u0026rsquo;t lost in the game.\nThere\u0026rsquo;s a big risk to use an unsafe website. If you logged into an unsafe website, you might leak your private information. Others might steal your information.\nI know the fake news and actual news. I am not a victim of fake news.\nWe should not write our information on different sites and regularly change our passwords.\nMobile Legends: Bang Bang\nCHAT:\nIn pairs/groups, talk about these topics or words from the article. What does the article say about them? What can you say about these words and your life?\nInternet dangers\nFake news\nPersonal data\nplatform\ninformation\nopportunities\nstrategy\nsolution\nFree speech\nHave a chat about the topics you liked. Change the subject and partner frequently.\nGOOD:\nStudent A strongly believes the internet is a good thing; Student B strongly thinks the Internet is a bad thing. Change partners again and talk about your conversation.\nDANGERS:\nWhat are the dangers of the internet? How can we avoid them? Complete this table with your partner(s). Change partners often and share what you wrote.\nDangers How to avoid them Identity theft Phishing Cyber-bullying Fake news Personal data Addiction Problems\nRank this with your partner. Put the biggest problems with the Internet at the top. Change partners often and share your ranking.\nI will revise the material to make it a bit easy.\nComment: Today we had our 2nd class and we used computer-related material. He has difficulty distinguishing sounds in words when speaking. Ren remembers new words and reads very well. However, some words are a bit hard for him. In listening and comprehension exercises and activities, he usually does well. He follows the material easily. Ren is achieving good success with English.\n15th May 2022 Self-introduction\n16th May 2022 Comment: very persistent in learning. I love the learning attitude. Keep it up.\nSelf-introduction\n17th May 2022 Self-introduction\n18th May 2022 Teacher Anj\nI just pull my weight. You were very enthusiastic, just keep on working with your pronunciation vocabulary.\nThanks, Anj. I love your class, you are full of passion and patience. You are an excellent and professional teacher. I think you have magic in the class. When I take your class, you can take all of my attention. I think you are very popular on this platform, your class is very hard to reserve.\nI have worked from home since two months ago.\nTeacher June\nTalk something about Solid State Disk.\nRen asks pertinent questions about the material under discussion. He listens attentively and usually understands what I\u0026rsquo;m explaining to the class. Ren demonstrates his understanding of new materials by providing an answer to the teacher\u0026rsquo;s question. Ren\u0026rsquo;s understanding of the material is excellent.\n19th May 2022 Teacher June\nTalk something about computer\ncomplex/ complicated\nDistribution version\nLaggy： old computer is laggy\nHe can correctly use basic verb tenses in short sentences but I would like him to start speaking in longer, more accurate sentences. He has some difficulty understanding people who speak with average speed. Ren demonstrates an excellent understanding of new material by always providing an answer to the teacher\u0026rsquo;s question. Airren is continuing to do very well in English.\n20st May 2022 Teacher Anj\nThe vocal concert is Live family obligation \u0026amp; reunion \u0026amp; the school\u0026rsquo;s annual reunion Participate It wears me out. Tradition To give a blessing.\nThank you for having me again. You have so many good ideas to share. You can expand your ideas very well. Thank you again for attending the class, take care. See you again.\nAsk about \u0026ldquo;It wears me out\u0026rdquo;\nTeacher Indi\nelaborate\nElaborate design/ an elaborate computer system/ elaborate meal\nFishing rod\nUntil the dark is coming\nI will find the word.\nI have been working from home for two months now.\nKids are much busier than adults.\nWhen I was a child\u0026hellip;\nMost of my friends are my classmates\nYou enjoyed sharing ideas and thoughts. You were a capable student, and you comprehended a great deal of the lessons taught. You were also a good listener, thus, you grasped everything in the class. Keep on exhibiting such an amazing/fantastic performance.\nTeacher June\nAllure overtake why didn\u0026rsquo;t you go for a 256GB iPhone？ It was expensive.\n21st May 2022 Teacher Anj\nTalk about who is much busier\n23rd May 2022 I am very happy today because today we have 3 hours to go out of the housing estate. And one hour to go to the supermarket to buy necessities of life. But unfortunately, only one person is allowed to go out for one household, so that, my wife stay at home while I went out. These past two months, lockdown in the housing estate was like putting me into jail. I think the prisoner is much happier than me, they don\u0026rsquo;t need to cook by themselves.\nAnd the prisoners are allowed out of their cells for two hours a day, but in the past two months, we have even can\u0026rsquo;t allow going out of our apartment door.\nIf someone says thanks to you, how to turn back?\nDon\u0026rsquo;t mention it. It\u0026rsquo;s my pleasure. No worries. No problem. Any time. ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/English-learning/2022-05-19/","summary":"Today，Let\u0026rsquo;s talk something about computer\nAll the computers that are developed are not the same, they have different designs and features. Some computers have a very high capacity as well as working speed; however, some are slow. Depending on the requirements, computers are being developed.\nDepending upon the internal structure, and applicability, the computer system is categorized as follows −\nMainframe Computer It is high capacity and costly computer. It is largely used by big organizations where many people can use it simultaneously.","tags":null,"title":""},{"categories":null,"contents":"Q1 2022 Insight The SDEWAN E2E demo installs and verifies process is simplified, shortened to about 40 minutes, and improved efficiency by optimizing the automatic deployment and test scripts. Help the Smart Edge team integrate SDEWAN with DEK, prepare guides, answer questions, and do hands-on debugging.\nVerified the POC in Ubuntu that StrongsWAN integrates with CTK through PKCS#11, which put the private key in -the SGX enclave to protect it. And propose ubuntu-SGX container as a sidecar work with CNF to provide the security IPsec Tunnel connection.\nChallenge: While building SGX SDK, CTK, and strongsWAN in Ubuntu encountered some barriers with C project toolchains. Finally, remove most of them. But while building OpenWRT with SGX, most of the compile seems complicated to solve, so choose another way instead of making that.\nOne Intel:\nOne Intel: Qiang proactivity helps Smart Edge team to integrate SDEWAN with DEK, prepare guides, answer questions, do hands-on debugging and always solve issues in time.\nFearless: Qiang always keeps curiosity for the unknown region can complete the work with challenges. Qiang successfully complete the POC strongsWAN integrated with CTK in ubuntu overcoming a lot of difficulties.\nOKR for Q2 Object 1：Intergrate SGX with CNF to protect the private key. optimize the image size, strongsWAN-CTK image base on Ubuntu, limit to 200M. Complete web server(Golang) in Ubuntu container and Client(Lua) in OpenWRT container, to accomplish start/stop/restart strongsWAN service in Ubuntu. Test the sync cost time between two sides of the shared Volum. One side is in OpenWRT, and another is in Ubuntu. Expose RESTful API in Ubuntu-SGX to generate private keys in Enclave, and create the CSR for the private key in Enclave. Object 2: Refine SDEWAN auto-install script and complete the document Optimize auto-install script, make it suitable for VM deploy and physical deploy. Complete the SDEWAN documentation along with the version updated. Object 3: Deep dive into Kubernetes Network ,Custome Resource and Sapphire Rapids Read more about Virtual Network and CNI definition of Kubernetes veth pair, tun/tap, Linux bridge, VXLAN, Macvlan Calico, Flannel Write a Customer Controller Demo through Kubebuilder or Operator SDK. Read the Spec of Intel Feature AMX, and prepare a presention for IDF sharing in 3rd, May. Try to join a K8s SIG-Netwoking, watch the latest 10 SIG-Networking meeting videos. make gen-yaml IMG=\u0026ldquo;integratedcloudnative/sdewan-controller:devtest1\u0026rdquo;\nQ2 2022 Insight Insight For the SDEWAN project: Test several work modes of CNF, one is multiple interfaces that can use host-device mode or nodus direct mode to share the physical interface to CNF, and another is CNF work as a service export through NodePort mode. Support SGX HSM co-work with CNF as a sidecar and test SDEWAN pull mode through the script.\nHelp the SmartEdge team finish the SASE EK release, by upgrading the auto-deploy script with the latest components. And verified the possibility of using SDEWAN with Nodus in WAN on AWS.\nRelease a Sapphire rapids feature AMX presentation and verify the IDF proposal\u0026rsquo;s feasibility that uses the AVX or AMX to accelerate the query speed of Time-Series Data. And bring up an IDF proposal of Cloud Native HSM.\nChallenge: While working for the SDEWAN SGX support model, solved some tricky problems which are cross-compile the p11-kit tool for OpenWrt and changing the pkcs#11 token initialize arguments to fit CTK and squashing the HSM image with SGX to reach an ideal size.\nQuality: Help the Smart Edge team release SDEWAN with the latest stable component. Ensure the stability and reliability of the auto-deploy script.\nResult Driven: Even encountering many tricky problems while enabling SGX for CNF, Qiang solved the problem step by step and finally accomplish the component as the previous design architecture.\nOKR for Q2 OKR for Q3 OBJ1: Enable IA optimizations and innovations in open-source Edge Orchestration projects\nKR1: Integrate and ship Nodus and SDEWAN 22.09 with SmartEdge-O release\nKR2: Enhance SGX E2E flow with Cert Manager(Useing SGX as externel issuer) support SDEWAN 22.09 release.\nKR3: SDEWAN auto CICD process, optimize the version manager, and split the code repo\nOBJ2: Build Intel leadership in open-source Edge Orchestration projects with focus on individual career growth\nKR3: Deliver 1 technical submission on edge usages with SDEWAN (KubeCon China)\nKR4: v\npromiscuous\nQ3 Insight Works in Q3\nSupport Smart Edge Team design and verify service function chain in the HUB. Help verify SDEWAN with nodus work on a multi-node cluster and IPsec cross NAT.\nFinished SDEWAN release with SGX feature enhancement and test a new feature for SDL supported.\nNodus support. Ramp up, test and verify the patch for K8s latest version, and SFC for IPV6.\nPlan for Q4\nDeliver SDEWAN 22.12 releases. Features include: SGX e2e flow enhancement for SDL requirements.\nIntegrate SDEWAN with SmartEdge release.\nIntel Values\nOneIntel: Help Smart Edge team set up new features based on SDEWAN, design and verify the proposals. Such as, service function chains, nodus work in multi node and IPsec tunnel cross NAT.\nFearless: While working with nodus, facing the relatively unfamiliar fields of OVN and CNI, Qiang reads related materials, dives into this field, and gets involved with Nodus relevant job.\npoints for improvement：\nLearning: Qiang should continuously learn Kubernetes related technologies and improve software design skill to deliver high quality product\nInnovation: Qiang should continuously learn intel platform features and innovate on how to prompt integration in edge computing domain.\nQ4 OKR OBJ1: Enable IA optimizations and innovations in open-source Edge Orchestration projects\nDeliver SDEWAN 22.12 releases. Features include: SGX e2e flow enhancement for SDL requirements.\nOBJ2: Build Intel leadership in open-source Edge Orchestration projects with focus on individual career growth\nSubmit 1 edge orchestration related IDF submission\n做的好的，以及需要改进的，value 2-3 个\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/Insight/","summary":"Q1 2022 Insight The SDEWAN E2E demo installs and verifies process is simplified, shortened to about 40 minutes, and improved efficiency by optimizing the automatic deployment and test scripts. Help the Smart Edge team integrate SDEWAN with DEK, prepare guides, answer questions, and do hands-on debugging.\nVerified the POC in Ubuntu that StrongsWAN integrates with CTK through PKCS#11, which put the private key in -the SGX enclave to protect it. And propose ubuntu-SGX container as a sidecar work with CNF to provide the security IPsec Tunnel connection.","tags":null,"title":""},{"categories":null,"contents":"package main\nimport \u0026ldquo;fmt\u0026rdquo;\nvar testMap = map[string]map[string]struct { Name string }{ \u0026ldquo;first\u0026rdquo;: {\u0026ldquo;second\u0026rdquo;: {Name: \u0026ldquo;12312\u0026rdquo;}}, \u0026ldquo;second\u0026rdquo;: {\u0026ldquo;second\u0026rdquo;: {\u0026ldquo;12312\u0026rdquo;}}, }\nfunc main() { d := testMap[\u0026ldquo;first\u0026rdquo;][\u0026ldquo;second\u0026rdquo;].Name fmt.Printf(\u0026quot;++-%v-++\\n\u0026quot;, d)\nc := testMap[\u0026quot;first22\u0026quot;][\u0026quot;second\u0026quot;].Name fmt.Printf(\u0026quot;++-%v-++\\n\u0026quot;, c) }title: 2021-04-21 Socket\nhttps://www.cnblogs.com/wmx-learn/p/5312259.html\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/interview/daily/2021-04-21-/","summary":"package main\nimport \u0026ldquo;fmt\u0026rdquo;\nvar testMap = map[string]map[string]struct { Name string }{ \u0026ldquo;first\u0026rdquo;: {\u0026ldquo;second\u0026rdquo;: {Name: \u0026ldquo;12312\u0026rdquo;}}, \u0026ldquo;second\u0026rdquo;: {\u0026ldquo;second\u0026rdquo;: {\u0026ldquo;12312\u0026rdquo;}}, }\nfunc main() { d := testMap[\u0026ldquo;first\u0026rdquo;][\u0026ldquo;second\u0026rdquo;].Name fmt.Printf(\u0026quot;++-%v-++\\n\u0026quot;, d)\nc := testMap[\u0026quot;first22\u0026quot;][\u0026quot;second\u0026quot;].Name fmt.Printf(\u0026quot;++-%v-++\\n\u0026quot;, c) }title: 2021-04-21 Socket\nhttps://www.cnblogs.com/wmx-learn/p/5312259.html","tags":null,"title":""},{"categories":null,"contents":"项目架构 ES6 和TypeScript\nAnd Design Pro\nlog 可以放在src/assets/images/klogo.svg。 然后在页面中通过以下方式使用\n1 2// @ 表示在src 目录下面 3import logo from \u0026#39;@/assets/images/logo.svg\u0026#39; 4 5\u0026lt;LoginForm 6\tlogo={\u0026lt;image alt=\u0026#34;logo\u0026#34; src={logo}\u0026gt;} ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/interview/imooc/imooc_antd%E6%95%99%E7%A8%8B/1st_%E8%AF%BE%E7%A8%8B%E5%AF%BC%E5%AD%A6/","summary":"项目架构 ES6 和TypeScript\nAnd Design Pro\nlog 可以放在src/assets/images/klogo.svg。 然后在页面中通过以下方式使用\n1 2// @ 表示在src 目录下面 3import logo from \u0026#39;@/assets/images/logo.svg\u0026#39; 4 5\u0026lt;LoginForm 6\tlogo={\u0026lt;image alt=\u0026#34;logo\u0026#34; src={logo}\u0026gt;} ","tags":null,"title":""},{"categories":null,"contents":"2. React介绍 2.1 React 基本介绍 FaceBook 开源的JavaScript库\nReact结合生态库构成一个MV*框架\nReact特点\nDeclarative 声明式编码\nComponent-Based 组件化编码\n高效-高效的DOM Diff算法，最小化页面重绘\n单项数据流\nMV*框架代表- 只关注视图view层+数据层Model\n生态介绍\nVue生态： Vue+Vue-Router+Vuex+Axios+Babel + Webpack React生态： React+React-Router+Redux+Axios+Babel + WebPack 编程式实现\n需要以具体代码表达在哪里(where)做什么(what)，如何实现（how） 声明式实现\n只需要声明在哪里（where）做什么（what），而无需关系如何实现（how） 2.2 React脚手架、yarn 如何安装和使用React脚手架 1npm install -g create-react-app 2creat-react-app my-app 3 4cd my-app 5npm start 什么是Yarn\nyarn 是新一代的包管理工具 为什么使用Yarn\n速度快 安装版本统一、更安全 更简洁的输出 更好的语义化 如何使用Yarn\n1yarn init 2yarn add # npm install 3yarn remove # npm uninstall 4yarn/yarn install # npm install 或者 npm i http:// reactjs.org/docs/add-react-to-a-new-app.html\n项目初始化 1npm install -g create-react-app 2create-react-app imoocmanager # 路由是没有的 router redux没有 目录结构\n1node_modules #依赖 2public # 静态文件 3src # 核心文件 4 5App.js # 根组件 6index.js # 入口 yarn 使用说明 https://yarn.bootcss.com/\n代码通过 包（package） (或者称为 模块（module）) 的方式来共享。 一个包里包含所有需要共享的代码，以及描述包信息的文件，称为 package.json 。\nYarn 使用介绍 初始化一个新项目\n1yarn init 添加依赖包\n1yarn add [package] 2yarn add [package]@[version] 3yarn add [package]@[tag] 将依赖项添加到不同依赖项类别中\n分别添加到 devDependencies、peerDependencies 和 optionalDependencies 类别中：\n1yarn add [package] --dev 2yarn add [package] --peer 3yarn add [package] --optional 升级依赖包\n1yarn upgrade [package] 2yarn upgrade [package]@[version] 3yarn upgrade [package]@[tag] 移除依赖包\n1yarn remove [package] 安装项目的全部依赖\n1yarn 或者\n1yarn install 增加路由管理 1yarn add react-router Webpack 配置： 编译成静态文件\n2.3 React生命周期介绍 React生命周期包含哪些 10 个API getDefaultProps\ngetInitialState\ncomponentWillMount\nRender\ncomponentDidMount\ncomponentWillReceiveProps\nshouldComponentUpdate\ncomponentWillupdate\ncomponentDidUpdate\ncomponentWillUnmount\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/interview/imooc/imooc_antd%E6%95%99%E7%A8%8B/2nd_React%E4%BB%8B%E7%BB%8D/","summary":"2. React介绍 2.1 React 基本介绍 FaceBook 开源的JavaScript库\nReact结合生态库构成一个MV*框架\nReact特点\nDeclarative 声明式编码\nComponent-Based 组件化编码\n高效-高效的DOM Diff算法，最小化页面重绘\n单项数据流\nMV*框架代表- 只关注视图view层+数据层Model\n生态介绍\nVue生态： Vue+Vue-Router+Vuex+Axios+Babel + Webpack React生态： React+React-Router+Redux+Axios+Babel + WebPack 编程式实现\n需要以具体代码表达在哪里(where)做什么(what)，如何实现（how） 声明式实现\n只需要声明在哪里（where）做什么（what），而无需关系如何实现（how） 2.2 React脚手架、yarn 如何安装和使用React脚手架 1npm install -g create-react-app 2creat-react-app my-app 3 4cd my-app 5npm start 什么是Yarn\nyarn 是新一代的包管理工具 为什么使用Yarn\n速度快 安装版本统一、更安全 更简洁的输出 更好的语义化 如何使用Yarn\n1yarn init 2yarn add # npm install 3yarn remove # npm uninstall 4yarn/yarn install # npm install 或者 npm i http:// reactjs.","tags":null,"title":""},{"categories":null,"contents":"3. 主页面架构设计 课程目标介绍\n第二章 项目主页工程搭建\n基础插件安装，less文件加载配置 项目主页结构开发 菜单组件开发 头部组件开发 底部组件开发 3-1 基础插件安装（1） 基础插件安装，less文件加载配置 安装所需的插件\n安装React-Router, Axios 安装antD界面框架 暴露webpack配置文件 安装less-loader 修改less-loader 1 yarn add react-router-dom axios less-loader # 3.0升级到 4.0 AntD 是基于less开发的\n暴露webpack文件使用less 1yarn eject create-react-app添加less配置\n修改完成配置后需要重启项目，从后向前使用， less的配置放在css，scss之后\n可能需要删除node_module文件夹重新yarn install\nyarn add less\n需要修改的文件config/webpack.config.js\n1// style files regexes 2const cssRegex = /\\.css$/; 3const cssModuleRegex = /\\.module\\.css$/; 4const lessRegex = /\\.less$/; 5const lessModuleRegex = /\\.module\\.less$/; 6const sassRegex = /\\.(scss|sass)$/; 7const sassModuleRegex = /\\.module\\.(scss|sass)$/; 1{ 2 test: lessRegex, 3 exclude: lessModuleRegex, 4 use: getStyleLoaders( 5 { 6 importLoaders: 2, 7 sourceMap: isEnvProduction 8 ? shouldUseSourceMap 9 : isEnvDevelopment, 10 }, 11 \u0026#39;less-loader\u0026#39; 12 ), 13 sideEffects: true, 14}, 15 16 { 17 test: lessModuleRegex, 18 use: getStyleLoaders( 19 { 20 importLoaders: 2, 21 sourceMap: isEnvProduction 22 ? shouldUseSourceMap 23 : isEnvDevelopment, 24 modules: true, 25 getLocalIdent: getCSSModuleLocalIdent, 26 }, 27 \u0026#39;less-loader\u0026#39; 28 ), 29 }, 使用antd的组件 1yanr add antd 1import React from \u0026#39;react\u0026#39; 2import Child from \u0026#39;./Child\u0026#39; 3import \u0026#39;./index.less\u0026#39; 4import { Button } from \u0026#39;antd\u0026#39; 5import \u0026#39;antd/dist/antd.css\u0026#39; 6export default class Life extends React.Component { 7 8 // constructor(props) { 9 // super(props); 10 // this.state = { 11 // count: 0 12 // }; 13 // } 14 state = { 15 count: 0 16 } 17 18 // ES 6 写法 19 handleAdd = () =\u0026gt; { 20 this.setState({ 21 count: this.state.count + 1 22 }) 23 } 24 25 handleClick() { 26 this.setState({ 27 count: this.state.count + 1 28 }) 29 } 30 31 32 render() { 33 // let style = { 34 // padding:200 35 // } 36 // return 必须有根元素，不能同时出现两个div 37 // return \u0026lt;div style={style}\u0026gt; 38 return \u0026lt;div className=\u0026#34;content\u0026#34;\u0026gt; 39 \u0026lt;p\u0026gt;React声明周期介绍\u0026lt;/p\u0026gt; 40 \u0026lt;Button onClick={this.handleAdd}\u0026gt;AntD点击一下\u0026lt;/Button\u0026gt; 41 \u0026lt;button onClick={this.handleAdd}\u0026gt;点击一下\u0026lt;/button\u0026gt; 42 \u0026lt;button onClick={this.handleClick.bind(this)}\u0026gt;点击一下\u0026lt;/button\u0026gt; 43 \u0026lt;p\u0026gt;{this.state.count}\u0026lt;/p\u0026gt; 44 \u0026lt;Child name={this.state.count}\u0026gt;\u0026lt;/Child\u0026gt; 45 \u0026lt;/div\u0026gt; 46 } 47} 使用 babel-plugin-import babel-plugin-import 是一个用于按需加载组件代码和样式的 babel 插件（原理），现在我们尝试安装它并修改 config-overrides.js 文件。\n1yarn add babel-plugin-import 1yarn add less@^2.7.3 # 制修订版本安装 babel-plugin-import配置babel按需引入antd模块\n将less版本降到3.0以下 比如安装 2.7.3版本。\n需要修改的文件config/webpack.config.js\n1{ 2 test: /\\.(js|mjs|jsx|ts|tsx)$/, 3 include: paths.appSrc, 4 loader: require.resolve(\u0026#39;babel-loader\u0026#39;), 5 options: { 6 customize: require.resolve( 7 \u0026#39;babel-preset-react-app/webpack-overrides\u0026#39; 8 ), 9 10 plugins: [ 11 [ 12 require.resolve(\u0026#39;babel-plugin-named-asset-import\u0026#39;), 13 { 14 loaderMap: { 15 svg: { 16 ReactComponent: \u0026#39;@svgr/webpack?-prettier,-svgo![path]\u0026#39;, 17 }, 18 }, 19 }, 20 ], 21 [\u0026#39;import\u0026#39;,{libraryName:\u0026#39;antd\u0026#39;,style:true}], 22 ], 23 // This is a feature of `babel-loader` for webpack (not Babel itself). 24 // It enables caching results in ./node_modules/.cache/babel-loader/ 25 // directory for faster rebuilds. 26 cacheDirectory: true, 27 // Don\u0026#39;t waste time on Gzipping the cache 28 cacheCompression: false, 29 }, 30 }, 更换主题 1options:{ 2 modules: false, 3 modifyVars: { 4 \u0026#34;@primary-color\u0026#34;: \u0026#34;#f9c700\u0026#34; // 全局主色 5 } 6}, 3-3 项目主页结构开发 主页结构定义\n页面结构定义 目录结构的定义 栅格系统使用 calc计算方法使用 calc 动态计算长度值\n3-2 基础插件安装（2） 3-3 （安装课程中Webpack版本的用户请忽略这一小节）Webpack4.19.1版本文件合并后配置按需加载 3-4 页面结构开发（1） 3-5 页面结构开发（2） 3-6 菜单组件开发（1） 3-7 菜单组件开发（2） 3-8 头部组件实现（1） 3-9 头部组件实现（2） 3-10 底部组件功能实现（1） 3-11 底部组件功能实现（2）\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/interview/imooc/imooc_antd%E6%95%99%E7%A8%8B/3rd_%E4%B8%BB%E9%A1%B5%E9%9D%A2%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/","summary":"3. 主页面架构设计 课程目标介绍\n第二章 项目主页工程搭建\n基础插件安装，less文件加载配置 项目主页结构开发 菜单组件开发 头部组件开发 底部组件开发 3-1 基础插件安装（1） 基础插件安装，less文件加载配置 安装所需的插件\n安装React-Router, Axios 安装antD界面框架 暴露webpack配置文件 安装less-loader 修改less-loader 1 yarn add react-router-dom axios less-loader # 3.0升级到 4.0 AntD 是基于less开发的\n暴露webpack文件使用less 1yarn eject create-react-app添加less配置\n修改完成配置后需要重启项目，从后向前使用， less的配置放在css，scss之后\n可能需要删除node_module文件夹重新yarn install\nyarn add less\n需要修改的文件config/webpack.config.js\n1// style files regexes 2const cssRegex = /\\.css$/; 3const cssModuleRegex = /\\.module\\.css$/; 4const lessRegex = /\\.less$/; 5const lessModuleRegex = /\\.module\\.less$/; 6const sassRegex = /\\.(scss|sass)$/; 7const sassModuleRegex = /\\.","tags":null,"title":""},{"categories":null,"contents":" 2nd_操作系统\n3rd_网络\n4th_数据库\n5th_程序设计基础\n6th_编码技巧\n7th_面向对象\n8th_设计模式\n9th_高级知识点\n10th_Google笔试题解\n11th_面试技巧和总结\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/interview/imooc/imooc_Google%E8%AE%B2Java/0_Category/","summary":"2nd_操作系统\n3rd_网络\n4th_数据库\n5th_程序设计基础\n6th_编码技巧\n7th_面向对象\n8th_设计模式\n9th_高级知识点\n10th_Google笔试题解\n11th_面试技巧和总结","tags":null,"title":""},{"categories":null,"contents":"","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/interview/imooc/imooc_Google%E8%AE%B2Java/10th_Google%E5%9C%A8%E7%BA%BF%E7%AC%94%E8%AF%95%E9%A2%98%E8%A7%A3/","summary":"","tags":null,"title":""},{"categories":null,"contents":"面试软技巧和总结 解决问题的能力 面对问题的态度 分析问题的方法 结构化分析问题 剔除干扰项 提问面试官 介绍一下所在的项目组 介绍一下所用的技术栈 对我的个人的意见和建议 后续学习 基础知识： 广度优先， 在兴趣点深入 编码能力： LeetCode， Google在线平台 面向对象和设计模式： 尝试重构自己写过的代码 ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/interview/imooc/imooc_Google%E8%AE%B2Java/11th_%E9%9D%A2%E8%AF%95%E8%BD%AF%E6%8A%80%E5%B7%A7%E5%92%8C%E6%80%BB%E7%BB%93/","summary":"面试软技巧和总结 解决问题的能力 面对问题的态度 分析问题的方法 结构化分析问题 剔除干扰项 提问面试官 介绍一下所在的项目组 介绍一下所用的技术栈 对我的个人的意见和建议 后续学习 基础知识： 广度优先， 在兴趣点深入 编码能力： LeetCode， Google在线平台 面向对象和设计模式： 尝试重构自己写过的代码 ","tags":null,"title":""},{"categories":null,"contents":"操作系统 进程和线程 进程： 进程中的内存是逻辑内存， 所有进程的逻辑内存之和要远远大于物理内存。 文件/网络句柄是共享的 线程 TLS： Thread Local Storage 缓冲区溢出 协程 进程之间不可以共享内存， 线程之间可以共享内存 进程间的通信方式： 管道，TCP/IP 比较优劣 线程间的通信方式： 共享内存 存储和寻址 存储 寻址空间 每个进程有自己的独立寻址空间 进程独立\n32位 -\u0026gt; 4G 64位 -\u0026gt; ~10^19Bytes 1wPB 64位JVM -\u0026gt; 可以使用更大的内存，32 -\u0026gt; 需要重新编译 寻址 int n= *p; -\u0026gt; MOV EAX,[EBX] 把EBX寄存器中的数据读出，放入EAX 寄存器。n -\u0026gt; EAX, p -\u0026gt; EBX.\n逻辑内存的大小与物理内存没有关系，只有操作系统有关。 操作系统的位数决定逻辑内存的位数。 逻辑内存映射到物理内存，数据不一定在物理内存中，也可能存在虚拟内存中。 当数据在虚拟内存中时候，不是只把逻辑内存对应的数据加载到物理内存，而是把数据所在的分页加载到物理内存。如果物理内存放不下，就交换一部分数据到虚拟内存。 ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/interview/imooc/imooc_Google%E8%AE%B2Java/2nd_%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/","summary":"操作系统 进程和线程 进程： 进程中的内存是逻辑内存， 所有进程的逻辑内存之和要远远大于物理内存。 文件/网络句柄是共享的 线程 TLS： Thread Local Storage 缓冲区溢出 协程 进程之间不可以共享内存， 线程之间可以共享内存 进程间的通信方式： 管道，TCP/IP 比较优劣 线程间的通信方式： 共享内存 存储和寻址 存储 寻址空间 每个进程有自己的独立寻址空间 进程独立\n32位 -\u0026gt; 4G 64位 -\u0026gt; ~10^19Bytes 1wPB 64位JVM -\u0026gt; 可以使用更大的内存，32 -\u0026gt; 需要重新编译 寻址 int n= *p; -\u0026gt; MOV EAX,[EBX] 把EBX寄存器中的数据读出，放入EAX 寄存器。n -\u0026gt; EAX, p -\u0026gt; EBX.\n逻辑内存的大小与物理内存没有关系，只有操作系统有关。 操作系统的位数决定逻辑内存的位数。 逻辑内存映射到物理内存，数据不一定在物理内存中，也可能存在虚拟内存中。 当数据在虚拟内存中时候，不是只把逻辑内存对应的数据加载到物理内存，而是把数据所在的分页加载到物理内存。如果物理内存放不下，就交换一部分数据到虚拟内存。 ","tags":null,"title":""},{"categories":null,"contents":"网络 网络基础 不可靠 丢包，重复包 出错 乱序 不安全 中间人攻击 窃取 篡改 滑动窗口 TCP协议中使用\n维持发送方/接收方缓冲区\n流量控制+拥塞控制 在传输过程中会调整窗口的大小 窗口的大小为0是合法的，（如果消息来不及处理可以设置为0） 不使用滑动窗口的话吞吐量会非常低\n滑动窗口的Ack是有序的 如果丢ACk 会启动超时重传机制 WireShark 抓包 wireShark 抓包\n网络例题 一个来回的时间：1500km/(2*10^5km/s) *2 = 0.015s 来回的次数至多：100s/0.015 = 6666.67次\n每次传输至少： 100GB/6666.67 = 15M\n数据链路层 网络层 传输层 TCP/UDP 应用层\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/interview/imooc/imooc_Google%E8%AE%B2Java/3rd_%E7%BD%91%E7%BB%9C/","summary":"网络 网络基础 不可靠 丢包，重复包 出错 乱序 不安全 中间人攻击 窃取 篡改 滑动窗口 TCP协议中使用\n维持发送方/接收方缓冲区\n流量控制+拥塞控制 在传输过程中会调整窗口的大小 窗口的大小为0是合法的，（如果消息来不及处理可以设置为0） 不使用滑动窗口的话吞吐量会非常低\n滑动窗口的Ack是有序的 如果丢ACk 会启动超时重传机制 WireShark 抓包 wireShark 抓包\n网络例题 一个来回的时间：1500km/(2*10^5km/s) *2 = 0.015s 来回的次数至多：100s/0.015 = 6666.67次\n每次传输至少： 100GB/6666.67 = 15M\n数据链路层 网络层 传输层 TCP/UDP 应用层","tags":null,"title":""},{"categories":null,"contents":"数据库 关系型数据库 基于关系代数理论 缺点： 表结构不直观，实现复杂速，速度慢 优点： 健壮性高，社区庞大 Product\nproduct_id product_name category_id price 4 toyota 2 100000 3 prosche 2 1000000 2 addidas 2 500 1 nike 600 category\ncategory_id category_name 2 automobile 1 shoes 1select * from product join category; -- 结果为笛卡尔积 8条记录 2 3select * from product p join category c on p.category_id=c.category_id; -- 按照id相等去连接， 忽略id 为空的记录 内连接 null的数据不会显示 4 5 6select * from product p left join category c on p.category_id=c.category_id; -- 左外连接， 左边为主表 7 8 9select p.category_id,category_name ,count(1) as total from product p left join category c on p.category_id=c.category_id group by p.category_id; -- count 聚合函数 10 11select p.category_id,category_name ,MIN(price) as total from product p left join category c on p.category_id=c.category_id group by p.category_id; -- min 聚合函数 12 13 14select * from product p left join ( 15 select p.category_id,category_name ,MIN(price) as min_price 16 from product p left join category c 17 on p.category_id=c.category_id group by p.category_id) as cat_min 18on p.category_id = cat_min.category_id 19where p.price = cat_min.min_price; 20/* 21 获取某个品类中价格最低的商品 22 */ 事务 ACID\nAtomicity 原子性 Consistency 一致性 Isolation 独立性 Durability 持久性 事务的隔离级别\nRead Uncommited Read Committed Repeatable Read Serializable For Update 对查询的数加锁 ## 悲观锁 乐观锁 使用版本校验的方法保证事务的独立性 Sql的返回值是影响了多少行\n读取数据，记录timestamp 修改数据 检查和提交数据 数据库例题 可以用来程序调优\n改善数据访问方式以提高缓存命中率 使用数据库连接池替代直接的数据库访问 使用迭代来代替递归 合并多个远程调用批量发送 共享冗余数据提高访问效率（不可变对象） ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/interview/imooc/imooc_Google%E8%AE%B2Java/4th_%E6%95%B0%E6%8D%AE%E5%BA%93/","summary":"数据库 关系型数据库 基于关系代数理论 缺点： 表结构不直观，实现复杂速，速度慢 优点： 健壮性高，社区庞大 Product\nproduct_id product_name category_id price 4 toyota 2 100000 3 prosche 2 1000000 2 addidas 2 500 1 nike 600 category\ncategory_id category_name 2 automobile 1 shoes 1select * from product join category; -- 结果为笛卡尔积 8条记录 2 3select * from product p join category c on p.category_id=c.category_id; -- 按照id相等去连接， 忽略id 为空的记录 内连接 null的数据不会显示 4 5 6select * from product p left join category c on p.","tags":null,"title":""},{"categories":null,"contents":"程序设计语言基础 程序设计语言 类型检查\n编译时：C, C++, Java, Go 运行时： Python, Perl, JavaScript, Ruby 运行/编译\n编译为机器代码运行：C, C++ 编译为中间代码，在虚拟机运行： Java, C# 解释执行： Python, Perl, JavaScript 编程范式 Programming Paradigm\n面向过程: C, Visual Basic 面向对象: Java, C++, C#, Scala 函数式: Haskell, Erlang 数据类型和补码 数据类型\nboolean, byte, char short, int, long, float, double String, Enum, Array Object\u0026hellip; 补码\n32位int 范围 -2^31 ~ 2^31 -1 11000...0 -2^32 21111...1 -1 30000...0 0 40111...1 2^31-1 5 6-1 + 1 = 0 浮点数与定点数 浮点数 (+/-)1.XXXXXX * 2^y\n符号位| 指数部分 | 基数部分 64 位double 范围： +/- 10^308 64 位double 精度： 10^15 15位有效小数位 浮点数比较\na == b? Math.abs(a-b) \u0026lt; eps 使用BigDecimal 算钱 定点数 Java 拆箱与装箱 Primitive type vs Object\nprimitive type: int, long 值类型， 可以用a = b 去判断 Object: Integer, Long, Float, String 引用类型， a == b 判断是否为同一个Object， 用a.equals(b) 或者 Object.equals(a,b)][a 可以为 null]判断值是否相等。 Boxing and Unboxing Integer a = 2; // Boxing Integet b = new Integer(2); // Boxing int v = a.intValue(); 1new Integer(2) ==2; // true 自动拆箱 2new Integer(2) == new Integer(2); // false 3Integer.value(2) == Integer.value(2); // true 系统分配的箱子 IntegerCache.low IntegerCache.high (-128 127) 4Integer.value(2).intvalue() == 2; // true 5new Integer(2).equals(new Integer(2)) // true ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/interview/imooc/imooc_Google%E8%AE%B2Java/5th_%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1%E5%9F%BA%E7%A1%80/","summary":"程序设计语言基础 程序设计语言 类型检查\n编译时：C, C++, Java, Go 运行时： Python, Perl, JavaScript, Ruby 运行/编译\n编译为机器代码运行：C, C++ 编译为中间代码，在虚拟机运行： Java, C# 解释执行： Python, Perl, JavaScript 编程范式 Programming Paradigm\n面向过程: C, Visual Basic 面向对象: Java, C++, C#, Scala 函数式: Haskell, Erlang 数据类型和补码 数据类型\nboolean, byte, char short, int, long, float, double String, Enum, Array Object\u0026hellip; 补码\n32位int 范围 -2^31 ~ 2^31 -1 11000...0 -2^32 21111...1 -1 30000...0 0 40111...1 2^31-1 5 6-1 + 1 = 0 浮点数与定点数 浮点数 (+/-)1.","tags":null,"title":""},{"categories":null,"contents":"编码技巧 编码技巧概述 递归控制 循环控制 边界控制 数据结构 好的代码， 代码短，思路清晰\n白板上写程序 先思考后写， 不要惧怕修改和重写\n数学归纳法 用于证明断言对所有的自然数成立\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/interview/imooc/imooc_Google%E8%AE%B2Java/6th_%E7%BC%96%E7%A0%81%E6%8A%80%E5%B7%A7/","summary":"编码技巧 编码技巧概述 递归控制 循环控制 边界控制 数据结构 好的代码， 代码短，思路清晰\n白板上写程序 先思考后写， 不要惧怕修改和重写\n数学归纳法 用于证明断言对所有的自然数成立","tags":null,"title":""},{"categories":null,"contents":"面向对象 面向对象思想 类与对象 接口与实现 继承与封装 不可变对象 泛型 从用户(终端用户，使用你代码的用户)的角度思考问题 摒弃完全基于逻辑的思维 类与对象 类的成员变量 -\u0026gt; 对象状态\n类的成员函数 -\u0026gt; 对象行为\n类的静态变量\n类的静态函数\n逻辑结构 1class Employee{ 2 void getPaid(BankEndPont bank){ 3 bank.payment(name, salary); // this 4 } 5} 类的静态变量和静态函数\n没有this引用， 金泰变量全局唯一一份 普通函数引用静态变量和静态函数？ OK 对象引用静态变量, 函数？ 编译器警告 静态函数引用普通成员变量、 函数 ？ 编译错误 对象的特殊函数 构造函数 equals Object 的equals方法默认判断是否为同一个对象 hashCode a.hashCode() == b.hashCode() \u0026laquo;\u0026ndash; a.equals(b) toString 接口与抽象类 为什么要有接口的概念\n从用户(使用实现的代码)的角度看看问题 由编译器强制的一个模块间协作的合约(Contarct)， 强制协作双方无法犯错 无成员变量 成员函数只有声明不能有实现 接口的声明 Java : interface C++: 一个全部是纯虚函数的类 Python/ 大部分动态语言： 依靠注释申明 抽象类 至少有一个抽象方法， 抽象方法没有实现；\n从实现角度看 抽象类可以有成员变量 抽象类可以有部分实现 抽象类不可以多重继承， 接口可以 实现Iterable接口 ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/interview/imooc/imooc_Google%E8%AE%B2Java/7th_%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1/","summary":"面向对象 面向对象思想 类与对象 接口与实现 继承与封装 不可变对象 泛型 从用户(终端用户，使用你代码的用户)的角度思考问题 摒弃完全基于逻辑的思维 类与对象 类的成员变量 -\u0026gt; 对象状态\n类的成员函数 -\u0026gt; 对象行为\n类的静态变量\n类的静态函数\n逻辑结构 1class Employee{ 2 void getPaid(BankEndPont bank){ 3 bank.payment(name, salary); // this 4 } 5} 类的静态变量和静态函数\n没有this引用， 金泰变量全局唯一一份 普通函数引用静态变量和静态函数？ OK 对象引用静态变量, 函数？ 编译器警告 静态函数引用普通成员变量、 函数 ？ 编译错误 对象的特殊函数 构造函数 equals Object 的equals方法默认判断是否为同一个对象 hashCode a.hashCode() == b.hashCode() \u0026laquo;\u0026ndash; a.equals(b) toString 接口与抽象类 为什么要有接口的概念\n从用户(使用实现的代码)的角度看看问题 由编译器强制的一个模块间协作的合约(Contarct)， 强制协作双方无法犯错 无成员变量 成员函数只有声明不能有实现 接口的声明 Java : interface C++: 一个全部是纯虚函数的类 Python/ 大部分动态语言： 依靠注释申明 抽象类 至少有一个抽象方法， 抽象方法没有实现；","tags":null,"title":""},{"categories":null,"contents":"第8讲 设计模式 1. 单例模式 Singleton 设计模式的提出：博士论文 设计 vs 语言限制 更多的模式： 并发模式、架构模式 从架构的思想上看\nSingleton优缺点 确保全局至多只有一个对象 用于： 构造缓慢的对象，需要统一管理的资源 缺点： 很多全局状态， 线程安全性 Singleton的创建（创建非常慢的对象） 双重锁模式 Double checked locking 作为Java 类的静态变量（程序初始化的时候就要创建出来） 使用框架提供的能力 依赖注入的框架（DI框架 Spring, Google Juice）\n2. State 模式 变继承关系为组合关系 继承关系 描述is-a关系 复用，增加修改 不用用继承关系来实现复用 使用设计模式实现复用 如果 Employee 升级成了 Manager ？ 新建成一个Manager, 原先的引用应该被回收。\n或者使用state模式\n3. Decorator模式 装饰者模式 1interface Runable{ 2 void run(); 3} 如何实现LoggingRunable, TransactionRunable, \u0026hellip;.\n开始运行，运行结束，运行持续是时间\ncommit， roll back\n4. 如何创建对象 编译时就要确定是创建哪一个对象 ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/interview/imooc/imooc_Google%E8%AE%B2Java/8th_%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/","summary":"第8讲 设计模式 1. 单例模式 Singleton 设计模式的提出：博士论文 设计 vs 语言限制 更多的模式： 并发模式、架构模式 从架构的思想上看\nSingleton优缺点 确保全局至多只有一个对象 用于： 构造缓慢的对象，需要统一管理的资源 缺点： 很多全局状态， 线程安全性 Singleton的创建（创建非常慢的对象） 双重锁模式 Double checked locking 作为Java 类的静态变量（程序初始化的时候就要创建出来） 使用框架提供的能力 依赖注入的框架（DI框架 Spring, Google Juice）\n2. State 模式 变继承关系为组合关系 继承关系 描述is-a关系 复用，增加修改 不用用继承关系来实现复用 使用设计模式实现复用 如果 Employee 升级成了 Manager ？ 新建成一个Manager, 原先的引用应该被回收。\n或者使用state模式\n3. Decorator模式 装饰者模式 1interface Runable{ 2 void run(); 3} 如何实现LoggingRunable, TransactionRunable, \u0026hellip;.\n开始运行，运行结束，运行持续是时间\ncommit， roll back\n4. 如何创建对象 编译时就要确定是创建哪一个对象 ","tags":null,"title":""},{"categories":null,"contents":"高级知识点 1. 并行计算 将数据拆分到每个节点上 -\u0026gt; 如何拆分 每个节点并行的给出计算结果 -\u0026gt; 中间结果 将结果汇总 -\u0026gt; 如何汇总 2. 外部排序分析 如何排序100G个元素？\n只能有一部分数据放到内存\n归并排序 将数据分为左右两半，分别归并排序，再把两个有序数据归并 如何归并 归并节点的排序\u0026ndash; K路归并 使用堆实现 Priority Queue **使用Iterable 接口 **\n不断获取下一个元素 元素存储/获取方法被抽象, 与归并节点无关 Iterable merge(List\u0026lt; Iterable\u0026gt; sortData); 3. 死锁分析 多线程 线程安全 加锁， 锁的粒度，性能\n死锁分析 1void transfer(Account form, Account to, int amount){ 2 synchronized(form){ 3 synchronized(to){ 4 from.setAmount(for.getAmount() - amount); 5 to.setAmount(to.getAmount() + amount) 6 } 7 } 8} synchronized(form) -\u0026gt; 别的线程在等待from\nsynchronized(to) -\u0026gt; 别的线程已经锁住了to\n可能出现死锁：transfer(a,b,100) 和 transfer(b,a,100)同时进行\n在任何地方都可以进行线程切换，甚至在一句语句中间 要尽力设想对自己最不利的情况 死锁条件，必须同时满足 互斥等待 没有锁的必须等锁 hold and wait 拿到一个锁去等待另一个锁 循环等待 拿a等b 拿b等a 无法剥夺的等待 死锁防止 破除互斥等待 -\u0026gt; 一般无法破除 破除 hold and wait -\u0026gt; 一次性获取所有资源，大多数语言不支持 可以使用超时释放 破除 循环等待 -\u0026gt; 按顺序获取资源 破除 无法剥夺的等待 -\u0026gt; 不得已的办法，加入超时 4. 线程池介绍 线程池 创建线程开销大 线程池： 预先建立好线程，等待任务的派发 如果Blocking Queue的队列为空，所有的线程都会被block； 如果有任务进来，线程就会抢任务进行处理； 如果所有的线程都在处理任务，多余的任务就会在Blocking Queue中排队； 如果Blocking Queue中的也满了之后，应该采取一定的拒绝策略；\n线程池的参数 corePoolSize: 线程池中初始线程的数量，可能处于等待状态 maximumPoolSize: 线程池中最大允许线程数量 keepAliveTime: 超出corePoolSize部分线程如果等待这些时间将被回收\n5. 线程池 Java executor FrameWork 线程池的创建 任务派发 利用Future检查任务结果 线程数为30是生产环境中比较常见的一个数字\n1public class ExecutorTester { 2 3 public static void main(String[] args) 4 throws InterruptedException, ExecutionException { 5 ExecutorService executor = Executors.newFixedThreadPool(3); 6 7 List\u0026lt;Future\u0026lt;?\u0026gt;\u0026gt; taskResults = new LinkedList\u0026lt;\u0026gt;(); 8 for (int i = 0; i \u0026lt; 10; i++) { 9 taskResults.add(executor.submit(new CodingTask(i))); 10 } 11 System.out.println(\u0026#34;10 tasks dispatched successfully.\u0026#34;); 12 13 for (Future\u0026lt;?\u0026gt; taskResult : taskResults) { 14 taskResult.get(); 15 } 16 17 System.out.println(\u0026#34;All tasks finished.\u0026#34;); 18 executor.shutdown(); 19 } 20} 6. 资源管理 Java 垃圾回收 不被引用的对象会被回收 环形引用也会被回收掉 垃圾回收包括 Minor GC 和 Full GC 垃圾回收时所有运行暂停 内存泄露， 对象创建太多太快也会触发GC\nJava 资源管理 数据库的连接\n内存会被回收， 资源不会释放 databaseConnection需要databaseConnection.close()来释放 旧写法\n1try{ 2 Database databaseConnection = connect(...); 3 databaseConnection.beginTransaction(); 4 // do work 5}catch(Exception e){ 6 databaseConnection.rollBack(); 7}finally{ 8 databaseConnection.close(); // 关闭连接时候也有可能出现异常 9} 新写法 Java 1.7以后\n1try(Database databaseConnection = connect(...)){ 2 databaseConnection.beginTransaction(); 3 // do work 4}catch(Exception e){ 5 databaseConnection.rollBack(); 6} C++ 资源管理 C++ 没有finally, 没有try with resource C++ 有析构函数 1void dowork(){ 2 Database databaseConnection(); 3 try{ 4 databaseConnection.beginTransaction(); 5 // do work 6 }catch(Exception\u0026amp;e){ 7 databaseConnection.rollback(); 8 } 9} 10 11Database::~Database(){ 12 // close databaseConnection; 13} ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/interview/imooc/imooc_Google%E8%AE%B2Java/9th_%E9%AB%98%E7%BA%A7%E7%9F%A5%E8%AF%86%E7%82%B9/","summary":"高级知识点 1. 并行计算 将数据拆分到每个节点上 -\u0026gt; 如何拆分 每个节点并行的给出计算结果 -\u0026gt; 中间结果 将结果汇总 -\u0026gt; 如何汇总 2. 外部排序分析 如何排序100G个元素？\n只能有一部分数据放到内存\n归并排序 将数据分为左右两半，分别归并排序，再把两个有序数据归并 如何归并 归并节点的排序\u0026ndash; K路归并 使用堆实现 Priority Queue **使用Iterable 接口 **\n不断获取下一个元素 元素存储/获取方法被抽象, 与归并节点无关 Iterable merge(List\u0026lt; Iterable\u0026gt; sortData); 3. 死锁分析 多线程 线程安全 加锁， 锁的粒度，性能\n死锁分析 1void transfer(Account form, Account to, int amount){ 2 synchronized(form){ 3 synchronized(to){ 4 from.setAmount(for.getAmount() - amount); 5 to.setAmount(to.getAmount() + amount) 6 } 7 } 8} synchronized(form) -\u0026gt; 别的线程在等待from\nsynchronized(to) -\u0026gt; 别的线程已经锁住了to","tags":null,"title":""},{"categories":null,"contents":"imooc_React16 快速上手 实现TodoList react简介以及语法基础 react Fiber // React 16 之后的版本对应的框架\nredux\nreact 环境搭建\nReact 脚手架工具 create-react-app\n1npx create-react-app todolist # create-react-app 2cd todolist 3yarn start # npm run start 什么是组件 component\n简单的jsx语法 项目代码 1├── src 2│ ├── TodoItem.js 3│ ├── TodoList.js 4│ ├── index.js 5│ ├── serviceWorker.js 6│ └── style.css Index.js Index.js 是项目的入口\n1import React from \u0026#39;react\u0026#39;; 2import ReactDOM from \u0026#39;react-dom\u0026#39;; 3import \u0026#39;./style.css\u0026#39;; 4// 组件，大写字母开头 s 5import TodoList from \u0026#39;./TodoList\u0026#39;; 6 7 8ReactDOM.render(\u0026lt;TodoList /\u0026gt;, document.getElementById(\u0026#39;root\u0026#39;)); 所有的组件都是大写字母开头的， 引入React是为了识别大写字母开头的组件\nTodoList.js 组件, ES6语法规范下的一些新的写法\n1import React, {Component, Fragment}from \u0026#39;react\u0026#39;; 2import TodoItem from \u0026#39;./TodoItem\u0026#39;; 3 4// 组件需要继承 React.Component, 才能具有组件的方法以及生命周期 5class TodoList extends Component { 6 7 // constructor(props){ 8 // super(props); 9 // this.state={ 10 // list:[ 11 // \u0026#39;learn react\u0026#39;, 12 // \u0026#39;learn english\u0026#39; 13 // ] 14 // } 15 //this.handleDelete=this.handleDelete.bind(this) 16 // } 17 18 state = { 19 list: [], 20 inputValue: \u0026#39;\u0026#39; 21 } 22 23 handleAdd=()=\u0026gt; { 24 // this.state.list.push(\u0026#34;hello world\u0026#34;) 这样写是不工作的 25 this.setState({ 26 list: [...this.state.list, this.state.inputValue], 27 inputValue: \u0026#39;\u0026#39; 28 }) 29 30 console.log(\u0026#34;add new item: \u0026#34; + this.state.list) 31 } 32 33 handleInputChange(e) { 34 this.setState({ 35 inputValue: e.target.value 36 }) 37 } 38 39 handleDelete(index) { 40 // 如果要对state 中的数据进行操作，最好通过副本去操作 41 const list = [...this.state.list] 42 list.splice(index,1) 43 // this.setState({ 44 // list:list 45 // }) 46 this.setState({list}) 47 } 48 49 getItems(){ 50 return( 51 this.state.list.map((item, index) =\u0026gt; { 52 return \u0026lt;TodoItem key={index} 53 handleDelete={this.handleDelete.bind(this)} 54 content={item} 55 index={index}/\u0026gt; 56 }) 57 ) 58 } 59 60 render() { 61 // jsx 语法 62 // 父组件通过属性的方式向子组件传递参数 63 // 子组件通过props的方式接受父组件传递的参数 64 return ( 65 \u0026lt;Fragment\u0026gt; 66 \u0026lt;div\u0026gt; 67 \u0026lt;input value={this.state.inputValue} onChange={this.handleInputChange.bind(this)}\u0026gt;\u0026lt;/input\u0026gt; 68 {/* \u0026lt;button style={{background:\u0026#39;red\u0026#39;, color:\u0026#39;#fff\u0026#39;}} onClick={this.handleAdd.bind(this)} \u0026gt;add\u0026lt;/button\u0026gt; */} 69 \u0026lt;button className=\u0026#39;red-btn\u0026#39; onClick={this.handleAdd} \u0026gt;add\u0026lt;/button\u0026gt; 70 \u0026lt;/div\u0026gt; 71 \u0026lt;ul\u0026gt; 72 { 73 // this.state.list.map((item, index) =\u0026gt; { 74 // return \u0026lt;TodoItem key={index} 75 // handleDelete={this.handleDelete.bind(this)} 76 // content={item} 77 // index={index}/\u0026gt; 78 // // return \u0026lt;li onClick={this.handleDelete.bind(this, index)} key={index}\u0026gt;{item}\u0026lt;/li\u0026gt; 79 // }) 80 this.getItems() 81 } 82 \u0026lt;/ul\u0026gt; 83 \u0026lt;/Fragment\u0026gt; 84 ); 85 } 86} 87 88export default TodoList; TodoItem.js 1import React from \u0026#39;react\u0026#39; 2 3class TodoItem extends React.Component{ 4 // 子组件如果要和父组件通信要调用父组件传递过来的方法实现传值 5 handleDelete(){ 6 // 子组件向父组件传值 7 this.props.handleDelete(this.props.index) 8 console.log(this.props.index) 9 } 10 11 render(){ 12 const {content} = this.props; 13 return( 14 \u0026lt;div onClick={this.handleDelete.bind(this)}\u0026gt; 15 {/* {this.props.content} */} 16 {content} 17 \u0026lt;/div\u0026gt; 18 ) 19 } 20} 21 22export default TodoItem; ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/interview/imooc/Imooc_react16.4%E5%8F%8A%E5%85%B6%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B/","summary":"imooc_React16 快速上手 实现TodoList react简介以及语法基础 react Fiber // React 16 之后的版本对应的框架\nredux\nreact 环境搭建\nReact 脚手架工具 create-react-app\n1npx create-react-app todolist # create-react-app 2cd todolist 3yarn start # npm run start 什么是组件 component\n简单的jsx语法 项目代码 1├── src 2│ ├── TodoItem.js 3│ ├── TodoList.js 4│ ├── index.js 5│ ├── serviceWorker.js 6│ └── style.css Index.js Index.js 是项目的入口\n1import React from \u0026#39;react\u0026#39;; 2import ReactDOM from \u0026#39;react-dom\u0026#39;; 3import \u0026#39;./style.css\u0026#39;; 4// 组件，大写字母开头 s 5import TodoList from \u0026#39;./TodoList\u0026#39;; 6 7 8ReactDOM.","tags":null,"title":""},{"categories":null,"contents":"3rd_数据库架构 5th_Linux ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/interview/imooc/imooc_%E5%89%91%E6%8C%87offer/0_Category/","summary":"3rd_数据库架构 5th_Linux ","tags":null,"title":""},{"categories":null,"contents":"","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/interview/imooc/imooc_%E5%89%91%E6%8C%87offer/10th_Java%E5%B8%B8%E7%94%A8%E7%B1%BB%E5%BA%93%E4%B8%8E%E6%8A%80%E5%B7%A7/","summary":"","tags":null,"title":""},{"categories":null,"contents":"","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/interview/imooc/imooc_%E5%89%91%E6%8C%87offer/11th_Java%E6%A1%86%E6%9E%B6Spring/","summary":"","tags":null,"title":""},{"categories":null,"contents":"","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/interview/imooc/imooc_%E5%89%91%E6%8C%87offer/12th_%E8%AF%BE%E7%A8%8B%E6%80%BB%E7%BB%93%E4%B8%8E%E5%B1%95%E6%9C%9B/","summary":"","tags":null,"title":""},{"categories":null,"contents":"","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/interview/imooc/imooc_%E5%89%91%E6%8C%87offer/1st_%E8%AF%BE%E7%A8%8B%E5%AF%BC%E5%AD%A6/","summary":"","tags":null,"title":""},{"categories":null,"contents":"计算机网络面试核心 7. HTTP 简介 超文本传输协议的主要特点 是应用层的请求响应的无状态协议\n支持客户/服务器模式 ： 浏览器通过url向服务端发送请求， 服务端返回响应信息 简单快速 ： 请求方法 get post delete 通讯速度快 灵活： 数据格式灵活，允许任意格式的数据类型 无连接： 每次连接只处理一个请求，收到应答之后就断开连接 ， 1.1 之后使用了长连接 下层实现对上层透明， keep alive 无状态： 对事务处理没有记忆能力，缺少状态， version 1.1 引入了 keep alive 持续连接机制 2.0 升级成本太大 HTTP 请求结构 HTTP请求报文结构\n1GET /baidu/com HTTP1.1 2 Host: www.baidu.com 3 Connection:keep-alive # close 1.1之前 4 User-Agent： Mozilla/5.0 5 Accept-Encoding 6Cookie: XXX HTTP响应结构 1HTTP 1.1 200 OK 2\tServer: 3\tAccept-Ranges: 4\tContent-Type: 5\tContent-Languge: 6\tContent-Length: 7\tDate: 请求/响应步骤 客户端连接到WEB服务器 发送HTTP请求 服务器接受请求并返回HTTP响应 释放TCP连接： 服务器主动关闭TCP连接，浏览器被动释放TCP连接 客户端浏览器解析HTML内容 在浏览器地址键入http 开头的url，按下回车之后经历的流程 DNS解析 ：逐层查询路由器中的DNS缓存，浏览器-系统-路由器-IPS服务器-根域名服务器缓存-顶级域名服务器缓存，返回对应IP TCP连接：IP+80端口 三次握手 http协议版本 发送HTTP请求： 服务器处理并返回HTTP报文 浏览器解析渲染页面 连接结束 HTTP状态码 1XX：指示信息——表示请求已接收，继续处理\n2XX：成功——表示请求已被成功接收、理解、接受\n3XX：重定向——要完成请求必须进行更进一步的操作\n4XX：客户端错误——请求有语法错误或请求无法实现\n401 （未授权） 请求要求身份验证。 对于需要登录的网页，服务器可能返回此响应。 403 （禁止） 服务器拒绝请求。5XX：服务端错误——服务端未能实现合法的请求\nhttps://www.cnblogs.com/gitnull/p/9532129.html\n8. HTTP 介绍2 常见状态码 200 OK： 正常返回信息 400 Bad Request： 客户端请求有语法错误，不能被服务器理解 401 Unauthorized： 请求未经授权，这个状态码必须和WWW-Authenticate报头域一起使用 403 Forbidden： 服务器收到请求，但是拒绝提供服务 404 Not Found：请求资源不存在，eg，输入了错误的url 500 Internal Server Error： 服务器发生不可预期的错误 503 Server Unavailable：服务器当前不能处理客户端的请求，一段时间后可能回复正常 GET和POST的区别 HTTP报文层面：GET将请求信息放在URL中，POST放在报文体中， get的请求信息长度是有限制的。post是没有限制的 数据库层面： GET符合幂等性和安全性，POST不符合 其他层面： GET请求可以被缓存、被存储，而POST不行 Cookie 和Session的区别 Cookie 简介 是服务器发送给客户端的特殊信息，以文本的形式存放在客户端， 存放在Response Header中 客户端再次请求的时候，会把Cookie回发 服务器接收到后，会解析Cookie生成与客户端相对应的内容 Cookie的设置以及发送过程 Session简介 服务器端的机制，在服务器上保存信息 解析客户端请求，并操作session id，按需保存状态信息 Session的实现方式 使用Cookie来实现： JSESSIONID\n使用url回写来实现\n区别\nCookie数据存放在客户的浏览器上，session数据存放在服务端 Session相对于Cookie更安全 若考虑减轻服务器负担，应当使用Cookie 9. HTTP 和HTTPS 的区别 SSL （Security Socket Layer， 安全套接层） 为网络通信提供安全及数据完整性的一种安全协议 是操作系统对外的API，SSL3.9后更名为TSL 采用身份验证和数据加密保证网络通信的安全和数据的完整性 加密的方式 对称加密： 加密和解密使用同一个密钥 非对称加密： 加密使用的密钥和解密使用的密钥是不相同的 哈希算法： 将任意长度的信息转换我固定长度的值，算法不可逆 MD5 数字签名： 证明某个消息或者文件是某人发出/认同的 HTTPS数据传输流程 浏览器支持的加密算法信息发送给服务器\n服务器选择一套浏览器支持的加密算法，以证书的形式回发浏览器\n浏览器验证证书的合法性，并结合证书公钥加密信息发送给服务器\n服务器使用私钥解密信息，验证哈希，加密响应消息回发浏览器\n浏览器解密响应消息，并对消息进行验真，之后进行加密交互数据\n区别 HTTPS 需要到CA申请证书， HTTP不需要\nHTTPS密文传输，HTTP明文传输\n连接方式不同，HTTPS默认使用443端口，HTTP使用80端口\nHTTPS = HTTP+加密+认证+完整性保护，较HTTP安全\nHTTPS真的很安全吗\n默认浏览器填充http://, 请求需要进行跳转，有被劫持的风险 可以使用HSTS(HTTP Strict Transport Security)优化 10. Socket相关 进程间通信 pid唯一标识本地的进程，本地唯一\nSocket是对TCP/IP协议的抽象，是操作系统对外开放的接口\nSocket起源于Unix，一切皆是文件\nSocket通信流程 11. 网络知识总结 OSI七层架构 TCP/IP 协议\nTCP\n三次握手 SYN Flood 攻击 TCP报文头 为什么要进行三次握手 四次挥手 TIME_WAIT CLOSE_WAIT 为什么要进行四次挥手 滑动窗口 TCP和UDP的区别 HTTP\n请求结构 响应结构 请求响应步骤 浏览器键入URL经历的流程 状态码 GET和POST的区别 Cookie和Session的区别 HTTP和HTTPS的区别 Socket\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/interview/imooc/imooc_%E5%89%91%E6%8C%87offer/2nd_%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E8%AF%95%E6%A0%B8%E5%BF%83/","summary":"计算机网络面试核心 7. HTTP 简介 超文本传输协议的主要特点 是应用层的请求响应的无状态协议\n支持客户/服务器模式 ： 浏览器通过url向服务端发送请求， 服务端返回响应信息 简单快速 ： 请求方法 get post delete 通讯速度快 灵活： 数据格式灵活，允许任意格式的数据类型 无连接： 每次连接只处理一个请求，收到应答之后就断开连接 ， 1.1 之后使用了长连接 下层实现对上层透明， keep alive 无状态： 对事务处理没有记忆能力，缺少状态， version 1.1 引入了 keep alive 持续连接机制 2.0 升级成本太大 HTTP 请求结构 HTTP请求报文结构\n1GET /baidu/com HTTP1.1 2 Host: www.baidu.com 3 Connection:keep-alive # close 1.1之前 4 User-Agent： Mozilla/5.0 5 Accept-Encoding 6Cookie: XXX HTTP响应结构 1HTTP 1.1 200 OK 2\tServer: 3\tAccept-Ranges: 4\tContent-Type: 5\tContent-Languge: 6\tContent-Length: 7\tDate: 请求/响应步骤 客户端连接到WEB服务器 发送HTTP请求 服务器接受请求并返回HTTP响应 释放TCP连接： 服务器主动关闭TCP连接，浏览器被动释放TCP连接 客户端浏览器解析HTML内容 在浏览器地址键入http 开头的url，按下回车之后经历的流程 DNS解析 ：逐层查询路由器中的DNS缓存，浏览器-系统-路由器-IPS服务器-根域名服务器缓存-顶级域名服务器缓存，返回对应IP TCP连接：IP+80端口 三次握手 http协议版本 发送HTTP请求： 服务器处理并返回HTTP报文 浏览器解析渲染页面 连接结束 HTTP状态码 1XX：指示信息——表示请求已接收，继续处理","tags":null,"title":""},{"categories":null,"contents":"数据库 1. 数据库架构 关系型数据库的主要考点： 架构、 索引、锁、语法、理论范式\n范式一： 列不可再分 范式二： 标准键 范式三： 去除传递依赖\n如何设计一个关系型数据库 RDMBS\n存储管理：尽可能的减少IO，使用块或者页实现 缓存机制：不宜过大，要有淘汰机制 LRU SQL解析：SQL解析 日志管理：记录操作记录 binlog 权限划分： 容灾机制：处理异常 索引管理： 锁管理：\n1. 为什么要使用索引？ 避免全表扫描，快速查询数据\n全表扫描 所有的数据分批次加载到内存 索引 - 对应字典的偏旁部首等\n2. 什么样的信息能够成为索引 主键、唯一键、普通键等\n3. 索引的数据结构 生成索引，建立二叉查找树今次那个二分查找 生成索引，建立B-Tree进行查找\n生成索引，建立B+Tree结构进行查找\n生成索引，建立Hash结构进行查找\n2. 优化索引- 二叉查找树 二叉查找树 二叉查找树：左子节点小于 根节点， 右子节点大于根节点 平衡二叉树： 左右子树深度的差值不超过1\n二叉查找树容易变为线性二叉树 即使使用数的旋转也会出现数的深度递增导致IO的次数增加 3. 优化索引- B-Tree 平衡多路查找树 每个节点有至多m个孩子， M阶B树 定义：\n根节点至少包括两个孩子 树中每个节点最多含有有M个孩子(m\u0026gt;2) 除根节点和叶节点外，其他每个节点都至少有ceil(m/2)个孩子 所有的叶子节点都位于同一层 假设每个非终端节点中包含有n个关键字信息，其中 Ki(i=1,\u0026hellip;n) 为关键字，且关键字顺序按升序排序Ki-1\u0026lt; Ki 关键字的个数n必须满足：[ceil(m/2) -1]\u0026lt;= n \u0026lt;= m-1 非叶子节点的指针：P[1],P[2],\u0026hellip;P[M];其中P[1]指向关键字小于K[1]的子树，P[M]指向关键字大于K[M-1]的子树，其他P[i]指向关键字属于(K[i-1]K[i])的子树。 让每一个节点尽可能存储更多的信息，尽可能的减少数的深度，从而减少IO的次数\nB-Tree 会远比二叉树矮的多\n4. 优化索引 B+-Tree B+-Tree 与 B-Tree 的区别\n关键字的个数和指针的个数一致 B+-Tree 是B-Tree 的变体，其定义基本与B-Tree 相同 除了\n非叶子节点的子树指针与关键字个数相同 非叶子节点的子树指针P[i],指向关键字值[K[i],K[i+1])的子树。（左闭右开） 非叶子节点仅用来做索引，数据保存在叶子节点中 所有叶子节点均有一个链指针，指向下一个叶子节点。（有利于做范围统计） B+-Tree 更适合用来做存储索引 B+Tree 的磁盘读写代价更低，内部节点只存储索引 B+Tree 的查询效率更加稳定 O(logn) B+Tree 更有利于对数据库的扫描 5. 优化索引 - Hash以及BitMap Hash索引 缺点\n仅能满足\u0026quot;=\u0026quot;, \u0026ldquo;IN\u0026rdquo;,不能使用范围查询 无法被用来避免数据的排序操作 不能利用部分索引键查询 组合索引建立的hash 值 不能避免表扫描 遇到大量Hash值相等的情况后，性能并不一定会比B+-Tree索引高 BitMap 索引 锁的粒度非常的大，不适合高并发， OLAP\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/interview/imooc/imooc_%E5%89%91%E6%8C%87offer/3rd_%E6%95%B0%E6%8D%AE%E5%BA%93%E6%9E%B6%E6%9E%84/","summary":"数据库 1. 数据库架构 关系型数据库的主要考点： 架构、 索引、锁、语法、理论范式\n范式一： 列不可再分 范式二： 标准键 范式三： 去除传递依赖\n如何设计一个关系型数据库 RDMBS\n存储管理：尽可能的减少IO，使用块或者页实现 缓存机制：不宜过大，要有淘汰机制 LRU SQL解析：SQL解析 日志管理：记录操作记录 binlog 权限划分： 容灾机制：处理异常 索引管理： 锁管理：\n1. 为什么要使用索引？ 避免全表扫描，快速查询数据\n全表扫描 所有的数据分批次加载到内存 索引 - 对应字典的偏旁部首等\n2. 什么样的信息能够成为索引 主键、唯一键、普通键等\n3. 索引的数据结构 生成索引，建立二叉查找树今次那个二分查找 生成索引，建立B-Tree进行查找\n生成索引，建立B+Tree结构进行查找\n生成索引，建立Hash结构进行查找\n2. 优化索引- 二叉查找树 二叉查找树 二叉查找树：左子节点小于 根节点， 右子节点大于根节点 平衡二叉树： 左右子树深度的差值不超过1\n二叉查找树容易变为线性二叉树 即使使用数的旋转也会出现数的深度递增导致IO的次数增加 3. 优化索引- B-Tree 平衡多路查找树 每个节点有至多m个孩子， M阶B树 定义：\n根节点至少包括两个孩子 树中每个节点最多含有有M个孩子(m\u0026gt;2) 除根节点和叶节点外，其他每个节点都至少有ceil(m/2)个孩子 所有的叶子节点都位于同一层 假设每个非终端节点中包含有n个关键字信息，其中 Ki(i=1,\u0026hellip;n) 为关键字，且关键字顺序按升序排序Ki-1\u0026lt; Ki 关键字的个数n必须满足：[ceil(m/2) -1]\u0026lt;= n \u0026lt;= m-1 非叶子节点的指针：P[1],P[2],\u0026hellip;P[M];其中P[1]指向关键字小于K[1]的子树，P[M]指向关键字大于K[M-1]的子树，其他P[i]指向关键字属于(K[i-1]K[i])的子树。 让每一个节点尽可能存储更多的信息，尽可能的减少数的深度，从而减少IO的次数","tags":null,"title":""},{"categories":null,"contents":"Redis 缓存知识考点 熔断机制： 数据库down掉，可以缓存顶上\n缓存中间件-Memcache 和 Redis 的区别 Memcache: 代码层次类似Hash\n支持简单数据类型 不支持数据持久化 不支持主从 不支持分片 shard Redis 数据类型丰富 支持数据磁盘持久化存储 支持主从 支持分片 为什么Redis能这么快 100000+ QPS(QPS-\u0026gt; query per second, 每秒查询次数)\n完全基于内存， 绝大部分请求是纯粹的内存操作， 执行效率高 数据结构简单， 对数据的操作简单 采用单线程，单线程也能处理高并发请求，想多核也可以启动多实例 使用多路I/O复用模型，非阻塞I/O 多路I/O 复用模型 FD： File Descriptor , 文件描述符 一个打开的文件通过唯一的描述符进行引用， 该描述符是打开文件的元数据到文件本身的映射。\n传统的阻塞IO模型 多路IO复用模型 select 系统调用 Redis采用的IO多路复用函数： epoll【】/kqueue/evport/select \u0026hellip;\n因地制宜 优先选用时间复杂度为O(1)的IO多路复用函数作为底层实现 ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/interview/imooc/imooc_%E5%89%91%E6%8C%87offer/4th_Redis/","summary":"Redis 缓存知识考点 熔断机制： 数据库down掉，可以缓存顶上\n缓存中间件-Memcache 和 Redis 的区别 Memcache: 代码层次类似Hash\n支持简单数据类型 不支持数据持久化 不支持主从 不支持分片 shard Redis 数据类型丰富 支持数据磁盘持久化存储 支持主从 支持分片 为什么Redis能这么快 100000+ QPS(QPS-\u0026gt; query per second, 每秒查询次数)\n完全基于内存， 绝大部分请求是纯粹的内存操作， 执行效率高 数据结构简单， 对数据的操作简单 采用单线程，单线程也能处理高并发请求，想多核也可以启动多实例 使用多路I/O复用模型，非阻塞I/O 多路I/O 复用模型 FD： File Descriptor , 文件描述符 一个打开的文件通过唯一的描述符进行引用， 该描述符是打开文件的元数据到文件本身的映射。\n传统的阻塞IO模型 多路IO复用模型 select 系统调用 Redis采用的IO多路复用函数： epoll【】/kqueue/evport/select \u0026hellip;\n因地制宜 优先选用时间复杂度为O(1)的IO多路复用函数作为底层实现 ","tags":null,"title":""},{"categories":null,"contents":"Linux Linux 的体系结构 体系结构主要分为 用户态(用户上层活动)和内核态 内核： 本质是一段管理计算机硬件设备的程序 系统调用：内核的访问接口，是一种不能再简化的操作。 原子性的操作。 公用函数库： 系统调用的组合拳 Shell:命令解释器， 可编程 windows - cigwin\n查看系统调用 Linux - man 2 syscalls less / more / cat /tail\n切换默认shell\n查找特定的文件 find\n语法： find path [options] params 作用： 在指定目录下查找文件 1find ./ -name \u0026#34;fileName\u0026#34; # 精确查找 2find ~ -name \u0026#34;target*\u0026#34; # 模糊查找文件 3find ~ -iname \u0026#34;target*\u0026#34; # 忽略大小写的查找 4man find # 查看find的使用说明 检索文件内容 grep\n语法： grep [options] pattern file 全称 Global Regular Expression Print 作用： 用于查找文件里符合条件的字符串, 智慧筛选出目标字符串所在的行 1grep \u0026#34;moo\u0026#34; target* # 查找 target* 开头的文件中包含 \u0026#34;moo\u0026#34; 的行 管道操作符 | 可以将指令连接起来，前一个指令的输出作为后一个指令的输入 只处理前一个命令的正确输出， 不处理错误输出 右边命令必须接收标准输入流，否则传递过程中数据会被抛弃 sed, awk, grep, cut, head, top, less, more, wc, join, sort, split 等 1grep \u0026#39;partial\\[true\\]\u0026#39; test.log | grep -o \u0026#39;engine\\[[0-9 a-z]*\\]\u0026#39; # 符合正则表达式 2 3ps -ef|grep tomcat| grep -v \u0026#34;grep\u0026#34; # 过滤掉不需要的内容 对文件内容做统计 awk\n语法： awk [options] 'cmd' file 一次读取一行文本， 按照输入分隔符进行切片，切成多个组成部分 将切片直接保存在内建的变量中，$1, $2\u0026hellip;.($0 表示行的全部) 支持对单个切片的判断，支持循环判断，默认分隔符为空格 1awk \u0026#39;{print $1,$4}\u0026#39; fileName.txt # 获取文件的第1， 4 列 2 3awk \u0026#39;$1==\u0026#34;tcp\u0026#34; \u0026amp;\u0026amp; $2==1{print $0}\u0026#39; fileName.txt #按条件查询获取对应的行 4 5awk \u0026#39;($1==\u0026#34;tcp\u0026#34; \u0026amp;\u0026amp; $2==1) || NR==1 {print $0}\u0026#39; fileName.txt # 按条件查询，同时获取第1行 6 7awk -F \u0026#34;,\u0026#34; \u0026#39;{print $2}\u0026#39; fileName.txt # 分隔符号为 \u0026#34;,\u0026#34; 8 9XXXXXX | awk \u0026#39;{enginearr[$1]++}END{for(i in enginearr)print i \u0026#34;\\t\u0026#34; enginearr[i]}\u0026#39; # 统计 第1列 出现的次数 批量替换掉文本中的内容 sed\n语法: sed [option] 'sed command' fileName\n全名 stream editor， 流编辑器 适合对文本内容进行处理 1sed \u0026#39;s/^Str/String/\u0026#39; fileName.txt # 替换内容后输出 ^ 表示以Str 开头的 2 3sed -i \u0026#39;s/^Str/String/\u0026#39; fileName.txt # 替换源文件的内容， 无输出 4 5sed -i \u0026#39;s/\\.$/\\;/\u0026#39; fileName.txt # $ 代表以...结束 6 7sed -i \u0026#39;s/Jack/me/g\u0026#39; fileName.txt # g 表示全文替换，如果没有g只会替换第一个 8 9sed -i \u0026#39;/^ *$/d\u0026#39; fileName.txt # 删除空 10 11sed -i \u0026#39;/Integer/d\u0026#39; fileName.txt # 删除包含Integer 的行 跳槽过程中容易被忽略的细节 面试要偷偷摸摸进行 面试时间不要一味的将就对方 提离职要谨慎， 拿到offer再离职 好聚好散 跳槽时间衔接： 一般15号之后离职， 下个月15号前入职社保不会断 ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/interview/imooc/imooc_%E5%89%91%E6%8C%87offer/5th_Linux/","summary":"Linux Linux 的体系结构 体系结构主要分为 用户态(用户上层活动)和内核态 内核： 本质是一段管理计算机硬件设备的程序 系统调用：内核的访问接口，是一种不能再简化的操作。 原子性的操作。 公用函数库： 系统调用的组合拳 Shell:命令解释器， 可编程 windows - cigwin\n查看系统调用 Linux - man 2 syscalls less / more / cat /tail\n切换默认shell\n查找特定的文件 find\n语法： find path [options] params 作用： 在指定目录下查找文件 1find ./ -name \u0026#34;fileName\u0026#34; # 精确查找 2find ~ -name \u0026#34;target*\u0026#34; # 模糊查找文件 3find ~ -iname \u0026#34;target*\u0026#34; # 忽略大小写的查找 4man find # 查看find的使用说明 检索文件内容 grep\n语法： grep [options] pattern file 全称 Global Regular Expression Print 作用： 用于查找文件里符合条件的字符串, 智慧筛选出目标字符串所在的行 1grep \u0026#34;moo\u0026#34; target* # 查找 target* 开头的文件中包含 \u0026#34;moo\u0026#34; 的行 管道操作符 | 可以将指令连接起来，前一个指令的输出作为后一个指令的输入 只处理前一个命令的正确输出， 不处理错误输出 右边命令必须接收标准输入流，否则传递过程中数据会被抛弃 sed, awk, grep, cut, head, top, less, more, wc, join, sort, split 等 1grep \u0026#39;partial\\[true\\]\u0026#39; test.","tags":null,"title":""},{"categories":null,"contents":"","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/interview/imooc/imooc_%E5%89%91%E6%8C%87offer/6th_JVM/","summary":"","tags":null,"title":""},{"categories":null,"contents":"1. 垃圾回收之标记算法 GC\n对象被判定为垃圾的标准 没有被其他对象引用 判定对象是否为垃圾的算法 引用计数法 通过判断对象的引用数量决定对象是否可以被回收 每个对象实例都有一个引用计数器，被引用则+1， 完成引用则-1 任何引用计数为0的实例 可以当做垃圾被回收 优点： 执行效率高， 程序受影响比较小 缺点： 无法检测出循环引用的情况，导致内存泄露\n可达性分析算法 通过判断对象的引用链是否可达到，来决定对象是否可以被回收\n可以作为GC Root的对象：\n虚拟机栈中引用的对象（栈帧中的本地变量表） 方法区中的常量引用的对象 方法区中类静态属性引用的对象 本地方法栈中JNI(Native 方法) 的引用对象 活跃线程的引用对象 2. 谈谈你了解的垃圾回收算法 标记-清除法 Mark and Sweep 标记： 从根集合进行扫描，对存活的对象进行标记 清除： 对堆内存从头到尾进行线性遍历，回收不可达对象内存\nMark 阶段 -\u0026gt; Sweep 阶段\n存在问题： 碎片化严重，大对象无法找到连续的内存，容易触发下次垃圾回收，outofmemery\n复制算法 Coping - 年轻代 适用于对象存活时间比较低的情况\n分为对象面和空闲面 对象在对象面上创建 存活对象从对象面复制到空闲面 将对象面所有对象内存清除 有点： 解决了碎片化问题， 顺序分配内存，简单高效，适用于对象存活率低的场景\u0026ndash;年轻代\n标记整理法 - 老年代 整理： 移动所有存活的对象，且按内存地址次序依次排列，然后将末端内存地址以后的内存全部回收。\n优点： 避免了内存不连续，不用设置两块内存互换，适用于存活率高的场景\n分代收集算法 垃圾回收算法的组合拳\n按照生命周期的不同划分区域， 以采用不同的垃圾回收算法 提高了JVM的垃圾回收效率 Survivor Partitiion 年轻代 复制算法\n|Eden Space|From Space| To Space|\nOld Generation 老年代 - 标记清除算法 标记整理算法\nTenured Space\nPermanen Generation 持久代 -\nPermanent Space\nGC 的分类 Minor GC\n新生代： 尽可能的尽快收集掉那些生命周短的对象\nFull GC\n主要回收老年代\nFull GC比Minor GC 慢, 但是执行频率低\n新生代 1/3 堆空间 Eden 8/10 | from 1/10 | to 1/10\n老年代 2/3 堆空间\n年轻代垃圾回收过程\nEden 区域满会出发一次Minor GC Eden 和 From 区域中的对象会全部移动到 to 区域， 对象的age++，同时清空Eden和From区域\n对象移动到老年代 新生代中的对象达到一定的年龄后会移动到老年代 15岁默认 新生代区域Eden和 Suivivor装不下的大对象会直接移动到老年代 这块区域采用的是复制算法， 通多移动堆顶指针实现垃圾回收\n对象如何晋升到老年代 经历一定的minor 次数后依然存活的对象\nSurvivor 区域存放不下的对象\n新生的大对象-XX: +PretenureSizeThreshold\n常用的调优参数 -XX: SurvivorRatio Eden 和 Survivor 的比值， 默认为8:1 -XX: NewRatio 老年代和年轻代内存大小的比例 -XX: MaxTenuringThreshold 对象从年轻代晋升到老年代经过GC次数的最大阈值\n老年代： 存放生命周期较长的对象 标记清除法 标记整理法\n触发Full GC的条件 老年代空间不足 永久代空间不足(Before Java7)Java8 以后没有永久代，使用元空间代替 Minor GC时晋升到老年代的平均大小大于老年代的剩余空间 调用System.gc()时 CMG GC时出现promotion failed， concurrent mode failed 使用RMI来进行RPC或管理的JDK应用每小时执行一次Full GC ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/interview/imooc/imooc_%E5%89%91%E6%8C%87offer/7th_GC%E7%9B%B8%E5%85%B3/","summary":"1. 垃圾回收之标记算法 GC\n对象被判定为垃圾的标准 没有被其他对象引用 判定对象是否为垃圾的算法 引用计数法 通过判断对象的引用数量决定对象是否可以被回收 每个对象实例都有一个引用计数器，被引用则+1， 完成引用则-1 任何引用计数为0的实例 可以当做垃圾被回收 优点： 执行效率高， 程序受影响比较小 缺点： 无法检测出循环引用的情况，导致内存泄露\n可达性分析算法 通过判断对象的引用链是否可达到，来决定对象是否可以被回收\n可以作为GC Root的对象：\n虚拟机栈中引用的对象（栈帧中的本地变量表） 方法区中的常量引用的对象 方法区中类静态属性引用的对象 本地方法栈中JNI(Native 方法) 的引用对象 活跃线程的引用对象 2. 谈谈你了解的垃圾回收算法 标记-清除法 Mark and Sweep 标记： 从根集合进行扫描，对存活的对象进行标记 清除： 对堆内存从头到尾进行线性遍历，回收不可达对象内存\nMark 阶段 -\u0026gt; Sweep 阶段\n存在问题： 碎片化严重，大对象无法找到连续的内存，容易触发下次垃圾回收，outofmemery\n复制算法 Coping - 年轻代 适用于对象存活时间比较低的情况\n分为对象面和空闲面 对象在对象面上创建 存活对象从对象面复制到空闲面 将对象面所有对象内存清除 有点： 解决了碎片化问题， 顺序分配内存，简单高效，适用于对象存活率低的场景\u0026ndash;年轻代\n标记整理法 - 老年代 整理： 移动所有存活的对象，且按内存地址次序依次排列，然后将末端内存地址以后的内存全部回收。\n优点： 避免了内存不连续，不用设置两块内存互换，适用于存活率高的场景\n分代收集算法 垃圾回收算法的组合拳\n按照生命周期的不同划分区域， 以采用不同的垃圾回收算法 提高了JVM的垃圾回收效率 Survivor Partitiion 年轻代 复制算法","tags":null,"title":""},{"categories":null,"contents":"Java 多线程与并发 1. 进程与线程的区别 关于jdk版本的选择 JDK8,JDK11:Oracle 长期支持\nJava线程知识考点 进程和线程的区别 用户态和内核态的转换\n进程和线程的由来 串行 初期的计算机只能执行串行执行任务，并且需要长时间等待用户输入\n批处理 预先将用户指令集中成清单，批量串行处理用户指令，仍然无法并发执行\n进程 进程独占内存空间，保存各自运行状态，相互间不干扰且可以互相切换，为并发处理任务提供了可能\n线程 共享进程的内存资源，相互间切换更快捷，支持更细粒度的任务控制，使进程内的子任务得以并发执行\n进程和线程的区别 进程是资源分配的最小单位，线程是CPU调度的最小单位\n所有与进程相关的资源，都被记录在PCB中\n进程是抢占处理机的调度单位；线程属于某个进程，共享其资源\n线程只由堆栈寄存器、程序计数器和TCB组成\n总结\n线程不能看做独立应用，而进程可以看做独立应用 线程有独立的地址空间， 相互不影响，线程只是进程的不同执行路径 线程没有独立的地址空间，多进程的程序比多线程程序健壮 进程的切换比线程的切换开销大 Java进程和线程的关系 - Java对操作系统提供的功能进行封装，包括进程和线程 - 运行一个程序会产生一个进程，进程包含至少一个线程 - 每个进程对应一个JVM实例，多个线程共享JVM里的堆 - Java采用单线程编程模型，程序会自动创建主线程 - 主线程可以创建子线程，原则上要后于子线程完成执行 2. Thread 中start和run方法的区别 start native 方法 openjdk.java.net\n调用start() 方法会创建一个新的子线程并启动 run()方法只是一个Thread的一个普通方法的调用 3. Thread 和Runnable 的区别 Thread 实现了Runnable接口的类，使得run支持多线程 Runnable 只有一个抽象方法run 因为单一继承的原则，推荐多使用Runnable结构 4. 如何给run()方法传参 实现方式主要有三种\n构造函数传参 成员变量传参 回调函数传参 如何实现处理线程的返回值 实现方式主要有三种\n主线程等待法（有多个变量的时候比较难处理，循环等待的时间是不精确的） 使用Thread的join()方法阻塞当前线程以等待子线程处理完毕(粒度不够细) 通过Callable接口是实现： 通过FutureTask 或者 线程池获取 5.线程的状态 Thread 源码中有enum state 六个状态：\n新建 NEW: 创建后尚未启动的线程状态 运行 RUNNABLE：包含Running 和 Ready(等待时间片轮转) 无限期等待 WAITING：不会分配CPU执行时间，需要被显式的唤醒 没有设置Timeout参数的Object.wait() 方法 没有设置Timeout参数的Thread.join() 方法 LockSupport.park()方法 限期等待 Time Waiting 在一定时间后会由系统自动唤醒 Thread.sleep()方法 设置了Timeout参数的Object.wait()方法。 设置了Timeout参数的Thread.join()方法。 LockSupport.parkNanos()方法。 LockSupport.patkUtil()方法。 阻塞 Blocked 等待获取排它锁 synchronized 关键字 结束 Terminated : 已终止线程的状态，线程已经结束执行。（已经终止的线程不可以再次执行，否则会抛出IlleagleThreadStateException） 6 sleep和wait的区别 基本的差别：\nsleep() 是Thread类中定义的方法， wait是Object类中定义的方法。 sleep()方法可以在任何地方使用 wait()方法只能在synchronized方法或synchronized块中使用 最主要的本质区别 Thread.sleep()只会让出CPU， 不会导致锁行为的改变 Object.wait() 不仅会让出CPU，还会释放已经占有的同步资源锁 7.notify 和notifyall的区别 唤醒 wait\n两个概念 锁池 EntryList 等待池 WaitSet 锁池 假设线程A已经拥有了某个对象(不是类)的锁，而其他线程B/C想要调用这个对象的某个synchronize方法(或者块)，由于B/C线程在进入对象的synchronized方法(或者块)之前必须获得该对象锁的拥有权， 而恰巧该对象的锁目前正在线程A所占用， 此时B/C线程就会被阻塞， 进入一个地方去等待锁的释放， 这个地方便是该对象的锁池。 等待池 假设线程A调用了某个对象的wait()方法， 线程A就会释放该对象的锁， 同时线程A就进入了该对象的等待池中，进入到等待池中的线程不会去竞争该对象的资源锁。\nnotify和notifyall的区别 notifyAll 会让所有处于等待池中的线程全部进入锁池去竞争获取锁的机会 notify 只会随机选取一个处于等待池中的线程进入锁池去竞争获取锁的机会 volatile 修饰的变量，一旦线程A对其进行改动， 线程 B/C/D能够立马看线程A对其的改动\n8 yield函数 概念 当调用Thread.yield()函数时， 会给当前线程调度器一个当前线程愿意让出CPU的暗示，但是线程调度器可能会忽略这个暗示。 yield并不会让当前线程释放已经获得的锁\n9. 如何中断线程 已经被抛弃的方法：\n通过调用stop()方法停止线程 太过于暴力，线程不安全，数据不同步 通过调用suspend() 和 resume() 方法 目前使用的方法 调用interrupt()，通知线程应该中断了 如果线程处于被阻塞状态，那么线程将立即退出被阻塞状态，并且抛出一个InterruptedException异常。 如果线程处于正常活动状态，那么会将该线程的中断标志设置为true。被设置中断标志的线程将会继续正常运行，不受影响。 需要被调用的线程配合中断 在正常运行任务时，经常检查本线程的中断标志位，如果设置的了中断标志位就自行停止线程。 如果线程处于正常活跃状态，那么会将该线程的中断标志设置为true。 被设置中断标志的线程将继续正常运行，不受影响。 10. 前述方法以及线程状态总结 状态转换图\n彩蛋 如何有效谈薪资 增加自己的筹码\n尽量打听公司岗位职位的薪酬幅度 阿里p6 百度 p4 p5 感知目标公司的缺人程度， 工作的紧急程度 入职时间 最有效的方式是已经具备了有竞争力的offer ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/interview/imooc/imooc_%E5%89%91%E6%8C%87offer/8th_java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%8E%E5%B9%B6%E5%8F%91/","summary":"Java 多线程与并发 1. 进程与线程的区别 关于jdk版本的选择 JDK8,JDK11:Oracle 长期支持\nJava线程知识考点 进程和线程的区别 用户态和内核态的转换\n进程和线程的由来 串行 初期的计算机只能执行串行执行任务，并且需要长时间等待用户输入\n批处理 预先将用户指令集中成清单，批量串行处理用户指令，仍然无法并发执行\n进程 进程独占内存空间，保存各自运行状态，相互间不干扰且可以互相切换，为并发处理任务提供了可能\n线程 共享进程的内存资源，相互间切换更快捷，支持更细粒度的任务控制，使进程内的子任务得以并发执行\n进程和线程的区别 进程是资源分配的最小单位，线程是CPU调度的最小单位\n所有与进程相关的资源，都被记录在PCB中\n进程是抢占处理机的调度单位；线程属于某个进程，共享其资源\n线程只由堆栈寄存器、程序计数器和TCB组成\n总结\n线程不能看做独立应用，而进程可以看做独立应用 线程有独立的地址空间， 相互不影响，线程只是进程的不同执行路径 线程没有独立的地址空间，多进程的程序比多线程程序健壮 进程的切换比线程的切换开销大 Java进程和线程的关系 - Java对操作系统提供的功能进行封装，包括进程和线程 - 运行一个程序会产生一个进程，进程包含至少一个线程 - 每个进程对应一个JVM实例，多个线程共享JVM里的堆 - Java采用单线程编程模型，程序会自动创建主线程 - 主线程可以创建子线程，原则上要后于子线程完成执行 2. Thread 中start和run方法的区别 start native 方法 openjdk.java.net\n调用start() 方法会创建一个新的子线程并启动 run()方法只是一个Thread的一个普通方法的调用 3. Thread 和Runnable 的区别 Thread 实现了Runnable接口的类，使得run支持多线程 Runnable 只有一个抽象方法run 因为单一继承的原则，推荐多使用Runnable结构 4. 如何给run()方法传参 实现方式主要有三种\n构造函数传参 成员变量传参 回调函数传参 如何实现处理线程的返回值 实现方式主要有三种\n主线程等待法（有多个变量的时候比较难处理，循环等待的时间是不精确的） 使用Thread的join()方法阻塞当前线程以等待子线程处理完毕(粒度不够细) 通过Callable接口是实现： 通过FutureTask 或者 线程池获取 5.","tags":null,"title":""},{"categories":null,"contents":"","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/interview/imooc/imooc_%E5%89%91%E6%8C%87offer/9th_Java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%8E%E5%B9%B6%E5%8F%91%E5%8E%9F%E7%90%86/","summary":"","tags":null,"title":""},{"categories":null,"contents":"javabasic 课程涉及到的Java代码，持续更新中\u0026hellip;\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/interview/imooc/imooc_%E5%89%91%E6%8C%87offer/javabasic/README/","summary":"javabasic 课程涉及到的Java代码，持续更新中\u0026hellip;","tags":null,"title":""},{"categories":null,"contents":"","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/interview/imooc/imooc_%E7%8E%A9%E8%BD%AC%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/8th_%E4%BC%98%E5%85%88%E9%98%9F%E5%88%97%E5%92%8C%E5%A0%86/","summary":"","tags":null,"title":""},{"categories":null,"contents":"算法面试到底是什么鬼？ 1-1 算法面试不仅仅是正确的回答问题 算法面试的目的 展现思考问题的方式 算法面试过程 看做是和面试官一起探讨一个问题的解决方案。对于问题的细节和应用环境，可以和面试官沟通。 这种沟通本身很重要，它暗示着你思考问题的方式。\n我们需要对一组数据进行排序。 快速排序算法 O(nlogn)\n正确+更优 这组数据有什么样的特征？ 有没有可能包含有大量的重复元素？ 如果有这种可能的话，三路快排是更好的选择。 Java 默认是三路快排。\n这组数据有什么样的特征？ 是否大部分数据距离它的正确位置很近？是否近乎有序？ 如果是这样的话插入排序更优\n是否数据的取值范围非常有限？比如学生成绩排序。 计数排序更优\n对排序有什么额外的要求 是否需要稳定排序 归并排序更优\n数据的存储状况是怎样的 如果使用链表存储，归并排序更优\n数据的大小是否可以装在内存里， 外部排序\n什么是正确的回答一个算法问题\n正确还包含对问题的独到见解，容错性，\n1-2 算法面试只是面试的一部分 算法面试优秀不意味着技术面试优秀\n算法面试只是技术面试的一部分\n项目经历和项目中遇到的实际问题\n你遇到印象最深的bug是什么？\n面向对象\n设计模式\n网络相关：安全相关，内存相关，并发相关\n系统设计： scalability\n面试不仅仅是考察技术水平，以及对过去项目的思考\n项目经历\n通过过去了解你的思考行为方式\n遇到的最大的挑战\n犯过的错误\n遇到的失败\n最享受的工作内容\n遇到冲突的处理方式\n做的最与众不同的事儿\n准备好合适的问题问面试官\n1-3 如何准备算法面试 避免完美学习\n使用时间片学习\n远远不需要达到竞赛的水平\n不要轻视基础算法和数据结构，而只关注有意思的题目\n各种排序算法 技术数据结构和算法的实现： 如堆，二叉树，图 基础数据结构的使用： 如链表、栈、队列、哈希表、图、Tire、并查集 基础算法： 深度优先、广度优先、二分查找、递归 基本算法思想：递归、分治、回溯搜索、贪心、动态规划 选择合适的OJ online judge\nleetcode： online portal for interview\nhackRank: Revolutionizing Tech recruiting\nacmcode\n竞赛类oj\ncodeforces\ntopcoder\ncodechef\n1-4 如何回答算法面试问题 解决算法面试问题的整体思路\n注意题目中的条件，\n给定一个有序数组\n有一些题目中的条件本质是暗示\n设计一个O(nlogn)的算法 分治 无需考虑额外的空间 数据规模大概是10000 nlogn 百万级或者千万级别\n没有思路的时候给自己几个简单的用例\n暴力解法是思考的起点\n3：Longest Substring without Repeating characters 在一个字符串中寻找没有重复字母的最长子串\n优化算法\n遍历常见的算法思路\n遍历常见的数据结构\n空间和时间的交换 哈希表\n预处理信息 排序\n在瓶颈处寻找答案：\n实际编写问题\n极端条件的判断\n数组为空，字符串为空，\n变量名\n模块化和复用性\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/interview/imooc/imooc_%E7%8E%A9%E8%BD%AC%E7%AE%97%E6%B3%95%E9%9D%A2%E8%AF%95_leetcode%E7%89%88%E6%9C%AC/1st_md/","summary":"算法面试到底是什么鬼？ 1-1 算法面试不仅仅是正确的回答问题 算法面试的目的 展现思考问题的方式 算法面试过程 看做是和面试官一起探讨一个问题的解决方案。对于问题的细节和应用环境，可以和面试官沟通。 这种沟通本身很重要，它暗示着你思考问题的方式。\n我们需要对一组数据进行排序。 快速排序算法 O(nlogn)\n正确+更优 这组数据有什么样的特征？ 有没有可能包含有大量的重复元素？ 如果有这种可能的话，三路快排是更好的选择。 Java 默认是三路快排。\n这组数据有什么样的特征？ 是否大部分数据距离它的正确位置很近？是否近乎有序？ 如果是这样的话插入排序更优\n是否数据的取值范围非常有限？比如学生成绩排序。 计数排序更优\n对排序有什么额外的要求 是否需要稳定排序 归并排序更优\n数据的存储状况是怎样的 如果使用链表存储，归并排序更优\n数据的大小是否可以装在内存里， 外部排序\n什么是正确的回答一个算法问题\n正确还包含对问题的独到见解，容错性，\n1-2 算法面试只是面试的一部分 算法面试优秀不意味着技术面试优秀\n算法面试只是技术面试的一部分\n项目经历和项目中遇到的实际问题\n你遇到印象最深的bug是什么？\n面向对象\n设计模式\n网络相关：安全相关，内存相关，并发相关\n系统设计： scalability\n面试不仅仅是考察技术水平，以及对过去项目的思考\n项目经历\n通过过去了解你的思考行为方式\n遇到的最大的挑战\n犯过的错误\n遇到的失败\n最享受的工作内容\n遇到冲突的处理方式\n做的最与众不同的事儿\n准备好合适的问题问面试官\n1-3 如何准备算法面试 避免完美学习\n使用时间片学习\n远远不需要达到竞赛的水平\n不要轻视基础算法和数据结构，而只关注有意思的题目\n各种排序算法 技术数据结构和算法的实现： 如堆，二叉树，图 基础数据结构的使用： 如链表、栈、队列、哈希表、图、Tire、并查集 基础算法： 深度优先、广度优先、二分查找、递归 基本算法思想：递归、分治、回溯搜索、贪心、动态规划 选择合适的OJ online judge\nleetcode： online portal for interview","tags":null,"title":""},{"categories":null,"contents":"二叉树和递归 二叉树天然的递归结构 满二叉树\n二叉树的前序遍历 递归实现 1void preOrder(TreeNode node){ 2 if(node==null){ 3 return; // 递归终止条件 4 } 5 System.out.print(node.val); 6 preOrder(node.left); // 递归过程 7 preOrder(node.right); 8} 二叉树的定义：空是一棵二叉树\n二叉树总是否包含某个key 1boolean contain(TreeNode node, Key key){ 2 if(node == null){ 3 return false; 4 } 5 if(key == node.key){ 6 return true; 7 } 8 if(contain(node.left,key)|| contain(node.right, key)){ 9 return true; 10 } 11 return false; 12} 1// c++ 释放二叉树的内存 2void destory(TreeNode node){ 3 if(node == null){ 4 return; 5 } 6 destory(node.left); 7 destory(node.right); 8 delete node; 9 count-- 10} LeetCode 104： Maximum Depth of Binary Tree 求一棵二叉树的最高深度，从根节点到叶子节点的最长路径长度\n递归实现 1public static int maxDepth(TreeNode root){ 2 if(root == NULL){ 3 return 0; 4 } 5 return Math.max(maxDepth(root.left), maxDepth(root.right))+1; 6} 非递归实现 1class Solution { 2 public int maxDepth(TreeNode root) { 3 Queue\u0026lt;Pair\u0026lt;TreeNode, Integer\u0026gt;\u0026gt; stack = new LinkedList\u0026lt;\u0026gt;(); 4 if (root != null) { 5 stack.add(new Pair(root, 1)); 6 } 7 8 int depth = 0; 9 while (!stack.isEmpty()) { 10 Pair\u0026lt;TreeNode, Integer\u0026gt; current = stack.poll(); 11 root = current.getKey(); 12 int current_depth = current.getValue(); 13 if (root != null) { 14 depth = Math.max(depth, current_depth); 15 stack.add(new Pair(root.left, current_depth + 1)); 16 stack.add(new Pair(root.right, current_depth + 1)); 17 } 18 } 19 return depth; 20 } 21}; 复习二叉树相关的所有操作\nLeetCode 111：Minimum Depth of Binary Tree 求一棵二叉树的最低深度，从根节点到叶子节点的最短路径长度\n1class Solution { 2 public int minDepth(TreeNode root) { 3 if (root == null) { 4 return 0; 5 } 6 7 if ((root.left == null) \u0026amp;\u0026amp; (root.right == null)) { 8 return 1; 9 } 10 11 int min_depth = Integer.MAX_VALUE; 12 if (root.left != null) { 13 min_depth = Math.min(minDepth(root.left), min_depth); 14 } 15 if (root.right != null) { 16 min_depth = Math.min(minDepth(root.right), min_depth); 17 } 18 19 return min_depth + 1; 20 } 21} 一个简单的二叉树问题引发的血案 226： Invert Binary Tree 反转一棵二叉树\nMax Howell 因为不会做这道题目而被Google拒绝\nGoogle：90%of our engineer use the software you wrote(Homebrew), but you can\u0026rsquo;t invert a binary tree on a whiteboard so fuck off.\n1public TreeNode invertTree(TreeNode root) { 2 if (root == null) { 3 return null; 4 } 5 TreeNode right = invertTree(root.right); 6 TreeNode left = invertTree(root.left); 7 root.left = right; 8 root.right = left; 9 return root; 10} 100: Same Tree 给出两棵二叉树，判断这两棵二叉树是否完全一样\n1 public boolean isSameTree(TreeNode p, TreeNode q) { 2 // p and q are both null 3 if (p == null \u0026amp;\u0026amp; q == null) return true; 4 // one of p and q is null 5 if (q == null || p == null) return false; 6 if (p.val != q.val) return false; 7 return isSameTree(p.right, q.right) \u0026amp;\u0026amp; 8 isSameTree(p.left, q.left); 9 } 101: Sysmmetric Tree 给出一棵二叉树，判断其是否是左右对称的\n1public boolean isSymmetric(TreeNode root) { 2 return isMirror(root, root); 3} 4 5public boolean isMirror(TreeNode t1, TreeNode t2) { 6 if (t1 == null \u0026amp;\u0026amp; t2 == null) return true; 7 if (t1 == null || t2 == null) return false; 8 return (t1.val == t2.val) 9 \u0026amp;\u0026amp; isMirror(t1.right, t2.left) 10 \u0026amp;\u0026amp; isMirror(t1.left, t2.right); 11} 222: Count Complete Tree Node 给定一个棵完全二叉树，求完全二叉树节点的个数\n完全二叉树: 除了最后一层，所有层的节点数达到最大，与此同时，最后一层的所有节点都在最左侧。 堆使用完全二叉树。\n满二叉树： 所有层的节点数达到最大。\n1 public int countNodes(TreeNode root) { 2 if(root == null){ 3 return 0; 4 } 5 int left = countLevel(root.left); 6 int right = countLevel(root.right); 7 if(left == right){ 8 return countNodes(root.right) + (1\u0026lt;\u0026lt;left); 9 }else{ 10 return countNodes(root.left) + (1\u0026lt;\u0026lt;right); 11 } 12 } 13 private int countLevel(TreeNode root){ 14 int level = 0; 15 while(root != null){ 16 level++; 17 root = root.left; 18 } 19 return level; 20 } 110 : Balanced Binary Tree 判断一棵树是否为平衡二叉树\n平衡二叉树： 每一个节点的左右子树的高度差不超过1\n1public boolean isBalanced(TreeNode root) { 2 //它是一棵空树 3 if (root == null) { 4 return true; 5 } 6 //它的左右两个子树的高度差的绝对值不超过1 7 int leftDepth = getTreeDepth(root.left); 8 int rightDepth = getTreeDepth(root.right); 9 if (Math.abs(leftDepth - rightDepth) \u0026gt; 1) { 10 return false; 11 } 12 //左右两个子树都是一棵平衡二叉树 13 return isBalanced(root.left) \u0026amp;\u0026amp; isBalanced(root.right); 14 15} 16 17private int getTreeDepth(TreeNode root) { 18 if (root == null) { 19 return 0; 20 } 21 int leftDepth = getTreeDepth(root.left); 22 int rightDepth = getTreeDepth(root.right); 23 return Math.max(leftDepth, rightDepth) + 1; 24} 注意递归的终止条件 112： Path sum 给出一棵二叉树以及一个数字sum, 判断这棵二叉树上是否存在一条从根到叶子的路径。其路径上所有节点和为sum。\n易错情况\n1public static boolean hasPathSum(TreeNode root, int sum){ 2 if( root == null){ // 递归终止条件有问题 3\treturn sum == 0; 4 } 5 if(hasPathSum(root.left, sum -root.val)){ 6 return true; 7 } 8 if(hasPathSum(root.right, sum -root.val)){ 9 return true; 10 } 11 return false; 12} 1public static boolean hasPathSum(TreeNode root, int sum){ 2 if(root == null){ 3 return false; 4 } 5 if( root.left == null \u0026amp;\u0026amp; root.right = null){ // 递归终止条件有问题 6\treturn sum == root.val; 7 } 8 if(hasPathSum(root.left, sum -root.val)){ 9 return true; 10 } 11 if(hasPathSum(root.right, sum -root.val)){ 12 return true; 13 } 14 return false; 15 // return hasPathSum(root.left, sum -root.val)||hasPathSum(root.right, sum -root.val); 16} 404：Sum of Left Leaves 求出一棵二叉树所有左叶子的和\n1public int sumOfLeftLeaves(TreeNode root) { 2 if (root == null) return 0; 3 if (root.left == null) return sumOfLeftLeaves(root.right); //如果左子树为空，那么只需返回右子树的左叶子和 4 if (root.left.left == null \u0026amp;\u0026amp; root.left.right == null) // 如果左子树为叶子节点，那么需返回右子树的左叶子和 + 左孩子的值 5 return sumOfLeftLeaves(root.right) + root.left.val; 6 return sumOfLeftLeaves(root.left) + sumOfLeftLeaves(root.right); // 其他情况需返回左右子树的左叶子和之和 7} 257: Binary Tree Path\n给定一棵二叉树，返回所有表示从根节点到叶子节点路径的字符串\n1 public List\u0026lt;String\u0026gt; binaryTreePaths(TreeNode root) { 2 List\u0026lt;String\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(); 3 if(root == null){ 4 return list; 5 } 6 if(root.left == null \u0026amp;\u0026amp; root.right == null){ 7 list.add(\u0026#34;\u0026#34;+root.val); 8 } 9 List\u0026lt;String\u0026gt; left = binaryTreePaths(root.left); 10 for(String str: left){ 11 list.add(\u0026#34;\u0026#34;+root.val+\u0026#34;-\u0026gt;\u0026#34;+str); 12 } 13 List\u0026lt;String\u0026gt; right = binaryTreePaths(root.right); 14 for(String str: right){ 15 list.add(\u0026#34;\u0026#34;+root.val+\u0026#34;-\u0026gt;\u0026#34;+str); 16 } 17 return list; 18 } 113：Path Sum II\n给定一棵二叉树，返回所有从根节点到叶子节点的路径，其和为sum\n对于右侧二叉树，sum = 22，结果为[[5,4,11,2],[5,4,8,5]]\n129：Sum root to Leaf Numbers\n给定一棵二叉树，每个节点只包含数字0-9，从根节点到叶子节点的每条路径可以表示成一个数，求这些数的和。\n更复杂的递归逻辑 437： Path Sum II\n给出一棵二叉树以及一个数字sum，判断在这棵二叉树上存在多少条路径，其路径上所有节点和为sum。\n其中路径不一定哟啊起始于根节点；终止于叶子节点 路径可以从任意节点开始，但是只能是向下走的。 ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/interview/imooc/imooc_%E7%8E%A9%E8%BD%AC%E7%AE%97%E6%B3%95%E9%9D%A2%E8%AF%95_leetcode%E7%89%88%E6%9C%AC/7th_%E4%BA%8C%E5%8F%89%E6%A0%91%E5%92%8C%E9%80%92%E5%BD%92/","summary":"二叉树和递归 二叉树天然的递归结构 满二叉树\n二叉树的前序遍历 递归实现 1void preOrder(TreeNode node){ 2 if(node==null){ 3 return; // 递归终止条件 4 } 5 System.out.print(node.val); 6 preOrder(node.left); // 递归过程 7 preOrder(node.right); 8} 二叉树的定义：空是一棵二叉树\n二叉树总是否包含某个key 1boolean contain(TreeNode node, Key key){ 2 if(node == null){ 3 return false; 4 } 5 if(key == node.key){ 6 return true; 7 } 8 if(contain(node.left,key)|| contain(node.right, key)){ 9 return true; 10 } 11 return false; 12} 1// c++ 释放二叉树的内存 2void destory(TreeNode node){ 3 if(node == null){ 4 return; 5 } 6 destory(node.","tags":null,"title":""},{"categories":null,"contents":"动态规划基础 什么是动态规划 斐波那契数列 Fibonacci Sequence 1//时间复杂度 应该是指数级 2int fib(){ 3 if(n==0){ 4 return 0; 5 } 6 if(n==1){ 7 return 1; 8 } 9 return fib(n-1)+fib(n-2); 10} 递归会有很多的重复计算，重复的计算量会非常大。\n所以想办法对重复的计算 只计算一次\n记忆化搜索-自上而下的解决问题 改进的Fibonacci\n1// 记忆化搜索 时间复杂度O(n) 2int memo[]; 3int fib(){ 4 if(n==0){ 5 return 0; 6 } 7 if(n==1){ 8 return 1; 9 } 10 if(memo[n]==-1){ 11 memo[n]=fib(n-1)+fib(n-2); 12 } 13 return memo[n]; 14} 动态规划-自下而上的解决问题 1// 动态规划 2int fib(int n){ 3 vector\u0026lt;int\u0026gt; memo(n+1, -1); 4 memo[0] = 0; 5 memo[1] = 1; 6 for(int i=2; i\u0026lt;n;i++){ 7 memo[i] = memo[i-1]+memo[i-2]; 8 } 9 return memo[n]; 10} 动态规划：\n将原问题拆解成若干子问题，同时保存子问题的答案，使得每个子问题值求解一次，最终获得原问题的答案。 递归问题-\u0026gt; 重叠子问题\n爬楼梯问题 ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/interview/imooc/imooc_%E7%8E%A9%E8%BD%AC%E7%AE%97%E6%B3%95%E9%9D%A2%E8%AF%95_leetcode%E7%89%88%E6%9C%AC/9th_%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/","summary":"动态规划基础 什么是动态规划 斐波那契数列 Fibonacci Sequence 1//时间复杂度 应该是指数级 2int fib(){ 3 if(n==0){ 4 return 0; 5 } 6 if(n==1){ 7 return 1; 8 } 9 return fib(n-1)+fib(n-2); 10} 递归会有很多的重复计算，重复的计算量会非常大。\n所以想办法对重复的计算 只计算一次\n记忆化搜索-自上而下的解决问题 改进的Fibonacci\n1// 记忆化搜索 时间复杂度O(n) 2int memo[]; 3int fib(){ 4 if(n==0){ 5 return 0; 6 } 7 if(n==1){ 8 return 1; 9 } 10 if(memo[n]==-1){ 11 memo[n]=fib(n-1)+fib(n-2); 12 } 13 return memo[n]; 14} 动态规划-自下而上的解决问题 1// 动态规划 2int fib(int n){ 3 vector\u0026lt;int\u0026gt; memo(n+1, -1); 4 memo[0] = 0; 5 memo[1] = 1; 6 for(int i=2; i\u0026lt;n;i++){ 7 memo[i] = memo[i-1]+memo[i-2]; 8 } 9 return memo[n]; 10} 动态规划：","tags":null,"title":""},{"categories":null,"contents":"图 图的表示 邻接矩阵（Adjacent Matrix） 邻接表（Adjacent Matrix） 邻接表适合表示稀疏图（Sparse Graph）\n邻接矩阵适合表示稠密图（Dense Graph）\n稀疏图 稠密图和完全图 寻路 获得两点之间的一条路径\n图的深度优先遍历-时间复杂度\n稀疏图（邻接表）：O(V+E)\n稠密图（邻接矩阵）：O(v^2^)\n深度优先遍历算法-有向图\ndfs 查看是否有环- 有向图 广度优先遍历和最短路径 借助队列实现\n广度优先遍历求出了无权图的最短路径\n图的广度优先遍历-时间复杂度\n稀疏图（邻接表）：O(V+E)\n稠密图（邻接矩阵）：O(v^2^)\n无权图的应用- 迷宫生成，PS抠图 flood fill 魔棒抠图 连通分量\n扫雷 走迷宫、 迷宫生成 迷宫的本质是一棵树 本质是一个生成树的过程\n不能只用一种方式遍历， 随机队列遍历\n欧拉路径 哈密尔顿路径 二分图 同学选课\n地图着色 \u0001\u0001\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/interview/imooc/imooc_%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%BB%BC%E5%90%88%E6%8F%90%E5%8D%87%E7%AF%87/7th_%E5%9B%BE%E7%9A%84%E5%9F%BA%E7%A1%80/","summary":"图 图的表示 邻接矩阵（Adjacent Matrix） 邻接表（Adjacent Matrix） 邻接表适合表示稀疏图（Sparse Graph）\n邻接矩阵适合表示稠密图（Dense Graph）\n稀疏图 稠密图和完全图 寻路 获得两点之间的一条路径\n图的深度优先遍历-时间复杂度\n稀疏图（邻接表）：O(V+E)\n稠密图（邻接矩阵）：O(v^2^)\n深度优先遍历算法-有向图\ndfs 查看是否有环- 有向图 广度优先遍历和最短路径 借助队列实现\n广度优先遍历求出了无权图的最短路径\n图的广度优先遍历-时间复杂度\n稀疏图（邻接表）：O(V+E)\n稠密图（邻接矩阵）：O(v^2^)\n无权图的应用- 迷宫生成，PS抠图 flood fill 魔棒抠图 连通分量\n扫雷 走迷宫、 迷宫生成 迷宫的本质是一棵树 本质是一个生成树的过程\n不能只用一种方式遍历， 随机队列遍历\n欧拉路径 哈密尔顿路径 二分图 同学选课\n地图着色 \u0001\u0001","tags":null,"title":""},{"categories":null,"contents":"最小生成树 Minimum Span Tree 有权图 Weight Graph 邻接矩阵 Adjacent Matrix 邻接表 使用Edge 表示每一条连接边\n最小生成树问题和切分定理 带权无向图、连通图\n找V-1条边\n切分定理 Cut Property 把图中的节点分成两部分，成为一个切分(Cut)\n如果一个边的两个端点，属于切分不同的两边，这个边成为横切边(Crossing Edge);\n切分定理：\n给定任意切分，横切边中权值最小的边必然属于最小生成树\nPrim算法 Lazy Prim Lazy Prim 最小堆中依然有不会是横切边的边。\nLazy Prim 的时间复杂度为O(ElogE)\nPrim 算法优化 时间复杂度O(ElogV)\nIndexMinHeap\nKruskal算法 使用并查集\n使用Union Find 快速判断环\n最小生成树问题 最小生成树问题思考\nLazy Prim O(ElogE)\nPrim O(ElogV)\nKruskal O(ElogE)\n如果横切边有相等的边\n根据具体的算法实现，每次选择一个边\n此时，图存在多个最小生成树\nVyssotsky’s Algorithm\n将边逐渐添加到生成树中\n一旦形成环，删除环中权值最大的边\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/interview/imooc/imooc_%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%BB%BC%E5%90%88%E6%8F%90%E5%8D%87%E7%AF%87/8th_%E6%9C%80%E5%B0%8F%E7%94%9F%E6%88%90%E6%A0%91/","summary":"最小生成树 Minimum Span Tree 有权图 Weight Graph 邻接矩阵 Adjacent Matrix 邻接表 使用Edge 表示每一条连接边\n最小生成树问题和切分定理 带权无向图、连通图\n找V-1条边\n切分定理 Cut Property 把图中的节点分成两部分，成为一个切分(Cut)\n如果一个边的两个端点，属于切分不同的两边，这个边成为横切边(Crossing Edge);\n切分定理：\n给定任意切分，横切边中权值最小的边必然属于最小生成树\nPrim算法 Lazy Prim Lazy Prim 最小堆中依然有不会是横切边的边。\nLazy Prim 的时间复杂度为O(ElogE)\nPrim 算法优化 时间复杂度O(ElogV)\nIndexMinHeap\nKruskal算法 使用并查集\n使用Union Find 快速判断环\n最小生成树问题 最小生成树问题思考\nLazy Prim O(ElogE)\nPrim O(ElogV)\nKruskal O(ElogE)\n如果横切边有相等的边\n根据具体的算法实现，每次选择一个边\n此时，图存在多个最小生成树\nVyssotsky’s Algorithm\n将边逐渐添加到生成树中\n一旦形成环，删除环中权值最大的边","tags":null,"title":""},{"categories":null,"contents":"最短路径 路径最短问题和松弛操作（Relaxation） 最短路径问题 Shortest Path 路径规划 城市，路由\n工作任务规划\n广度优先遍历 -\u0026gt; 最短路径树 Shortest Path Tree\n单源最短路径 Single Source Shortest Path\n无权图的最短路径\n松弛操作是求最短路径的核心\nDijkstra 算法的思想 dijkstra 单源最短路径算法 前提： 图中不能有负权边\n复杂度 O(ElogV)\n负权边和Bellman-Ford算法 拥有负权环的图，没有最短路径\nBellman-Ford 单源最短路径算法 前提：图中不能有负权环\nBellman-Ford 判断图中是否有负权环\n复杂度O(EV)\n如果一个图没有负权环，从一个点到另一个点的最短路径，最多经过所有的V个顶线，有V-1条边。否则存在定点经过了两次，即存在负权环。\n对一个点的一次松弛操作，就是找到经过这个点的另外一条路径，多一条边，权值更小。\n如果一个图没有负权环，从一个点到另外一个点的最短路径，最多经过所有的V个顶线，有V-1条边。\n对所有的点进行V-1次松弛操作。\n对所有的点进程V-1次松弛操作，理论上就找到了从源点到其他所有点的最短路径。\n如果还可以继续松弛，就说明原图中有负权环\n##更多和最短路径相关的思考\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/interview/imooc/imooc_%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%BB%BC%E5%90%88%E6%8F%90%E5%8D%87%E7%AF%87/9th_%E6%9C%80%E7%9F%AD%E8%B7%AF%E5%BE%84/","summary":"最短路径 路径最短问题和松弛操作（Relaxation） 最短路径问题 Shortest Path 路径规划 城市，路由\n工作任务规划\n广度优先遍历 -\u0026gt; 最短路径树 Shortest Path Tree\n单源最短路径 Single Source Shortest Path\n无权图的最短路径\n松弛操作是求最短路径的核心\nDijkstra 算法的思想 dijkstra 单源最短路径算法 前提： 图中不能有负权边\n复杂度 O(ElogV)\n负权边和Bellman-Ford算法 拥有负权环的图，没有最短路径\nBellman-Ford 单源最短路径算法 前提：图中不能有负权环\nBellman-Ford 判断图中是否有负权环\n复杂度O(EV)\n如果一个图没有负权环，从一个点到另一个点的最短路径，最多经过所有的V个顶线，有V-1条边。否则存在定点经过了两次，即存在负权环。\n对一个点的一次松弛操作，就是找到经过这个点的另外一条路径，多一条边，权值更小。\n如果一个图没有负权环，从一个点到另外一个点的最短路径，最多经过所有的V个顶线，有V-1条边。\n对所有的点进行V-1次松弛操作。\n对所有的点进程V-1次松弛操作，理论上就找到了从源点到其他所有点的最短路径。\n如果还可以继续松弛，就说明原图中有负权环\n##更多和最短路径相关的思考","tags":null,"title":""},{"categories":null,"contents":"imooc_算法与数据结构综合提升篇 ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/interview/imooc/imooc_%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%BB%BC%E5%90%88%E6%8F%90%E5%8D%87%E7%AF%87/category/","summary":"imooc_算法与数据结构综合提升篇 ","tags":null,"title":""},{"categories":null,"contents":"二叉树的序列化和反序列化 二叉树-\u0026gt; ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/interview/imooc/%E7%89%9B%E5%AE%A2%E7%BD%91%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/1_%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%92%8C%E4%BA%8C%E5%8F%89%E6%A0%91%E9%97%AE%E9%A2%98/","summary":"二叉树的序列化和反序列化 二叉树-\u0026gt; ","tags":null,"title":""},{"categories":null,"contents":"CAS 和 ABA 问题 在多并发程序设计中，我们不得不面对并发、互斥、竞争、死锁、资源抢占等问题，归根结底就是读写的问题，有了读写才有增删改查，才有一切。同样也有了谁读谁写、这样的顺序和主次问题，于是就有了上锁，乐观锁和悲观锁、同步和异步、睡眠和换入换出等问题，归根结底就是模拟了社会的分工协作与资源共享的抢占，要理解好这些现象的本质，我们需要更加深刻的进行类比和辨析。要知道这些内容的本质就是内存和CPU之间的故事，有时候还会有一些外存和其他缓存。\nhttps://www.cnblogs.com/zyrblog/p/9864932.html\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/interview/JavaNote/CAS/","summary":"CAS 和 ABA 问题 在多并发程序设计中，我们不得不面对并发、互斥、竞争、死锁、资源抢占等问题，归根结底就是读写的问题，有了读写才有增删改查，才有一切。同样也有了谁读谁写、这样的顺序和主次问题，于是就有了上锁，乐观锁和悲观锁、同步和异步、睡眠和换入换出等问题，归根结底就是模拟了社会的分工协作与资源共享的抢占，要理解好这些现象的本质，我们需要更加深刻的进行类比和辨析。要知道这些内容的本质就是内存和CPU之间的故事，有时候还会有一些外存和其他缓存。\nhttps://www.cnblogs.com/zyrblog/p/9864932.html","tags":null,"title":""},{"categories":null,"contents":"RandomAccessFile 不同于FileInputStream和FileOutputStream,不是他们的子类 当我们想对一个文件进行读写操作的时候，创建一个指向该文件的RandomAccessFile流就可以了 ； 但是对于OutputStream和DataOutputStream，我们在使用的时候都是通过他们的构造方法来附加或更新文件，即在构造方法中new FileOutputStream；\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/interview/JavaNote/IO%E6%96%87%E4%BB%B6%E8%AF%BB%E5%86%99/","summary":"RandomAccessFile 不同于FileInputStream和FileOutputStream,不是他们的子类 当我们想对一个文件进行读写操作的时候，创建一个指向该文件的RandomAccessFile流就可以了 ； 但是对于OutputStream和DataOutputStream，我们在使用的时候都是通过他们的构造方法来附加或更新文件，即在构造方法中new FileOutputStream；","tags":null,"title":""},{"categories":null,"contents":"","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/interview/JavaNote/Java-%E5%BC%82%E5%B8%B8/","summary":"","tags":null,"title":""},{"categories":null,"contents":"Java8 新特性 Java8 速度更快，代码更少，强大的Stream API，便于并行 最大化减少空指针异常 optional\nLambda表达式 Lambda 是一个匿名函数，我们可以把Lambda 表达式理解为是一段可以传递的代码（将代码像数据一样进行传递）。可以写出更简洁、更灵活的代码。作为一种更紧凑的代码风格，使 Java的语言表达能力得到了提升。\n从匿名类到Lambda 的转换 1// 匿名内部类 2Runnable r1 = new Runnable(){ 3 @Override 4 public void run(){ 5 System.out.println(\u0026#34;Hello world\u0026#34;); 6 } 7} 8 9//Lambda 表达式 10Runnable r1 = () -\u0026gt; System.out.println(); 11 12//原来使用匿名内部类作为参数传递 13TreeSet\u0026lt;String\u0026gt; ts = new TreeSet\u0026lt;\u0026gt;(new Comparator\u0026lt;String\u0026gt;(){ 14 @Override 15 public int compare(String o1, String o2){ 16 return Integer.compare(o1.length(), o2.length()); 17 } 18}); 19 20//Lambda 表达式作为参数传递 21TreeSet\u0026lt;String\u0026gt; ts2 = new TreeSet\u0026lt;\u0026gt;( 22\t(o1, o2) -\u0026gt; Integer.compare(o1.length, o2.length)); 23 Lambda表达式语法 Lambda表达式在Java语言中引入了一个新的语法元素和操作符。这个操作符为“-\u0026gt;”，这个操作符被称为Lambda操作符或箭头操作符。它将Lambda分为两个部分：\n左侧：指定了Lambda 表达式需要的所有参数\n右侧：指定了Lambda体，即Lambda表达式要执行的功能\n语法格式 无参，无返回值，Lambda 体只需一条语句 1Runnable r1= ()-\u0026gt;System.out.println(\u0026#34;Hello World\u0026#34;); Lambda 需要一个参数\n1Consumer\u0026lt;String\u0026gt; fun = (args)-\u0026gt; System.out.println(args); Lambda 只需一个参数时，参数的小括号可以省略\n1Consumer\u0026lt;String\u0026gt; fun = args -\u0026gt; System.out.printlna(args); Lambda 需要两个参数，并且有返回值\n1BinaryOperator\u0026lt;Long\u0026gt; bo = (x,y) -\u0026gt; { 2 System.out.println(\u0026#34;实现函数接口方法！\u0026#34;); 3 return x+y; 4} 当Lambda体只有一条语句时，return与大括号可以省略\n1BinaryOperator\u0026lt;Long\u0026gt; bo = (x,y)-\u0026gt; x+y; 参数的数据类型可以省略，因为可以由编译器推断得出，称为“类型判断”\n1BinaryOperator\u0026lt;Long\u0026gt; bo = (Long x, Long y) -\u0026gt; { 2 System.out.println(\u0026#34;实现函数接口方法！\u0026#34;); 3 return x+y; 4} 类型推断 上述 Lambda 表达式中的参数类型都是由编译器推断得出的。Lambda 表达式中无需指定类型，程序依然可以编译，这是因为 javac 根据程序的上下文，在后台推断出了参数的类型。Lambda 表达式的类型依赖于上下文环境，是由编译器推断出来的。这就是所谓的 “类型推断”\n函数式接口 什么是是函数式接口 只包含一个抽象方法的接口，称为函数式接口。 你可以通过 Lambda 表达式来创建该接口的对象。（若 Lambda 表达式抛出一个受检异常，那么该异常需要在目标接口的抽象方法上进行声明）。 我们可以在任意函数式接口上使用 @FunctionalInterface 注解， 这样做可以检查它是否是一个函数式接口，同时 javadoc 也会包含一条声明，说明这个接口是一个函数式接口。 自定义函数式接口 1@FunctionalInterface 2public interface MyNumber{ 3 public double getValue(); 4} 函数式接口中使用泛型\n1@FunctionalInterface 2public interface MyFunc\u0026lt;T\u0026gt;{ 3 public T getValue(T t); 4} 函数式接口作为参数传递给Lambda表达式\n1public String toUpperString(Myfunc\u0026lt;String\u0026gt; mf, String str){ 2 return mf.getValue(str); 3} 4 5// 作为参数传递Lambda 表达式 6String newStr = toUpperString( 7\t(str) -\u0026gt; str.toUpperCase, \u0026#34;abcdef\u0026#34;; 8); 9Systen.out.println(newStr); 作为参数传递 Lambda 表达式：为了将 Lambda 表达式作为参数传递，接收Lambda 表达式的参数类型必须是与该 Lambda 表达式兼容的函数式接口 的类型。\n方法引用与构造器引用 Stream API 接口中默认方法与静态方法 jie\n新日期时间 API 其他新特性 Optional类 Optional 类(java.util.Optional) 是一个容器类，代表一个值存在或不存在， 原来用 null 表示一个值不存在，现在 Optional 可以更好的表达这个概念。并且可以避免空指针异常。\n常用方法：\nOptional.of(T t) : 创建一个 Optional 实例\nOptional.empty( : 创建一个空的 Optional 实例\nOptional.ofNullable(T t):若 t 不为 null,创建 Optional 实例,否则创建空实例\nisPresent() : 判断是否包含值\norElse(T t) : 如果调用对象包含值，返回该值，否则返回t\norElseGet(Supplier s) :如果调用对象包含值，返回该值，否则返回 s 获取的值\nmap(Function f): 如果有值对其处理，并返回处理后的Optional，否则返回 Optional.empty() flatMap(Function mapper)与 map 类似，要求返回值必须是Optional\n重复注解与类型注解 两点改进： 可重复的注解及可用于类型的注解\n1@Target({TYPE, FIELD, METHOD, PARAMETER, CON}) ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/interview/JavaNote/Java8%E6%96%B0%E7%89%B9%E6%80%A7/","summary":"Java8 新特性 Java8 速度更快，代码更少，强大的Stream API，便于并行 最大化减少空指针异常 optional\nLambda表达式 Lambda 是一个匿名函数，我们可以把Lambda 表达式理解为是一段可以传递的代码（将代码像数据一样进行传递）。可以写出更简洁、更灵活的代码。作为一种更紧凑的代码风格，使 Java的语言表达能力得到了提升。\n从匿名类到Lambda 的转换 1// 匿名内部类 2Runnable r1 = new Runnable(){ 3 @Override 4 public void run(){ 5 System.out.println(\u0026#34;Hello world\u0026#34;); 6 } 7} 8 9//Lambda 表达式 10Runnable r1 = () -\u0026gt; System.out.println(); 11 12//原来使用匿名内部类作为参数传递 13TreeSet\u0026lt;String\u0026gt; ts = new TreeSet\u0026lt;\u0026gt;(new Comparator\u0026lt;String\u0026gt;(){ 14 @Override 15 public int compare(String o1, String o2){ 16 return Integer.compare(o1.length(), o2.length()); 17 } 18}); 19 20//Lambda 表达式作为参数传递 21TreeSet\u0026lt;String\u0026gt; ts2 = new TreeSet\u0026lt;\u0026gt;( 22\t(o1, o2) -\u0026gt; Integer.","tags":null,"title":""},{"categories":null,"contents":"","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/interview/JavaNote/JavaIO/","summary":"","tags":null,"title":""},{"categories":null,"contents":"Java 虚拟机 虚拟机调优 Java 虚拟机调优参数 -Xms 起始内存 JVM堆内存 -Xmx 最大内存 JVM堆内存 -Xmn 新生代内存 -Xss 栈大小。 就是创建线程后，分配给每一个线程的大小 -XX:NewRatio 设置年轻代和老年代的比值。默认为2:1。如果为3，表示年轻代与老年代的比值为1:3，年轻代占整个年轻代和老年代的1/4。 -XX:SurvivorRatio年轻代中Eden区和两个Survivor区的比值。如果为3，表示Eden:Survivor = 3:2, 因为有两个Survivor区域，所以一个Survivor区占整个年轻代的1/5. -XX:MaxPermSize设置持久代的大小。 收集器的设置\n-XX:+UseSerialGC设置串行收集器 -XX:+UseParallelGC设置并行收集器 -XX:+UseParallelOld设置并行老年代收集器 -XX:+UseConcMarkSweepGC设置并发收集器 垃圾回收统计信息\n-XX:PrintGC -XX:PrintGCDetails -XX:PrintGCTimeStamps -Xloggc:filename 并行收集器设置\n-XX:ParallelGCThreads=n设置并行收集器收集时使用的CPU数。并行收集线程数。 -XX:MaxGCPauseMillis=n设置并行收集最大暂停时间 -XX:GCTimeRatio=n设置垃圾回收时间占程序运行时间的百分比。公式为1/(1+n) 并发收集器设置\nXX:+CMSIncrementalMode设置为增量模式。适用于单CPU情况。 XX:ParallelGCThreads=n设置并发收集器年轻代收集方式为并行收集时，使用的CPU数。并行收集线程数。 -Xms1G -Xmx2G -Xmn500M -XX:MaxPermSize=64M -XX:+UseConcMarkSweepGC -XX:SurvivorRatio=3\n-Xms1G JVM初始内存1G 这一部分是不是应该是堆内存 -Xmx2G JVM最大内存 2G -Xmn500M 新生代内存 500M -XX:MaxPermSize 持久代内存 64M -XX:SurvivorRatio=3 新生代中Eden:Servivor = 3:2 JVM 调优 -Xms2G -Xmx2G 将JVM最大内存与初始内存设置相等，避免JVM垃圾回收后重新分配内存。 -Xmn1G 年轻代内存Sun官方推荐配置为整个堆的3/8,通常设置为1/3或1/4。 -Xss256K减小每条线程栈的大小，能生成更多的线程 -XX:NewRatio=4 调整年轻代与老年代的比例 年轻代:老年代=1:4 -XX:MaxTenuringThreshold=0 设置晋升到老年代的对象的年龄。 如果设置为0，则年轻代对象不经过Survivor区，直接进入老年代。如果设置一个较大的值，则年轻代对象会在Survivor区进行多次复制。 -XX:+UseConcMarkSweepGC JVM在server模式下默认使用PararrelScavenge＋SerialOld的收集器组合进行内存回收，不支持与用户线程并发执行。可使用ParNew+CMS+SerialOld的收集器组合进行内存回收（SerialOld收集器做为CMS收集器出现ConcurrentModeFailure失败后的后备收集器使用），减少stop-the-world时间。 -XX:CMSFullGCsBeforeCompaction 使用CMS时，设置CMS收集器在进行若干次垃圾收集后再启动一次内存碎片 ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/interview/JavaNote/Java%E8%99%9A%E6%8B%9F%E6%9C%BA/","summary":"Java 虚拟机 虚拟机调优 Java 虚拟机调优参数 -Xms 起始内存 JVM堆内存 -Xmx 最大内存 JVM堆内存 -Xmn 新生代内存 -Xss 栈大小。 就是创建线程后，分配给每一个线程的大小 -XX:NewRatio 设置年轻代和老年代的比值。默认为2:1。如果为3，表示年轻代与老年代的比值为1:3，年轻代占整个年轻代和老年代的1/4。 -XX:SurvivorRatio年轻代中Eden区和两个Survivor区的比值。如果为3，表示Eden:Survivor = 3:2, 因为有两个Survivor区域，所以一个Survivor区占整个年轻代的1/5. -XX:MaxPermSize设置持久代的大小。 收集器的设置\n-XX:+UseSerialGC设置串行收集器 -XX:+UseParallelGC设置并行收集器 -XX:+UseParallelOld设置并行老年代收集器 -XX:+UseConcMarkSweepGC设置并发收集器 垃圾回收统计信息\n-XX:PrintGC -XX:PrintGCDetails -XX:PrintGCTimeStamps -Xloggc:filename 并行收集器设置\n-XX:ParallelGCThreads=n设置并行收集器收集时使用的CPU数。并行收集线程数。 -XX:MaxGCPauseMillis=n设置并行收集最大暂停时间 -XX:GCTimeRatio=n设置垃圾回收时间占程序运行时间的百分比。公式为1/(1+n) 并发收集器设置\nXX:+CMSIncrementalMode设置为增量模式。适用于单CPU情况。 XX:ParallelGCThreads=n设置并发收集器年轻代收集方式为并行收集时，使用的CPU数。并行收集线程数。 -Xms1G -Xmx2G -Xmn500M -XX:MaxPermSize=64M -XX:+UseConcMarkSweepGC -XX:SurvivorRatio=3\n-Xms1G JVM初始内存1G 这一部分是不是应该是堆内存 -Xmx2G JVM最大内存 2G -Xmn500M 新生代内存 500M -XX:MaxPermSize 持久代内存 64M -XX:SurvivorRatio=3 新生代中Eden:Servivor = 3:2 JVM 调优 -Xms2G -Xmx2G 将JVM最大内存与初始内存设置相等，避免JVM垃圾回收后重新分配内存。 -Xmn1G 年轻代内存Sun官方推荐配置为整个堆的3/8,通常设置为1/3或1/4。 -Xss256K减小每条线程栈的大小，能生成更多的线程 -XX:NewRatio=4 调整年轻代与老年代的比例 年轻代:老年代=1:4 -XX:MaxTenuringThreshold=0 设置晋升到老年代的对象的年龄。 如果设置为0，则年轻代对象不经过Survivor区，直接进入老年代。如果设置一个较大的值，则年轻代对象会在Survivor区进行多次复制。 -XX:+UseConcMarkSweepGC JVM在server模式下默认使用PararrelScavenge＋SerialOld的收集器组合进行内存回收，不支持与用户线程并发执行。可使用ParNew+CMS+SerialOld的收集器组合进行内存回收（SerialOld收集器做为CMS收集器出现ConcurrentModeFailure失败后的后备收集器使用），减少stop-the-world时间。 -XX:CMSFullGCsBeforeCompaction 使用CMS时，设置CMS收集器在进行若干次垃圾收集后再启动一次内存碎片 ","tags":null,"title":""},{"categories":null,"contents":"Java 集合类 线程安全与线程不安全 参考链接 https://www.cnblogs.com/williamjie/p/9099141.html\nhttps://www.cnblogs.com/heyonggang/p/9112731.html\nhttps://blog.csdn.net/andy_budd/article/details/81413464\nhttps://blog.csdn.net/wufaliang003/article/details/80219296\nhttps://blog.csdn.net/VIP_WangSai/article/details/70182933\nhttps://blog.csdn.net/qq_41216743/article/details/101311040\nhttps://blog.csdn.net/cn12306com/article/details/81318871\n相关面试题 1. 举例说明List 、Set、HashMap是线程不安全的 List ​ 我们知道ArrayList 是线程不安全的，请编写一个不安全的案例并给出解决方案？对于List我们使用的大多数场景是在单线程下，如果在高并发的情况下，便会出现一些线程不安全的问题\n1public class ContainerNotSafeDemo { 2 public static void main(String[] args) throws InterruptedException { 3 List\u0026lt;String\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(); 4 5// 3种解决方案 6// List\u0026lt;String\u0026gt; list = new Vector\u0026lt;\u0026gt;(); 7// List list = Collections.synchronizedList(new ArrayList\u0026lt;\u0026gt;()); 8// List list = new CopyOnWriteArrayList(); 9 10 for (int i = 0; i \u0026lt; 30; i++) { // 30 个线程，每一个线程都有对list的写与读操作 11 new Thread(() -\u0026gt; { 12 list.add(String.valueOf(new Random().nextInt(100))); 13// System.out.println(list); // 如果没有这一行就不会抛异常,但是list中的数据也不是30个 14 }, String.valueOf(i)).start(); 15 } 16 17 18 Thread.sleep(3000); 19 System.out.println(list+\u0026#34;\u0026#34;+list.size()); 20 } 21} 22 23/*1.故障现象 24* 报错java.util.ConcurrentModificationException 25* 2.导致原因 26* 并发争抢修改导致 27* 3.解决方案 28* new Vector(); 29* Collections.synchronizedList(new ArrayList\u0026lt;\u0026gt;()); 30* new CopyOnWriteArrayList\u0026lt;\u0026gt;(); 31* 4.优化建议 32* 在读多写少的时候推荐使用 CopeOnWriteArrayList 这个类 33*/ CopyOnWriteArrayList说明： CopyOnWrite容器即写时复制容器。往一个容器添加元素时，不直接往当前容器Object[] 进行Copy,复制出一个新的容器Object[] newElements, 然后新的容器setArray(newElements); 这样做的好处是可以对CopyOnWrite容器进行并发的读，而不需要加锁，因为当前容器不会添加任何元素，所以CopyOnWrite容器也是一直读写分离的思想，读和写是不同的容器。\nCopyOnWriteArrayList 下的Add方法：\n1 public boolean add(E e) { 2 final ReentrantLock lock = this.lock; 3 lock.lock(); 4 try { 5 Object[] elements = getArray(); 6 int len = elements.length; 7 Object[] newElements = Arrays.copyOf(elements, len + 1); 8 newElements[len] = e; 9 setArray(newElements); 10 return true; 11 } finally { 12 lock.unlock(); 13 } 14 } Set Set 是线程不安全的，请编写一个不安全的案例并给出解决方案？\n1 public static void main(String[] args) { 2 Set\u0026lt;String\u0026gt; set = new HashSet\u0026lt;\u0026gt;(); //导致线程不安全 3// 2种解决方案 4// Set\u0026lt;String\u0026gt; set = Collections.synchronizedSet(new HashSet\u0026lt;\u0026gt;()); 5// Set\u0026lt;String\u0026gt; set = new CopyOnWriteArraySet\u0026lt;\u0026gt;(); 6 for (int i = 1; i \u0026lt;= 30; i++) { 7 new Thread(()-\u0026gt;{ 8 set.add(UUID.randomUUID().toString().substring(0,8)); 9 System.out.println(set); 10 },String.valueOf(i)).start(); 11 } 12 //HashSet 底层是HashMap 13 } HashMap HashMap 是线程不安全的，请编写一个不安全的案例并给出解决方案？\n1 public static void main(String[] args) { 2 Map\u0026lt;String,String\u0026gt; map = new HashMap\u0026lt;\u0026gt;(); //导致线程不安全 3// 2种解决方案 4// Map\u0026lt;String,String\u0026gt; map = Collections.synchronizedMap(new HashMap\u0026lt;\u0026gt;()); 5// Map\u0026lt;String,String\u0026gt; map = new ConcurrentHashMap\u0026lt;\u0026gt;(); 6 for (int i = 0; i \u0026lt;= 30; i++) { 7 new Thread(()-\u0026gt;{ 8 map.put(Thread.currentThread().getName(), UUID.randomUUID().toString().substring(0,8)); 9 System.out.println(map); 10 },String.valueOf(i)).start(); 11 } 12 } ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/interview/JavaNote/Java%E9%9B%86%E5%90%88%E7%B1%BB/","summary":"Java 集合类 线程安全与线程不安全 参考链接 https://www.cnblogs.com/williamjie/p/9099141.html\nhttps://www.cnblogs.com/heyonggang/p/9112731.html\nhttps://blog.csdn.net/andy_budd/article/details/81413464\nhttps://blog.csdn.net/wufaliang003/article/details/80219296\nhttps://blog.csdn.net/VIP_WangSai/article/details/70182933\nhttps://blog.csdn.net/qq_41216743/article/details/101311040\nhttps://blog.csdn.net/cn12306com/article/details/81318871\n相关面试题 1. 举例说明List 、Set、HashMap是线程不安全的 List ​ 我们知道ArrayList 是线程不安全的，请编写一个不安全的案例并给出解决方案？对于List我们使用的大多数场景是在单线程下，如果在高并发的情况下，便会出现一些线程不安全的问题\n1public class ContainerNotSafeDemo { 2 public static void main(String[] args) throws InterruptedException { 3 List\u0026lt;String\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(); 4 5// 3种解决方案 6// List\u0026lt;String\u0026gt; list = new Vector\u0026lt;\u0026gt;(); 7// List list = Collections.synchronizedList(new ArrayList\u0026lt;\u0026gt;()); 8// List list = new CopyOnWriteArrayList(); 9 10 for (int i = 0; i \u0026lt; 30; i++) { // 30 个线程，每一个线程都有对list的写与读操作 11 new Thread(() -\u0026gt; { 12 list.","tags":null,"title":""},{"categories":null,"contents":"多线程 ​\n守护线程 Java的main是普通线程，并不是守护线程，\n守护线程会等待所有的线程执行结束后再结束\n线程同步 https://www.jianshu.com/p/2394317257ec\nhttps://www.jianshu.com/p/988bfceadb62\nhttps://www.jianshu.com/p/6f98f03430eb\nhttps://www.cnblogs.com/williamjie/p/9099141.html\nJava 主线程等待所有子线程执行完毕 Java 主线程等待所有子线程执行完毕再执行。\n用sleep() 让主线程睡眠一段时间，但是这个睡眠时间是主观设置的，是有我们自己主观设定的，所以不推荐使用。\n1public static void main(String[] args) throws InterrupteException{ 2 for(int i=0; i\u0026lt;5;i++){ 3 new Thread( 4 new Runnable(){ 5 public void run(){ 6 try{ 7 Thread.sleep(1000); 8 }catch(InterruptException e){ 9 e.preintStrackTrace(); 10 } 11 System.out.println(\u0026#34;子线程执行！\u0026#34;); 12 } 13 } 14 ).start(); 15 } 16 Thread.sleep(5000); 17 System.out.println(\u0026#34;主线程执行！\u0026#34;); 18} 使用Thread的jion()等待所有的子线程执行完毕，主线程再执行，thread.jion()把指定线程加入到当前线程，可以将两个交替执行的线程合并为顺序执行的线程。比如在B中调用了线程A的jion()方法，直到线程A执行完毕后，才会继续执行线程B。\n1public static void main(String[] args) throws InterrupteException{ 2 Vector\u0026lt;Thread\u0026gt; threadVector = new Vector\u0026lt;\u0026gt;(); 3 for(int i=0; i\u0026lt;5;i++){ 4 Thread childThread = new Thread( 5 new Runnable(){ 6 public void run(){ 7 try{ 8 Thread.sleep(1000); 9 }catch(InterruptException e){ 10 e.preintStrackTrace(); 11 } 12 System.out.println(\u0026#34;子线程执行！\u0026#34;); 13 } 14 } 15 ); 16 threadVector.add(childThread); 17 childThread.start(); 18 } 19 for(Thread thread: threadVector){ 20 thread.jion(); 21 } 22 System.out.println(\u0026#34;主线程执行！\u0026#34;); 23} 等待多线程完成的CountDownLatch\n1public static void main(String[] args) throws InterruptedException{ 2 final CountDownLatch latch = new CountDownLatch(5); 3 for(int i =0; i\u0026lt;5; i++){ 4 new Thread(new Runnable(){ 5 public void run(){ 6 try{ 7 Thread.sleep(1000); 8 }catch(InterruptException e){ 9 e.printStackTrace; 10 } 11 System.out.println(\u0026#34;子线程执行！\u0026#34;); 12 latch.countDown(); // 让Latch 中的数值减1 13 } 14 }).start; 15 latch.await(); // 阻塞当前线程直到latch中的值为0 16 System.out.println(\u0026#34;主线程执行！\u0026#34;); 17 } 18} 在这里说明一点，countDownLatch不可能重新初始化或者修改CountDownLatch对象内部计数器的值，一个线程调用countdown方法happen-before另外一个线程调用await方法\n同步屏障CyclicBarrier\n1public static void main(String[] args) throws InterruptedException{ 2 final CyclicBarrier barrier = new CyclicBarrier(5); 3 for(int i =0; i\u0026lt;5; i++){ 4 new Thread(new Runnable(){ 5 public void run(){ 6 try{ 7 Thread.sleep(1000); 8 }catch(InterruptException e){ 9 e.printStackTrace; 10 } 11 System.out.println(\u0026#34;子线程执行！\u0026#34;); 12 try{ 13 barrier.awiat(); // 到达屏障 14 }catch(Exception e){ 15 e.printStrackTrace(); 16 } 17 18 } 19 }).start; 20 barrier.await(); 21 System.out.println(\u0026#34;主线程执行！\u0026#34;); 22 } 23} countDownLatch只能使用一次，而CyclicBarrier方法可以使用reset()方法重置，所以CyclicBarrier方法可以能处理更为复杂的业务场景。\n我曾经在网上看到一个关于countDownLatch和cyclicBarrier的形象比喻，就是在百米赛跑的比赛中若使用 countDownLatch的话冲过终点线一个人就给评委发送一个人的成绩，10个人比赛发送10次，如果用CyclicBarrier，则只在最后一个人冲过终点线的时候发送所有人的数据，仅仅发送一次，这就是区别。\n参考链接 https://blog.csdn.net/HaHa_Sir/article/details/79521028\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/interview/JavaNote/%E5%A4%9A%E7%BA%BF%E7%A8%8B/","summary":"多线程 ​\n守护线程 Java的main是普通线程，并不是守护线程，\n守护线程会等待所有的线程执行结束后再结束\n线程同步 https://www.jianshu.com/p/2394317257ec\nhttps://www.jianshu.com/p/988bfceadb62\nhttps://www.jianshu.com/p/6f98f03430eb\nhttps://www.cnblogs.com/williamjie/p/9099141.html\nJava 主线程等待所有子线程执行完毕 Java 主线程等待所有子线程执行完毕再执行。\n用sleep() 让主线程睡眠一段时间，但是这个睡眠时间是主观设置的，是有我们自己主观设定的，所以不推荐使用。\n1public static void main(String[] args) throws InterrupteException{ 2 for(int i=0; i\u0026lt;5;i++){ 3 new Thread( 4 new Runnable(){ 5 public void run(){ 6 try{ 7 Thread.sleep(1000); 8 }catch(InterruptException e){ 9 e.preintStrackTrace(); 10 } 11 System.out.println(\u0026#34;子线程执行！\u0026#34;); 12 } 13 } 14 ).start(); 15 } 16 Thread.sleep(5000); 17 System.out.println(\u0026#34;主线程执行！\u0026#34;); 18} 使用Thread的jion()等待所有的子线程执行完毕，主线程再执行，thread.jion()把指定线程加入到当前线程，可以将两个交替执行的线程合并为顺序执行的线程。比如在B中调用了线程A的jion()方法，直到线程A执行完毕后，才会继续执行线程B。\n1public static void main(String[] args) throws InterrupteException{ 2 Vector\u0026lt;Thread\u0026gt; threadVector = new Vector\u0026lt;\u0026gt;(); 3 for(int i=0; i\u0026lt;5;i++){ 4 Thread childThread = new Thread( 5 new Runnable(){ 6 public void run(){ 7 try{ 8 Thread.","tags":null,"title":""},{"categories":null,"contents":"设计模式 单例模式 一个应用程序中，某个类的实例对象只有一个，你没有办法去new，因为构造器是被private修饰的，一般通过getInstance()的方法来获取它们的实例。\ngetInstance()的返回值是一个对象的引用，并不是一个新的实例。\n双重校验锁 1public class Singleton{ 2 private volatile static Singleton singleton; 3 private Singleton(){} 4 public static Singleton getSingleton(){ 5 if(singleton == null){ 6 synchronized(Singleton.class){ 7 if(singleton==null){ 8 singleton = new singleton; 9 } 10 } 11 } 12 } 13} 观察者模式 对象间一对多的依赖关系，当一个对象的状态发生改变时，所有依赖于它的对象都得到通知并被自动更新。\nhttps://mp.weixin.qq.com/s/sdj9DcnZZNRiWssgygiTTw\n装饰者模式 对已有的业务逻辑进一步的封装，使其增加额外的功能，如Java中的IO流就使用了装饰者模式，用户在使用的时候，可以任意组装，达到自己想要的效果。\n适配器模式 工厂模式 ##代理模式\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/interview/JavaNote/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/","summary":"设计模式 单例模式 一个应用程序中，某个类的实例对象只有一个，你没有办法去new，因为构造器是被private修饰的，一般通过getInstance()的方法来获取它们的实例。\ngetInstance()的返回值是一个对象的引用，并不是一个新的实例。\n双重校验锁 1public class Singleton{ 2 private volatile static Singleton singleton; 3 private Singleton(){} 4 public static Singleton getSingleton(){ 5 if(singleton == null){ 6 synchronized(Singleton.class){ 7 if(singleton==null){ 8 singleton = new singleton; 9 } 10 } 11 } 12 } 13} 观察者模式 对象间一对多的依赖关系，当一个对象的状态发生改变时，所有依赖于它的对象都得到通知并被自动更新。\nhttps://mp.weixin.qq.com/s/sdj9DcnZZNRiWssgygiTTw\n装饰者模式 对已有的业务逻辑进一步的封装，使其增加额外的功能，如Java中的IO流就使用了装饰者模式，用户在使用的时候，可以任意组装，达到自己想要的效果。\n适配器模式 工厂模式 ##代理模式","tags":null,"title":""},{"categories":null,"contents":"字节跳动面试题总结 1. 进程创建的过程 进程的创建过程可分为以下步骤： （1）申请空白的PCB。 进程控制块 描述信息，控制信息，资源信息，CPU现场 （2）为新进程分配资源。 （3）初始化PCB。 （4）将进程插入就绪队列。\n2. linux 文件管理系统 inode(发音：eye-node)译成中文就是索引节点，它用来存放档案及目录的基本信息，包含时间、档名、使用者及群组等。\nnode inode\ninode（即index node，索引节点）是类Unix OS中保存文件系统中的对象元数据的数据结构。\nhttps://www.jianshu.com/p/d60a2b44e78e\n3.数据库事务 数据库事务\n隔离级别\n脏读\n不可重复读\n幻读\n丢失修改\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/interview/%E5%AD%97%E8%8A%82%E8%B7%B3%E5%8A%A8%E9%9D%A2%E8%AF%95/","summary":"字节跳动面试题总结 1. 进程创建的过程 进程的创建过程可分为以下步骤： （1）申请空白的PCB。 进程控制块 描述信息，控制信息，资源信息，CPU现场 （2）为新进程分配资源。 （3）初始化PCB。 （4）将进程插入就绪队列。\n2. linux 文件管理系统 inode(发音：eye-node)译成中文就是索引节点，它用来存放档案及目录的基本信息，包含时间、档名、使用者及群组等。\nnode inode\ninode（即index node，索引节点）是类Unix OS中保存文件系统中的对象元数据的数据结构。\nhttps://www.jianshu.com/p/d60a2b44e78e\n3.数据库事务 数据库事务\n隔离级别\n脏读\n不可重复读\n幻读\n丢失修改","tags":null,"title":""},{"categories":null,"contents":"小红书面试 如何判断单链表有环\n1public boolean IsLoop(Node head){ 2 Node fast = head; 3 Node slow = head; 4 if(head = null){ 5 return false; 6 } 7 8 while(fast != null\u0026amp;\u0026amp; slow ！= null){ 9 fast = fast.next.next; 10 slow = slow.next; 11 if(fast = slow){ 12 return true; 13 } 14 } 15 16 return false; 17} 三次握手， 为什么要三次\nA -\u0026gt; B SYN=1, seq = x;\nA \u0026lt;- B SYN = 1, ACK=1, seq = y, ack = x+1;\nA-\u0026gt; B SYN = 1, ACK =1, seq = x+1, ack = y+1;\n实现信息对等，双方的收发报文能力 防止脏连接 TCP/UDP\nTCP 是面向连接的可靠传输，具有流量控制和拥塞避免\nUDP 是不可靠的，\n线程和进程\n进程是资源分配的最小单元\n线程是调度的最小单元\n二叉树先序遍历，递归和非递归\n1// 递归先序遍历 2public void preOrder(TreeNode node){ 3 if(node == null ){ 4 return; 5 } 6 System.out.print(node.val); 7 preOrder(node.left); 8 preOrder(node.right); 9} 1public void preOrder(TreeNode root){ 2 if(root==null){ 3 return; 4 } 5 6 Stack\u0026lt;TreeNode\u0026gt; stack = new Stack\u0026lt;\u0026gt;(); 7 stack.push(root); 8 9 while(!stack.isEmpty()){ 10 TreeNode node = stack.pop(); 11 System.out.print(node.val); 12 if(node.left != null){ 13 stack.push(node.left); 14 } 15 if(node.right !=null){ 16 stack.push(node.right) 17 } 18 } 19} map 的扩容，HashMap\nHashMap的容量为 2^n^, 所以每次扩容都为2倍， 在重新分配元素的时候会比较快\n索引的实现\nB+Tree 平衡搜索树\n前缀树\n1class TireNode{ 2 private TireNode[] links; 3 private final int R = 26; 4 private boolean isEnd; 5 public TireNode(){ 6 links = new TireNode[R]; 7 } 8 9 public boolean containsKey(char ch){ 10 return links[ch - \u0026#39;a\u0026#39;] != null; 11 } 12 public TireNode get(char ch){ 13 return links[ch -\u0026#39;a\u0026#39;]; 14 } 15 public void put(){ 16 17 } 18} redis 的好处\n存取速度快， 可以保证数据一致性\n一个从1加到n不用循环求和 递归啊 1public static int sum(int n){ 2\tif (n==1) { 3\treturn 1; 4\t}else { 5\treturn n+sum(n-1);//加法 6\t// return n*sum(n-1); //乘法 7\t} 8} 一个字符串数字结合遇到数字重复前面字符，求第n个字符\nHashmap底层实现＋如何扩容\n13.二叉树的几种搜索方式 NLR LNR LRN 前中后 层次遍历\n14.两种二叉树深搜方式的差别 深度优先搜索算法的实现运用的主要是回溯法，类似于树的先序遍历算法。 广度优先搜索算法借助队列的先进先出的特点，类似于树的层次遍历 https://blog.csdn.net/liupeifeng3514/article/details/83819583\n1面\n1.编程题：给你一个可以生成0-6随机数的函数，设计一个可以生成0-9随机数的函数\n面试官提示的思路是：先生成两位0-6的随机数，然后7进制转10机制，如果转化结果\u0026lt;=39，就用结果对10求余，因为生成0-39的概率是相等的，所以获得0-9的概率也相等\n2.编程题：给你两个数组，求并集\n3.操作系统：常用的线程调度算法有哪几种？\n有先来先服务，最短作业优先，基于优先权的调度算法，时间片轮转等\n4.操作系统：线程和进程的区别？\n5.操作系统：线程同步有哪几种方式？\n线程同步的方式主要有: 临界区（Critical Section）、互斥量（Mutex）、信号量（Semaphore）、事件（Event）。\n他们的主要区别和特点如下：\n**1）临界区：**通过对多线程的串行化来访问公共资源或一段代码，速度快，适合控制数据访问。在任意时刻只允许一个线程对共享资源进行访问，\n​ 如果有多个线程试图访问公共资源，那么在有一个线程进入后，其他试图访问公共资源的线程将被挂起，并一直等到进入临界区的线程离开，临界区在被释放后，其他线程才可以抢占。\n**2）互斥量：**采用互斥对象机制。 只有拥有互斥对象的线程才有访问公共资源的权限，因为互斥对象只有一个，所以能保证公共资源不会同时被多个线程访问。\n​ 互斥不仅能实现同一应用程序的公共资源安全共享，还能实现不同应用程序的公共资源安全共享。\n**3）信号量：**它允许多个线程在同一时刻访问同一资源，但是需要限制在同一时刻访问此资源的最大线程数目。\n4）事 件： 通过通知操作的方式来保持线程的同步，还可以方便实现对多个线程的优先级比较的操作。\n2面 1.C++：有哪几种智能指针？\n2.C++：简述模板以及为什么使用模板的时候#include\u0026lt;***.hpp\u0026gt;？\n3.编程题：用递归和迭代两种方式写反转二叉树\n4.编程题：每k个一组反转链表\n5.数据库：redis和其他数据库的区别是什么？什么时候选择redis？\n5.设计模式：写一个单例模式\n3面 1.计算机网络：TCP/IP4层模型有哪4层？\n2.计算机网络：mac层寻址过程\n3.编程题：从文本中查找敏感词\n面试官希望使用前缀树来做这道题\n4.编程题：给你一个含有()和[]的字符串，输出括号每对括号的位置下标如（1,2），如果有不合法括号返回空\n5.操作系统：有哪几种IO模型？阻塞IO在底层阻塞在了哪里？\n拓展 听到的一些别人的问题\n1.编程题：第k大的数\n2.编程题：判断一个二叉树是不是完全二叉树\n3.编程题：反转链表\n4.编程题：用栈实现队列\n5.编程题：全排列\n6.编程题：从二维数组中查找数（每列递增，每行递增）\n7.大数问题：找到1亿个数里出现次数前k大的数，内存有限制 ———————————————— 版权声明：本文为CSDN博主「djqueen」的原创文章，遵循 CC 4.0 BY-SA 版权协议，转载请附上原文出处链接及本声明。 原文链接：https://blog.csdn.net/u013536232/article/details/100586988\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/interview/%E5%B0%8F%E7%BA%A2%E4%B9%A6%E9%9D%A2%E8%AF%95/","summary":"小红书面试 如何判断单链表有环\n1public boolean IsLoop(Node head){ 2 Node fast = head; 3 Node slow = head; 4 if(head = null){ 5 return false; 6 } 7 8 while(fast != null\u0026amp;\u0026amp; slow ！= null){ 9 fast = fast.next.next; 10 slow = slow.next; 11 if(fast = slow){ 12 return true; 13 } 14 } 15 16 return false; 17} 三次握手， 为什么要三次\nA -\u0026gt; B SYN=1, seq = x;\nA \u0026lt;- B SYN = 1, ACK=1, seq = y, ack = x+1;","tags":null,"title":""},{"categories":null,"contents":"10 每日一面 java 中 throws Exception和 catch Exception的区别 AB转账问题，保持数据一致性 TreeMap如何保证有序 ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/interview/%E6%AF%8F%E6%97%A5%E4%B8%80%E9%9D%A2/10th_%E6%AF%8F%E6%97%A5%E4%B8%80%E9%9D%A2/","summary":"10 每日一面 java 中 throws Exception和 catch Exception的区别 AB转账问题，保持数据一致性 TreeMap如何保证有序 ","tags":null,"title":""},{"categories":null,"contents":"11 每日一面 Ucloud\nrpc\nsql优化，如何解决高并发\nexplain 慢查询，建索引\n什么方式实现缓存，什么情况下需要用到token,token失效怎么办等\n主从复制\n数据库四种隔离级别，分别举例子，每种在上一种的基础上加了什么锁(很简单不说了)\nTcp，坚持计时器。keepalive计时器。\n写了一个shell命令，列出重复数据。awk+unique+sort很简单也不说了。\n网络协议 计算机网络五层协议：物理层、数据链路层、网络层、传输层、应用层\n计算机网络的七层OSI协议： 物理层、数据链路层、网络层、传输层、会话层、表示层、应用层\n路由器属于网络层\n网卡与交换机数据数据链路层\nTCP和UDP TCP 是面向连接的字节流服务，对系统资源要求比较多。程序结构复杂，保证数据的正确性和顺序性。\nUDP是无连接的，面向数据报，对系统的资源要求比较少，程序结构简单，不能保证数据的正确性和顺序性\n网站安全与防护\nsql 注入\n使用例如PDO的预处理，使用或者编写类似mysql_real_escape_string的方法对sql的特殊字符进行转义\n**XSS（cross site script）**跨站脚本攻击\n将外部脚本植入到页面中\n**CSRF(cross-site request forgey)**跨站请求伪造\n伪造受信任的用户信息来请求网站\n算法相关\n冒泡排序\n选择排序\n​\t快速排序\n快速排序思想：通过一趟排序将序列分成两部分，一部分所有数据比另一部分所有数据小，然后在这两个序列的内部再分别进行快速排序操作，直到最后形成一个有序序列\n二分插入排序思想(之前的序列为有序)：插入第i个元素时，对前面的0~i-1进行折半，当前元素与中间元素比较，如果小，前半部分再次折半，如果大，后半部分进行折半，直到最后left\u0026gt;right,然后把目标位置到i-1的所有元素整体后移，把当前元素放进去\n基本查找算法：\n顺序查找\n二分法查找(折半查找)：将序列分为两部分，找到序列的中间值，如果查找值大于中间值，继续对右半部分进行折半，如果查找值小于中间值，对左半部分进行折半，直到找到或front\u0026gt;end结束，时间复杂度O(log2n)以2为底n的对数\n设计模式\nMVC是一种设计框架，而不是设计模式，框架是比模式更高的概念\nmodel负责数据逻辑\ncontroller负责用户交互\nview负责数据显示流程：\n用户对控制器的某个方法发出请求，控制器调用相应的模型返回数据，然后将数据渲染到视图中返回给用户\n单例模式i. 私有化构造方法和__clone方法ii. 提供公有的静态的方法返回实例iii. 提供私有的静态属性保存实例\n简单工厂模式(重点在创建不同对象，作用就是用来创建对象的) - 例如一个计算器的加减乘除求余取整i. 定义抽象基类让子类分别继承并实现相应方法ii. 定义Factory工厂类里面提供静态方法用于根据不同的参数实例化相应的子类对象\n策略模式(重点在于实例化不同类的解决策略不同，作用是根据不同的情况调用相应的策略或算法) - 例如qq普通用户 vip svip购买皮肤的优惠策略i. 定义抽象基类让子类分别继承并实现相应的方法ii. 根据不同的场景实例化相应的类，然后调用其中的方法获取结果\n观察者模式\ni. 需要有一个抽象的主题接口和一个抽象的观察者接口\nii. 实现一个主题，实现多个观察者\niii. 实例化主题，然后调用主题的方法并将不同的观察者对象实例化传入，在主题的方法中保存传入的观察者对象到一个属性，在主题中定义另外的方法通过保存观察者对象调用观察者的方法\n大流量和高并发网站解决思路\napache或者nginx进行相关配置\nCDN加速\n减少http请求，添加异步请求\n启用浏览器缓存 代码压缩(去除空白符) 页面静态化：\n信息变更不是很频繁的页面进行静态化处理，生成html文件\n数据缓存(数据库缓存redis,文件缓存)\n使用Nginx，负载均衡\nmysql数据库优化 字段数据类型优化 索引优化 SQL语句优化 存储引擎优化 表结构设计优化 分表分库分区 主从复制，读写分离\nCOOKIE 和 SESSION\nCookie和Session\nsession与cookie都是会话技术，默认情况下session在客户端依赖于cookie\ncookie保存在客户端，保存的是字符串，session保存在服务端，保存的是对象\ncookie安全性低，可被拦截或从本地分析得到，session安全性高\nsession保存在服务器上，会占用服务器的资源，理论上大小没有限制，和服务器内存有关\n单个cookie保存的数据不能超过4K,很多浏览器都限制一个站点最多20个cookie\n登录信息等重要信息存放为session，其他信息如需保留，可以存在cookie中\nMyISAM 和 InnoDB\nMyISAM 是表级锁，不支持事务和外键操作\nInnoDB是行级锁，支持事务处理和外键\n执行大量的select MyISAM更好，执行大量的insert 和update 用InnoDB更好\nGET 和POST\nGET POST 参数在url后面，长度有限制 参数在RequestBody中，长度无限制 可以保存为浏览器缓存 不可以保存为书签，不可以缓存 保持幂等性 数据会被修改 HTTP动词，规约 一次完成的HTTP请求过程\n域名解析DNS： 浏览器解析域名（主机名）为相应的IP地址\n建立TCP连接 三次握手\n浏览器想服务器发起http请求\n服务器响应http请求，返回html数据\n浏览器解析html代码并请求html中的资源\n浏览器对页面进行渲染然后展示给用户\n关闭TCP连接\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/interview/%E6%AF%8F%E6%97%A5%E4%B8%80%E9%9D%A2/11th_%E6%AF%8F%E6%97%A5%E4%B8%80%E9%9D%A2/","summary":"11 每日一面 Ucloud\nrpc\nsql优化，如何解决高并发\nexplain 慢查询，建索引\n什么方式实现缓存，什么情况下需要用到token,token失效怎么办等\n主从复制\n数据库四种隔离级别，分别举例子，每种在上一种的基础上加了什么锁(很简单不说了)\nTcp，坚持计时器。keepalive计时器。\n写了一个shell命令，列出重复数据。awk+unique+sort很简单也不说了。\n网络协议 计算机网络五层协议：物理层、数据链路层、网络层、传输层、应用层\n计算机网络的七层OSI协议： 物理层、数据链路层、网络层、传输层、会话层、表示层、应用层\n路由器属于网络层\n网卡与交换机数据数据链路层\nTCP和UDP TCP 是面向连接的字节流服务，对系统资源要求比较多。程序结构复杂，保证数据的正确性和顺序性。\nUDP是无连接的，面向数据报，对系统的资源要求比较少，程序结构简单，不能保证数据的正确性和顺序性\n网站安全与防护\nsql 注入\n使用例如PDO的预处理，使用或者编写类似mysql_real_escape_string的方法对sql的特殊字符进行转义\n**XSS（cross site script）**跨站脚本攻击\n将外部脚本植入到页面中\n**CSRF(cross-site request forgey)**跨站请求伪造\n伪造受信任的用户信息来请求网站\n算法相关\n冒泡排序\n选择排序\n​\t快速排序\n快速排序思想：通过一趟排序将序列分成两部分，一部分所有数据比另一部分所有数据小，然后在这两个序列的内部再分别进行快速排序操作，直到最后形成一个有序序列\n二分插入排序思想(之前的序列为有序)：插入第i个元素时，对前面的0~i-1进行折半，当前元素与中间元素比较，如果小，前半部分再次折半，如果大，后半部分进行折半，直到最后left\u0026gt;right,然后把目标位置到i-1的所有元素整体后移，把当前元素放进去\n基本查找算法：\n顺序查找\n二分法查找(折半查找)：将序列分为两部分，找到序列的中间值，如果查找值大于中间值，继续对右半部分进行折半，如果查找值小于中间值，对左半部分进行折半，直到找到或front\u0026gt;end结束，时间复杂度O(log2n)以2为底n的对数\n设计模式\nMVC是一种设计框架，而不是设计模式，框架是比模式更高的概念\nmodel负责数据逻辑\ncontroller负责用户交互\nview负责数据显示流程：\n用户对控制器的某个方法发出请求，控制器调用相应的模型返回数据，然后将数据渲染到视图中返回给用户\n单例模式i. 私有化构造方法和__clone方法ii. 提供公有的静态的方法返回实例iii. 提供私有的静态属性保存实例\n简单工厂模式(重点在创建不同对象，作用就是用来创建对象的) - 例如一个计算器的加减乘除求余取整i. 定义抽象基类让子类分别继承并实现相应方法ii. 定义Factory工厂类里面提供静态方法用于根据不同的参数实例化相应的子类对象\n策略模式(重点在于实例化不同类的解决策略不同，作用是根据不同的情况调用相应的策略或算法) - 例如qq普通用户 vip svip购买皮肤的优惠策略i. 定义抽象基类让子类分别继承并实现相应的方法ii. 根据不同的场景实例化相应的类，然后调用其中的方法获取结果\n观察者模式\ni. 需要有一个抽象的主题接口和一个抽象的观察者接口\nii. 实现一个主题，实现多个观察者","tags":null,"title":""},{"categories":null,"contents":"1. 每日一面 蚂蚁金服一面\nJava 容器有哪些，哪些是同步容器，哪些是并发容器 ArrayList 和LinkedList 的插入和访问的时间复杂度 java反射原理， 注解原理 新生代分为几个区？使用什么算法进行垃圾回收？为什么使用这个算法？ HashMap在什么情况下回扩容，或者有哪些操作会导致扩容？ HashMap put方法的执行过程 HashMap检测到hash冲突后，将元素插入在链表的末尾还是开头？ 1.8 还采用了红黑树，讲讲红黑树的特性，为什么人家一定要用红黑是而不是AVL，B树之类的； https 和http 的区别，有没有用过其他安全传输手段？ 线程池的工作原理，几个重要参数，然后给了具体几个参数分析线程池会怎么做，最后问阻塞队列的作用是什么？ Linux怎么查看系统负载情况？ 请详细描述SpringMVN处理请求全流程 Spring 一个Bean 的装配过程 讲一讲AutomicInteger 为什么要用CAS而不是synchronized？ 线程会单独拷贝一份数据到自己的工作空间，只有sync代码块被执行完才会将数据从工作内存刷到主内存，所以，指令重排为什么会导致多线程数据不一致的问题，应该是volatile的内存可见性是解决数据不一致问题的原因\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/interview/%E6%AF%8F%E6%97%A5%E4%B8%80%E9%9D%A2/1st_%E6%AF%8F%E6%97%A5%E4%B8%80%E9%9D%A2/","summary":"1. 每日一面 蚂蚁金服一面\nJava 容器有哪些，哪些是同步容器，哪些是并发容器 ArrayList 和LinkedList 的插入和访问的时间复杂度 java反射原理， 注解原理 新生代分为几个区？使用什么算法进行垃圾回收？为什么使用这个算法？ HashMap在什么情况下回扩容，或者有哪些操作会导致扩容？ HashMap put方法的执行过程 HashMap检测到hash冲突后，将元素插入在链表的末尾还是开头？ 1.8 还采用了红黑树，讲讲红黑树的特性，为什么人家一定要用红黑是而不是AVL，B树之类的； https 和http 的区别，有没有用过其他安全传输手段？ 线程池的工作原理，几个重要参数，然后给了具体几个参数分析线程池会怎么做，最后问阻塞队列的作用是什么？ Linux怎么查看系统负载情况？ 请详细描述SpringMVN处理请求全流程 Spring 一个Bean 的装配过程 讲一讲AutomicInteger 为什么要用CAS而不是synchronized？ 线程会单独拷贝一份数据到自己的工作空间，只有sync代码块被执行完才会将数据从工作内存刷到主内存，所以，指令重排为什么会导致多线程数据不一致的问题，应该是volatile的内存可见性是解决数据不一致问题的原因","tags":null,"title":""},{"categories":null,"contents":"2 每日一面 美团一面\n最近做的比较熟悉的项目是哪一个，画一下项目技术架构图 JVM老年代和新生代的比例 YGC和FGC发生的具体场景 jstack，jmap，jutil分别的意义？ 如何线上排查JVM的相关问题 线程池的构造类的方法的5个参数的具体意义？ 单机上一个线程池正在处理服务如果突然断电怎么办（正在处理和阻塞在队列里的请求怎么处理）？ 使用无界阻塞队列会出现什么问题？ 接口如何处理重复请求？ ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/interview/%E6%AF%8F%E6%97%A5%E4%B8%80%E9%9D%A2/2nd_%E6%AF%8F%E6%97%A5%E4%B8%80%E9%9D%A2/","summary":"2 每日一面 美团一面\n最近做的比较熟悉的项目是哪一个，画一下项目技术架构图 JVM老年代和新生代的比例 YGC和FGC发生的具体场景 jstack，jmap，jutil分别的意义？ 如何线上排查JVM的相关问题 线程池的构造类的方法的5个参数的具体意义？ 单机上一个线程池正在处理服务如果突然断电怎么办（正在处理和阻塞在队列里的请求怎么处理）？ 使用无界阻塞队列会出现什么问题？ 接口如何处理重复请求？ ","tags":null,"title":""},{"categories":null,"contents":"3 每日一面 百度一面\n介绍一下集合框架 HashMap 和hashtable 底层实现什么区别？ HashTable 和ConcurrentHashTable 区别？ HashMap 和TreeMap 什么区别？底层数据结构是什么？ Synchronized 和 Lock 什么区别？synchronized 什么情况是对象锁，什么时候是全局锁 ThreadLocal 是什么？底层是如何实现的？写一个例子 volitile的工作原理 cas 如何实现的 至少用四种方法实现一个单例模式 请介绍一个JVM的内存模型？用什么样的垃圾回收器 线上发送频繁full GC如何处理？CPU使用率过高怎么办 如何定位问题？如何解决，说一下解决思路和处理方法 知道字节码吗？字节码都有哪些？Integer x=5；int y=5；比较x=y都经过哪些步骤？ 讲讲类加载机制？有哪些类加载器，这些类加载器加载哪些文件？ 手写类加载Demo 知道osgi吗？他是如何实现的 请问你做过哪些JVM优化？使用什么方法达到什么效果？ Class.forName(\u0026ldquo;java.lang.String\u0026rdquo;) 和String.classGetClassLoader() LoadClass(\u0026ldquo;java.lang.String\u0026rdquo;) 什么区别 四种垃圾回收算法\n七种垃圾回收器\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/interview/%E6%AF%8F%E6%97%A5%E4%B8%80%E9%9D%A2/3rd_%E6%AF%8F%E6%97%A5%E4%B8%80%E9%9D%A2/","summary":"3 每日一面 百度一面\n介绍一下集合框架 HashMap 和hashtable 底层实现什么区别？ HashTable 和ConcurrentHashTable 区别？ HashMap 和TreeMap 什么区别？底层数据结构是什么？ Synchronized 和 Lock 什么区别？synchronized 什么情况是对象锁，什么时候是全局锁 ThreadLocal 是什么？底层是如何实现的？写一个例子 volitile的工作原理 cas 如何实现的 至少用四种方法实现一个单例模式 请介绍一个JVM的内存模型？用什么样的垃圾回收器 线上发送频繁full GC如何处理？CPU使用率过高怎么办 如何定位问题？如何解决，说一下解决思路和处理方法 知道字节码吗？字节码都有哪些？Integer x=5；int y=5；比较x=y都经过哪些步骤？ 讲讲类加载机制？有哪些类加载器，这些类加载器加载哪些文件？ 手写类加载Demo 知道osgi吗？他是如何实现的 请问你做过哪些JVM优化？使用什么方法达到什么效果？ Class.forName(\u0026ldquo;java.lang.String\u0026rdquo;) 和String.classGetClassLoader() LoadClass(\u0026ldquo;java.lang.String\u0026rdquo;) 什么区别 四种垃圾回收算法\n七种垃圾回收器","tags":null,"title":""},{"categories":null,"contents":"4.每日一面 携程面试\n问项目， 注意项目细节\nNetty\nBIO 同步阻塞IO，一个线程只有一个连接\nNIO 同步非阻塞IO ，一个线程有多个连接，一个线程中有很多Channel，通过selector 选择线程\nAIO 异步非阻塞IO\n双重检验单例\n1public class Singleton{ 2 private volatile static Singleton singleton; 3 private Singleton(){ 4 5 } 6 public Singleton getSingleton(){ 7 if(singleton == null){ 8 synchronized(Singleton.class){ 9 if(singleton == null){ 10 singleton = new Singleton(); 11 } 12 } 13 } 14 return singleton; 15 } 16} http1.1 长连接， 心跳包， http2 http3\nHTTP 1.1 支持长连接(PersistentConnection)和请求的流水线(Pipelining)处理,在一个TCP连接上可以传送多个HTTP请求，减少了建立和关闭连接的消耗和延迟。在HTTP1.1中默认开启Connection：keep-alive，一定程度上弥补了HTTP 1.0 每次请求都要创建连接的缺点。\n在header 中设置connection = keep-alive，keep-alive：timeout = 60；\nHTTP 2.0 多路复用 多个请求可以在同一个连接上并行执行。\n线程池，参数列表，阻塞队列的默认值\n垃圾回收 G1，实际项目中怎么优化\nhttps://www.cnblogs.com/diegodu/p/9849611.html\n年轻代大小选择\n响应时间优先的应用：尽可能设大，直到接近系统的最低响应时间限制（根据实际情况选择）。在此种情况下，年轻代收集发生的频率也是最小的。同时，减少到达年老代的对象。 吞吐量优先的应用：尽可能的设置大，可能到达Gbit的程度。因为对响应时间没有要求，垃圾收集可以并行进行，一般适合8CPU以上的应用。 1000万条数据中选取最小的100个，分析每一步的时间复杂度，除了堆还有什么方法\n设计索引\n多线程限流\n设计模式在工作中的使用？redis原理，消息中间件原理，jvm调优，类加载机制，spring，mybatis原理，针对面试官问的这些内容，这名网友认为这些问题不太实用，工作中都是找轮子调api，写业务逻辑代码\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/interview/%E6%AF%8F%E6%97%A5%E4%B8%80%E9%9D%A2/4th_%E6%AF%8F%E6%97%A5%E4%B8%80%E9%9D%A2/","summary":"4.每日一面 携程面试\n问项目， 注意项目细节\nNetty\nBIO 同步阻塞IO，一个线程只有一个连接\nNIO 同步非阻塞IO ，一个线程有多个连接，一个线程中有很多Channel，通过selector 选择线程\nAIO 异步非阻塞IO\n双重检验单例\n1public class Singleton{ 2 private volatile static Singleton singleton; 3 private Singleton(){ 4 5 } 6 public Singleton getSingleton(){ 7 if(singleton == null){ 8 synchronized(Singleton.class){ 9 if(singleton == null){ 10 singleton = new Singleton(); 11 } 12 } 13 } 14 return singleton; 15 } 16} http1.1 长连接， 心跳包， http2 http3\nHTTP 1.1 支持长连接(PersistentConnection)和请求的流水线(Pipelining)处理,在一个TCP连接上可以传送多个HTTP请求，减少了建立和关闭连接的消耗和延迟。在HTTP1.1中默认开启Connection：keep-alive，一定程度上弥补了HTTP 1.0 每次请求都要创建连接的缺点。","tags":null,"title":""},{"categories":null,"contents":"5 每日一面 今日头条\nHashMap如果一直put元素会怎么样？hashCode全都相同如何？ 重写equals时候为什么要重写hash方法 ApplicationContext 的初始化过程？初始化过程发现循环依赖Spring 是如何处理 GC用什么收集器？收集过程如何？哪些部分可以作为GC Root？ Volatile关键字，指令重排序有什么意义？synchronize怎么用？ 并发包里的原子类有哪些，怎么实现？cas在cpu级别是怎么实现的 Redis数据结构有哪些？如何实现Sorted set？这种数据结构在极端情况下 系统设计题：一个推送场景。50条内容，定时推送，先推5%用户，……设计相关库表，系统模块 MySQL索引是什么数据结构？B-Tree有什么特点？有点是什么 慢查询怎么优化 项目 cache 各部分职责，有哪些优点 ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/interview/%E6%AF%8F%E6%97%A5%E4%B8%80%E9%9D%A2/5th_%E6%AF%8F%E6%97%A5%E4%B8%80%E9%9D%A2/","summary":"5 每日一面 今日头条\nHashMap如果一直put元素会怎么样？hashCode全都相同如何？ 重写equals时候为什么要重写hash方法 ApplicationContext 的初始化过程？初始化过程发现循环依赖Spring 是如何处理 GC用什么收集器？收集过程如何？哪些部分可以作为GC Root？ Volatile关键字，指令重排序有什么意义？synchronize怎么用？ 并发包里的原子类有哪些，怎么实现？cas在cpu级别是怎么实现的 Redis数据结构有哪些？如何实现Sorted set？这种数据结构在极端情况下 系统设计题：一个推送场景。50条内容，定时推送，先推5%用户，……设计相关库表，系统模块 MySQL索引是什么数据结构？B-Tree有什么特点？有点是什么 慢查询怎么优化 项目 cache 各部分职责，有哪些优点 ","tags":null,"title":""},{"categories":null,"contents":"6 每日一面 Dubbo超时重试？Dubbo超时时间设置 如何保障请求顺序执行 分布式事务与分布式锁（扣款不要出现负数） 分布式session设置 执行某操作，前50次成功，第51次失败，a全部回滚，b前50次提交第51次抛异常，a b场景分别如何设置Spring？（传播特性） Zookeeper有哪些作用 JVM内存模型 数据库垂直和水平拆分 MyBatis如何分页；如何设置缓存;MySql分页 熟悉IO吗？与NIO的区别，阻塞和非阻塞 ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/interview/%E6%AF%8F%E6%97%A5%E4%B8%80%E9%9D%A2/6th_%E6%AF%8F%E6%97%A5%E4%B8%80%E9%9D%A2/","summary":"6 每日一面 Dubbo超时重试？Dubbo超时时间设置 如何保障请求顺序执行 分布式事务与分布式锁（扣款不要出现负数） 分布式session设置 执行某操作，前50次成功，第51次失败，a全部回滚，b前50次提交第51次抛异常，a b场景分别如何设置Spring？（传播特性） Zookeeper有哪些作用 JVM内存模型 数据库垂直和水平拆分 MyBatis如何分页；如何设置缓存;MySql分页 熟悉IO吗？与NIO的区别，阻塞和非阻塞 ","tags":null,"title":""},{"categories":null,"contents":"7 每日一面 ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/interview/%E6%AF%8F%E6%97%A5%E4%B8%80%E9%9D%A2/7th_%E6%AF%8F%E6%97%A5%E4%B8%80%E9%9D%A2/","summary":"7 每日一面 ","tags":null,"title":""},{"categories":null,"contents":"8 每日一面 ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/interview/%E6%AF%8F%E6%97%A5%E4%B8%80%E9%9D%A2/8th_%E6%AF%8F%E6%97%A5%E4%B8%80%E9%9D%A2/","summary":"8 每日一面 ","tags":null,"title":""},{"categories":null,"contents":"9 每一日面 字节跳动\n很荣幸字节跳动一路走到了四面，不管是运气还是实力，都好好准备接下来的面试吧，加油\n编程 判断字符串B是否是字符串A的子串 数据结构中的桶排序、平衡二叉树 .手撕代码：机器人跳跃(牛客原题） 手撕代码：逆时针打印矩阵（剑指offer改） 合并两个有序链表，空间复杂度O(1)； DP最长回文串； 给两个1T的文件在2g ram的内存中找出相同项。 给一个有向图，判断有向图中是否有环，如果有环，环的数量是多少？ 给一个大小为n的数组，寻找比k小的最大数的位置。 1.最长回文子串 地图上有若干个点，怎样得到某个点到达某个点的所有的换乘路线 ？ 是否是联通，如果不连通怎么处理 给你一个字符串，字符串当中是一段c语言的代码和注释，注释只有/** /这样的可以嵌套，不包含// 请返回去除所有注释的代码 如果代码当中的/*和/*可以不完全匹配如何告知出现错误 写了一个程序，有个小球，球从 100 米高度自由落下，每次落地后反跳回原高度的一半；再落下，求它在第10 次落地时，共经过多少米？第 10 次反弹多高？ 写代码：火车售票系统是早7点-晚23点进行网上售票，写一个程序判断是否可以进行网上买票 讲一下二叉搜索树，写节点的删除代码 最大连续子序列和 代码：实现lru，不会哦临时想了一种lgn的实现，面试官不满意 写一个最小堆建堆，分析复杂度 多个串，将含有相同字母的串放到同一个集合，返回集合向量 讲思路 编程：36进制加法（忘记处理最高位的进位，面试官提醒了一下） 在一亿个数中找出最大的10个数，在一亿个数中找出中间的10个数 编程：将0-n的整数放到一个长度为n的数组中，找出缺失的那个数 编程：36进制加法（又来？） 题目：n条直线可以将空间划分为多少个区域 面试题 TCP 和UDP\n进程和线程\n设计模式\nMySQL索引的数据结构\n进程间的通信方式\n设计一个存储海量评论的结构，要求大量数据的写入，可以随意翻页？\n熟悉计算机和网络原理，熟悉操作系统原理，对存储、队列、计算、集群管理中的一项或多项有深入的理解和认识；\n常用的排序算法的复杂度，写快排；\nJava的JVM的内存布局，垃圾回收的实现，回收器分几部分，都有什么作用；\n项目大体阐述下，用了哪些技术、设计模式，最大的感受是什么；十分钟实现用过的观察者模式、工厂模式；\nTCP四次挥手讲下？为什么有TIME_WAIT？ TCP比UDP多消耗哪些系统资源？\nA(FIN_WAIT_1) -\u0026gt; B(CLOSE_WAIT) FIN=1,seq = u\nA(FIN_WAIT_2)\u0026lt;-B ACK=1, seq=v,ack=u+1;\nA \u0026lt;-B(LAST_ACK) FIN=1,seq = w,ack=u+1;\nA(TIME_WAIT) ACK=1 ,seq=u+1,ack=w+1;\nTIME_WAIT 阶段\n要确定主动断开连接的一端的ACK信息成功发送到对方\n如果有很多的CLOSE_WAIT 是因为什么原因\n被动要求关闭的机器收到对方关闭连接的FIN报文，在第一次ACK应答后马上进入CLOSE_WAIT状态。 这种状态其实是在等待关闭，并且通知应用程序发送剩余数据，处理现场信息，关闭相关资源。 多进程上下文切换讲下？\n讲一下同步，异步，阻塞，非阻塞，多路IO复用？\n讲下epoll和select的区别？\nepoll跟select都能提供多路I/O复用的解决方案\nepoll的触发方式 水平触发和边沿触发说一说\nhttp复用连接 如何区分请求？\ntcp的重排序的细节是什么 如果传输的数据很大是如何重排序的\n.tcp是如何保证稳定传输的\n给你一个2G的电脑 10G的文本 文本有1k行的字符串，要求输出所有互为逆序的字符串的组合\u0026ndash;哈希\n上下文切换的全过程讲了十分钟 mysql引擎，事务，隔离级别，索引的实现，不同引擎索引的区别，剩下的数据库问题的名词没听说过，不会哦\ni++是否原子操作，锁的底层实现讲了十分钟\nioc是怎样实现的\naop实现日志之类的功能应该使用什么样的技术（我没太明白，理解为设计模式）\n怎么实现ThreadLocal\nCAS，是原子操作吗，问我如果比较之后相等，准备写的时候被改了怎么办（我说好像确实存在这个问题，后来查了一下底层可以保证原子性）\n逻辑地址\u0026mdash;（分段硬件）\u0026raquo;\u0026gt; 线型地址 \u0026mdash; （分页硬件)\u0026raquo;\u0026gt; 物理地址 的过程，虚拟内存的实现\nTIME_WAIT状态\njava中的垃圾回收策略\n怎么解决内存碎片问题\n为什么以4开头的http状态码是客户端的问题，以5开头的是服务端的问题？？？\nLeetCode 76.\n作者：DerekDeng https://www.nowcoder.com/discuss/217361来源：牛客网\n系统收到网络数据交付给应用程序的整个过程（从网卡说起，面试官说我对底层了解的挺深）\nUDP发送100个字节，对方的应用程序只recv了90个字节，剩下的10个字节怎么处理（没太明白正常情况下为什么会剩10个字节，跟面试官讨论了半天，他说这个问题太刁钻就过了）\nTCP的传输速率受什么影响（先扯了硬件，再扯了Nagle算法，面试官说知道这个不错，最后扯数据分片，面试官说这个没关系就过了）\nTCP发送消息如果对方不接收，我们这边会有什么情况发生（扯了应用层相关的，其实面试官只是为了引导我回答TCP的传输速率与接收窗口有关）\nTCP的拥塞控制\nTCP的滑动窗口\nTCP的超时时间计算\n手撕跳台阶（剑指offer原题\u0026hellip;\u0026hellip;）\n手撕N个“(”和N个“)”的排列组合（就是有重复数据的全排列，不需要括号匹配）\n提问 该部门的主要业务和主要技术栈\n对应届生的要求？\n参加创业类活动所获得的的奖励，和其他的一些专业的兴趣爱好是否会成为您选择人才的加分项\nHR面试 面经汇总：https://www.nowcoder.com/discuss/240413?type=post\u0026amp;order=time\u0026amp;pos=\u0026amp;page=0\nhttps://www.cnblogs.com/zkfopen/p/11215315.html\nhttps://www.nowcoder.com/discuss/153849?type=post\u0026order=time\u0026pos=\u0026page=3\nhttps://blog.csdn.net/ELI_CJ/article/details/51793477\nhttps://www.nowcoder.com/discuss/153849\nhttps://www.nowcoder.com/discuss/217361\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/interview/%E6%AF%8F%E6%97%A5%E4%B8%80%E9%9D%A2/9th_%E6%AF%8F%E6%97%A5%E4%B8%80%E9%9D%A2/","summary":"9 每一日面 字节跳动\n很荣幸字节跳动一路走到了四面，不管是运气还是实力，都好好准备接下来的面试吧，加油\n编程 判断字符串B是否是字符串A的子串 数据结构中的桶排序、平衡二叉树 .手撕代码：机器人跳跃(牛客原题） 手撕代码：逆时针打印矩阵（剑指offer改） 合并两个有序链表，空间复杂度O(1)； DP最长回文串； 给两个1T的文件在2g ram的内存中找出相同项。 给一个有向图，判断有向图中是否有环，如果有环，环的数量是多少？ 给一个大小为n的数组，寻找比k小的最大数的位置。 1.最长回文子串 地图上有若干个点，怎样得到某个点到达某个点的所有的换乘路线 ？ 是否是联通，如果不连通怎么处理 给你一个字符串，字符串当中是一段c语言的代码和注释，注释只有/** /这样的可以嵌套，不包含// 请返回去除所有注释的代码 如果代码当中的/*和/*可以不完全匹配如何告知出现错误 写了一个程序，有个小球，球从 100 米高度自由落下，每次落地后反跳回原高度的一半；再落下，求它在第10 次落地时，共经过多少米？第 10 次反弹多高？ 写代码：火车售票系统是早7点-晚23点进行网上售票，写一个程序判断是否可以进行网上买票 讲一下二叉搜索树，写节点的删除代码 最大连续子序列和 代码：实现lru，不会哦临时想了一种lgn的实现，面试官不满意 写一个最小堆建堆，分析复杂度 多个串，将含有相同字母的串放到同一个集合，返回集合向量 讲思路 编程：36进制加法（忘记处理最高位的进位，面试官提醒了一下） 在一亿个数中找出最大的10个数，在一亿个数中找出中间的10个数 编程：将0-n的整数放到一个长度为n的数组中，找出缺失的那个数 编程：36进制加法（又来？） 题目：n条直线可以将空间划分为多少个区域 面试题 TCP 和UDP\n进程和线程\n设计模式\nMySQL索引的数据结构\n进程间的通信方式\n设计一个存储海量评论的结构，要求大量数据的写入，可以随意翻页？\n熟悉计算机和网络原理，熟悉操作系统原理，对存储、队列、计算、集群管理中的一项或多项有深入的理解和认识；\n常用的排序算法的复杂度，写快排；\nJava的JVM的内存布局，垃圾回收的实现，回收器分几部分，都有什么作用；\n项目大体阐述下，用了哪些技术、设计模式，最大的感受是什么；十分钟实现用过的观察者模式、工厂模式；\nTCP四次挥手讲下？为什么有TIME_WAIT？ TCP比UDP多消耗哪些系统资源？\nA(FIN_WAIT_1) -\u0026gt; B(CLOSE_WAIT) FIN=1,seq = u\nA(FIN_WAIT_2)\u0026lt;-B ACK=1, seq=v,ack=u+1;\nA \u0026lt;-B(LAST_ACK) FIN=1,seq = w,ack=u+1;\nA(TIME_WAIT) ACK=1 ,seq=u+1,ack=w+1;","tags":null,"title":""},{"categories":null,"contents":"#计算机操作系统\n基本特征 并发 并发是指宏观上在一段时间内能同时运行多个程序，而并行则指同一时刻能运行多个指令。\n并行需要硬件支持，如多流水线、多核处理器或者分布式计算系统。\n操作系统通过引入进程和线程，使得程序能够并发运行。\n共享 共享是指系统中的资源可以被多个并发进程共同使用。\n有两种共享方式：互斥共享和同时共享。\n互斥共享的资源称为临界资源，例如打印机等，在同一时刻只允许一个进程访问，需要用同步机制来实现互斥访问。\n虚拟 虚拟技术把一个物理实体转换为多个逻辑实体。\n主要有两种虚拟技术：时（时间）分复用技术和空（空间）分复用技术。\n多个进程能在同一个处理器上并发执行使用了时分复用技术，让每个进程轮流占用处理器，每次只执行一小个时间片并快速切换。\n虚拟内存使用了空分复用技术，它将物理内存抽象为地址空间，每个进程都有各自的地址空间。地址空间的页被映射到物理内存，地址空间的页并不需要全部在物理内存中，当使用到一个没有在物理内存的页时，执行页面置换算法，将该页置换到内存中。\n异步 异步指进程不是一次性执行完毕，而是走走停停，以不可知的速度向前推进。\n基本功能 进程管理 进程控制、进程同步、进程通信、死锁处理、处理机调度等。\n内存管理 内存分配、地址映射、内存保护与共享、虚拟内存等。\n文件管理 文件存储空间的管理、目录管理、文件读写管理和保护等。\n设备管理 完成用户的 I/O 请求，方便用户使用各种设备，并提高设备的利用率。\n主要包括缓冲管理、设备分配、设备处理、虛拟设备等。\n系统调用 如果一个进程在用户态需要使用内核态的功能，就进行系统调用从而陷入内核，由操作系统代为完成。\nLinux 的系统调用主要有以下这些：\nTask Commands 进程控制 fork(); exit(); wait(); 进程通信 pipe(); shmget(); mmap(); 文件操作 open(); read(); write(); 设备操作 ioctl(); read(); write(); 信息维护 getpid(); alarm(); sleep(); 安全 chmod(); umask(); chown(); 大内核和微内核 大内核 大内核是将操作系统功能作为一个紧密结合的整体放到内核。\n由于各模块共享信息，因此有很高的性能。\n微内核 由于操作系统不断复杂，因此将一部分操作系统功能移出内核，从而降低内核的复杂性。移出的部分根据分层的原则划分成若干服务，相互独立。\n在微内核结构下，操作系统被划分成小的、定义良好的模块，只有微内核这一个模块运行在内核态，其余模块运行在用户态。\n因为需要频繁地在用户态和核心态之间进行切换，所以会有一定的性能损失。\n中断分类 外中断 由 CPU 执行指令以外的事件引起，如 I/O 完成中断，表示设备输入/输出处理已经完成，处理器能够发送下一个输入/输出请求。此外还有时钟中断、控制台中断等。\n异常 由 CPU 执行指令的内部事件引起，如非法操作码、地址越界、算术溢出等。\n陷入 在用户程序中使用系统调用。\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/interview/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/","summary":"#计算机操作系统\n基本特征 并发 并发是指宏观上在一段时间内能同时运行多个程序，而并行则指同一时刻能运行多个指令。\n并行需要硬件支持，如多流水线、多核处理器或者分布式计算系统。\n操作系统通过引入进程和线程，使得程序能够并发运行。\n共享 共享是指系统中的资源可以被多个并发进程共同使用。\n有两种共享方式：互斥共享和同时共享。\n互斥共享的资源称为临界资源，例如打印机等，在同一时刻只允许一个进程访问，需要用同步机制来实现互斥访问。\n虚拟 虚拟技术把一个物理实体转换为多个逻辑实体。\n主要有两种虚拟技术：时（时间）分复用技术和空（空间）分复用技术。\n多个进程能在同一个处理器上并发执行使用了时分复用技术，让每个进程轮流占用处理器，每次只执行一小个时间片并快速切换。\n虚拟内存使用了空分复用技术，它将物理内存抽象为地址空间，每个进程都有各自的地址空间。地址空间的页被映射到物理内存，地址空间的页并不需要全部在物理内存中，当使用到一个没有在物理内存的页时，执行页面置换算法，将该页置换到内存中。\n异步 异步指进程不是一次性执行完毕，而是走走停停，以不可知的速度向前推进。\n基本功能 进程管理 进程控制、进程同步、进程通信、死锁处理、处理机调度等。\n内存管理 内存分配、地址映射、内存保护与共享、虚拟内存等。\n文件管理 文件存储空间的管理、目录管理、文件读写管理和保护等。\n设备管理 完成用户的 I/O 请求，方便用户使用各种设备，并提高设备的利用率。\n主要包括缓冲管理、设备分配、设备处理、虛拟设备等。\n系统调用 如果一个进程在用户态需要使用内核态的功能，就进行系统调用从而陷入内核，由操作系统代为完成。\nLinux 的系统调用主要有以下这些：\nTask Commands 进程控制 fork(); exit(); wait(); 进程通信 pipe(); shmget(); mmap(); 文件操作 open(); read(); write(); 设备操作 ioctl(); read(); write(); 信息维护 getpid(); alarm(); sleep(); 安全 chmod(); umask(); chown(); 大内核和微内核 大内核 大内核是将操作系统功能作为一个紧密结合的整体放到内核。\n由于各模块共享信息，因此有很高的性能。\n微内核 由于操作系统不断复杂，因此将一部分操作系统功能移出内核，从而降低内核的复杂性。移出的部分根据分层的原则划分成若干服务，相互独立。\n在微内核结构下，操作系统被划分成小的、定义良好的模块，只有微内核这一个模块运行在内核态，其余模块运行在用户态。\n因为需要频繁地在用户态和核心态之间进行切换，所以会有一定的性能损失。\n中断分类 外中断 由 CPU 执行指令以外的事件引起，如 I/O 完成中断，表示设备输入/输出处理已经完成，处理器能够发送下一个输入/输出请求。此外还有时钟中断、控制台中断等。","tags":null,"title":""},{"categories":null,"contents":"线程同步 线程同步的概念 线程同步：即当有一个线程在对内存进行操作时，其他线程都不可以对这个内存地址进行操作，直到该线程完成操作， 其他线程才能对该内存地址进行操作，而其他线程又处于等待状态，实现线程同步的方法有很多，临界区对象就是其中一种。\n在多线程编程里面，一些敏感数据不允许被多个线程同时访问，此时就使用同步访问技术，保证数据在任何时刻，最多有一个线程访问，以保证数据的完整性。\n线程有可能和其他线程共享一些资源，比如，内存，文件，数据库等。\n当多个线程同时读写同一份共享资源的时候，可能会引起冲突。这时候，我们需要引入线程“同步”机制，即各位线程之间要有个先来后到，不能一窝蜂挤上去抢作一团。\n线程同步的真实意思和字面意思恰好相反。线程同步的真实意思，其实是“排队”：几个线程之间要排队，一个一个对共享资源进行操作，而不是同时进行操作。\n线程同步的方式和机制 临界区（Critical Section）、互斥对象（Mutex）：主要用于互斥控制；都具有拥有权的控制方法，只有拥有该对象的线程才能执行任务，所以拥有，执行完任务后一定要释放该对象。\n信号量（Semaphore）、事件对象（Event）：事件对象是以通知的方式进行控制，主要用于同步控制。\n临界区 通过对多线程的串行化来访问公共资源或一段代码，速度快，适合控制数据访问。在任意时刻只允许一个线程对共享资源进行访问，如果有多个线程试图访问公共资源，那么在有一个线程进入后，其他试图访问公共资源的线程将被挂起，并一直等到进入临界区的线程离开，临界区在被释放后，其他线程才可以抢占。它并不是核心对象，不是属于操作系统维护的，而是属于进程维护的。\n1）关键段共有初始化、销毁、进入和离开关键区域四个函数。\n2）关键段可以解决线程的互斥问题，但因为具有“线程所有权”，所以无法解决同步问题。\n3）推荐关键段与旋转锁配合使用。\n互斥量 互斥对象和临界区很像，采用互斥对象机制，只有拥有互斥对象的线程才有访问公共资源的权限。因为互斥对象只有一个，所以能保证公共资源不会同时被多个线程同时访问。当前拥有互斥对象的线程处理完任务后必须将线程交出，以便其他线程访问该资源。\n1）互斥量是内核对象，它与关键段都有“线程所有权”所以不能用于线程的同步。\n2）互斥量能够用于多个进程之间线程互斥问题，并且能解决某进程意外终止所造成的“遗弃”问题。 3、信号量：信号量也是内核对象。它允许多个线程在同一时刻访问同一资源，但是需要限制在同一时刻访问此资源的最大线程数目\n信号量 在用CreateSemaphore()创建信号量时即要同时指出允许的最大资源计数和当前可用资源计数。一般是将当前可用资源计数设置为最 大资源计数，每增加一个线程对共享资源的访问，当前可用资源计数就会减1 ，只要当前可用资源计数是大于0 的，就可以发出信号量信号。但是当前可用计数减小 到0 时则说明当前占用资源的线程数已经达到了所允许的最大数目，不能在允许其他线程的进入，此时的信号量信号将无法发出。线程在处理完共享资源后，应在离 开的同时通过ReleaseSemaphore （）函数将当前可用资源计数加1 。在任何时候当前可用资源计数决不可能大于最大资源计数。\n事件对象 通过通知操作的方式来保持线程的同步，还可以方便实现对多个线程的优先级比较的操作\n1）事件是内核对象，事件分为手动置位事件和自动置位事件。事件Event内部它包含一个使用计数（所有内核对象都有），一个布尔值表示是手动置位事件还是自动置位事件，另一个布尔值用来表示事件有无触发。\n2）事件可以由SetEvent()来触发，由ResetEvent()来设成未触发。还可以由PulseEvent()来发出一个事件脉冲。\n3）事件可以解决线程间同步问题，因此也能解决互斥问题。\n线程同步的方法 (1)wait():使一个线程处于等待状态，并且释放所持有的对象的lock。\n(2)sleep():使一个正在运行的线程处于睡眠状态，是一个静态方法，调用此方法要捕捉 InterruptedException异常。\n(3)notify():唤醒一个处于等待状态的线程，注意的是在调用此方法的时候，并不能确切的 唤醒某一个等待状态的线程，而是由JVM确定唤醒哪个线程，而且不是按优先级。\n(4)notityAll ():唤醒所有处入等待状态的线程，注意并不是给所有唤醒线程一个对象的锁， 而是让它们竞争。\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/interview/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BA%BF%E7%A8%8B%E5%90%8C%E6%AD%A5/","summary":"线程同步 线程同步的概念 线程同步：即当有一个线程在对内存进行操作时，其他线程都不可以对这个内存地址进行操作，直到该线程完成操作， 其他线程才能对该内存地址进行操作，而其他线程又处于等待状态，实现线程同步的方法有很多，临界区对象就是其中一种。\n在多线程编程里面，一些敏感数据不允许被多个线程同时访问，此时就使用同步访问技术，保证数据在任何时刻，最多有一个线程访问，以保证数据的完整性。\n线程有可能和其他线程共享一些资源，比如，内存，文件，数据库等。\n当多个线程同时读写同一份共享资源的时候，可能会引起冲突。这时候，我们需要引入线程“同步”机制，即各位线程之间要有个先来后到，不能一窝蜂挤上去抢作一团。\n线程同步的真实意思和字面意思恰好相反。线程同步的真实意思，其实是“排队”：几个线程之间要排队，一个一个对共享资源进行操作，而不是同时进行操作。\n线程同步的方式和机制 临界区（Critical Section）、互斥对象（Mutex）：主要用于互斥控制；都具有拥有权的控制方法，只有拥有该对象的线程才能执行任务，所以拥有，执行完任务后一定要释放该对象。\n信号量（Semaphore）、事件对象（Event）：事件对象是以通知的方式进行控制，主要用于同步控制。\n临界区 通过对多线程的串行化来访问公共资源或一段代码，速度快，适合控制数据访问。在任意时刻只允许一个线程对共享资源进行访问，如果有多个线程试图访问公共资源，那么在有一个线程进入后，其他试图访问公共资源的线程将被挂起，并一直等到进入临界区的线程离开，临界区在被释放后，其他线程才可以抢占。它并不是核心对象，不是属于操作系统维护的，而是属于进程维护的。\n1）关键段共有初始化、销毁、进入和离开关键区域四个函数。\n2）关键段可以解决线程的互斥问题，但因为具有“线程所有权”，所以无法解决同步问题。\n3）推荐关键段与旋转锁配合使用。\n互斥量 互斥对象和临界区很像，采用互斥对象机制，只有拥有互斥对象的线程才有访问公共资源的权限。因为互斥对象只有一个，所以能保证公共资源不会同时被多个线程同时访问。当前拥有互斥对象的线程处理完任务后必须将线程交出，以便其他线程访问该资源。\n1）互斥量是内核对象，它与关键段都有“线程所有权”所以不能用于线程的同步。\n2）互斥量能够用于多个进程之间线程互斥问题，并且能解决某进程意外终止所造成的“遗弃”问题。 3、信号量：信号量也是内核对象。它允许多个线程在同一时刻访问同一资源，但是需要限制在同一时刻访问此资源的最大线程数目\n信号量 在用CreateSemaphore()创建信号量时即要同时指出允许的最大资源计数和当前可用资源计数。一般是将当前可用资源计数设置为最 大资源计数，每增加一个线程对共享资源的访问，当前可用资源计数就会减1 ，只要当前可用资源计数是大于0 的，就可以发出信号量信号。但是当前可用计数减小 到0 时则说明当前占用资源的线程数已经达到了所允许的最大数目，不能在允许其他线程的进入，此时的信号量信号将无法发出。线程在处理完共享资源后，应在离 开的同时通过ReleaseSemaphore （）函数将当前可用资源计数加1 。在任何时候当前可用资源计数决不可能大于最大资源计数。\n事件对象 通过通知操作的方式来保持线程的同步，还可以方便实现对多个线程的优先级比较的操作\n1）事件是内核对象，事件分为手动置位事件和自动置位事件。事件Event内部它包含一个使用计数（所有内核对象都有），一个布尔值表示是手动置位事件还是自动置位事件，另一个布尔值用来表示事件有无触发。\n2）事件可以由SetEvent()来触发，由ResetEvent()来设成未触发。还可以由PulseEvent()来发出一个事件脉冲。\n3）事件可以解决线程间同步问题，因此也能解决互斥问题。\n线程同步的方法 (1)wait():使一个线程处于等待状态，并且释放所持有的对象的lock。\n(2)sleep():使一个正在运行的线程处于睡眠状态，是一个静态方法，调用此方法要捕捉 InterruptedException异常。\n(3)notify():唤醒一个处于等待状态的线程，注意的是在调用此方法的时候，并不能确切的 唤醒某一个等待状态的线程，而是由JVM确定唤醒哪个线程，而且不是按优先级。\n(4)notityAll ():唤醒所有处入等待状态的线程，注意并不是给所有唤醒线程一个对象的锁， 而是让它们竞争。","tags":null,"title":""},{"categories":null,"contents":"","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/interview/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C/","summary":"","tags":null,"title":""},{"categories":null,"contents":"从底层技术角度看，Pod内不同容器之间共享存储和一些namespace。\nPID namespace: Pod中不同应用程序看拿到的其他进程的ID。Sidecar 模式下只能看到一个进程？\nNetwork Namespace: Pod 中的多个容器具有相同的网络配置，共享一个端口范围。\nIPC Namespace： Pod中的多个容器能够使用SystemV IPC 或 POSIX消息队列进行通信。\nUTS Namespace: Pod中的多个容器共享一个主机名。\n在Kubernetes的网络模型中，每台服务器上的容器有自己独立的IP段。\n为了实现这一目标，重点解决一下两点：\n各台服务器上的容器IP段不能重叠，所以需要某种IP段分配机制，为各台机器分配独立的IP段。 从某个Pod发出的流量到达所在的机器的Host上时，机器网络层应当根据目标IP地址，将流量转发到目标机器的能力。 综上，两个能力： IP地址分配和Route.\n容器之间直接通信，不需要额外的NAT。\nPod to Pod 所有的Pod之间要保证3层网络的联通性\nPod to Service Servcie 总共有4种类型，其中组常用的就是Cluster IP. 这种类型的Service会分配一个仅集群内可以访问的虚拟IP。\nKubernetes通过kube-proxy组件实现Service Cluster IP的功能。kube-proxy 是一个daemonset，通过复杂的iptables/IPVS 规则在Pod和Service之间进行各种过滤和NAT.\nPod到集群外 从Pod内部到集群外的流量，Kubernetes会通过SNAT来处理。\nKubernets 默认的组网方案是bridge，CNI主要是用来解决容器的跨机通信。典型的跨机通信方案有bridge和overlay。\n创建Pod时候，首先会创建一个pause容器。占用一个 linux的network namespace。Pod内的其他容器共享这个network namespace。此时，只有一个lo设备。 CNI负责初始化pause container 中的网络设备。\nkubernetes主机内组网\u0026amp;跨节点组网 kubernetes 经典的主机内组网模型是veth pair+bridge。\n跨机通信一般是bridge + overlay。 vxlan\ndownward API 通过HostAlias修改pod中的/etc/host(Pod在host network下不支持)\nPod的隔离中 network namspce 是最先创建的，如果ns使用了host模式，则uts也会使用host模式。\nPause扮演PID 1的角色，并在子进程成为“孤儿进程”时，通过wait() 收割这些僵尸子进程。\nUnix的init进程的作用是当某个子进程由于父进程的错误退出而变成了“孤儿进程”，便会被init进程“收养”并在退出该进程时回收资源。\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/kubernetes/k8s_ops_pod/","summary":"从底层技术角度看，Pod内不同容器之间共享存储和一些namespace。\nPID namespace: Pod中不同应用程序看拿到的其他进程的ID。Sidecar 模式下只能看到一个进程？\nNetwork Namespace: Pod 中的多个容器具有相同的网络配置，共享一个端口范围。\nIPC Namespace： Pod中的多个容器能够使用SystemV IPC 或 POSIX消息队列进行通信。\nUTS Namespace: Pod中的多个容器共享一个主机名。\n在Kubernetes的网络模型中，每台服务器上的容器有自己独立的IP段。\n为了实现这一目标，重点解决一下两点：\n各台服务器上的容器IP段不能重叠，所以需要某种IP段分配机制，为各台机器分配独立的IP段。 从某个Pod发出的流量到达所在的机器的Host上时，机器网络层应当根据目标IP地址，将流量转发到目标机器的能力。 综上，两个能力： IP地址分配和Route.\n容器之间直接通信，不需要额外的NAT。\nPod to Pod 所有的Pod之间要保证3层网络的联通性\nPod to Service Servcie 总共有4种类型，其中组常用的就是Cluster IP. 这种类型的Service会分配一个仅集群内可以访问的虚拟IP。\nKubernetes通过kube-proxy组件实现Service Cluster IP的功能。kube-proxy 是一个daemonset，通过复杂的iptables/IPVS 规则在Pod和Service之间进行各种过滤和NAT.\nPod到集群外 从Pod内部到集群外的流量，Kubernetes会通过SNAT来处理。\nKubernets 默认的组网方案是bridge，CNI主要是用来解决容器的跨机通信。典型的跨机通信方案有bridge和overlay。\n创建Pod时候，首先会创建一个pause容器。占用一个 linux的network namespace。Pod内的其他容器共享这个network namespace。此时，只有一个lo设备。 CNI负责初始化pause container 中的网络设备。\nkubernetes主机内组网\u0026amp;跨节点组网 kubernetes 经典的主机内组网模型是veth pair+bridge。\n跨机通信一般是bridge + overlay。 vxlan\ndownward API 通过HostAlias修改pod中的/etc/host(Pod在host network下不支持)\nPod的隔离中 network namspce 是最先创建的，如果ns使用了host模式，则uts也会使用host模式。\nPause扮演PID 1的角色，并在子进程成为“孤儿进程”时，通过wait() 收割这些僵尸子进程。","tags":null,"title":""},{"categories":null,"contents":"文件权限 文件权限表示 1drwxrwxrwx 3 root wheel 96 Oct 13 20:30 opt 2drwxr-xr-x 6 root wheel 192 Oct 8 18:57 private 3drwxr-xr-x@ 64 root wheel 2048 Oct 8 18:55 sbin 【文件或文件夹】【owner权限】【group权限】【others权限】【 文件数量】 【文件所有者】【文件所在组】【文件夹最后操作日期和时间】\nd 表示文件类型为 文件夹 ， - 表示文件类型为 文本文件， l 表示链接文件 r 读权限read 4, w 写权限write 2, x 操作权限execute 1 : rwx 按二进制位置 111， 所以对应 421 修改文件权限 1chmod 权限数字 文件名 2chmod -R 744 /mnt/fileA # 表示将整个/mnt/fileA目录与其中的文件和子目录的权限都设置为744 3chmod o w xxx.xxx #表示给其他人授予写xxx.xxx这个文件的权限 4chmod go-rw xxx.xxx #表示删除xxx.xxx中组群和其他人的读和写的权限 5 6# u 代表所有者（user） 7# g 代表所有者所在的组群（group） 8# o 代表其他人，但不是u和g （other） 9# a 代表全部的人，也就是包括u，g和o 10# r 表示文件可以被读（read） 4 11# w 表示文件可以被写（write）2 12# x 表示文件可以被执行（如果它是程序的话）1 13# - 表示没有任何权限 0 ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/linux/chmod/","summary":"文件权限 文件权限表示 1drwxrwxrwx 3 root wheel 96 Oct 13 20:30 opt 2drwxr-xr-x 6 root wheel 192 Oct 8 18:57 private 3drwxr-xr-x@ 64 root wheel 2048 Oct 8 18:55 sbin 【文件或文件夹】【owner权限】【group权限】【others权限】【 文件数量】 【文件所有者】【文件所在组】【文件夹最后操作日期和时间】\nd 表示文件类型为 文件夹 ， - 表示文件类型为 文本文件， l 表示链接文件 r 读权限read 4, w 写权限write 2, x 操作权限execute 1 : rwx 按二进制位置 111， 所以对应 421 修改文件权限 1chmod 权限数字 文件名 2chmod -R 744 /mnt/fileA # 表示将整个/mnt/fileA目录与其中的文件和子目录的权限都设置为744 3chmod o w xxx.xxx #表示给其他人授予写xxx.","tags":null,"title":""},{"categories":null,"contents":"https://www.jianshu.com/p/a6c6f47a5ef7\nhttps://blog.csdn.net/weixin_42096901/article/details/103017044\nhttps://blog.csdn.net/weixin_39406430/article/details/123715072\nhttp://t.zoukankan.com/yangyongjie-p-14576216.html\nhttps://zhuanlan.zhihu.com/p/430848775\nhttps://blog.csdn.net/weixin_42340926/article/details/126211173\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/linux/linux_zero_copy/","summary":"https://www.jianshu.com/p/a6c6f47a5ef7\nhttps://blog.csdn.net/weixin_42096901/article/details/103017044\nhttps://blog.csdn.net/weixin_39406430/article/details/123715072\nhttp://t.zoukankan.com/yangyongjie-p-14576216.html\nhttps://zhuanlan.zhihu.com/p/430848775\nhttps://blog.csdn.net/weixin_42340926/article/details/126211173","tags":null,"title":""},{"categories":null,"contents":"1title: Linux Network Virtualization Network Namespace In order to provide the isolation, Linux has 6 namespaces to split the different resources, shown as follows:\nNamespace Description Mount Namespace File system mount point CLONE_NEWNET UTS Namespace Hostname CLONE_NETUTS IPC Namespace POSIX process messaging queue CLONE_NEWIPC PID Namespace Process PID number namespace CLONE_NEWPID Network Namespace IP address/Port/Router/IPtables CLONE_NEWNS User Namespace User isolation CLONE_NEWUSER For the process, if they want to use the resources of the Namespace, they should enter the namespace first. And the resources don\u0026rsquo;t share between different namespaces.\nNetwork Namespace Overview You can use ip netns to manage the Network Namespace, or you can write C code to operate the Network Namespace through the system call. We can use clone()(a extend for fork()) to create a usual Namespace, and specify the parameter CLONE_NEWNET to create a Network Namespace.\n1ip netns add netns1 After you created the namespace, you can use ip netns show or ip netns list to check the result. At the same time, a file named netns1 is created at /var/run/netns/netns1, this is the Mount Point. On the one hand, this file is for managing the namespace, on the other hand, even if no process running in the namespace, the namespace still exists.\nOnce the Network Namespace is created, you can use ip netns exec \u0026lt;namespace\u0026gt; \u0026lt;command\u0026gt; to enter it to do some configuration.\nFor example,\n1# run bash in network namespace \u0026lt;netns1\u0026gt; 2ip netns exec netns1 bash 3 4# get the network interface of the network namespace \u0026lt;netns1\u0026gt; 5ip net exec netns1 ip link list After you create a Network Namespace, it contains a Loopback Interface at least.\nIf you want to delete the Network Namespace, try\n1ip netns delete netns1 Noted, actually, the above command does not totally delete the Network Namespace, this only removed the Mount Point. If there is any process still running, the Network Namespace will still exist.\nConfiguration When we talk about the network communication of the processes in the Network Namespace, the Virtual/Actual Network Device is required.\nThe new Network Namespace only contains a Loopback Interface, and the status of this interface is DOWN. After setting the loup, you can ping 127.0.0.1 and get the response.\nBut, if we want to contact the outside, we need to create a couple of virtual ether network cards, it\u0026rsquo;s the veth pair. Veth pair always presents in couples. It was like a two-way pipe, the datagram went into one side, and came out from another side.\nLet\u0026rsquo;s create a veth pair, and put one side into the netns1.\n1# create a veth pair veth0-veth1 2ip link add veth0 type veth peer name veth1 3# mv veth1 to netns1 network namespace 4ip link set veth1 netns netns1 After that, we created 2 veth interface. But these are in DOWNstatus. Next, we set them up and bind an IP to the interface.\n1ip netns exec netns1 ifconfig veth1 10.1.1.1/24 up 2ifconfig veth0 10.1.1.2/up Now, you can ping 10.1.1.1 on the host.\nThe route table and IPtables are different between different Network Namespace.\nWhen we enter the netns1 Network Namespace, the route table and IPtables are empty. So, when you are in the netns1 you can\u0026rsquo;t connect to the Internet. There are several ways to solve that:\nCreate a Linux bridge on the host, and bind one side of the veth pair to the bridge\nAdd NAT rule on the host and enable Linux IP forward.\n1# enable or disable IP forwarding status 2sysctl -w net.ipv4.ip_forward=0 3# OR 4sysctl -w net.ipv4.ip_forward=1 5 6# check the IP forwarding status 7cat /proc/sys/net/ipv4/ip_forward 80 Note\nUsers can put the physical/virtual network device to any network namespace, and one device only can be put into one Network Namespace.\nThe process can enter the Network Namespace through the Linux System Call clone()/unshare()/setns(). No-root process in a specific Network Namespace only can assess and config the local Network Namespace.\nThe root process can create a network device in the Network Namespace. And, root process can put the local Network Namespace\u0026rsquo;s device in another namespace.\n1# move interface form netns1 to PID=1 2ip net exec netns1 ip link set veth1 netns 1 The above command moves the veth1 interface from netns1 to host default Network namespace.\nFor the root user of the network namespace, they can move the network device to any Network Namespace, even the host network namespace. So, there will be a potential risk. If users want to avoid the risk, they need to combine the PID Namespace and Mount Namespace to make the Network Namespace totally isolated.\nHow do combine the PID Namespace and Mount Namespace to make the Network Namespace totally isolated?\nNetwork Namespace API The API is related with Linux System Call: clone() unshare() setns() and file in /proc. This chapter will introduce the usage of the network namespace API through several examples.\nclone() unshare() setns() use the const variable CLONE_NEW* to represent different namespace:\nNamespace Description Mount Namespace File system mount point CLONE_NEWNS UTS Namespace Hostname CLONE_NEWUTS IPC Namespace POSIX process messaging queue CLONE_NEWIPC PID Namespace Process PID number namespace CLONE_NEWPID Network Namespace IP address/Port/Router/IPtables CLONE_NEWNET User Namespace User isolation CLONE_NEWUSER Create namespace through clone() 1int clone(int (*child_func)(void *), void *child_stack, int flags, void *arg); clone() is an extension of fork(), we can control the function through the flags parameter. clone()has more than 20 CLONE_* flag to control the processes\u0026rsquo; actions.\nIf set a flag CLONE_NEW, the system will create a corresponding type namespace and a new process and put the process into the new Namespace. Through | we can specify multiple CLONE_NEW flags.\nThe parameters\u0026rsquo; meaning, from left to right\nFunction point child_func, specify a new function for the new process. When the function returned, the child process ended. This function returns an integer value to represent the exit code. Point child_stack is put into the child process\u0026rsquo;s stack, another word, put user-mode stack point to child process\u0026rsquo;s esp register. The process that calls clone() needs to allocate a new stack to the child process. Int flags represent the CLONE_* flag, which can be multiply connected with |. args is the user-defined parameter. Finally, you should pay attention to the authorization and safety, most of the Namespace creates need the system capability, which not should be total root permission, but need CAP_SYS_ADMIN to execute the essential System Call.\nLinux 的特权是将root的权限分为各个小部分，使得一个进程只需要被授予刚刚好的权限来执行特定的任务。如果这些特权足够小，且选择的恰到好处，那么即使一个进程受损（比如缓冲区溢出），它所造成的危害也会受限于它所拥有的的特权。 例如，CAP_KILL 允许向任意的进程发送信号， 而CAP_SYS_TIME允许进程设置系统的时钟。\nKeep namespace existing Every process has its own /proc/PID/ns, and every file in this path represents a type of namespace.\nBefore Linux Kernel v3.8, the file in this path is a hard link, and only has IPC, nets, and uts. After v3.8, every file is a special symbolic link file and these files provide a way to operate the namespace related to the process.\n1ls -l /proc/$$/ns # $$ is the PID of bash One of the symbolic link file\u0026rsquo;s usage is to show if two processes use the same namespace. If two processes are in the same namespace, the inode number on the symbolic link file should be the same. (You can through stat()to get the inode number in st_ino )\n1#define _GNU_SOURCE 2#define NULL 0x0 3#include \u0026lt;sys/types.h\u0026gt; 4#include \u0026lt;sys/wait.h\u0026gt; 5#include \u0026lt;sys/mount.h\u0026gt; 6#include \u0026lt;stdio.h\u0026gt; 7#include \u0026lt;sched.h\u0026gt; 8#include \u0026lt;signal.h\u0026gt; 9#include \u0026lt;unistd.h\u0026gt; 10#include \u0026lt;stdlib.h\u0026gt; 11 12#define STACK_SIZE (1024 * 1024) 13 14// sync primitive 15int checkpoint[2]; 16 17static char child_stack[STACK_SIZE]; 18char *const child_args[] = { 19 \u0026#34;/bin/bash\u0026#34;, 20 NULL}; 21 22int child_main(void *arg) 23{ 24 char c; 25 26 // init sync primitive 27 printf(\u0026#34;\u0026gt;\u0026gt; wait for signal\u0026#34;); 28 close(checkpoint[1]); 29 printf(\u0026#34;\u0026gt;\u0026gt; receive signal\u0026#34;); 30 31 // setup hostname 32 printf(\u0026#34;- [%5d] World !\\n\u0026#34;, getpid()); 33 sethostname(\u0026#34;In Namespace\u0026#34;, 12); 34 35 // remount \u0026#34;/proc\u0026#34; to get accurate \u0026#34;top\u0026#34; \u0026amp;\u0026amp; \u0026#34;ps\u0026#34; output 36 mount(\u0026#34;proc\u0026#34;, \u0026#34;/proc\u0026#34;, \u0026#34;proc\u0026#34;, 0, NULL); 37 38 // wait for network setup in parent 39 read(checkpoint[0], \u0026amp;c, 1); 40 41 // setup network 42 system(\u0026#34;ip link set lo up\u0026#34;); 43 system(\u0026#34;ip link set veth1 up\u0026#34;); 44 system(\u0026#34;ip addr add 192.168.0.2/24 dev veth1\u0026#34;); 45 execv(child_args[0], child_args); 46 printf(\u0026#34;Oops \\n\u0026#34;); 47 return 1; 48} 49 50int main() 51{ 52 // init sync primitive 53 pipe(checkpoint); 54 55 printf(\u0026#34;- [%5d] Hello ?\\n\u0026#34;, getpid()); 56 57 int child_pid = clone(child_main, child_stack + STACK_SIZE, 58 CLONE_NEWUTS | CLONE_NEWIPC | CLONE_NEWPID | CLONE_NEWNS | CLONE_NEWNET | SIGCHLD, NULL); 59 60 // further init; create a veth pair 61 char *cmd; 62 asprintf(\u0026amp;cmd, \u0026#34;ip link set veth1 netns %d\u0026#34;, child_pid); 63 system(\u0026#34;ip link add veth0 type veth peer name veth1\u0026#34;); 64 system(cmd); 65 system(\u0026#34;ip link set veth0 up\u0026#34;); 66 system(\u0026#34;ip addr add 192.168.0.1/24 dev veth0\u0026#34;); 67 free(cmd); 68 69 // single \u0026#34;done\u0026#34; 70 close(checkpoint[1]); 71 printf(\u0026#34;\u0026gt;\u0026gt;\u0026gt; signal done\u0026#34;); 72 73 waitpid(child_pid, NULL, 0); 74 return 0; 75} NC command\nuse for network test\nC primitive\nVeth Pair The principle of Veth Pair is that put data into one side of the veth pair, and get out from another side.\nThe kernel code if veth pair Relationship between container and veth pair The typical model of the container network is veth pair + bridge. The interface in the container eth0 is a peer of the host veth interface. So, how to find which is the peer interface?\nMethod 1:\nFirst, in the target container find that,\n1cat /sys/class/net/eth0/iflink And then check all the files on the host /sys/class/net/,check the ifindex value which is the same as the iflink. The interface with the same value is another side of the veth pair.\nMethod 2\nLinux Bridge What is Linux Bridge Create and Manage the Linux Bridge\n1ip link add name br0 type bridge 2ip link set br0 up Besides the ip command, we can use the brctl tool in the bridge-utils package to create a bridge.\n1brctl addr br0 ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/linux/network_virtualization/","summary":"1title: Linux Network Virtualization Network Namespace In order to provide the isolation, Linux has 6 namespaces to split the different resources, shown as follows:\nNamespace Description Mount Namespace File system mount point CLONE_NEWNET UTS Namespace Hostname CLONE_NETUTS IPC Namespace POSIX process messaging queue CLONE_NEWIPC PID Namespace Process PID number namespace CLONE_NEWPID Network Namespace IP address/Port/Router/IPtables CLONE_NEWNS User Namespace User isolation CLONE_NEWUSER For the process, if they want to use the resources of the Namespace, they should enter the namespace first.","tags":null,"title":""},{"categories":null,"contents":"Hi, Kural,\nAbout the IPV6 SFC, the following is my debug process.\nNow, the func CalculateRoutes() can genarate the create route to the pod, but can\u0026rsquo;t add to the corresponding pod.\nThe calculated result for the sfc-head pod:\nBut for the agent pod, while adding routes to the container through func ContainerAddRoute() failed. Because in this function, it will get the host network configuration to find the default gateway, to add an extra route to the host network through the default gateway on the host. If the host is without an IPV6 default gateway will cause the failure.\nSo, I think this path will work normally with the host in an ipv6 environment.\nSo, shall we still work to fix it? make it suitable for the host not to run in an IPV6 environment, Or just test this patch in an IPv6 fully support host machine.\nOr, Could this work transfer to the NEX team colleagues, I can help the finish the test in IPV6 env or host to fix it and make it suitable for Dual-Stacks.\nThe attachment is the log of operator and agent.\nipv4 and ipv6 are not isolated in the code, somewhere use hard code to disparate that, and this could be a potential risk.\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/nodus/ipv6-debug/","summary":"Hi, Kural,\nAbout the IPV6 SFC, the following is my debug process.\nNow, the func CalculateRoutes() can genarate the create route to the pod, but can\u0026rsquo;t add to the corresponding pod.\nThe calculated result for the sfc-head pod:\nBut for the agent pod, while adding routes to the container through func ContainerAddRoute() failed. Because in this function, it will get the host network configuration to find the default gateway, to add an extra route to the host network through the default gateway on the host.","tags":null,"title":""},{"categories":null,"contents":"for containerd\nfor crio\nfor docker\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/nodus/k8s-install-script/","summary":"for containerd\nfor crio\nfor docker","tags":null,"title":""},{"categories":null,"contents":"fork create process\nfork 被调用一次，可以返回两次。\n在调用fork之后的代码会执行两次，一次在父进程中执行，返回的是创建成功的子进程的Id，一次是在子进程中执行，返回的是0；如果出现错误，fork返回的是负值。\n1/*linux下：*/ 2 3#include \u0026lt;stdio.h\u0026gt; 4#include \u0026lt;unistd.h\u0026gt; 5 6int main() { 7 pid_t pid; 8 pid = fork(); 9 if(pid == 0) //返回子进程 10 { 11 printf(\u0026#34;child pid: %d\\n\u0026#34;, getpid()); 12 } else { 13 printf(\u0026#34;pid: %d\\n\u0026#34;, pid);//父进程中返回子进程的pid 14 printf(\u0026#34;father pid: %d\\n\u0026#34;, getpid()); 15 } 16} 1pid: 2876921 2father pid: 2876920 3child pid: 2876921 fork的两种用法\n父进程希望复制自己，使父子进程同时执行不同的代码段。\n比如在网络服务程序中，父进程等待客户端的服务请求。当请求到达时，父进程调用fork()使子进程处理此请求；而父进程继续等待下一个请求。\n一个进程要执行不同的程序\n这个在shell下比较常见，这种情况下， fork()之后一般立即接exec函数。\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/note_c/c_process/","summary":"fork create process\nfork 被调用一次，可以返回两次。\n在调用fork之后的代码会执行两次，一次在父进程中执行，返回的是创建成功的子进程的Id，一次是在子进程中执行，返回的是0；如果出现错误，fork返回的是负值。\n1/*linux下：*/ 2 3#include \u0026lt;stdio.h\u0026gt; 4#include \u0026lt;unistd.h\u0026gt; 5 6int main() { 7 pid_t pid; 8 pid = fork(); 9 if(pid == 0) //返回子进程 10 { 11 printf(\u0026#34;child pid: %d\\n\u0026#34;, getpid()); 12 } else { 13 printf(\u0026#34;pid: %d\\n\u0026#34;, pid);//父进程中返回子进程的pid 14 printf(\u0026#34;father pid: %d\\n\u0026#34;, getpid()); 15 } 16} 1pid: 2876921 2father pid: 2876920 3child pid: 2876921 fork的两种用法\n父进程希望复制自己，使父子进程同时执行不同的代码段。\n比如在网络服务程序中，父进程等待客户端的服务请求。当请求到达时，父进程调用fork()使子进程处理此请求；而父进程继续等待下一个请求。\n一个进程要执行不同的程序\n这个在shell下比较常见，这种情况下， fork()之后一般立即接exec函数。","tags":null,"title":""},{"categories":null,"contents":"","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/note_c/unix_socket/","summary":"","tags":null,"title":""},{"categories":null,"contents":"","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/note_go/1st--/","summary":"","tags":null,"title":""},{"categories":null,"contents":"类型 2.1 变量 标识符与关键字 标识符 在编程语言中标识符就是程序员定义的具有特殊意义的词，比如变量名、常量名、函数名等等。 Go语言中标识符由字母数字和_(下划线）组成，并且只能以字母和_开头。 举几个例子：abc, _, _123, a123。\n关键字 关键字是指编程语言中预先定义好的具有特殊含义的标识符。 关键字和保留字都不建议用作变量名。\nGo语言中有25个关键字：\n1 break default func interface select 2 case defer go map struct 3 chan else goto package switch 4 const fallthrough if range type 5 continue for import return var 此外，Go语言中还有37个保留字。\n1 Constants: true false iota nil 2 3 Types: int int8 int16 int32 int64 4 uint uint8 uint16 uint32 uint64 uintptr 5 float32 float64 complex128 complex64 6 bool byte rune string error 7 8 Functions: make len cap new append copy close delete 9 complex real imag 10 panic recover go 语言中的变量必须先声明再使用。\n1package main 2 3// 导入语句 4import \u0026#34;fmt\u0026#34; 5 6// 函数外只能放置标识符(常量/变量/函数/类型)，不能放置语句 7// fmt.Println(\u0026#34;hello world\u0026#34;) // 非法语句 8 9// 程序入口函数 10func main() { 11\tvar s string 12\t// s = \u0026#34;hello\u0026#34; 13\tfmt.Println(s) 14\tfmt.Println(\u0026#34;hello\u0026#34;) 15\tfmt.Printf(\u0026#34;name: %s\u0026#34;, s) 16} 运行时内存分配操作会确保变量自动化初始为二进制零值(zero value), 避免出现不可预测的行为。\n1var x int // 自动化初始为0 2var y = false // 自动推断为bool类型 3 4var x,y int // 相同类型多个变量 5 6// 建议以组的方式整理多行变量定义 7var{ 8 x,y int 9 a,s = 100,\u0026#34;abc\u0026#34; 10} 简短模式 short variable declaration 定义变量同时显式初始化 不能提供数据类型 只能在函数内部使用 1 2 3func main(){ 4 x := 100 5 a,s := 1, \u0026#34;adc\u0026#34; 6} 简短模式并不总是重新定义变量，也可能是部分退化的赋值操作\n1func main(){ 2 x := 100 3 print(\u0026amp;x) 4 5 x, y := 200,\u0026#34;abc\u0026#34; 6 println(\u0026amp;x, x) 7 println(y) 8} 退化赋值的条件是：最少有一个新的变量被定义，且必须是同一作用域\n在处理函数错误返回值时，退化赋值允许我们重复使用err变量\n多变量赋值 在进行多变量赋值时，首先计算出所有的右值，然后再依次完成赋值操作\ngo tool objdump -s \u0026quot;main/.main\u0026quot; test\n未使用错误 编译器将未使用的局部变量当做错误。\n全局变量没问题\n2.2 命名 命名建议 字母或者下划线开始 区分大小写 使用驼峰格式 局部变量优先使用短名字 专有名词大写 Go 支持用汉字等Unicode字符命名\n1func main(){ 2\tvar c int 3 for i :=0; i\u0026lt;10;i++{ 4 c++ 5 } 6} 符号名字 首字母大小写决定了其作用域\n首字母大写的为导出成员，可以被包外引用，而小写仅能在包内使用。\n空表示符 \u0026ldquo;_\u0026rdquo; blank identifier。 通常作为忽略占位符使用，可做表达式左值，无法读取内容\n1import \u0026#34;strconv\u0026#34; 2func main(){ 3 x,_:=strcow.Atoi(\u0026#34;12\u0026#34;) 4 println(x) 5} 空标识符可以用来临时规避编译器对未使用变量和导入包的错误检查。是预置成员，不能重新定义。\n匿名变量 不占用命名空间，不会分配内存，所以匿名变量存在重复声明\n函数外的每个语句逗必须以关键字开始const var func\n类型推导 1package main 2 3func main(){ 4 var a = 101 // a是 int 5 b := int8(12) // b 是 int8 6 7 f := 1.2345 // 默认Go语言中的小数都是64位 8 // float32 转float32 要进行强制类型转换，不能直接赋值 9 a := \u0026#39;啥\u0026#39; 10\tfmt.Printf(\u0026#34;%v\\n\u0026#34;,a) 11\tfmt.Printf(\u0026#34;%T\\n\u0026#34;,a) 12\tfmt.Printf(\u0026#34;%c\\n\u0026#34;,a) // 字符默认竟然是 int32 13} 2.3 常量 定义常量之后，在运行期间不会改变\nConst 可以放在全局的也可以放在局部的\n1const x,y int = 123, 0x22 2const s = \u0026#34;hello\u0026#34; 可以在函数代码中定义常量，不曾使用的常量不会引发编译错误\n常量值可以使某些编译器能计算出结果的表达式\n1import \u0026#34;unsafe\u0026#34; 2const{ 3 ptrSize = unsafe.Sizeof(uintptr(0)) 4 strSize = len(\u0026#34;hello, world\u0026#34;) 5} 批量声明\n1const( 2\ta = 1 3\tb 4\tc 5) 6// a,b,c 均为100 iota iota是go语言的常量计数器，只能在常量的表达式中使用。\niota在const关键字出现时将被重置为0。const中每新增一行常量声明将使iota计数一次(iota可理解为const语句块中的行索引)。 使用iota能简化定义，在定义枚举时很有用。\n举个例子：\n1const ( 2\tn1 = iota //0 3\tn2 //1 4\tn3 //2 5\tn4 //3 6\t) 几个常见的iota示例:\n使用_跳过某些值\n1const ( 2\tn1 = iota //0 3\tn2 //1 4\t_ 5\tn4 //3 6\t) iota声明中间插队\n1const ( 2\tn1 = iota //0 3\tn2 = 100 //100 4\tn3 = iota //2 5\tn4 //3 6\t) 7\tconst n5 = iota //0 定义数量级 （这里的\u0026lt;\u0026lt;表示左移操作，1\u0026lt;\u0026lt;10表示将1的二进制表示向左移10位，也就是由1变成了10000000000，也就是十进制的1024。同理2\u0026lt;\u0026lt;2表示将2的二进制表示向左移2位，也就是由10变成了1000，也就是十进制的8。）\n1const ( 2\t_ = iota 3\tKB = 1 \u0026lt;\u0026lt; (10 * iota) 4\tMB = 1 \u0026lt;\u0026lt; (10 * iota) 5\tGB = 1 \u0026lt;\u0026lt; (10 * iota) 6\tTB = 1 \u0026lt;\u0026lt; (10 * iota) 7\tPB = 1 \u0026lt;\u0026lt; (10 * iota) 8\t) 多个iota定义在一行\n1const ( 2\ta, b = iota + 1, iota + 2 //1,2 3\tc, d //2,3 4\te, f //3,4 5\t) 5 条评论\n枚举 1const ( 2\tx = iota // 0 3 y 4 z 5) 展开 1var x = 0x100 2const y = 0x200 3func main(){ 4 print(\u0026amp;x,x) 5 pront(\u0026amp;y, y ) // cannot take the address of y 6} 不同于变量在运行期分配存储内存(非优化状态)， 常量通常会被编译器在预处理阶段直接展开，作为指令数据使用。\n1const y = 0x200 2 3func main(){ 4 print(y) 5} 1go build \u0026amp;\u0026amp; go tool objdump -s \u0026#34;main./main\u0026#34; test 数字常量不会分配存储空间， 无须像变量那样通过内存寻址来取值，因此无法获取地址。\n鉴于Go当前对动态库的支持还不完善，是否存在\u0026quot;常量陷阱\u0026quot;的问题还有待观察\n2.4 基本类型 占位符 类型 %s 字符串 %b 二进制 %o 八进制 %d 十进制 %x 十六进制 %T 数据的类型 %.2f 浮点型数据 %v value 1package main 2 3import \u0026#34;fmt\u0026#34; 4 5// fmt占位符 6func main() { 7\tvar n = 100 8\t// 查看类型 9\tfmt.Printf(\u0026#34;%T\\n\u0026#34;, n) 10\tfmt.Printf(\u0026#34;%v\\n\u0026#34;, n) 11\tfmt.Printf(\u0026#34;%b\\n\u0026#34;, n) 12\tfmt.Printf(\u0026#34;%d\\n\u0026#34;, n) 13\tfmt.Printf(\u0026#34;%o\\n\u0026#34;, n) 14\tfmt.Printf(\u0026#34;%x\\n\u0026#34;, n) 15\tvar s = \u0026#34;Hello 沙河！\u0026#34; 16\tfmt.Printf(\u0026#34;字符串：%s\\n\u0026#34;, s) 17\tfmt.Printf(\u0026#34;字符串：%v\\n\u0026#34;, s) 18\tfmt.Printf(\u0026#34;字符串：%#v\\n\u0026#34;, s) 19} 八进制\u0026amp; 十六进制 Go语言中无法直接定义二进制数\n1package main 2 3import ( 4\t\u0026#34;fmt\u0026#34; 5\t\u0026#34;math\u0026#34; 6) 7 8func main() { 9\ta, b, c := 100, 0144, 0x64 10\tprintln(a, b, c) 11\tfmt.Println(a, b, c) 12\tfmt.Printf(\u0026#34;0b%b, %#o, %#x\\n\u0026#34;, a, b, c) 13 14\tfmt.Println(math.MinInt8, math.MaxInt8) 15} strconv\n1package main 2 3import \u0026#34;strconv\u0026#34; 4 5func main() { 6\ta, _ := strconv.ParseInt(\u0026#34;1100100\u0026#34;, 2, 32) 7\tb, _ := strconv.ParseInt(\u0026#34;0144\u0026#34;, 8, 32) 8\tc, _ := strconv.ParseInt(\u0026#34;64\u0026#34;, 16, 32) 9 10\tprintln(a, b, c) 11 12\tprintln(\u0026#34;0b\u0026#34; + strconv.FormatInt(a, 2)) 13\tprintln(\u0026#34;0\u0026#34; + strconv.FormatInt(b, 8)) 14\tprintln(\u0026#34;0x\u0026#34; + strconv.FormatInt(c, 16)) 15 16} 浮点型 Go语言支持两种浮点型数：float32和float64。这两种浮点型数据格式遵循IEEE 754标准： float32 的浮点数的最大范围约为 3.4e38，可以使用常量定义：math.MaxFloat32。 float64 的浮点数的最大范围约为 1.8e308，可以使用一个常量定义：math.MaxFloat64。\n打印浮点数时，可以使用fmt包配合动词%f，代码如下：\n1package main 2import ( 3 \u0026#34;fmt\u0026#34; 4 \u0026#34;math\u0026#34; 5) 6func main() { 7 fmt.Printf(\u0026#34;%f\\n\u0026#34;, math.Pi) 8 fmt.Printf(\u0026#34;%.2f\\n\u0026#34;, math.Pi) 9} 复数 complex64和complex128\n1var c1 complex64 2c1 = 1 + 2i 3var c2 complex128 4c2 = 2 + 3i 5fmt.Println(c1) 6fmt.Println(c2) 复数有实部和虚部，complex64的实部和虚部为32位，complex128的实部和虚部为64位。\n布尔值 Go语言中以bool类型进行声明布尔型数据，布尔型数据只有true（真）和false（假）两个值。\n注意：\n布尔类型变量的默认值为false。 Go 语言中不允许将整型强制转换为布尔型. 布尔型无法参与数值运算，也无法与其他类型进行转换。 字符串 Go语言中的字符串以原生数据类型出现，使用字符串就像使用其他原生数据类型（int、bool、float32、float64 等）一样。 Go 语言里的字符串的内部实现使用UTF-8编码。 字符串的值为双引号(\u0026quot;)中的内容，可以在Go语言的源码中直接添加非ASCII码字符，例如：\n1s1 := \u0026#34;hello\u0026#34; 2s2 := \u0026#34;你好\u0026#34; 字符串转义符 Go 语言的字符串常见转义符包含回车、换行、单双引号、制表符等，如下表所示。\n转义符 含义 \\r 回车符（返回行首） \\n 换行符（直接跳到下一行的同列位置） \\t 制表符 \\' 单引号 \\\u0026quot; 双引号 \\\\ 反斜杠 举个例子，我们要打印一个Windows平台下的一个文件路径：\n1package main 2import ( 3 \u0026#34;fmt\u0026#34; 4) 5func main() { 6 fmt.Println(\u0026#34;str := \\\u0026#34;c:\\\\Code\\\\lesson1\\\\go.exe\\\u0026#34;\u0026#34;) 7} 多行字符串 Go语言中要定义一个多行字符串时，就必须使用反引号字符：\n1s1 := `第一行 2第二行 3第三行 4` 5fmt.Println(s1) 反引号间换行将被作为字符串中的换行，但是所有的转义字符均无效，文本将会原样输出。\n字符串的常用操作 方法 介绍 len(str) 求长度 +或fmt.Sprintf 拼接字符串 strings.Split 分割 strings.contains 判断是否包含 strings.HasPrefix,strings.HasSuffix 前缀/后缀判断 strings.Index(),strings.LastIndex() 子串出现的位置 strings.Join(a[]string, sep string) join操作 1package main 2 3import ( 4\t\u0026#34;fmt\u0026#34; 5\t\u0026#34;strings\u0026#34; 6) 7 8// 字符串 9 10func main() { 11\t// \\ 本来是具有特殊含义的，我应该告诉程序我写的\\就是一个单纯的\\ 12\tpath := \u0026#34;\u0026#39;D:\\\\Go\\\\src\\\\code.oldboyedu.com\\\\studygo\\\\day01\u0026#39;\u0026#34; 13\tfmt.Println(path) 14 15\ts := \u0026#34;I\u0026#39;m ok\u0026#34; 16\tfmt.Println(s) 17\t// 多行的字符串 18\ts2 := ` 19世情薄 20\t人情恶 21\t雨送黄昏花易落 22\t` 23\tfmt.Println(s2) 24\ts3 := `D:\\Go\\src\\code.oldboyedu.com\\studygo\\day01` 25\tfmt.Println(s3) 26 27\t// 字符串相关操作 28\tfmt.Println(len(s3)) // ? 29 30\t// 字符串拼接 31\tname := \u0026#34;理想\u0026#34; 32\tworld := \u0026#34;大帅比\u0026#34; 33 34\tss := name + world 35\tfmt.Println(ss) 36\tss1 := fmt.Sprintf(\u0026#34;%s%s\u0026#34;, name, world) 37\t// fmt.Printf(\u0026#34;%s%s\u0026#34;, name, world) 38\tfmt.Println(ss1) 39\t// 分隔 40\tret := strings.Split(s3, \u0026#34;\\\\\u0026#34;) 41\tfmt.Println(ret) 42\t// 包含 43\tfmt.Println(strings.Contains(ss, \u0026#34;理性\u0026#34;)) 44\tfmt.Println(strings.Contains(ss, \u0026#34;理想\u0026#34;)) 45\t// 前缀 46\tfmt.Println(strings.HasPrefix(ss, \u0026#34;理想\u0026#34;)) 47\t// 后缀 48\tfmt.Println(strings.HasSuffix(ss, \u0026#34;理想\u0026#34;)) 49 50\ts4 := \u0026#34;abcdeb\u0026#34; 51\tfmt.Println(strings.Index(s4, \u0026#34;c\u0026#34;)) 52\tfmt.Println(strings.LastIndex(s4, \u0026#34;b\u0026#34;)) 53\t// 拼接 54\tfmt.Println(strings.Join(ret, \u0026#34;+\u0026#34;)) 55} 56 57/* 58\u0026#39;D:\\Go\\src\\code.oldboyedu.com\\studygo\\day01\u0026#39; 59I\u0026#39;m ok 60 61世情薄 62 人情恶 63 雨送黄昏花易落 64 65D:\\Go\\src\\code.oldboyedu.com\\studygo\\day01 6642 67理想大帅比 68理想大帅比 69[D: Go src code.oldboyedu.com studygo day01] 70false 71true 72true 73false 742 755 76D:+Go+src+code.oldboyedu.com+studygo+day01 77*/ 别名 在官方语言规范中专门提到两个别名\n1byte alias for unit8 2rune alias for int32 1package main 2 3import \u0026#34;fmt\u0026#34; 4 5// byte和rune类型 6 7// Go语言中为了处理非ASCII码类型的字符 定义了新的rune类型 8 9func main() { 10\ts := \u0026#34;Hello沙河사샤\u0026#34; 11\t// len()求得是byte字节的数量 12\tn := len(s) // 求字符串s的长度,把长度保存到变量n中 13\tfmt.Println(n) 14 15\t// for i := 0; i \u0026lt; len(s); i++ { 16\t// // fmt.Println(s[i]) 17\t// fmt.Printf(\u0026#34;%c\\n\u0026#34;, s[i]) // %c:字符 18\t// } 19 20\tfor _, c := range s { // 从字符串中拿出具体的字符 21\tfmt.Printf(\u0026#34;%c\\n\u0026#34;, c) // %c:字符 22\t} 23 24\t// \u0026#34;Hello\u0026#34; =\u0026gt; \u0026#39;H\u0026#39; \u0026#39;e\u0026#39; \u0026#39;l\u0026#39; \u0026#39;l\u0026#39; \u0026#39;o\u0026#39; 25\t// 字符串修改 26\ts2 := \u0026#34;白萝卜\u0026#34; // =\u0026gt; \u0026#39;白\u0026#39; \u0026#39;萝\u0026#39; \u0026#39;卜\u0026#39; 27\ts3 := []rune(s2) // 把字符串强制转换成了一个rune切片 28\ts3[0] = \u0026#39;红\u0026#39; 29\tfmt.Println(string(s3)) // 把rune切片强制转换成字符串 30 31\tc1 := \u0026#34;红\u0026#34; 32\tc2 := \u0026#39;红\u0026#39; // rune(int32) 33\tfmt.Printf(\u0026#34;c1:%T c2:%T\\n\u0026#34;, c1, c2) 34\tc3 := \u0026#34;H\u0026#34; // string 35\tc4 := byte(\u0026#39;H\u0026#39;) // byte(uint8) 36\tfmt.Printf(\u0026#34;c3:%T c4:%T\\n\u0026#34;, c3, c4) 37\tfmt.Printf(\u0026#34;%d\\n\u0026#34;, c4) 38 39\t// 类型转换 40\tn1 := 10 // int 41\tvar f float64 42\tf = float64(n1) 43\tfmt.Println(f) 44\tfmt.Printf(\u0026#34;%T\\n\u0026#34;, f) 45} 修改字符串 要修改字符串，需要先将其转换成[]rune或[]byte，完成后再转换为string。无论哪种转换，都会重新分配内存，并复制字节数组。\n1func changeString() { 2\ts1 := \u0026#34;big\u0026#34; 3\t// 强制类型转换 4\tbyteS1 := []byte(s1) 5\tbyteS1[0] = \u0026#39;p\u0026#39; 6\tfmt.Println(string(byteS1)) 7 8\ts2 := \u0026#34;白萝卜\u0026#34; 9\truneS2 := []rune(s2) 10\truneS2[0] = \u0026#39;红\u0026#39; 11\tfmt.Println(string(runeS2)) 12} 类型转换 Go语言中只有强制类型转换，没有隐式类型转换。该语法只能在两个类型之间支持相互转换的时候使用。\n强制类型转换的基本语法如下：\n1T(表达式) 其中，T表示要转换的类型。表达式包括变量、复杂算子和函数返回值等.\n比如计算直角三角形的斜边长时使用math包的Sqrt()函数，该函数接收的是float64类型的参数，而变量a和b都是int类型的，这个时候就需要将a和b强制类型转换为float64类型。\n1func sqrtDemo() { 2\tvar a, b = 3, 4 3\tvar c int 4\t// math.Sqrt()接收的参数是float64类型，需要强制转换 5\tc = int(math.Sqrt(float64(a*a + b*b))) 6\tfmt.Println(c) 7} 2.5 引用类型 ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/note_go/2_%E7%B1%BB%E5%9E%8B/","summary":"类型 2.1 变量 标识符与关键字 标识符 在编程语言中标识符就是程序员定义的具有特殊意义的词，比如变量名、常量名、函数名等等。 Go语言中标识符由字母数字和_(下划线）组成，并且只能以字母和_开头。 举几个例子：abc, _, _123, a123。\n关键字 关键字是指编程语言中预先定义好的具有特殊含义的标识符。 关键字和保留字都不建议用作变量名。\nGo语言中有25个关键字：\n1 break default func interface select 2 case defer go map struct 3 chan else goto package switch 4 const fallthrough if range type 5 continue for import return var 此外，Go语言中还有37个保留字。\n1 Constants: true false iota nil 2 3 Types: int int8 int16 int32 int64 4 uint uint8 uint16 uint32 uint64 uintptr 5 float32 float64 complex128 complex64 6 bool byte rune string error 7 8 Functions: make len cap new append copy close delete 9 complex real imag 10 panic recover go 语言中的变量必须先声明再使用。","tags":null,"title":""},{"categories":null,"contents":"流程控制 if\u0026hellip;else 1package main 2 3import \u0026#34;fmt\u0026#34; 4 5func main() { 6 var number int = 5 7\tif number += 4; 10 \u0026gt; number { 8\tnumber :=0 9\tnumber += 3 10\tfmt.Print(number) 11\t} else if 10 \u0026lt; number { 12\tnumber -= 2 13\tfmt.Print(number) 14\t} 15\tfmt.Println(number) 16} 17 18// 39 ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/note_go/3_%E6%B5%81%E7%A8%8B%E6%8E%A7%E5%88%B6/","summary":"流程控制 if\u0026hellip;else 1package main 2 3import \u0026#34;fmt\u0026#34; 4 5func main() { 6 var number int = 5 7\tif number += 4; 10 \u0026gt; number { 8\tnumber :=0 9\tnumber += 3 10\tfmt.Print(number) 11\t} else if 10 \u0026lt; number { 12\tnumber -= 2 13\tfmt.Print(number) 14\t} 15\tfmt.Println(number) 16} 17 18// 39 ","tags":null,"title":""},{"categories":null,"contents":"函数 现代计算机的进程执行模型大部分是基于“堆栈”的，编译器不需要对函数做过多的转换就能让其在栈上运行\n2.1 基本概念 2.1.1 函数定义 一个函数的定义包含如下几个部分： 函数声明关键字func、函数名、参数列表、返回列表和函数体。\n首字母的大小写决定该函数在其他包的可见：大写时其他包可见，小写时只有相同的包可以访问。\n函数可以没有输入参数、也可以没有返回值（默认返回0）\n1func A(){ 2} 3 4func B() int{ 5 return 1 6} 多个相同类型的参数可以使用简写模式\n1func add(a,b int) int{ // a int, b int 简写为 a,b int 2 return a+b 3} 支持有名的返回值，参数名相当于函数体最外层的局部变量，命名返回值变量会被初始化为类型零值最后的return可以不带参数名直接返回。\n1func add(a,b int) (sum int){ // sum 相当于函数内部的局部变量，被初始化为0 2 sum = a+b 3 return // return sum 的简写模式 4 5 // sum := a+b 6 // return sum // 需要显式的调用return sum 7} 不支持默认值参数？？\n不支持函数重载\n不支持函数嵌套，严格的说不支持命名函数的嵌套定义，但支持匿名函数\n1func add(a, b int) (sum int){ 2 anonymous := func(x,y int) int{ 3\treturn x+y 4 } 5 6 return anonymous(a,b) 7} 2.1.2 多值返回 定义多值返回的返回参数列表时候要使用“()”，支持命名参数的返回\n1func swap(a,b int) (int, int){ 2 return b,a 3} 习惯用法：\n如果多值返回有错误类型，则一般将错误类型作为最后一个返回值\n2.1.2 实参到形参的传递 Go 函数实参到形参的传递永远是值拷贝，有时候函数调用后，实参指向的值发生了变化，那是因为参数传递的是指针值的拷贝，实参是一个指针变量，传递给形参的是这个指针变量的副本，二者指向同一个地址，本质上参数传递仍然是值拷贝。\n1package main 2 3import \u0026#34;fmt\u0026#34; 4 5func chvalue(a int) int { // 实参传递给形参的是值拷贝 6\ta = a + 1 7\treturn a 8} 9 10func chpointer(a *int) { // 实参传递给形参的仍然是只拷贝，只不过复制的是a的地址 11\t*a = *a + 1 12\treturn 13} 14func main() { 15\ta := 10 16 17\tchvalue(a) 18\tfmt.Println(a) 19 20\tchpointer(\u0026amp;a) 21\tfmt.Println(a) 22} 2.1.4 不定参数 Go 函数支持不定数目的形式参数，不定参数声明使用param \u0026hellip;type的语法格式\n所有的不定参数类型必须是相同的\n不定参数必须是函数的最后一个参数\n不定参数名在函数体重相当于切片，对切片的操作同样适合不定参数的操作\n1func sum(arr ...int)(sum int){ 2 for _,v := range arr{ // 此时arr 就相当于切片，可以使用range访问 3 sum +=v 4 } 5 return 6} 切片可以作为参数传递给不定参数，切片名后面要加上“\u0026hellip;”\n1func sum(arr ...int) (sum int){ 2 for _,v := range arr{ 3 sum += v 4 } 5 return 6} 7 8func main(){ 9 slice :=[]{1,2,3,4} 10 array := [...]{1,2,3,4} 11 // 数组不可以作为实参传递给不定参数的函数 12 sum(slice...) 13} 注意 slice 和 array定义的区别\n形参为不定参数的函数和为切片的函数类型不相同\n1func suma(arr ...int)(sum int){ 2\tfor _,v := range arr{ 3\tsum +=v 4\t} 5\treturn 6} 7 8func sumb(arr [4]int) (sum int) { 9\tfor _,v := range arr{ 10\tsum +=v 11\t} 12\treturn 13} 14 15func main() { 16\tslice := []int{2,3,4,5} 17\tarray := [4]int{2,3,4,5} 18 19\tprintln(suma(slice...)) 20\tprintln(sumb(array)) 21} 22 23// suma 和sumb 不一样 2.2 函数签名和匿名函数 2.2.1 函数签名 函数类型又叫做函数签名，一个函数的类型就是函数定义首行去掉函数名，参数名和{，可以使用fmt.Printf的%T格式化参数打印函数的类型\n1func add(a,b int )(sum int){ 2\tsum = a +b 3\treturn sum 4} 5 6func main() { 7\tfmt.Printf(\u0026#34; func type is：%T\u0026#34;,add ) // func type is：func(int, int) int 8} 两个函数类型相同的条件是： 拥有相同的形参列表和返回值列表（列表元素的次序，个数和类型都相同），形参名可以不同。一下两个函数类型是完全一样的\n1func add(a,b int) int{ return a+b} 2func sub(x int, y int)(z int){z = x-y; return z} 可以使用type定义函数类型，函数类型变量可以作为函数的参数或返回值。\n1package main 2 3import \u0026#34;fmt\u0026#34; 4 5 6func add(a,b int )(sum int){ 7\tsum = a +b 8\treturn sum 9} 10 11func sub(a,b int) int { 12\treturn b-a 13} 14 15type Op func(int, int) int // 定义一个函数类型，输入是两个int，返回值是一个int类型 16 17 18func do(f Op, a,b int) int{ // 定义一个函数，第一个参数是函数类型Op 19\treturn f(a,b) // 函数类型变量可以直接用来进行函数调用 20} 21 22 23func main() { 24\ta := do(add, 1,2) 25\tfmt.Println(a) // 3 26 27\ts := do(sub, 1,2) // 1 28\tfmt.Println(s) 29} 函数类型和map、slice、chan一样，实际函数类型变量和函数名都可以当做指针变量，该指针指向函数代码的开始位置。通常说函数变量类型是一种引用类型，未初始化的函数类型的变量默认是nil。\nGo 中函数是“第一公民（first class）”。有名函数的函数名可以看作函数类型的常量，可以直接使用函数名调用函数。也可以直接赋值给函数类型变量，后续通过该变量来调用该函数。\n1func sum(a,b int) int{ 2 return a+b 3} 4func main(){ 5 sum(3,4) // 直接调用 6 f := sum // 有名函数可以直接赋值给变量 7 f(1,2) 8} 2.2.2 匿名函数 https://zhuanlan.zhihu.com/p/71829933\nhttps://eddycjy.com/posts/go/go1.16-3/\nhttps://segmentfault.com/a/1190000037679588\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/note_go/4_%E5%87%BD%E6%95%B0/","summary":"函数 现代计算机的进程执行模型大部分是基于“堆栈”的，编译器不需要对函数做过多的转换就能让其在栈上运行\n2.1 基本概念 2.1.1 函数定义 一个函数的定义包含如下几个部分： 函数声明关键字func、函数名、参数列表、返回列表和函数体。\n首字母的大小写决定该函数在其他包的可见：大写时其他包可见，小写时只有相同的包可以访问。\n函数可以没有输入参数、也可以没有返回值（默认返回0）\n1func A(){ 2} 3 4func B() int{ 5 return 1 6} 多个相同类型的参数可以使用简写模式\n1func add(a,b int) int{ // a int, b int 简写为 a,b int 2 return a+b 3} 支持有名的返回值，参数名相当于函数体最外层的局部变量，命名返回值变量会被初始化为类型零值最后的return可以不带参数名直接返回。\n1func add(a,b int) (sum int){ // sum 相当于函数内部的局部变量，被初始化为0 2 sum = a+b 3 return // return sum 的简写模式 4 5 // sum := a+b 6 // return sum // 需要显式的调用return sum 7} 不支持默认值参数？？","tags":null,"title":""},{"categories":null,"contents":"Go并发编程案例解析 nginx\ninfluxdb 时序数据库 Prometheus\nGrafana\n实例代码\nhttps://github.com/itsmikej/imooc_logprocess\n常见的并发模型 进程\u0026amp;线程 Apache C10K 服务器要同时支持10K的并发连接 异步非阻塞 （Nginx，Libevent， NodeJs）epoll 复杂度高 协程 GoLang， Erlang， Lua Golang并发实现 程序并发执行 goroutine 多个goroutine间的数据同步通信channels 多个channel选择数据读取或者写入select Goroutines Goroutines 程序并发执行\n1foo() // 执行函数foo, 程序等待函数foo返回 2go foo() // 执行函数foo 3bar（） // 不用等待foo返回 Channels Channels多个goroutine间的数据通信与同步\n1c := make(chan string) // 创建一个channel 2go func(){ 3 time.Sleep(1*time.Second) 4 c \u0026lt;- \u0026#34;message from closure\u0026#34; // 发送数据到channel 中 5}() 6 7msg:=\u0026lt;- c // 阻塞直到接收到数据 Select Select 从多个Channel 中读取或写入数据\n1select{ 2 case v:= \u0026lt;-c1: 3 fmt.Println(\u0026#34;channel 1 sends\u0026#34;,v) 4 case v:=\u0026lt;- c2: 5 fmt.Println(\u0026#34;channel 2 sends\u0026#34;) 6 default: // 可选 7 fmt.Println(\u0026#34;neither channel was ready\u0026#34;) 8} 并发与并行 Rob Pike Concurrency is not Parallelism\n并发： 指同一时刻，系统通过调度，来回切换交替运行的多个任务，“看起来”是同时运行 并行： 执行统一时刻，两个任务“真正的”同时运行 Concurrency： 单核CPU，逻辑上同时执行\nParallelism： 多核CPU，物理上同时执行\n![image-20191121193911320](/Users/airren/Library/Application Support/typora-user-images/image-20191121193911320.png)\n多个goroutine 并发执行\n将复杂的任务拆分，通过goroutine 去并发执行\n通过channel做数据通信\nGolang 中的面向对象 struct 类型 inteface 继承、封装、多态 封装 1type Foo struct{ 2 baz string 3} 4 5func (f *Foo) echo(){ // 接受者 成员函数 6 fmt.Println(f.baz) 7} 8 9func main(){ 10 f := Foo{baz: \u0026#34;hello, struct\u0026#34;} 11 f.echo() 12} 继承 1type Foo struct{ 2 baz string 3} 4 5type Bar struct{ 6 Foo 7} 8 9func (f *Foo) echo(){ // 接受者 成员函数 10 fmt.Println(f.baz) 11} 12 13func main(){ 14 b := Bar{Foo{baz: \u0026#34;hello, struct\u0026#34;}} 15 b.echo() 16} 多态 非侵入式的接口 duck 接口\n1type Foo interface{ 2 qux() 3} 4 5type Bar struct{} 6type Baz struct{} 7\t8func (b *Bar) qux(){} 9func (b *Baz) qux(){} 10 11func main(){ 12\tvar f Foo 13 f = Bar{} 14 f = Baz{} 15 fmt.Println(f) 16} 2. 日志监控程序的实现 LogProcess 读取模块实现 打开文件 从文件末尾开始逐行读取 写入read channel 解析模块的实现 提取数据中有价值的信息\n从Read Channel 中读取每行日志数据 正则提取所需的监控数据(path, status, method 等) 写入Write channel 写入模块的实现 初始化influxDB client 从write channel中读取监控数据 构造数据并写入influxDB InfluxDB 简介：\ninfluxdb是一个开源的时序型的数据库，使用Go语言编写，被广泛应用于存储系统的监控数据，IoT行业的试试数据等场景。有以下特性。\n部署简单，无外部依赖 内置http支持，使用http读写 类sql的灵活查询(max, min, sum 等) Influx db关键概念\ndatabase ： 数据库 measurement：数据库中的表 points： 表里面的一行数据 tags 各种有索引的属性 fields 各种记录的值 time 数据记录的时间戳， 也是自动生成的主索引 分析监控需求 某个协议下的某个请求在某个请求方法的 QPS\u0026amp; 响应时间\u0026amp; 流量\n**Tags：**Path 、Method、Scheme、Status Fields： UpstreamTime， RequestTime，ByteSent TIme： TimeLocal\n​\n5. 绘制监控图 6. 监控模块的实现 总处理日志的行数 系统吞吐量 read channel 长度 write channel 长度 运行总时间 错误数量 并发的基础知识\n并行和并发的区别\nGolang 面向对象\n并发编程的思路\n模块化编程\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/note_go/99_Go%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E6%A1%88%E4%BE%8B%E8%A7%A3%E6%9E%90/","summary":"Go并发编程案例解析 nginx\ninfluxdb 时序数据库 Prometheus\nGrafana\n实例代码\nhttps://github.com/itsmikej/imooc_logprocess\n常见的并发模型 进程\u0026amp;线程 Apache C10K 服务器要同时支持10K的并发连接 异步非阻塞 （Nginx，Libevent， NodeJs）epoll 复杂度高 协程 GoLang， Erlang， Lua Golang并发实现 程序并发执行 goroutine 多个goroutine间的数据同步通信channels 多个channel选择数据读取或者写入select Goroutines Goroutines 程序并发执行\n1foo() // 执行函数foo, 程序等待函数foo返回 2go foo() // 执行函数foo 3bar（） // 不用等待foo返回 Channels Channels多个goroutine间的数据通信与同步\n1c := make(chan string) // 创建一个channel 2go func(){ 3 time.Sleep(1*time.Second) 4 c \u0026lt;- \u0026#34;message from closure\u0026#34; // 发送数据到channel 中 5}() 6 7msg:=\u0026lt;- c // 阻塞直到接收到数据 Select Select 从多个Channel 中读取或写入数据","tags":null,"title":""},{"categories":null,"contents":"软件开发的新挑战\n多核硬件架构\n超大规模分布式计算集群\nweb模式下导致的前所未有的规模和更新速度\n区块链开发语言，\nKubernetes\nDocker\n只有25个关键字\n有垃圾回收机制，但是仍然可以直接使用指针访问内存\nCSP并发机制\n关键字\nc 37\nc++ 11 84\ngo 25\ngo 垃圾回收，使用指针直接内存访问.\n复合和继承\ndocker kubernetes\ngo 默认使用静态连接，编译完成是一个独立的二进制\n1package main // package name 2 3import \u0026#34;fmt\u0026#34; // dependence 4 5// functionality 6func main() { 7\tfmt.Print(\u0026#34;hello world \\n\u0026#34;) 8} 应用程序入口，\n必须是main包 package main 必须是main方法 func main() 文件名不一定是main.go package 的名字不需要与目录保持一致\n退出返回值\n与其他主要编程语言的差异\nGo main函数不支持任何返回值 通过os.Exit 来返回状态 1package main 2 3import ( 4\t\u0026#34;fmt\u0026#34; 5\t\u0026#34;os\u0026#34; 6) 7 8func main() { 9\tfmt.Print(\u0026#34;hello world \\n\u0026#34;) 10\tos.Exit(-1) 11} 获取命令行参数\nmain函数不支持传入参数\nfunc main(arg []string)\n在程序中直接通过os.Args 获取命令行参数\n获取的第一个参数是文件执行的相对路径，也就是文件名\n1package main 2 3import ( 4\t\u0026#34;fmt\u0026#34; 5\t\u0026#34;os\u0026#34; 6) 7 8func main() { 9\tif len(os.Args) \u0026gt; 1 { 10\tfmt.Println(\u0026#34;hello world\u0026#34;,os.Args[1]) 11\t} 12\tos.Exit(1) 13} The master has failed more time than the beginner has tried.\n编写测试程序\n源码文件以_test 结尾，xxx_test.go\n测试方法名以 Test 开头, func TestXXX( t *testing.T){\u0026hellip;}\n1package test 2 3import \u0026#34;testing\u0026#34; 4 5func TestFirstTry(t *testing.T ){ 6\tt.Log(\u0026#34;hello test\u0026#34;) 7} 变量赋值\n赋值可以自动类型推断 在一个赋值语句中，可以对多个变量同时赋值 1var a int = 1 2var b int = 2 3var ( 4\tc int = 1 5 // go 类型推断 6 d = 2 7 e := 3 8) 常量定义，快速的连续值的设置\n数据类型\n1bool 2string 3int int8 int16 int32 int64 4uint unit8 uint16 uint32 uint64 5byte # alias for uint8 6rune # alias for int32,represents a Unicode code point 7float32 float64 8complex64 complex128 类型转化\n不允许隐式类型转换 别名和原有类型也不能进行隐式类型转换 类型的预定义值\nmath.MaxInt64\nmath.MaxFloat64\nmath.MaxUint32\n指针类型\n不支持指针运算 string 是值类型，其默认初始化值为空字符串，而不是nil 算术运算符\n1+ - * / % 2++ 3-- 4# 没有前置的 ++ -- // ++a 比较运算符\n1== 2!= 3\u0026gt; \u0026lt; 4\u0026gt;= \u0026lt;= 用 == 比较数组\n相同维数，且含有相同个数元素的数组才可以比较 每个元素都相同时才相等（顺序） 长度不同的数组比较会有一个编译错误\n逻辑运算符\n1\u0026amp;\u0026amp; || ! 位运算符\n1\u0026amp; ! ^ 2\u0026lt;\u0026lt; \u0026gt;\u0026gt; 3 4\u0026amp;^ 按位置0 5 61 \u0026amp;^ 0 -- 1 # 右边的操作书为0，左边不变 71 \u0026amp;^ 1 -- 0 # 右边的操作数为1，左边则为0 80 \u0026amp;^ 1 -- 0 90 \u0026amp;^ 0 -- 0 循环\n仅支持循环关键字 for\n1for j:=7;j\u0026lt;n ;j++{ 2 3} 4 5for n\u0026lt; 5{ 6 n++ 7} 8 9for { 10 11} 条件\ncondition 表达式结果必须为bool值\n支持变量赋值\n1if var declaration; condition{ 2 3} 1if condition{ 2 3}else{ 4 5} 6 7if condition-1{ 8 9}else if condition-2{ 10 11}else{ 12 13} switch 条件\n条件不限制为常量或者整数 单个case中可以出现多个结果选项，使用逗号分隔 不需要用break用来推出当前case 可以不设置switch之后的条件表达式，在这种情况下，switch结构与多个if\u0026hellip;else 的逻辑作用相同。 1switch os := runtime.GOOS; os{ 2 case \u0026#34;darwin\u0026#34;: 3 fmt.Println(\u0026#34;Mac OS\u0026#34;) 4 // break 5 case \u0026#34;linux\u0026#34;: 6 fmt.Println(\u0026#34;Linux\u0026#34;) 7 default： 8 // freebsd, openbsd, plan9, windows.. 9 fmt.Printf(\u0026#34;%s\u0026#34;,os) 10} 11 12 13switch{ 14 case 0\u0026lt;=NUM \u0026amp;\u0026amp; NUM \u0026lt;=3: 15 fmt.Printf(\u0026#34;0-3\u0026#34;) 16 case 4 \u0026lt;=NUM \u0026amp;\u0026amp; NUM \u0026lt;= 6: 17 fmt.Printf(\u0026#34;4-6\u0026#34;) 18 case 7\u0026lt;=NUM \u0026amp;\u0026amp; NUM \u0026lt;= 9: 19 fmt.Printf(\u0026#34;7-9\u0026#34;) 20} 连续存储空间\n数组:\n1var a [3]int // 声明并初始化为默认零值 2a[0] = 1 3 4b := [3]int{1,2,3} // 声明并初始化 5c := [2][2]int{{1,2},{3,4}} // 多维数组 数组元素遍历\n1func TestArrayTravel(t *testing.T) { 2\tarr := [...]int{1, 2, 3, 4, 5} 3\tfor idx, i := range arr { 4\tt.Log(idx, i) 5\t} 6} 数组截取\na[开始索引(包含)，结束索引(不包含)], 左闭右开区间\n1a:= [...]int{1, 2, 3, 4, 5} 2a[1:2] // 2 3a[1:3] // 2,3 4a[1:len(1)] // 2,3,4,5 5a[1:] // 2,3,4,5 6a[:3] // 1,2,3 切片Slice\n切片内部结构，会造成大量GC\nhttps://gyazo.com/b4dd7a1f65dcab076fc41d9dfac95180\nprt -\u0026gt; Array 的地址\nlen 可以访问的元素个数，\ncap 内部数组的容量\n1var s0 []int 2s0 = append(s0, 1) 3 4s := []int 5s1 := []int{1,2,3} 6s2 := make([]int,2,4) 7/* []type,len,cap 8其中len个元素会被初始化为默认零值，未初始化元素不可访问 9*/ 切片共享存储结构\nhttps://gyazo.com/96049daf69a2855181cedd023fe396d8\n1024 以下是2的倍数，大于1024 约 1.25倍\n自增长的代价\n数组VS 切片\n容量是否可以伸缩\n是否可以进行比较\nslice 只能与nil 进行比较？？\nMap 声明\n1m := map[stirng]int{\u0026#34;one\u0026#34;:1,\u0026#34;two\u0026#34;:2,\u0026#34;three\u0026#34;:3} 2m1 := map[string]int 3m1[\u0026#34;one\u0026#34;] = 1 4m2 := make(ma) 5 6m2 := make(map[string]int, 10 ) 7// 10 initial capacity 8// 为什么不初始化len， 会出事化为默认零值，所以不需要 9// cap 无法计算map 容量。 len 可以计算map 数据长度 map 不存在的时候默认会零值，可能会有歧义\n在访问的key不存在的时候，仍会返回零值，不能通过nil来判断元素是否存在。\nmap 遍历， map 是否是有序的\nmap 与工厂模式， 实现set\n函数是一等公民\nmap的value也可能是一个方法 与go 的duck type 接口方式一起，可以方便的实现单一方法对象的工厂模式 实现Set\ngo 内置集合中没有set实现，可以map[type]struct{}\n元素的唯一性 基本操作 添加元素 判断元素是否存在 删除元素 元素个数 字符串\nunicode，utf8\nstring 是数据类型，不是引用或者指针类型 string是只读的byte slice， len函数可以计算所包含的byte数 string的byte数组可以存放任何数据， 不可见二进制编码 string 是一个不可变的 byte slice\nunicode UTF8\nUnicode 是一种字符集(code point) UTF8 是unicode的存储实现（转换为字节序列的规则） 字符 “中\u0026quot;\nUnicode 0x4E2D\nUTF-8 0xE4B8AD\nstring/[]byte [0xE4, 0xB8, 0xAD]\n常用字符串函数\nstrings\nstrconv\n函数 一等公民\n可以有多个返回值 所有的参数都是值传递， slice，map, channel 函数可以作为变量的值 函数可以作为参数的和返回值 类似于装饰器的demo， 重用\n《计算机程序的构造和解释》 函数式编程\n可变参数, 类型一直，无需指定参数的个数\n1func sum(ops ...int)int{ 2\ts := 0 3\tfor _,op := ops{ 4\ts +=op 5\t} 6 return s 7} defer 函数\n释放锁，或者关闭资源，避免资源的浪费\n封装数据和行为\n结构体定义\n1type Employee struct{ 2 Id string 3 Name string 4 Age int 5} 6 7e := Employee{\u0026#34;0\u0026#34;,\u0026#34;Bob\u0026#34;,20} 8e1 := Employee{Name:\u0026#34;Mike\u0026#34;,Age:20} 9e2 := new(Employee) // 注意，这里返回的是引用/指针, 相当于 e := \u0026amp;Employee{} 10e2.Id = \u0026#34;2\u0026#34; // 与其他编程语言的差异，通过实例的指针访问成员不需要 -\u0026gt; 11e2.Age = 22 12e2.Name = \u0026#34;Rose\u0026#34; 行为方法定义\n1// 第一中方式在实例对应的方法被调用时，实例的成员会进行值复制 2func(e Employee) String（） string{ 3 return fmt.Sprintf(\u0026#34;ID:%s-Name:%s-Age:%s\u0026#34;, e.Id,e.Name,e.Age) 4} 5 6// 通常情况下为了避免内存copy我们使用第二种方式 7func(e *Employee) String（） string{ 8 return fmt.Sprintf(\u0026#34;ID:%s-Name:%s-Age:%s\u0026#34;, e.Id,e.Name,e.Age) 9} Go语言的相关接口\n接口为非侵入性，实现不依赖与接口定义 所有接口的定义可以包含在接口使用者包内（解决循环依赖） interface 判断是否为nil\n自定义类型\n1type IntConvertionFn func(n int) int // 自定义函数类型 2type MyPoint int 扩展与服用\n复合vs继承\n不支持LSP 原则\n匿名嵌套类型\n无法重载父类的方法 多态\ninterface 对应的只能是一个struct的指针\n空interface\n空接口可以表示任何类型\n通过断言将空接口转换为定制类型\n1v,ok := p.(int) // ok=true 时转换成功 Go 接口最佳实现\nsingle method interface\n错误处理 没有异常机制，\nGO的错误机制\n没有异常机制 error 类型实现了error 接口 可以通过errors.New 来快速创建错误实例 1type error interface{ 2 Error() string 3} 4 5errors.New(\u0026#34;n must be in range[0,10]\u0026#34;) 有错误及早失败，避免嵌套\npackage\n基本复用的模块单元\n首字母大写表明可以被包外的代码访问\n代码的package 可以和所在的目录不一致\n同一目录里的Go代码的Package要保持一致\ninit\n在main被执行前，所有依赖的package的init方法都会被执行 不通包的init函数按照包导入的依赖关系决定执行顺序 每个包可以有多个init函数 包的每一个源文件也可以有多个init函数， go get -u \u0026lt; module name/ 源码的github 路径 \u0026gt;\ngo get -u 强制从网络更新远程依赖\npanic\n用于不可恢复的错误 推出前会执行defer的内容 os.Exit（） 退出时不会调用defer指定的函数\nos.Exit（） 退出时不会调用当前栈信息\nrecover\n1# java 2try{ 3}catch(Throwable t){} 4# c++ 5try{}catch(..){} 1defer func(){ 2 if err := recover(); err != nil{ 3 // 恢复错误 4 } 5}() 最常见的“错误恢复”\n1defer func(){ 2 if err:= recover(); err!= nil{ 3 log.Error(\u0026#34;recoverd panic\u0026#34;,err) 4 } 5}() 6// 当心recover成为恶魔 7// 形成僵尸服务进程，导致health check失效 8// \u0026#34;Let it creash\u0026#34; 往往是我们恢复不确定性错误的最好方法 9// 让守护进程重启服务 依赖管理\n同一环境下，不同项目使用同一包的不同版本？ 无法管理对包的特定版本的依赖？ vendor路径\n查找依赖包路径的顺序\n在当前包的vendor目录 向上级目录查找，直到找到src 下的vendor目录 在GOPATH下面查找依赖包 在GOROOT目录下查找 现在都用go mod\n协程机制\nThread VS Goutine\n创建时默认stack的大小 JDK5以后JAVA Thread Stack 默认为1M Goroutine 的Stack初始化大小为2k 和KSE(kernel space entity)的对应关系 Java Thread 是1：1 Goroutine 是M:N 线程切换 context的消耗高\n计数每个processer完成的数量\n如果系统进程在等待IO了，P会绑定其他的系统线程\n使用协程的时候注意闭包的参数传递\n共享内存和并发机制\nLock\n1Lock lock=...; 2lock.lock() 3try{ 4\t// process 5}catch(Exception ex){ 6 7}finally{ 8 lock.unlock 9} 1package sync 2mutex 3RWLock WaitGroup\nRWLock 读不是互斥的\nCSP (Communicating Sequential processes)并发控制\n无buffer 的等待（双方都在）\n多路选择和超时控制\n如果 retCh1 和retCH2 都ready的情况下，无法保证select的顺序。\n如果没有default会阻塞在select session上\n雪崩是比quick fail还要可怕的一种错误\nchannel 的关闭和广播\nchannel的关闭\n向关闭的channel发送数据，会导致panic\n接受关闭的通道的数据，接受到的是对应数据类型的零值，如果通道未关闭，且通道中没有数据，接受者会阻塞\nv,ok \u0026lt;- ch， ok 为bool值，true表示正常接受，false表示通道关闭\n所有channel接受者都会在channel关闭时，立刻从阻塞等待中返回，且上述ok值为false。这个广播机制常被利用，进行向多个订阅者同时发送信号。如，退出信号。\n无锁队列？？？\n多个receiver的情况下\n生产者在数据发送完成后可以关闭channel\n任务的取消（多消费者）\nContext 与任务取消\nContext\n根Context, 通过context.Background() 创建\n子Context: context.WithCancel(parentContext)\nctx, cancel := contxt.WithCancel(contxt.Background())\n当前context取消时候，基于他的子context 都会被取消。\n接收取消通知 \u0026lt;- ctx.Done// cancel()\n只运行一次\nsync.Once() 原理\n仅需任意任务完成\n所有任务完成\n对象池（数据库连接，网络连接）\n使用buffered channel实现对象池\n归还对象-\u0026gt; chan-\u0026gt; 获取对象\nsync pool 对象缓存\nsync.Pool 对象缓存？？ sync cache\nhttps://gyazo.com/f8aeaf38cd3069044685d33868e6a12d\nhttps://gyazo.com/c32c6b3b02cbafab85d59d26375f0e71\nhttps://gyazo.com/af2fbba4e5b940ad64a41a570639ca98\nsync.Pool 对象的生命周期\nGC会清除sync.Pool 缓存的对象 对象缓存的有效期为下次GC之前 只要没有put操作在私有对象池里面是没有的\nsync.Pool 总结\n锁带来的开销大，还是创建对象带来的开销大？ https://gyazo.com/efb267b39289b30347c7478581d26890 康威定律 DDD\n请求进来，向下扇出，并且call很多下游API\n单元测试\n1func Square(n int)int{ 2 return n*n 3} 4 5func TestSquate(t *testing.T){ 6 inputs:=[...]int{1,2,3} 7 expected:=[...]int{1,4,9} 8 for i:=0;i\u0026lt;len(inputs);i++{ 9 ret := Square(inputs[i]) 10 if ret != expected[i]{ 11 t.Error(\u0026#34;input is %d, the expected is %d, the actual %d\u0026#34;, 12 input[i],expected[i],ret) 13 } 14 } 15} 内置单元测试框架：\nFail，Error :该测试失败，该测试继续，其他测试继续执行 FailNow, Fatal: 该测试失败，该测试终止，其他测试继续执行 代码覆盖率\ngo test -v -cover\n断言 github.com/stretchr/testify\nBenchmark\nhttps://gyazo.com/aca94861bc4d40551e52e55d093947fa\nhttps://gyazo.com/b77c73ac12c5926f0a98c49eddd70e7f\n1go test -bench=. https://gyazo.com/f5f279536e4e069ed150839d395ee628\nBDD\nBehavior Driven Development\nhttps://gyazo.com/5d5ffb45da7404bb33ba185700767109\nhttps://gyazo.com/df785c94e5e02756c3dbe12c7fe71707\nhttps://gyazo.com/9a616c400ae7216c310fd4b19a11fae4\nhttps://gyazo.com/be028ad50b5833a27bb799a5683b7bd1\n反射编程\nreflect.TypeOf vs reflect.ValueOf\nreflect.TypeOf 返回值类型 reflect.Type\nreflect.ValueOf 返回值 reflect.Value\n可以从reflect.Value 获得类型\n可以通过kind判断类型\nhttps://gyazo.com/b93fce6a84469927612985a4cfac0e10\nhttps://gyazo.com/c427b98e181d3df67aab98d0f33f08c9\n1 2type Employee struct{ 3\tEmployeeId string 4\tName string `format:\u0026#34;normal\u0026#34;` 5\tAge int 6} 7func(e *Employee)UpdateAge(newVal int){ 8\te.Age = newVal 9} 10 11type Customer struct{ 12\tCookieId string 13\tName string 14\tAge int 15} 16 17func TestInvokeByName(t *testing.T){ 18\te :=\u0026amp;Employee{\u0026#34;1\u0026#34;,\u0026#34;Mike\u0026#34;,30} 19\t// 直接获取成员 20\tt.Logf(\u0026#34;Name: value(%[1]v),Type(%[1]T)\u0026#34;,reflect.ValueOf(*e).FieldByName(\u0026#34;Name\u0026#34;)) 21\t// 成员可能不存在 22\tif nameField,ok := reflect.TypeOf(*e).FieldByName(\u0026#34;Name\u0026#34;);!ok{ 23\tt.Error(\u0026#34;Failed to get \u0026#39;Name\u0026#39; field.\u0026#34;) 24\t}else{ 25\tt.Log(\u0026#34;Tag: format\u0026#34;,nameField.Tag.Get(\u0026#34;format\u0026#34;)) 26\t} 27\treflect.ValueOf(e).MethodByName(\u0026#34;UpdateAge\u0026#34;).Call([]reflect.Value{reflect.ValueOf(1)}) 28\tt.Log(\u0026#34;Updated Age:\u0026#34;e) 29} https://gyazo.com/b266dc5d61461672dfe210005190ae8b\n万能程序\nDeepEqual\n比较切片和Map\n1func TestDeepEqual(t *testing.T){ 2 a:= map[int]string{1:\u0026#34;one\u0026#34;,2:\u0026#34;two\u0026#34;,3:\u0026#34;three\u0026#34;} 3 b:= map[int]string{1:\u0026#34;one\u0026#34;,2:\u0026#34;two\u0026#34;,3:\u0026#34;three\u0026#34;} 4 t.Log(reflect.DeepEqual(a,b)) 5 6 s1 := []int{1,2,3} 7 s2 := []int{1,2,3} 8 s2 := []int{3,2,1} 9 t.Log(reflect.DeepEqual(s1,s2)) 10 t.Log(reflect.DeepEqual(s1,s3)) 11 12 c1 := Custumer{\u0026#34;1\u0026#34;,\u0026#34;Mike\u0026#34;,40} 13 c2 := Custumer{\u0026#34;1\u0026#34;,\u0026#34;Mike\u0026#34;,40} 14 t.Log(reflect.DeepEqual(c1,c2)) 15 16 17} https://gyazo.com/a10a1bcb995573dd695ab27d362ceca1\nhttps://gyazo.com/fc411a9bea3bba9c78f13bb9f47f57a8\nhttps://gyazo.com/ebd871ec44f80daf8b4d50d59fba0a9e\nhttps://gyazo.com/5a7666fe357f7a9576db005cd53eb745\nhttps://gyazo.com/a5b94370bac23e75094e495405c111f1\n关于反射你应该知道的\n提高了程序的灵活性，降低了程序的可读性，降低了程序的性能 不安全编程\nhttps://gyazo.com/917b71d73089020c708b31836cce58b2\nhttps://gyazo.com/f500624a5a03fa01e39bf2cf6f9f3e28\nhttps://gyazo.com/e63eb8f56624a55d773ca820c119b65d\nhttps://gyazo.com/2e992064b118159d0a58a656d017d380\nhttps://gyazo.com/9c90262305e5b81aa0005ff9bf16ca15\nhttps://gyazo.com/a3ca87532dab82e02ec360a144ad18b6\n架构模式\nhttps://gyazo.com/3d2dd605b897f106549c2939da35182e\nPipe-Filter 架构\nhttps://gyazo.com/ea75711a765ce8554e2854afb974658e\n非常适合数据处理以及数据分析系统\nFilter封装数据处理的功能\n松耦合： Filter只跟数据(格式)耦合\nPipe用于连接Filter传递数据，或者在异步处理过程中缓冲数据流，\n进程内同步调用时，pipe演变为数据在方法调用间传递\nhttps://gyazo.com/dfe390ab438b9758de391accd05fb082\nhttps://gyazo.com/eb5079cf5f82c333c83af1b90b69078a\nhttps://gyazo.com/674b755eeb2b3bd401d4e1afb79abb3e\n内置Json解析\nhttps://gyazo.com/62caf1d3ac52c3641583b05c91e651b3\neasyJson\n尽量少的使用反射\nhttps://gyazo.com/9d35fb4b70f7b028d9650d5481b0d297\nGo 程序设计语言\n面向模式的软件架构\n计算机程序的构造和解释\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/note_go/99_jike_go_note/","summary":"软件开发的新挑战\n多核硬件架构\n超大规模分布式计算集群\nweb模式下导致的前所未有的规模和更新速度\n区块链开发语言，\nKubernetes\nDocker\n只有25个关键字\n有垃圾回收机制，但是仍然可以直接使用指针访问内存\nCSP并发机制\n关键字\nc 37\nc++ 11 84\ngo 25\ngo 垃圾回收，使用指针直接内存访问.\n复合和继承\ndocker kubernetes\ngo 默认使用静态连接，编译完成是一个独立的二进制\n1package main // package name 2 3import \u0026#34;fmt\u0026#34; // dependence 4 5// functionality 6func main() { 7\tfmt.Print(\u0026#34;hello world \\n\u0026#34;) 8} 应用程序入口，\n必须是main包 package main 必须是main方法 func main() 文件名不一定是main.go package 的名字不需要与目录保持一致\n退出返回值\n与其他主要编程语言的差异\nGo main函数不支持任何返回值 通过os.Exit 来返回状态 1package main 2 3import ( 4\t\u0026#34;fmt\u0026#34; 5\t\u0026#34;os\u0026#34; 6) 7 8func main() { 9\tfmt.","tags":null,"title":""},{"categories":null,"contents":" 1package dal 2 3import \u0026#34;testing\u0026#34; 4 5func Empty() { 6\tstr := \u0026#34;12312\u0026#34; 7\tif str == \u0026#34;\u0026#34; { 8 9\t} 10} 11func Lenzero() { 12\tstr := \u0026#34;\u0026#34; 13\tif len(str) == 0 { 14 15\t} 16} 17func BenchmarkEmpty(b *testing.B) { 18\tfor n := 0; n \u0026lt; b.N; n++ { 19\tEmpty() 20\t} 21} 22 23func BenchmarkLenzero(b *testing.B) { 24\tfor n := 0; n \u0026lt; b.N; n++ { 25\tLenzero() 26\t} 27} ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/note_go/base/string_operate/","summary":"1package dal 2 3import \u0026#34;testing\u0026#34; 4 5func Empty() { 6\tstr := \u0026#34;12312\u0026#34; 7\tif str == \u0026#34;\u0026#34; { 8 9\t} 10} 11func Lenzero() { 12\tstr := \u0026#34;\u0026#34; 13\tif len(str) == 0 { 14 15\t} 16} 17func BenchmarkEmpty(b *testing.B) { 18\tfor n := 0; n \u0026lt; b.N; n++ { 19\tEmpty() 20\t} 21} 22 23func BenchmarkLenzero(b *testing.B) { 24\tfor n := 0; n \u0026lt; b.","tags":null,"title":""},{"categories":null,"contents":"零copy，\nclose wait and time wait. Tcp/IP\nhttps\ntcp 拥塞控制，粘包\nio, select, epoll\n红黑树\u0026amp;\nraft\n元空间中创建对象会不会用到物理内存\n无重复字符的最长子串 106 25. K 个一组翻转链表 84 206. 反转链表 83 215. 数组中的第K个最大元素 81 146. LRU缓存机制 https://www.zhihu.com/question/339135205\nGolang slice 可以动态扩容，但是如何动态缩容呢？\nGolang race\nHeap 和stack\nporm 技术栈test golang 教程\nhttps://www.kancloud.cn/mutouzhang/gocookbook/686698\nhttps://gobyexample.com/sha1-hashes\nhttp://c.biancheng.net/view/vip_7363.html\nprome 教程\nhttp://www.eryajf.net/2468.html\nhttps://ethancai.github.io/2016/06/23/bad-parts-about-json-serialization-in-Golang/\n123123123123\nhttps://www.robustperception.io/cardinality-is-key\nhttps://github.com/nusr/hacker-laws-zh\n编译原理\nhttps://segmentfault.com/a/1190000020239208\nraft\nGDPR 报警\ngrafql\nhttps://jobs.intel.com/ShowJob/Id/2891615/Cloud-Native-Runtime-Development-Engineer\nhttps://jobs.intel.com/ShowJob/Id/2829606/Software-Development-Engineer\nhttps://jobs.intel.com/ShowJob/Id/2891612/Edge-Software-Engineer\n*https://jobs.intel.com/ShowJob/Id/2891618/Cloud-Native-Software-Engineer\n主题更新维护 没有时间阅读，很难深度思考\n块存储\nBook Read 《Kubernetes网络权威指南》\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/Plan/","summary":"零copy，\nclose wait and time wait. Tcp/IP\nhttps\ntcp 拥塞控制，粘包\nio, select, epoll\n红黑树\u0026amp;\nraft\n元空间中创建对象会不会用到物理内存\n无重复字符的最长子串 106 25. K 个一组翻转链表 84 206. 反转链表 83 215. 数组中的第K个最大元素 81 146. LRU缓存机制 https://www.zhihu.com/question/339135205\nGolang slice 可以动态扩容，但是如何动态缩容呢？\nGolang race\nHeap 和stack\nporm 技术栈test golang 教程\nhttps://www.kancloud.cn/mutouzhang/gocookbook/686698\nhttps://gobyexample.com/sha1-hashes\nhttp://c.biancheng.net/view/vip_7363.html\nprome 教程\nhttp://www.eryajf.net/2468.html\nhttps://ethancai.github.io/2016/06/23/bad-parts-about-json-serialization-in-Golang/\n123123123123\nhttps://www.robustperception.io/cardinality-is-key\nhttps://github.com/nusr/hacker-laws-zh\n编译原理\nhttps://segmentfault.com/a/1190000020239208\nraft\nGDPR 报警\ngrafql\nhttps://jobs.intel.com/ShowJob/Id/2891615/Cloud-Native-Runtime-Development-Engineer\nhttps://jobs.intel.com/ShowJob/Id/2829606/Software-Development-Engineer\nhttps://jobs.intel.com/ShowJob/Id/2891612/Edge-Software-Engineer\n*https://jobs.intel.com/ShowJob/Id/2891618/Cloud-Native-Software-Engineer\n主题更新维护 没有时间阅读，很难深度思考\n块存储\nBook Read 《Kubernetes网络权威指南》","tags":null,"title":""},{"categories":null,"contents":"ESXI configuration and usage ESXI admin interface : https://10.239.241.100/\n1user: root passwd: CREshare- 跳板机CRE-relay\n1ssh cre@cre-relay.sh.intel.com # 10.239.241.116 2user: cre passwd: 123456 BIOS：123456/123123\nHow to create a VM with SGX and NIC direct mode 1.select a creation type 2.Select a name and guest OS 3.Select storage 4.Customize settings, CPU/Mem/Disk/SGX/PCI device, and select an OS image SGX enable Add a PCI device Select an OS Image 5.Start your machine and check the status ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/sdewan/CRE-Share/","summary":"ESXI configuration and usage ESXI admin interface : https://10.239.241.100/\n1user: root passwd: CREshare- 跳板机CRE-relay\n1ssh cre@cre-relay.sh.intel.com # 10.239.241.116 2user: cre passwd: 123456 BIOS：123456/123123\nHow to create a VM with SGX and NIC direct mode 1.select a creation type 2.Select a name and guest OS 3.Select storage 4.Customize settings, CPU/Mem/Disk/SGX/PCI device, and select an OS image SGX enable Add a PCI device Select an OS Image 5.Start your machine and check the status ","tags":null,"title":""},{"categories":null,"contents":"openwrt login 1curl -XPOST curl --location -v --request POST \u0026#39;https://10-233-76-144.default.pod.cluster.local/cgi-bin/luci/?luci_username=root\u0026amp;luci_password=root1\u0026#39; --cacert ./ca.pem 2 3 # Cert is the cnf-default-cert, must use the h 4curl --location -v --request POST \u0026#39;https://10-233-76-144.default.pod.cluster.local/cgi-bin/luci/\u0026#39; \\ 5--header \u0026#39;Content-Type: application/x-www-form-urlencoded\u0026#39; \\ 6--data-urlencode \u0026#39;luci_username=root\u0026#39; \\ 7--data-urlencode \u0026#39;luci_password=root1\u0026#39; \\ 8--cacert ./ca.pem Create CSR\n1curl -XGET \u0026#39;https://10-233-76-144.default.pod.cluster.local/cgi-bin/luci/sdewan/nat/v1/nats\u0026#39; --cacert ./ca.pem 1curl -XGET \u0026#39;https://10-233-76-144.default.pod.cluster.local/cgi-bin/luci/sdewan/pkcs11/v1/crs\u0026#39; --cacert ./ca.pem 1#!/bin/bash 2 3set -x 4 5cnf_ip=\u0026#34;10-233-76-144.default.pod.cluster.local\u0026#34; 6cert_label=\u0026#34;node-1\u0026#34; 7cert_subject=\u0026#34;/CN=node-1\u0026#34; 8 9# you alway a same csr, even you try many times 10curl --location --request POST \u0026#34;https://${cnf_ip}/cgi-bin/luci/sdewan/pkcs11/v1/crs\u0026#34; \\ 11--header \u0026#39;Content-Type: application/json\u0026#39; \\ 12--data-raw \u0026#34;{ 13 \\\u0026#34;cert\\\u0026#34;: { 14 \\\u0026#34;key_pair\\\u0026#34;: { 15 \\\u0026#34;key_type\\\u0026#34;: \\\u0026#34;rsa:2048\\\u0026#34;, 16 \\\u0026#34;label\\\u0026#34;: \\\u0026#34;${cert_label}\\\u0026#34;, 17 \\\u0026#34;id\\\u0026#34;: \\\u0026#34;0001\\\u0026#34; 18 }, 19 \\\u0026#34;subject\\\u0026#34;: \\\u0026#34;${cert_subject}\\\u0026#34;, 20 \\\u0026#34;pem\\\u0026#34;: \\\u0026#34;\\\u0026#34; 21 } 22}\u0026#34; --cert ca.pem | tee new.csr 23 24openssl x509 -req -days 365 -CA caCert.pem -CAkey caKey.pem -set_serial 1 -in new.csr -out client.crt 25 26cert=\u0026#34;-----BEGIN CERTIFICATE-----\\n$(cat client.crt|awk \u0026#34;NR\u0026gt;1{print $1}\u0026#34;|sed \u0026#39;$d\u0026#39;|tr -d \u0026#34;\\n\u0026#34;)\\n-----END CERTIFICATE-----\u0026#34; 27 28curl --location --request POST \u0026#34;https://${cnf_ip}/cgi-bin/luci/sdewan/pkcs11/v1/cert\u0026#34; \\ 29--header \u0026#39;Content-Type: application/json\u0026#39; \\ 30--data-raw \u0026#34;{ 31 \\\u0026#34;token\\\u0026#34;: { 32 \\\u0026#34;label\\\u0026#34;: \\\u0026#34;sdewan-sgx\\\u0026#34;, 33 \\\u0026#34;slot\\\u0026#34;: 0, 34 \\\u0026#34;so_pin\\\u0026#34;: \\\u0026#34;12345678\\\u0026#34;, 35 \\\u0026#34;pin\\\u0026#34;: \\\u0026#34;12345678\\\u0026#34; 36 }, 37 \\\u0026#34;cert\\\u0026#34;: { 38 \\\u0026#34;key_pair\\\u0026#34;: { 39 \\\u0026#34;key_type\\\u0026#34;: \\\u0026#34;rsa:2048\\\u0026#34;, 40 \\\u0026#34;label\\\u0026#34;: \\\u0026#34;node-1\\\u0026#34;, 41 \\\u0026#34;id\\\u0026#34;: \\\u0026#34;12345678\\\u0026#34; 42 }, 43 \\\u0026#34;subject\\\u0026#34;: \\\u0026#34;/CN=node-1\\\u0026#34;, 44 \\\u0026#34;pem\\\u0026#34;: \\\u0026#34;${cert}\\\u0026#34; 45 } 46}\u0026#34; 1pkcs11-tool --module /lib/x86_64-linux-gnu/pkcs11/p11-kit-client.so -L 2 2 pkcs11-tool --module /usr/local/lib/libp11sgx.so --login --pin 12345678 -O 3 3 pkcs11-tool --module /usr/local/lib/libp11sgx.so --login --pin 12345678 -b --type cert --label node-1 4 4 pkcs11-tool --module /usr/local/lib/libp11sgx.so -L 5 5 pkcs11-tool --module /usr/local/lib/libp11sgx.so --login --pin 12345678 -b --type cert --label node-1 --slot 0x7bfa3749 6 6 pkcs11-tool --module /usr/local/lib/libp11sgx.so -L 7 7 pkcs11-tool --module /usr/local/lib/libp11sgx.so --login --pin 12345678 -O 8 8 pkcs11-tool --module /usr/local/lib/libp11sgx.so --login --pin 12345678 -b --type cert --label node-1 --slot 0x7bfa3749 9 9 pkcs11-tool --module /usr/local/lib/libp11sgx.so --login --pin 12345678 -O 10 10 pkcs11-tool --module /usr/local/lib/libp11sgx.so --login --pin 12345678 -b --type cert --label node-1 --slot 0x7bfa3749 11 11 pkcs11-tool --module /usr/local/lib/libp11sgx.so --login --pin 12345678 -O 12 12 pkcs11-tool --help \u0026gt; help 13 13 vi help 14 14 apt update 15 15 apt install vim 16 16 ls 17 17 vi help 18 18 -O 19 19 pkcs11-tool --module /usr/local/lib/libp11sgx.so --login --pin 12345678 -O 20 20 pkcs11-tool --module /usr/local/lib/libp11sgx.so --login --pin 12345678 -b --type cert --label node-1 --slot 0x7bfa3749 21 21 pkcs11-tool --module /usr/local/lib/libp11sgx.so --login --pin 12345678 -O 22 22 pkcs11-tool --module /usr/local/lib/libp11sgx.so -L 23 23 pkcs11-tool --module /usr/local/lib/libp11sgx.so --login --pin 12345678 -O 24 24 pkcs11-tool --module /usr/local/lib/libp11sgx.so --login --pin 12345678 -b --type cert --label node-1 --token sdewan-sgx 25 25 pkcs11-tool --module /usr/local/lib/libp11sgx.so --login --pin 12345678 -O 26 26 pkcs11-tool --module /usr/local/lib/libp11sgx.so --login --pin 12345678 -b --type cert --label node-1 --token sdewan-sgx 27 28 29 30 certificatesigningrequests.certificates.k8s.io ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/sdewan/sdewan-cnf-test/","summary":"openwrt login 1curl -XPOST curl --location -v --request POST \u0026#39;https://10-233-76-144.default.pod.cluster.local/cgi-bin/luci/?luci_username=root\u0026amp;luci_password=root1\u0026#39; --cacert ./ca.pem 2 3 # Cert is the cnf-default-cert, must use the h 4curl --location -v --request POST \u0026#39;https://10-233-76-144.default.pod.cluster.local/cgi-bin/luci/\u0026#39; \\ 5--header \u0026#39;Content-Type: application/x-www-form-urlencoded\u0026#39; \\ 6--data-urlencode \u0026#39;luci_username=root\u0026#39; \\ 7--data-urlencode \u0026#39;luci_password=root1\u0026#39; \\ 8--cacert ./ca.pem Create CSR\n1curl -XGET \u0026#39;https://10-233-76-144.default.pod.cluster.local/cgi-bin/luci/sdewan/nat/v1/nats\u0026#39; --cacert ./ca.pem 1curl -XGET \u0026#39;https://10-233-76-144.default.pod.cluster.local/cgi-bin/luci/sdewan/pkcs11/v1/crs\u0026#39; --cacert ./ca.pem 1#!/bin/bash 2 3set -x 4 5cnf_ip=\u0026#34;10-233-76-144.default.pod.cluster.local\u0026#34; 6cert_label=\u0026#34;node-1\u0026#34; 7cert_subject=\u0026#34;/CN=node-1\u0026#34; 8 9# you alway a same csr, even you try many times 10curl --location --request POST \u0026#34;https://${cnf_ip}/cgi-bin/luci/sdewan/pkcs11/v1/crs\u0026#34; \\ 11--header \u0026#39;Content-Type: application/json\u0026#39; \\ 12--data-raw \u0026#34;{ 13 \\\u0026#34;cert\\\u0026#34;: { 14 \\\u0026#34;key_pair\\\u0026#34;: { 15 \\\u0026#34;key_type\\\u0026#34;: \\\u0026#34;rsa:2048\\\u0026#34;, 16 \\\u0026#34;label\\\u0026#34;: \\\u0026#34;${cert_label}\\\u0026#34;, 17 \\\u0026#34;id\\\u0026#34;: \\\u0026#34;0001\\\u0026#34; 18 }, 19 \\\u0026#34;subject\\\u0026#34;: \\\u0026#34;${cert_subject}\\\u0026#34;, 20 \\\u0026#34;pem\\\u0026#34;: \\\u0026#34;\\\u0026#34; 21 } 22}\u0026#34; --cert ca.","tags":null,"title":""},{"categories":null,"contents":"Leverage TEE to enhance the integrity and security of the SASE network\nSoftware-Define wide area network is one of the most essential components of the SASE architecture, which is based on network technologies that create virtualized WAN connections. SD-WAN decouples the network services from the underlying networks and allows the application traffic to be carried independently of the underlying network hardware, enabling the client\u0026rsquo;s connection anywhere to the applications. How to build up a strong shield for the overlay network of SD-WAN has become a hot issue in the industry. Most virtual private network (VPN) technology needs a certificate for authentication and cryptographic operations. The traditional hardware security module (HSM) is the best plugin for most VPN services to provide cryptographic functions., However, in the SASE scenario, most applications need the capability of scaling and dynamic migration capability, but the physical HSM is hard to meet.\nOur solution utilizes the Trusted Execution Environment (TEE) technology (e.g., Intel SGX) embedded in generic servers to build and cloud-native HSM service to provide extra defense against the attack by protecting the keys used during a handshake. We can achieve flexibility, performance, security, and cloud-scale network service by integrating inside the SD-WAN solution. In this presentation, we will demonstrate how we leverage the power of hardware TEE to protect the overlay network establishment and transportation.\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/sdewan/sdewan-proposal/","summary":"Leverage TEE to enhance the integrity and security of the SASE network\nSoftware-Define wide area network is one of the most essential components of the SASE architecture, which is based on network technologies that create virtualized WAN connections. SD-WAN decouples the network services from the underlying networks and allows the application traffic to be carried independently of the underlying network hardware, enabling the client\u0026rsquo;s connection anywhere to the applications. How to build up a strong shield for the overlay network of SD-WAN has become a hot issue in the industry.","tags":null,"title":""},{"categories":null,"contents":"Test Result Passed Case: Cluster k8s scc crd-controller cnf cert-manager overlay v1.17.0 old version latest version 0.5.1 v1.1.0 hub/edge-1/edge-2 v1.23.0 - latest version 0.5.1 v1.6.1 Failed Case: case1:\nCluster k8s scc crd-controller cnf cert-manager overlay v1.23.0 new version latest version 0.5.1 v1.6.1 hub/edge-1/edge-2 v1.23.0 - latest version 0.5.1 v1.6.1 case2:\nCluster k8s scc crd-controller cnf cert-manager overlay v1.23.0 new version latest version 0.5.0 v1.6.1 hub/edge-1/edge-2 v1.23.0 - latest version 0.5.0 v1.6.1 Bugs: CNF can\u0026rsquo;t auto load cacert \u0026ldquo;CN=overlay1-cert\u0026rdquo; from /etc/ipsec.d/cacerts/localtodevice*_ca.pem. If multiple cacerts in one file, Strongswan only can load the first cert through ipsec rereadall. Do not find the root cause, on in the Failed Case. If the Default NAT CR added the Iptables rule to CNF before the Data Plane Tunnel is established, it will add a wrong rule without an interface name. this bug also exist in Passed Case. DNS IP 10.248.2.5\nvi /etc/resolve.conf\n1sysctl net.ipv4.ip_forward xxxxxxxxxx udhcpc -i net1\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/sdewan/test-result/","summary":"Test Result Passed Case: Cluster k8s scc crd-controller cnf cert-manager overlay v1.17.0 old version latest version 0.5.1 v1.1.0 hub/edge-1/edge-2 v1.23.0 - latest version 0.5.1 v1.6.1 Failed Case: case1:\nCluster k8s scc crd-controller cnf cert-manager overlay v1.23.0 new version latest version 0.5.1 v1.6.1 hub/edge-1/edge-2 v1.23.0 - latest version 0.5.1 v1.6.1 case2:\nCluster k8s scc crd-controller cnf cert-manager overlay v1.23.0 new version latest version 0.5.0 v1.6.1 hub/edge-1/edge-2 v1.23.0 - latest version 0.5.0 v1.","tags":null,"title":""},{"categories":null,"contents":"RabbitMQ 消息中间件 技术精讲\n1. RabbitMQ 简介以及AMQP协议 RabbitMQ 是一个开源的消息代理和\nRabbitMQ底层是采用Erlang语言进行编写 开源、性能优秀， 稳定性保障 与spring AMQP完美整合，API丰富 集群模式丰富，表达式配置， HA模式， 镜像队列模型 保证数据不丢失的前提做到高可靠性，可用性 AMQP： 高级消息队列协议 RabbitMQ 的安装以及使用 erlang socat rabbitmq-server rpm -ivh XXXXX.rpm lsof -i:5672 # 查看端口 启用控制台插件 rabbit 可以选择使用内存进行存储\nRabbitMQ 核心概念 AMQP核心概念\nServer：又称作Broker， 接收客户端的连接，实现AMQP实体服务\nConnection： 连接， 应用程序与Broker的网络连接\nChannel： 网络信道，几乎所有的操作都在Channel中进行，Channel是进行消息读写的一个通道。客户端可以建立多个Channel，每个Channel代表一个会话任务。\nMessage： 消息， 服务器和应用程序之间传送的数据，由Properties和Body组成。Properties可以对消息进行修饰，比如消息的优先级、延迟等高级特性；Body则就是消息体内容。\nVirtual host： 虚拟地址，用于进行逻辑隔离，是最上层的消息路由。一个Virtual Host里面可以有若干个Exchange 和Queue， 同一个Virtual Host里面不能有相同名称的Exchange或Queue。\nExchange： 交换机，接收消息，根据路由键转发消息到绑定的队列\nBinding： Exchange 和Queue之间的虚拟连接，binding可以包含routing key\nRouting key: 一个路由规则，虚拟机可以用它来确定如何路由一个特定消息\nQueue： 也称为Massage Queue, 消息队列，保存消息并将他们转发给消费者\nRabbitMQ RabbitMQ默认端口号 4369 (epmd), 25672 (Erlang distribution) 4369 erlang 发现端口 25672 server间通信端口 5672, 5671 (AMQP 0-9-1 without and with TLS) client端通信口 15672 (if management plugin is enabled) 管理界面ui端口 61613, 61614 (if STOMP is enabled) 1883, 8883 (if MQTT is enabled) 生产端的可靠投递 保证消息从生产者到MQ之间的传输是100%可靠的，生产者发送的消息一定能进入消息队列\n保障消息成功发出， 如果中途由于网络或者其他原因导致发送失败，要保证消息不丢失，可以再次发送。 （如果消息发送成功，但是消费端对消息处理失败，也要考虑消息的重新处理，但不属于此范围） 保证MQ节点成功接收到消息 发送端要收到MQ节点(Broker)的确认应答 完善的消息进行补偿机制？？ 方案1： 消息落库，对消息状态进行打标 BIZ DB：订单数据库(或其他具体业务) \u0026ndash; 可以说是消息的Payload，具体的消息内容。 MSG DB：消息发送日志数据库 \u0026ndash; 存储消息的发送状态(发送中 0，已确认 1， Retry\u0026gt;max 之后设置为发送失败 2)，重试次数，发送时间等。\n第1步：将订单数据入库，之后创建一条MSG(状态为0) 入MSG DB库 第2步：将消息发送到MQ 第3步：监听消息应答(来自Broker) 第4步：修改消息的状态为1(成功)（只要有应答，MQ一定是收到了消息？消息是否根据exchange和routingKey放入了正确的队列，是否会有异常出现） 第5步：分布式定时任务抓取状态为0的消息 第6步：将状态为0的消息重发 第7步：如果尝试了3次(可按实际情况修改)以上则将状态置为2(消息投递失败状态)\nPS: 这种方案需要两次入库，在高并发的场景下性能不是很好。\n方案二： 消息延迟投递，做二次确认，回调检查 Upstream service：上游服务，可能为生产端 Downstream service：下游服务，可能为消费端 MQ Broker：MQ Callback service：回调服务，监听confirm消息\n第1步：首先业务数据落库，成功才后第一次消息发送 第2步：紧着着发送第2条消息（可以用于寻找第1条消息,消息的ID是唯一的），用于延迟(可能2,3分钟后才发送)消息投递检查 第3步：Broker端收到消息后，消费端进行消息处理 第4步：处理成功后，发送confirm消息（Callback service如何获得confirm信息\u0026gt;） 第5步：收到confirm消息后，将消息进行持久化存储 第6步：收到了delay消息，检查DB数据库，若对应的第1条消息已处理完成，则不做任何事情；若收到了delay消息，检查DB数据库，发现对应的第1条消息处理失败(或无记录)，则发送重传命令到上游服务，循环第1步。\n消息的幂等性\n执行某个操作，无论执行多少次，结果都是一致的就说具有幂等性。\n例如一条更新库存的SQL语句\n1update T_REPS set count=count-1, version=version-1 where version=1 第一步查出记录的version，第二步通过这个version信息进行其他字段的更新。这样无论这条SQL执行 多少次，所得到的的结果都是一致的，就保证了幂等性。\n如何避免重复消费\n消费端实现幂等性，然后永远都不会出现重复消费多次的情况，即使受到多条一样的消息\n消费幂等性 消费端实现幂等性的主流解决方案有以下两种：\n唯一ID +指纹码 机制\n利用Redis的原子性实现\n唯一ID +指纹码 机制 利用数据库主键去重 指纹码：可能是业务规则，时间戳+具体银行范围的唯一信息码，能保障这次操作的绝对唯一 比如select count(1) from T_ORDER where id = \u0026lt;唯一ID+指纹码\u0026gt; 将唯一ID+指纹码设成主键，如果上面SQL返回1，说明已经操作了，则不需要再次操作；否则才去执行操作 优点： 实现简单 缺点：高并发下有数据库写入的性能瓶颈（解决方案：通过ID进行分库分表进行算法路由）\n利用Redis的原子性实现 通过setnx等命令 SET 订单号 时间戳 过期时间\n1SET 1893505609317740 1466849127 EX 300 NX 利用Redis进行幂等，需要考虑的问题：\n如果要进行数据落库，关键解决的问题是数据库和缓存如何做到数据一致性。 如果不落库，那么都存在缓存中，如何设置定时同步的策略(同步是指将数据存储到数据库中，不落库指的是暂时不落库，不可能永远不落库)\n投递消息机制 Confirm确认消息 消息确认，是指生产者消息投递后，如果Broker收到消息，则会给生产者一个应答 生产者进行接收应答，用来确定这条消息是否正常的发送到Broker，这种方式也是消息的可靠性投递的核心保障 生产者发送消息与监听Confirm是异步的。(Nack是指接收超时吗?)\n1public class Producer { 2 3 public static void main(String[] args) throws IOException, TimeoutException, InterruptedException { 4 Connection connection = ConnectionUtil.getConn(); 5 //1. 通过connection创建一个Channel 6 Channel channel = connection.createChannel(); 7 //2.指定消息确认模式 8 channel.confirmSelect(); 9 String exchangeName = \u0026#34;test_confirm_exchange\u0026#34;; 10 String routingKey = \u0026#34;confirm.save\u0026#34;; 11 12 //3. 通过Channel发送数据 13 String message = \u0026#34;Hello from Producer\u0026#34;; 14 channel.basicPublish(exchangeName,routingKey,null,message.getBytes()); 15 16 //4. 添加一个确认监听 17 channel.addConfirmListener(new ConfirmListener() { 18 @Override 19 public void handleAck(long deliveryTag, boolean multiple) throws IOException { 20 //成功的情况 deliveryTag:消息的唯一标签； 21 System.out.println(\u0026#34;——get ack——\u0026#34;); 22 } 23 24 @Override 25 public void handleNack(long deliveryTag, boolean multiple) throws IOException { 26 //失败的情况 27 System.out.println(\u0026#34;——have no ack——\u0026#34;); 28 } 29 }); 30 31 // 关闭掉就没confirm了 32 // CloseTool.closeElegantly(channel,connection); 33 34 } 35} 1public class Consumer { 2 3 public static void main(String[] args) throws Exception { 4 Connection connection = ConnectionUtil.getConn(); 5 6 //1. 通过connection创建一个Channel 7 Channel channel = connection.createChannel(); 8 9 String exchangeName = \u0026#34;test_confirm_exchange\u0026#34;; 10 String routingKey = \u0026#34;confirm.save\u0026#34;; 11 String queueName = \u0026#34;test_confirm_queue\u0026#34;; 12 //2. 声明一个exchange 13 channel.exchangeDeclare(exchangeName,\u0026#34;topic\u0026#34;,true); 14 //3. 声明一个队列 15 channel.queueDeclare(queueName,true,false,false,null); 16 //4. 绑定 17 channel.queueBind(queueName,exchangeName,routingKey); 18 //5. 创建消费者 19 QueueingConsumer queueingConsumer = new QueueingConsumer(channel); 20 //6. 设置Channel 21 channel.basicConsume(queueName,true,queueingConsumer); 22 //7. 获取消息 23 while (true) { 24 //nextDelivery 会阻塞直到有消息过来 25 QueueingConsumer.Delivery delivery = queueingConsumer.nextDelivery(); 26 String message = new String(delivery.getBody()); 27 System.out.println(\u0026#34;收到:\u0026#34; + message); 28 } 29 } 30} return返回消息 Return Listener用于处理一些不可路由消息 生产者指定Exchange和RoutingKey，将消息投递到某个队列，然后消费者监听队列，进行消息处理 但在某些情况下，在发送消息时，若当前的exchange不存在或指定的路由key路由失败，这时，如果需要监听这种不可达的消息，则要使用return listener return 消息机制\n在基础API中有一个关键的配置项：\nMandatory : 若为true,则监听器会接收到路由不可达的消息，然后进行后粗处理 ；若为false，则broker端自动删除该消息\n发送端发送了一条消息，但是没有发现Exchange，则可通过return listener监听这些消息\n1public class Producer { 2 public static final String MQ_HOST = \u0026#34;192.168.222.101\u0026#34;; 3 public static final String MQ_VHOST = \u0026#34;/\u0026#34;; 4 public static final int MQ_PORT = 5672; 5 6 public static void main(String[] args) throws IOException, TimeoutException { 7 //1. 创建一个ConnectionFactory 8 ConnectionFactory connectionFactory = new ConnectionFactory(); 9 connectionFactory.setHost(MQ_HOST);//配置host 10 connectionFactory.setPort(MQ_PORT);//配置port 11 connectionFactory.setVirtualHost(MQ_VHOST);//配置vHost 12 13 //2. 通过连接工厂创建连接 14 Connection connection = connectionFactory.newConnection(); 15 //3. 通过connection创建一个Channel 16 Channel channel = connection.createChannel(); 17 String exchange = \u0026#34;test_return_exchange\u0026#34;; 18 String routingKey = \u0026#34;return.save\u0026#34;; 19 String routingKeyError = \u0026#34;abc.save\u0026#34;; 20 21 22 //4. 通过Channel发送数据 23 String message = \u0026#34;Hello Return Message\u0026#34;; 24 25 channel.addReturnListener((replyCode, replyText, exchange1, routingKey1, properties, body) -\u0026gt; { 26 System.out.println(\u0026#34;——handle return——\u0026#34;); 27 System.out.println(\u0026#34;replyCode:\u0026#34; + replyCode); 28 System.out.println(\u0026#34;replyText:\u0026#34; + replyText); 29 System.out.println(\u0026#34;exchange1:\u0026#34; + exchange1); 30 System.out.println(\u0026#34;routingKey1:\u0026#34; + routingKey1); 31 System.out.println(\u0026#34;properties:\u0026#34; + properties); 32 System.out.println(\u0026#34;body:\u0026#34; + new String(body)); 33 }); 34 35 //mandatory : true 36 //channel.basicPublish(exchange,routingKey,true,null,message.getBytes()); 37 channel.basicPublish(exchange,routingKeyError,true,null,message.getBytes()); 38 } 39} 1 2public class Consumer { 3 4 public static void main(String[] args) throws Exception { 5 Connection connection = ConnectionUtil.getConn(); 6 7 //1. 通过connection创建一个Channel 8 Channel channel = connection.createChannel(); 9 10 String exchange = \u0026#34;test_return_exchange\u0026#34;; 11 String routingKey = \u0026#34;return.#\u0026#34;; 12 String queueName = \u0026#34;test_return_queue\u0026#34;; 13 14 //2. 声明一个exchange 15 channel.exchangeDeclare(exchange,\u0026#34;topic\u0026#34;,true,false,null); 16 //3. 声明一个队列 17 channel.queueDeclare(queueName,true,false,false,null); 18 //4. 绑定 19 channel.queueBind(queueName,exchange,routingKey); 20 //5. 创建消费者 21 QueueingConsumer queueingConsumer = new QueueingConsumer(channel); 22 //6. 设置Channel 23 channel.basicConsume(queueName,true,queueingConsumer); 24 //7. 获取消息 25 while (true) { 26 //nextDelivery 会阻塞直到有消息过来 27 QueueingConsumer.Delivery delivery = queueingConsumer.nextDelivery(); 28 String message = new String(delivery.getBody()); 29 System.out.println(\u0026#34;收到:\u0026#34; + message); 30 } 31 32 33 } 34} 当生产端执行channel.basicPublish(exchange,routingKey,true,null,message.getBytes());消息能发送成功，也可以从消费端看到打印\n当执行channel.basicPublish(exchange,routingKeyError,true,null,message.getBytes());消息发送失败，因为路由失败了嘛，生产端能看到如下打印：\n1——handle return—— 2replyCode:312 3replyText:NO_ROUTE 4exchange1:test_return_exchange 5routingKey1:abc.save 6properties:#contentHeader\u0026lt;basic\u0026gt;(content-type=null, content-encoding=null, headers=null, delivery-mode=null, priority=null, correlation-id=null, reply-to=null, expiration=null, message-id=null, timestamp=null, type=null, user-id=null, app-id=null, cluster-id=null) 7body:Hello Return Message 若生产端将mandatory设为false,则ReturnListener不会进行回调\n保障100% 的消息可靠性投递方案落地实现 ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/tips/RabbitMQ/","summary":"RabbitMQ 消息中间件 技术精讲\n1. RabbitMQ 简介以及AMQP协议 RabbitMQ 是一个开源的消息代理和\nRabbitMQ底层是采用Erlang语言进行编写 开源、性能优秀， 稳定性保障 与spring AMQP完美整合，API丰富 集群模式丰富，表达式配置， HA模式， 镜像队列模型 保证数据不丢失的前提做到高可靠性，可用性 AMQP： 高级消息队列协议 RabbitMQ 的安装以及使用 erlang socat rabbitmq-server rpm -ivh XXXXX.rpm lsof -i:5672 # 查看端口 启用控制台插件 rabbit 可以选择使用内存进行存储\nRabbitMQ 核心概念 AMQP核心概念\nServer：又称作Broker， 接收客户端的连接，实现AMQP实体服务\nConnection： 连接， 应用程序与Broker的网络连接\nChannel： 网络信道，几乎所有的操作都在Channel中进行，Channel是进行消息读写的一个通道。客户端可以建立多个Channel，每个Channel代表一个会话任务。\nMessage： 消息， 服务器和应用程序之间传送的数据，由Properties和Body组成。Properties可以对消息进行修饰，比如消息的优先级、延迟等高级特性；Body则就是消息体内容。\nVirtual host： 虚拟地址，用于进行逻辑隔离，是最上层的消息路由。一个Virtual Host里面可以有若干个Exchange 和Queue， 同一个Virtual Host里面不能有相同名称的Exchange或Queue。\nExchange： 交换机，接收消息，根据路由键转发消息到绑定的队列\nBinding： Exchange 和Queue之间的虚拟连接，binding可以包含routing key\nRouting key: 一个路由规则，虚拟机可以用它来确定如何路由一个特定消息\nQueue： 也称为Massage Queue, 消息队列，保存消息并将他们转发给消费者\nRabbitMQ RabbitMQ默认端口号 4369 (epmd), 25672 (Erlang distribution) 4369 erlang 发现端口 25672 server间通信端口 5672, 5671 (AMQP 0-9-1 without and with TLS) client端通信口 15672 (if management plugin is enabled) 管理界面ui端口 61613, 61614 (if STOMP is enabled) 1883, 8883 (if MQTT is enabled) 生产端的可靠投递 保证消息从生产者到MQ之间的传输是100%可靠的，生产者发送的消息一定能进入消息队列","tags":null,"title":""},{"categories":null,"contents":"Distributed System Engineering parallelism\nFault tolerance\nPhysical\nSecurity /isolated\nChallenges:\nconcurrency\nPartial failure\nPerformance\nLab\nMapReduce Raft for fault tolerrance K/V server Sharding K/V servers Infrastructure\nstorage Communication Computation Abstraction\nImplementation\nRPC, Thread，Concurrency Performance\nscalability , scabale to speed 2 x computer = 2X throughput Fault Tolerance\nAvailability Recoverability NV (non-volatile)storage /Replication Topic - Consistency\nPut (key, value) Get(key) -\u0026gt; value Map Reduce What is distributed system? multiple cooperating computers storage for big web sites, MapReduce, peer-to-peer sharing, \u0026amp;c lots of critical infrastructure is distributed Why do people build distributed system? to increase capacity via parallelism to tolerate faults via replication to place computing physically close to external entities to achieve security via isolation But:\nmany concurrent parts, complex interactions must cope with partial failure tricky to realize performance potential Why take this course ?\ninteresting \u0026ndash; hard problem, powerful solutions used by real system \u0026ndash; driven by rise of big web sites. active research area \u0026ndash; important unsolved problems hands-on \u0026ndash; you\u0026rsquo;ll build real system in the labs Lab https://pdos.csail.mit.edu/6.824/labs/lab-mr.html\nReference:\nhttps://chunlife.top/2020/04/18/The-Google-File-System%E4%B8%AD%E6%96%87%E7%89%88/\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/6.824/LEC_1_Introduction/","summary":"Distributed System Engineering parallelism\nFault tolerance\nPhysical\nSecurity /isolated\nChallenges:\nconcurrency\nPartial failure\nPerformance\nLab\nMapReduce Raft for fault tolerrance K/V server Sharding K/V servers Infrastructure\nstorage Communication Computation Abstraction\nImplementation\nRPC, Thread，Concurrency Performance\nscalability , scabale to speed 2 x computer = 2X throughput Fault Tolerance\nAvailability Recoverability NV (non-volatile)storage /Replication Topic - Consistency\nPut (key, value) Get(key) -\u0026gt; value Map Reduce What is distributed system? multiple cooperating computers storage for big web sites, MapReduce, peer-to-peer sharing, \u0026amp;c lots of critical infrastructure is distributed Why do people build distributed system?","tags":null,"title":"「6.824」 Lecture 1 Introduction"},{"categories":null,"contents":"","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/6.824/MapReduce/","summary":"","tags":null,"title":"「6.824」 MapReduce"},{"categories":null,"contents":" 什么是consul Consul是用来做什么的 服务如何注册到Consul，以及如何进行服务发现 Consul部署 基于docker部署\nnode consul-server server consul-1 client consul-2 client 1docker run -d -p 8500:8500 -e CONSUL_BIND_INTERFACE=eth0 --name consul-server consul:1.9.4 2docker run -d -e CONSUL_BIND_INTERFACE=eth0 --name consul-1 consul:1.9.4 agent -dev -join=172.17.0.13 3docker run -d -e CONSUL_BIND_INTERFACE=eth0 --name consul-2 consul:1.9.4 agent -dev -join=172.17.0.13 4 5# docker stop consul-server consul-1 consul-2 6# docker rm consul-server consul-1 consul-2 Tips： 查看consul-server ip\n1 docker exec -t consul-server ifconfig 可以通过8500端口访问UI\nServer:\nClient:\nClient 只与Server交互。\nPort：\nPost Desc 8300 consul agent服务 relplaction 、rpc（client-server） 8301 lan gossip 8302 wan gossip 8500 http api端口 8600 DNS服务端口 服务注册 服务自己调用http API注册 1curl -X PUT -d \u0026#39;{\u0026#34;Datacenter\u0026#34;: \u0026#34;sz-1\u0026#34;, \u0026#34;Node\u0026#34;: \u0026#34;mysql-1\u0026#34;, \u0026#34;Address\u0026#34;: \\ 2\u0026#34;mysql-1.node.consul\u0026#34;,\u0026#34;Service\u0026#34;: {\u0026#34;Service\u0026#34;: \u0026#34;mysql\u0026#34;, \u0026#34;tags\u0026#34;: [\u0026#34;master\u0026#34;,\u0026#34;v1\u0026#34;], \\ 3\u0026#34;Port\u0026#34;: 3306}}\u0026#39; http://127.0.0.1:8500/v1/catalog/register json配置文件注册 启动时候指定配置文件路径-config-dir /etc/consul.d/\n1{ 2 \u0026#34;service\u0026#34;:{ 3 \u0026#34;name\u0026#34;:\u0026#34;alertmanager\u0026#34;, 4 \u0026#34;tags\u0026#34;:[ 5 \u0026#34;prom\u0026#34; 6 ], 7 \u0026#34;port\u0026#34;:9093, 8 \u0026#34;check\u0026#34;:{ 9 \u0026#34;name\u0026#34;:\u0026#34;ping\u0026#34;, 10 \u0026#34;args\u0026#34;:[\u0026#34;curl -s 10.227.4.115:9093\u0026#34;], 11 \u0026#34;interval\u0026#34;:\u0026#34;3s\u0026#34; 12 } 13 } 14} 服务发现 HttpAPI 通过服务名字“alertmanager”获取服务的IP和Port\nDNS 8600 使用dns查询，默认域名格式NAME.service.consul，NAME就是web.json里面定义的service的name。可以自己指定域和端口：-domain、-dns-port 53\nConsul Consul的主要作用是用于服务治理。\n在分布式场景下，服务会部署多个实例。传统的基于API直连的调用方式，在服务挂掉或者连接信息被修改之后就会导致API调用失败。如果调用方不用去关注所调用服务的实际部署情况，只要知道所调用服务的名称。其他实际部署情况，负载均衡、健康检查由一个统一的平台去做。这个就是Consul的作用。\nConsul分为Server Agent和Client Agent。\nServer：consul的server模式，表明这个consul是个server，这种模式下，功能和CLIENT都一样，唯一不同的是，它会把所有的信息持久化的本地，这样遇到故障，信息是可以被保留的。服务端, 保存配置信息, 高可用集群, 在局域网内与本地客户端通讯, 通过广域网与其他数据中心通讯. 每个数据中心的 server 数量推荐为 3 个或是 5 个。存储服务信息\nServer-Leader：\n个SERVER下面有LEADER的字眼，表明这个SERVER是它们的老大，它和其它SERVER不一样的一点是，它需要负责同步注册的信息给其它的SERVER，同时也要负责各个节点的健康监测。\nClient： 客户端, 无状态, 将 HTTP 和 DNS 接口请求转发给局域网内的服务端集群。注册到当前节点的信息都会转发给Server, 本身不持久化信息。\nConsul使用gossip协议管理成员关系、广播消息到整个集群，他有两个gossip pool（LAN pool和WAN pool），LAN pool是同一个数据中心内部通信的，WAN pool是多个数据中心通信的，LAN pool有多个，WAN pool只有一个。\n服务发现 http \u0026amp; DNS\nconsul支持两种方式实现服务发现，一种是通过http API来查询有哪些服务，另外一种是通过consul agent 自带的DNS（8600端口），域名是以NAME.service.consul的形式给出，NAME即在定义的服务配置文件中，服务的名称。DNS方式可以通过check的方式检查服务。\n服务配置 consul支持两种方式实现服务注册，一种是通过consul的服务注册http API，由服务自己调用API实现注册，另一种方式是通过json个是的配置文件实现注册，将需要注册的服务以json格式的配置文件给出。consul官方建议使用第二种方式。\n健康检查 键值存储 安全服务通信 多数据中心 类似的服务组件有Eureka，zookeeper，etcd\n一致性协议采用Raft算法\ntodo\nDig 参考文档 https://blog.csdn.net/a312586670/article/details/105337943/\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/component/MicroService/Consul/","summary":"什么是consul Consul是用来做什么的 服务如何注册到Consul，以及如何进行服务发现 Consul部署 基于docker部署\nnode consul-server server consul-1 client consul-2 client 1docker run -d -p 8500:8500 -e CONSUL_BIND_INTERFACE=eth0 --name consul-server consul:1.9.4 2docker run -d -e CONSUL_BIND_INTERFACE=eth0 --name consul-1 consul:1.9.4 agent -dev -join=172.17.0.13 3docker run -d -e CONSUL_BIND_INTERFACE=eth0 --name consul-2 consul:1.9.4 agent -dev -join=172.17.0.13 4 5# docker stop consul-server consul-1 consul-2 6# docker rm consul-server consul-1 consul-2 Tips： 查看consul-server ip\n1 docker exec -t consul-server ifconfig 可以通过8500端口访问UI\nServer:\nClient:","tags":null,"title":"「Consul」Consul"},{"categories":null,"contents":"TaskList 最短路径算法\n最小生成树\n深度优先遍历、广度优先遍历\nKMP算法\nLRU\n哈弗曼树\ngo知识学习 参考这个文档，完整的学习一边go\nhttps://draveness.me/golang/docs/part3-runtime/ch06-concurrency/golang-context/\ncontext 春招目标\n依图\nPDD\n字节跳动\n浦发\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/interview/daily/TaskList/","summary":"TaskList 最短路径算法\n最小生成树\n深度优先遍历、广度优先遍历\nKMP算法\nLRU\n哈弗曼树\ngo知识学习 参考这个文档，完整的学习一边go\nhttps://draveness.me/golang/docs/part3-runtime/ch06-concurrency/golang-context/\ncontext 春招目标\n依图\nPDD\n字节跳动\n浦发","tags":null,"title":"「Daily」TaskList"},{"categories":null,"contents":"centos 安装docker 把yum包更新到最新\n1yum update 安装需要的软件包\n1yum install -y yum-utils device-mapper-persistent-data lvm2 设置yum源\n1yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo 查看所有仓库中所有docker版本，并选择特定版本安装\n1yum list docker-ce --showduplicates | sort -r 2 3[root@MiWiFi-R3-srv ~]# yum list docker-ce --showduplicates | sort -r 4 * updates: mirrors.aliyun.com 5Loading mirror speeds from cached hostfile 6Loaded plugins: fastestmirror 7Installed Packages 8 * extras: mirrors.aliyun.com 9docker-ce.x86_64 3:18.09.0-3.el7 docker-ce-stable 10docker-ce.x86_64 18.06.1.ce-3.el7 docker-ce-stable 11docker-ce.x86_64 18.06.1.ce-3.el7 @docker-ce-stable 12docker-ce.x86_64 18.06.0.ce-3.el7 docker-ce-stable 13docker-ce.x86_64 18.03.1.ce-1.el7.centos docker-ce-stable 14docker-ce.x86_64 18.03.0.ce-1.el7.centos docker-ce-stable 15...... 安装Docker，命令：yum install docker-ce-版本号，我选的是18.06.1.ce-3.el7，如下\n1yum install docker-ce-18.06.1.ce-3.el7 启动Docker，命令：systemctl start docker，然后加入开机启动，如下\n1systemctl start docker 2systemctl enable docker 验证是否安装成功 docker version\n1[root@MiWiFi-R3-srv ~]# docker version 2Client: 3 Version: 18.06.1-ce 4 API version: 1.38 5 Go version: go1.10.3 6 Git commit: e68fc7a 7 Built: Tue Aug 21 17:23:03 2018 8 OS/Arch: linux/amd64 9 Experimental: false 10 11Server: 12 Engine: 13 Version: 18.06.1-ce 14 API version: 1.38 (minimum version 1.12) 15 Go version: go1.10.3 16 Git commit: e68fc7a 17 Built: Tue Aug 21 17:25:29 2018 18 OS/Arch: linux/amd64 19 Experimental: false 使用Docker 中国加速器 由于网络原因，我们在pull Image 的时候，从Docker Hub上下载会很慢。\n修改文件\n1vi /etc/docker/daemon.json 2#添加后： 3{ 4 \u0026#34;registry-mirrors\u0026#34;: [\u0026#34;https://registry.docker-cn.com\u0026#34;], 5 \u0026#34;registry-mirrors\u0026#34;: [\u0026#34;https://ustc-edu-cn.mirror.aliyuncs.com\u0026#34;], 6 7 \u0026#34;live-restore\u0026#34;: true 8} 重起docker服务\n1systemctl daemon-reload \u0026amp;\u0026amp; systemctl restart docker 进入容器Shell 1docker exec -it \u0026lt;continer\u0026gt; /bin/bash # or sh 2docker exec -it --user root \u0026lt;container id\u0026gt; /bin/bash # root 用户进入 -u root 修改容器中的文件 方法1：进入容器，使用vim修改\n方法2：docker cp\n1 # 将文件从容器中copy 到本地 2 docker cp fbaf54e9940a:/opt/cerebro/conf ./ 3 # 使用本地编辑器修改后，copy回容器中 4 docker cp application.conf fbaf54e9940a:/opt/cerebro/conf 方法3：运行容器时使用本地的文件\n1# 冒号前是本地路径（需要绝对路径），冒号后是容器中的路径 2docker run -itd -p 8080:80 -v /etc/nginx/nginx.conf:/etc/nginx/nginx.conf --name=webtest nginx:latest 安装docker Debain 1# 查看docker状态，并尝试启动. 2$ systemctl status docker 3$ /usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock 4$ echo \u0026#39;\u0026#39; \u0026gt; /etc/modprobe.d/nf-blacklist.conf 5$ systemctl status docker.service 6 7# 如果出现 8# failed to load listeners: no sockets found via socket activation: make sure the service was started by systemd 9$ systemctl daemon-reload 10$ service docker restart 11$ service docker status 12 13# 或者将 /etc/docker/daemon.json 置为空{} docker image 导出 1# 导出image 2docker save -o new_file.tar mysql:8.0.2 3 4# 通过tar包载入image, --input -i 指定导入的文件 5docker load --input new_file.tar docker神器 runlike\n批量删除已经exit 的容器 https://www.cnblogs.com/brady-wang/p/10500597.html\n容器自动重启 1docker update --restart=always [container ID] fix Exited(139) https://github.com/docker/for-linux/issues/58\nIn case someone stumbles on this closed issue, here\u0026rsquo;s quick howto: Description: centos:6 docker image fails to start, no output given. Workaround: append vsyscall=emulate to line GRUB_CMDLINE_LINUX_DEFAULT in your /etc/default/grub. E.g.\n1GRUB_CMDLINE_LINUX_DEFAULT=\u0026#34;consoleblank=0 systemd.show_status=true elevator=noop console=tty1 console=ttyS0 vsyscall=emulate\u0026#34; then update grub update-grub and reboot host machine reboot\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/cloudnative/Docker/dock_tips/","summary":"centos 安装docker 把yum包更新到最新\n1yum update 安装需要的软件包\n1yum install -y yum-utils device-mapper-persistent-data lvm2 设置yum源\n1yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo 查看所有仓库中所有docker版本，并选择特定版本安装\n1yum list docker-ce --showduplicates | sort -r 2 3[root@MiWiFi-R3-srv ~]# yum list docker-ce --showduplicates | sort -r 4 * updates: mirrors.aliyun.com 5Loading mirror speeds from cached hostfile 6Loaded plugins: fastestmirror 7Installed Packages 8 * extras: mirrors.aliyun.com 9docker-ce.x86_64 3:18.09.0-3.el7 docker-ce-stable 10docker-ce.x86_64 18.06.1.ce-3.el7 docker-ce-stable 11docker-ce.x86_64 18.06.1.ce-3.el7 @docker-ce-stable 12docker-ce.x86_64 18.06.0.ce-3.el7 docker-ce-stable 13docker-ce.x86_64 18.03.1.ce-1.el7.centos docker-ce-stable 14docker-ce.x86_64 18.03.0.ce-1.el7.centos docker-ce-stable 15.","tags":null,"title":"「Docker」 Docker 常用命令"},{"categories":null,"contents":"docker run创建容器时候，可以用-net指定容器的网络模式\n1# host 模式 2--net=host 3# container模式 4--net=container:NameorId 5# none模式 6-net=none 7# bridge模式 8-net=bridge host 模式\n如果启动容器的时候使用 host 模式，那么这个容器将不会获得一个独立的 Network Namespace，而是和宿主机共用一个 Network Namespace。容器将不会虚拟出自己的网卡，配置自己的 IP 等，而是使用宿主机的 IP 和端口。\n例如，我们在 10.10.101.105/24 的机器上用 host 模式启动一个含有 web 应用的 Docker 容器，监听 tcp 80 端口。当我们在容器中执行任何类似 ifconfig 命令查看网络环境时，看到的都是宿主机上的信息。而外界访问容器中的应用，则直接使用 10.10.101.105:80 即可，不用任何 NAT 转换，就如直接跑在宿主机中一样。但是，容器的其他方面，如文件系统、进程列表等还是和宿主机隔离的。\ncontainer 模式 这个模式指定新创建的容器和已经存在的一个容器共享一个 Network Namespace，而不是和宿主机共享。新创建的容器不会创建自己的网卡，配置自己的 IP，而是和一个指定的容器共享 IP、端口范围等。同样，两个容器除了网络方面，其他的如文件系统、进程列表等还是隔离的。两个容器的进程可以通过 lo 网卡设备通信。\nnone模式 这个模式和前两个不同。在这种模式下，Docker 容器拥有自己的 Network Namespace，但是，并不为 Docker容器进行任何网络配置。也就是说，这个 Docker 容器没有网卡、IP、路由等信息。需要我们自己为 Docker 容器添加网卡、配置 IP 等。\nbridge模式 bridge 模式是 Docker 默认的网络设置，此模式会为每一个容器分配 Network Namespace、设置 IP 等，并将一个主机上的 Docker 容器连接到一个虚拟网桥上。当 Docker server 启动时，会在主机上创建一个名为 docker0 的虚拟网桥，此主机上启动的 Docker 容器会连接到这个虚拟网桥上。虚拟网桥的工作方式和物理交换机类似，这样主机上的所有容器就通过交换机连在了一个二层网络中。接下来就要为容器分配 IP 了，Docker 会从 RFC1918 所定义的私有 IP 网段中，选择一个和宿主机不同的IP地址和子网分配给 docker0，连接到 docker0 的容器就从这个子网中选择一个未占用的 IP 使用。如一般 Docker 会使用 172.17.0.0/16 这个网段，并将 172.17.42.1/16 分配给 docker0 网桥（在主机上使用 ifconfig 命令是可以看到 docker0 的，可以认为它是网桥的管理接口，在宿主机上作为一块虚拟网卡使用）\n参考文档\nhttps://www.huaweicloud.com/articles/5bb8f4efe7aaca9d4332750d73876db8.html\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/cloudnative/Docker/docker_net/","summary":"docker run创建容器时候，可以用-net指定容器的网络模式\n1# host 模式 2--net=host 3# container模式 4--net=container:NameorId 5# none模式 6-net=none 7# bridge模式 8-net=bridge host 模式\n如果启动容器的时候使用 host 模式，那么这个容器将不会获得一个独立的 Network Namespace，而是和宿主机共用一个 Network Namespace。容器将不会虚拟出自己的网卡，配置自己的 IP 等，而是使用宿主机的 IP 和端口。\n例如，我们在 10.10.101.105/24 的机器上用 host 模式启动一个含有 web 应用的 Docker 容器，监听 tcp 80 端口。当我们在容器中执行任何类似 ifconfig 命令查看网络环境时，看到的都是宿主机上的信息。而外界访问容器中的应用，则直接使用 10.10.101.105:80 即可，不用任何 NAT 转换，就如直接跑在宿主机中一样。但是，容器的其他方面，如文件系统、进程列表等还是和宿主机隔离的。\ncontainer 模式 这个模式指定新创建的容器和已经存在的一个容器共享一个 Network Namespace，而不是和宿主机共享。新创建的容器不会创建自己的网卡，配置自己的 IP，而是和一个指定的容器共享 IP、端口范围等。同样，两个容器除了网络方面，其他的如文件系统、进程列表等还是隔离的。两个容器的进程可以通过 lo 网卡设备通信。\nnone模式 这个模式和前两个不同。在这种模式下，Docker 容器拥有自己的 Network Namespace，但是，并不为 Docker容器进行任何网络配置。也就是说，这个 Docker 容器没有网卡、IP、路由等信息。需要我们自己为 Docker 容器添加网卡、配置 IP 等。\nbridge模式 bridge 模式是 Docker 默认的网络设置，此模式会为每一个容器分配 Network Namespace、设置 IP 等，并将一个主机上的 Docker 容器连接到一个虚拟网桥上。当 Docker server 启动时，会在主机上创建一个名为 docker0 的虚拟网桥，此主机上启动的 Docker 容器会连接到这个虚拟网桥上。虚拟网桥的工作方式和物理交换机类似，这样主机上的所有容器就通过交换机连在了一个二层网络中。接下来就要为容器分配 IP 了，Docker 会从 RFC1918 所定义的私有 IP 网段中，选择一个和宿主机不同的IP地址和子网分配给 docker0，连接到 docker0 的容器就从这个子网中选择一个未占用的 IP 使用。如一般 Docker 会使用 172.","tags":null,"title":"「Docker」Docker 网络模式"},{"categories":null,"contents":"复用http.request.body\nhttps://studygolang.com/articles/15641?fr=sideba\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/note_go/5.4ioutil/","summary":"复用http.request.body\nhttps://studygolang.com/articles/15641?fr=sideba","tags":null,"title":"「Go」ioutil"},{"categories":null,"contents":"pprof\n可以用于分析程序的性能，并找到瓶颈点。\n程序中的 runtime/pprof 性能剖析工具 go tool pprof ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/note_go/performance_analysis/pprof/","summary":"pprof\n可以用于分析程序的性能，并找到瓶颈点。\n程序中的 runtime/pprof 性能剖析工具 go tool pprof ","tags":null,"title":"「Go」pprof 性能分析"},{"categories":null,"contents":"匿名struct比较\n1func main() { 2\tsn1 := struct { 3\tage int 4\tname string 5\t}{age: 11, name: \u0026#34;qq\u0026#34;} 6 7\tsn2 := struct { 8\tage int 9\tname string 10\t}{age: 11, name: \u0026#34;qq\u0026#34;} 11 12\tif sn1 == sn2 { 13\tfmt.Println(\u0026#34;sn1 == sn2\u0026#34;,sn1) 14\t} 15 16\tfmt.Printf(\u0026#34;sn1 addr %p\\n\u0026#34;,\u0026amp;sn1) 17\tfmt.Printf(\u0026#34;sn2 addr %p\\n\u0026#34;,\u0026amp;sn2) 18} 1sn1 == sn2 {11 qq} 2sn1 addr 0xc0000a6020 3sn2 addr 0xc0000a6040 ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/note_go/5.5Struct/","summary":"匿名struct比较\n1func main() { 2\tsn1 := struct { 3\tage int 4\tname string 5\t}{age: 11, name: \u0026#34;qq\u0026#34;} 6 7\tsn2 := struct { 8\tage int 9\tname string 10\t}{age: 11, name: \u0026#34;qq\u0026#34;} 11 12\tif sn1 == sn2 { 13\tfmt.Println(\u0026#34;sn1 == sn2\u0026#34;,sn1) 14\t} 15 16\tfmt.Printf(\u0026#34;sn1 addr %p\\n\u0026#34;,\u0026amp;sn1) 17\tfmt.Printf(\u0026#34;sn2 addr %p\\n\u0026#34;,\u0026amp;sn2) 18} 1sn1 == sn2 {11 qq} 2sn1 addr 0xc0000a6020 3sn2 addr 0xc0000a6040 ","tags":null,"title":"「Go」Struct"},{"categories":null,"contents":" 重点剖析Go运行时的内部机制，深入了解Go运行期状态，规避GC潜在的问题，节约内存，提升运行性能\n环境 Mac环境\n(不建议使用，会有很多困扰，直接用Linux)\nDebian环境 编译好的可执行文件真正的执行入口并不在main.go的mian()函数中。编译器总会插入一段引导代码，完成命令行参数、运行时初始化等工作才会进入用户逻辑。\n编译\u0026amp;GDB调试 main.go\n1package main 2 3func main() { 4\tprintln(\u0026#34;hello world\u0026#34;) 5} -gcflags \u0026ldquo;-N -l\u0026rdquo; 关闭编译器代码优化和函数内联，避免断点和单步执行无法准确对应源码行，避免小函数和局部变量被优化掉\n1go build -gcflags \u0026#34;-N -l\u0026#34; 2# go build -gcflags \u0026#34;-N -l\u0026#34; -o test main.go 通过info files可以找到程序真正的入口地址0x105a8c0 ,利用断点命令可以找到目标源文件信息。\nMac 下breakpoint 并未显示对应的文件信息，以下所有的操作均在Debian中查看。\n不同的操作系统就使用不同的汇编文件\n下面这这个汇编文件完成了初始化和运行时的启动动作。\n调用初始化函数 创建main goroutine用于执行runtime.main 让当前线程开始执行main goroutine 至此，汇编语言针对特定平台的引导过程全部完成，后续的内容基本上都是由Go代码实现的。\ngo的汇编\nGo ASM 和标准的汇编语法（ NASM 或 YASM ）不太一样，首先你会发现它是架构独立的，没有所谓的 32 或 64 位寄存器，如下图所示：\nTips:Mac 配置gdb环境 GDB Installation on Mac OS X\n​\t在macOS上，用于debug的工具有lldb和gdb. 其中lldb作为一种可复用的组件，参与了大型llvm项目库的构成；同时，lldb也是Xcode默认的调试工具, 支持Windows, macOS, iOS, Linux和FreeBSD. 而gdb是GNU项目的调试器，支持Windows和大多数UNIX变种，也包括macOS.\n1brew install gdb 配置证书签名\nKeyChain Access 新建一个系统证书, 指定Name为gdb_cert, Identity Type为Self Signed Root，Certificate Type 为Code Signing。 一直continue，Keychain为System。完成后设置为Always Trust。 新建一个叫做gdb-entitlement.xml的文件\n1\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; 2\u0026lt;!DOCTYPE plist PUBLIC \u0026#34;-//Apple//DTD PLIST 1.0//EN\u0026#34; \u0026#34;http://www.apple.com/DTDs/PropertyList-1.0.dtd\u0026#34;\u0026gt; 3\u0026lt;plist version=\u0026#34;1.0\u0026#34;\u0026gt; 4\u0026lt;dict\u0026gt; 5 \u0026lt;key\u0026gt;com.apple.security.cs.debugger\u0026lt;/key\u0026gt; 6 \u0026lt;true/\u0026gt; 7\u0026lt;/dict\u0026gt; 8\u0026lt;/plist\u0026gt; 执行\n1codesign --entitlements gdb-entitlement.xml -fs gdb_cert \u0026#34;${which gdb}\u0026#34; 2# 解决卡死问题 3echo \u0026#34;set startup-with-shell off\u0026#34; \u0026gt;\u0026gt; ~/.gdbinit ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/note_go/source_code_profiling/mem_allocation/mem_allocation/","summary":"重点剖析Go运行时的内部机制，深入了解Go运行期状态，规避GC潜在的问题，节约内存，提升运行性能\n环境 Mac环境\n(不建议使用，会有很多困扰，直接用Linux)\nDebian环境 编译好的可执行文件真正的执行入口并不在main.go的mian()函数中。编译器总会插入一段引导代码，完成命令行参数、运行时初始化等工作才会进入用户逻辑。\n编译\u0026amp;GDB调试 main.go\n1package main 2 3func main() { 4\tprintln(\u0026#34;hello world\u0026#34;) 5} -gcflags \u0026ldquo;-N -l\u0026rdquo; 关闭编译器代码优化和函数内联，避免断点和单步执行无法准确对应源码行，避免小函数和局部变量被优化掉\n1go build -gcflags \u0026#34;-N -l\u0026#34; 2# go build -gcflags \u0026#34;-N -l\u0026#34; -o test main.go 通过info files可以找到程序真正的入口地址0x105a8c0 ,利用断点命令可以找到目标源文件信息。\nMac 下breakpoint 并未显示对应的文件信息，以下所有的操作均在Debian中查看。\n不同的操作系统就使用不同的汇编文件\n下面这这个汇编文件完成了初始化和运行时的启动动作。\n调用初始化函数 创建main goroutine用于执行runtime.main 让当前线程开始执行main goroutine 至此，汇编语言针对特定平台的引导过程全部完成，后续的内容基本上都是由Go代码实现的。\ngo的汇编\nGo ASM 和标准的汇编语法（ NASM 或 YASM ）不太一样，首先你会发现它是架构独立的，没有所谓的 32 或 64 位寄存器，如下图所示：\nTips:Mac 配置gdb环境 GDB Installation on Mac OS X","tags":null,"title":"「Go」内存分配"},{"categories":null,"contents":"堆内存与栈内存\nGo程序会在两个地方为变量分配内存，一个是全局的堆空间用来动态分配内存，另一个是每个goroutine的栈空间。与Java、Python等语言类似，Go语言实现垃圾回收机制，所以Go语言的内存管理是自动的，通常开发者不用关心内存分配到栈上还是堆上。但是从性能的角度出发，在栈上和堆上分配内存，性能差异是非常大的。\n在函数中申请一个对象，，如果分配在栈中，函数执行结束时自动回收；如果分配在堆中，则在函数结束后某个时间点进行垃圾回收。\n在栈上分配和回收内存的开销很低，只需要2个cpu指令: PUSH和POP。一个是将数据push到栈空间以完成分配，pop则是释放空间。也就是说在栈上分配内存，消耗的仅是将数据copy到内存的时间。内存的I/O通常能达到30GB/s，因此在栈上分配内存的效率是非常高的。\n在堆上分配内存，一个很大的额外开销则是垃圾回收。Go语言使用的是标记清除算法，并且在此基础上使用了三色标记法和写屏障技术，提高了效率。\n参考资料：\nhttps://geektutu.com/post/hpg-escape-analysis.html\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/note_go/compile_optimize/escape_analysis/","summary":"堆内存与栈内存\nGo程序会在两个地方为变量分配内存，一个是全局的堆空间用来动态分配内存，另一个是每个goroutine的栈空间。与Java、Python等语言类似，Go语言实现垃圾回收机制，所以Go语言的内存管理是自动的，通常开发者不用关心内存分配到栈上还是堆上。但是从性能的角度出发，在栈上和堆上分配内存，性能差异是非常大的。\n在函数中申请一个对象，，如果分配在栈中，函数执行结束时自动回收；如果分配在堆中，则在函数结束后某个时间点进行垃圾回收。\n在栈上分配和回收内存的开销很低，只需要2个cpu指令: PUSH和POP。一个是将数据push到栈空间以完成分配，pop则是释放空间。也就是说在栈上分配内存，消耗的仅是将数据copy到内存的时间。内存的I/O通常能达到30GB/s，因此在栈上分配内存的效率是非常高的。\n在堆上分配内存，一个很大的额外开销则是垃圾回收。Go语言使用的是标记清除算法，并且在此基础上使用了三色标记法和写屏障技术，提高了效率。\n参考资料：\nhttps://geektutu.com/post/hpg-escape-analysis.html","tags":null,"title":"「Go」逃逸分析"},{"categories":null,"contents":"Grafana监控面板 安装\n1docker run -d --name=grafana -p 3000:3000 grafana/grafana ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/component/TimeSeries/install_grafana/","summary":"Grafana监控面板 安装\n1docker run -d --name=grafana -p 3000:3000 grafana/grafana ","tags":null,"title":"「Grafana」安装使用Grafana"},{"categories":null,"contents":"冥王峡谷可以使用HacMini实现傻瓜化的完美黑苹果，目前已经完美支持Big Sur 11.1。只需额外买一个无线网卡，既可以实现WiFi、蓝牙、Airdrop和HandOff的完美使用。\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/life/nuc_perfect_hacintosh/","summary":"冥王峡谷可以使用HacMini实现傻瓜化的完美黑苹果，目前已经完美支持Big Sur 11.1。只需额外买一个无线网卡，既可以实现WiFi、蓝牙、Airdrop和HandOff的完美使用。","tags":null,"title":"「Hackintosh」冥王峡谷 完美黑苹果"},{"categories":null,"contents":"hugo 增加 评论\n编译\u0026amp;发布\nMarkDown 语法 公式解析\n引入MathJax。MathJax 是一个Javascript库，通过官方提供的CDN集成到自己的页面非常简单，只需把一下内容添加到所有的页面，例如foot.html\n1\u0026lt;script type=\u0026#34;text/javascript\u0026#34; async 2 src=\u0026#34;https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML\u0026#34;\u0026gt; 3\u0026lt;/script\u0026gt; 配置文件 config.toml 代码高亮设置\n1pygmentsUseClasses = true 2[markup] 3 [markup.highlight] 4 codeFences = true 5 guessSyntax = true 6 hl_Lines = \u0026#34;\u0026#34; 7 lineNoStart = 1 # display line number 8 lineNos = true 9 lineNumbersInTable = false 10 noClasses = true 11 style = \u0026#34;github\u0026#34; 12 tabWidth = 4 行号已经可以显示了，但是复制的时候会与行号一起复制，修改自定义css\n1.highlight .ln { 2 width: 20px; 3 display: block; 4 float: left; 5 text-align: right; 6 user-select: none; # 表示复制是不能被选中的 7 padding-right: 8px; 8 color: #ccc; 9} ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/tips/hugo_basic/","summary":"hugo 增加 评论\n编译\u0026amp;发布\nMarkDown 语法 公式解析\n引入MathJax。MathJax 是一个Javascript库，通过官方提供的CDN集成到自己的页面非常简单，只需把一下内容添加到所有的页面，例如foot.html\n1\u0026lt;script type=\u0026#34;text/javascript\u0026#34; async 2 src=\u0026#34;https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML\u0026#34;\u0026gt; 3\u0026lt;/script\u0026gt; 配置文件 config.toml 代码高亮设置\n1pygmentsUseClasses = true 2[markup] 3 [markup.highlight] 4 codeFences = true 5 guessSyntax = true 6 hl_Lines = \u0026#34;\u0026#34; 7 lineNoStart = 1 # display line number 8 lineNos = true 9 lineNumbersInTable = false 10 noClasses = true 11 style = \u0026#34;github\u0026#34; 12 tabWidth = 4 行号已经可以显示了，但是复制的时候会与行号一起复制，修改自定义css\n1.highlight .ln { 2 width: 20px; 3 display: block; 4 float: left; 5 text-align: right; 6 user-select: none; # 表示复制是不能被选中的 7 padding-right: 8px; 8 color: #ccc; 9} ","tags":null,"title":"「Hugo」Hugo基本使用"},{"categories":null,"contents":"安装InfluxDB 1docker run --name=influxdb -d -p 8086:8086 influxdb 2docker exec -it influxdb influx InfluxDB Desc 对应数据库 database 数据库 measurement 数据库中的表 point 表中的一行数据 databases\n1show databases 2use iaas_metrics 3show measurements 数据查询\n1select * from host_CpuBusy where time \u0026gt; now() -7d order by time limit 10; influx(\u0026ldquo;telegraf\u0026rdquo;, \u0026lsquo;\u0026lsquo;\u0026lsquo;SELECT sum(usage_system) FROM \u0026ldquo;cpu\u0026rdquo; group by \u0026ldquo;host\u0026rdquo; \u0026lsquo;\u0026rsquo;\u0026rsquo;, \u0026ldquo;20m\u0026rdquo;, \u0026ldquo;2m\u0026rdquo;, \u0026ldquo;1m\u0026rdquo;)****\nhttps://zhuanlan.zhihu.com/p/97247465\nhttps://zhuanlan.zhihu.com/p/85097140\nhttps://www.cnblogs.com/suhaha/p/11692210.html\nhttps://www.cnblogs.com/suhaha/p/11692210.html\ngrafa 配置查询influxdb\nhttps://ken.io/note/grafana-quickstart-influxdb-datasource-graph\nhttps://www.jianshu.com/p/f0905f36e9c3\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/component/TimeSeries/install_influxdb/","summary":"安装InfluxDB 1docker run --name=influxdb -d -p 8086:8086 influxdb 2docker exec -it influxdb influx InfluxDB Desc 对应数据库 database 数据库 measurement 数据库中的表 point 表中的一行数据 databases\n1show databases 2use iaas_metrics 3show measurements 数据查询\n1select * from host_CpuBusy where time \u0026gt; now() -7d order by time limit 10; influx(\u0026ldquo;telegraf\u0026rdquo;, \u0026lsquo;\u0026lsquo;\u0026lsquo;SELECT sum(usage_system) FROM \u0026ldquo;cpu\u0026rdquo; group by \u0026ldquo;host\u0026rdquo; \u0026lsquo;\u0026rsquo;\u0026rsquo;, \u0026ldquo;20m\u0026rdquo;, \u0026ldquo;2m\u0026rdquo;, \u0026ldquo;1m\u0026rdquo;)****\nhttps://zhuanlan.zhihu.com/p/97247465\nhttps://zhuanlan.zhihu.com/p/85097140\nhttps://www.cnblogs.com/suhaha/p/11692210.html\nhttps://www.cnblogs.com/suhaha/p/11692210.html\ngrafa 配置查询influxdb\nhttps://ken.io/note/grafana-quickstart-influxdb-datasource-graph\nhttps://www.jianshu.com/p/f0905f36e9c3","tags":null,"title":"「InfluxDB」InfluxDB 安装"},{"categories":null,"contents":"Automic 原子类 1 Atomic 原子类介绍 Atomic 是指一个操作是不可中断的。即使是在多个线程一起执行的时候，一个操作一旦开始，就不会被其他线程干扰。\n所以，所谓原子类说简单点就是具有原子/原子操作特征的类。\n并发包 java.util.concurrent 的原子类都存放在java.util.concurrent.atomic下,如下图所示。\n根据操作的数据类型，可以将JUC包中的原子类分为4类\n基本类型\n使用原子的方式更新基本类型\nAtomicInteger：整型原子类 AtomicLong：长整型原子类 AtomicBoolean ：布尔型原子类 数组类型\n使用原子的方式更新数组里的某个元素\nAtomicIntegerArray：整型数组原子类 AtomicLongArray：长整型数组原子类 AtomicReferenceArray ：引用类型数组原子类 引用类型\nAtomicReference：引用类型原子类 AtomicReferenceFieldUpdater：原子更新引用类型里的字段 AtomicMarkableReference ：原子更新带有标记位的引用类型 对象的属性修改类型\nAtomicIntegerFieldUpdater:原子更新整型字段的更新器 AtomicLongFieldUpdater：原子更新长整型字段的更新器 AtomicStampedReference ：原子更新带有版本号的引用类型。该类将整数值与引用关联起来，可用于解决原子的更新数据和数据的版本号，可以解决使用 CAS 进行原子更新时可能出现的 ABA 问题。 AtomicMarkableReference：原子更新带有标记的引用类型。该类将 boolean 标记与引用关联起来，也可以解决使用 CAS 进行原子更新时可能出现的 ABA 问题。 CAS ABA 问题\n描述: 第一个线程取到了变量 x 的值 A，然后巴拉巴拉干别的事，总之就是只拿到了变量 x 的值 A。这段时间内第二个线程也取到了变量 x 的值 A，然后把变量 x 的值改为 B，然后巴拉巴拉干别的事，最后又把变量 x 的值变为 A （相当于还原了）。在这之后第一个线程终于进行了变量 x 的操作，但是此时变量 x 的值还是 A，所以 compareAndSet 操作是成功。 例子描述(可能不太合适，但好理解): 年初，现金为零，然后通过正常劳动赚了三百万，之后正常消费了（比如买房子）三百万。年末，虽然现金零收入（可能变成其他形式了），但是赚了钱是事实，还是得交税的！ 代码例子（以AtomicInteger为例） 1import java.util.concurrent.atomic.AtomicInteger; 2 3public class AtomicIntegerDefectDemo { 4 public static void main(String[] args) { 5 defectOfABA(); 6 } 7 8 static void defectOfABA() { 9 final AtomicInteger atomicInteger = new AtomicInteger(1); 10 11 Thread coreThread = new Thread( 12 () -\u0026gt; { 13 final int currentValue = atomicInteger.get(); 14 System.out.println(Thread.currentThread().getName() + \u0026#34; ------ currentValue=\u0026#34; + currentValue); 15 16 // 这段目的：模拟处理其他业务花费的时间 17 try { 18 Thread.sleep(300); 19 } catch (InterruptedException e) { 20 e.printStackTrace(); 21 } 22 23 boolean casResult = atomicInteger.compareAndSet(1, 2); 24 System.out.println(Thread.currentThread().getName() 25 + \u0026#34; ------ currentValue=\u0026#34; + currentValue 26 + \u0026#34;, finalValue=\u0026#34; + atomicInteger.get() 27 + \u0026#34;, compareAndSet Result=\u0026#34; + casResult); 28 } 29 ); 30 coreThread.start(); 31 32 // 这段目的：为了让 coreThread 线程先跑起来 33 try { 34 Thread.sleep(100); 35 } catch (InterruptedException e) { 36 e.printStackTrace(); 37 } 38 39 Thread amateurThread = new Thread( 40 () -\u0026gt; { 41 int currentValue = atomicInteger.get(); 42 boolean casResult = atomicInteger.compareAndSet(1, 2); 43 System.out.println(Thread.currentThread().getName() 44 + \u0026#34; ------ currentValue=\u0026#34; + currentValue 45 + \u0026#34;, finalValue=\u0026#34; + atomicInteger.get() 46 + \u0026#34;, compareAndSet Result=\u0026#34; + casResult); 47 48 currentValue = atomicInteger.get(); 49 casResult = atomicInteger.compareAndSet(2, 1); 50 System.out.println(Thread.currentThread().getName() 51 + \u0026#34; ------ currentValue=\u0026#34; + currentValue 52 + \u0026#34;, finalValue=\u0026#34; + atomicInteger.get() 53 + \u0026#34;, compareAndSet Result=\u0026#34; + casResult); 54 } 55 ); 56 amateurThread.start(); 57 } 58} 59​``` 60 61输出内容如下： Thread-0 \u0026mdash;\u0026mdash; currentValue=1 Thread-1 \u0026mdash;\u0026mdash; currentValue=1, finalValue=2, compareAndSet Result=true Thread-1 \u0026mdash;\u0026mdash; currentValue=2, finalValue=1, compareAndSet Result=true Thread-0 \u0026mdash;\u0026mdash; currentValue=1, finalValue=2, compareAndSet Result=true ​```\n下面我们来详细介绍一下这些原子类。\n2 基本类型原子类 2.1 基本类型原子类介绍 使用原子的方式更新基本类型\nAtomicInteger：整型原子类 AtomicLong：长整型原子类 AtomicBoolean ：布尔型原子类 上面三个类提供的方法几乎相同，所以我们这里以 AtomicInteger 为例子来介绍。\nAtomicInteger 类常用方法\n1public final int get() //获取当前的值 2public final int getAndSet(int newValue)//获取当前的值，并设置新的值 3public final int getAndIncrement()//获取当前的值，并自增 4public final int getAndDecrement() //获取当前的值，并自减 5public final int getAndAdd(int delta) //获取当前的值，并加上预期的值 6boolean compareAndSet(int expect, int update) //如果输入的数值等于预期值，则以原子方式将该值设置为输入值（update） 7public final void lazySet(int newValue)//最终设置为newValue,使用 lazySet 设置之后可能导致其他线程在之后的一小段时间内还是可以读到旧的值。 8​``` 9 10#### 2.2 AtomicInteger 常见方法使用 11 12​```java 13import java.util.concurrent.atomic.AtomicInteger; 14 15public class AtomicIntegerTest { 16 17\tpublic static void main(String[] args) { 18\t// TODO Auto-generated method stub 19\tint temvalue = 0; 20\tAtomicInteger i = new AtomicInteger(0); 21\ttemvalue = i.getAndSet(3); 22\tSystem.out.println(\u0026#34;temvalue:\u0026#34; + temvalue + \u0026#34;; i:\u0026#34; + i);//temvalue:0; i:3 23\ttemvalue = i.getAndIncrement(); 24\tSystem.out.println(\u0026#34;temvalue:\u0026#34; + temvalue + \u0026#34;; i:\u0026#34; + i);//temvalue:3; i:4 25\ttemvalue = i.getAndAdd(5); 26\tSystem.out.println(\u0026#34;temvalue:\u0026#34; + temvalue + \u0026#34;; i:\u0026#34; + i);//temvalue:4; i:9 27\t} 28 29} 30​``` 31 32#### 2.3 基本数据类型原子类的优势 33 34通过一个简单例子带大家看一下基本数据类型原子类的优势 35 36**①多线程环境不使用原子类保证线程安全（基本数据类型）** 37 38​```java 39class Test { 40 private volatile int count = 0; 41 //若要线程安全执行执行count++，需要加锁 42 public synchronized void increment() { 43 count++; 44 } 45 46 public int getCount() { 47 return count; 48 } 49} 50​``` 51**②多线程环境使用原子类保证线程安全（基本数据类型）** 52 53​```java 54class Test2 { 55 private AtomicInteger count = new AtomicInteger(); 56 57 public void increment() { 58 count.incrementAndGet(); 59 } 60 //使用AtomicInteger之后，不需要加锁，也可以实现线程安全。 61 public int getCount() { 62 return count.get(); 63 } 64} 2.4 AtomicInteger 线程安全原理简单分析 AtomicInteger 类的部分源码：\n1 // setup to use Unsafe.compareAndSwapInt for updates（更新操作时提供“比较并替换”的作用） 2 private static final Unsafe unsafe = Unsafe.getUnsafe(); 3 private static final long valueOffset; 4 5 static { 6 try { 7 valueOffset = unsafe.objectFieldOffset 8 (AtomicInteger.class.getDeclaredField(\u0026#34;value\u0026#34;)); 9 } catch (Exception ex) { throw new Error(ex); } 10 } 11 12 private volatile int value; AtomicInteger 类主要利用 CAS (compare and swap) + volatile 和 native 方法来保证原子操作，从而避免 synchronized 的高开销，执行效率大为提升。\nCAS的原理是拿期望的值和原本的一个值作比较，如果相同则更新成新的值。UnSafe 类的 objectFieldOffset() 方法是一个本地方法，这个方法是用来拿到“原来的值”的内存地址。另外 value 是一个volatile变量，在内存中可见，因此 JVM 可以保证任何时刻任何线程总能拿到该变量的最新值。\n3 数组类型原子类 3.1 数组类型原子类介绍 使用原子的方式更新数组里的某个元素\nAtomicIntegerArray：整形数组原子类 AtomicLongArray：长整形数组原子类 AtomicReferenceArray ：引用类型数组原子类 上面三个类提供的方法几乎相同，所以我们这里以 AtomicIntegerArray 为例子来介绍。\nAtomicIntegerArray 类常用方法\n1public final int get(int i) //获取 index=i 位置元素的值 2public final int getAndSet(int i, int newValue)//返回 index=i 位置的当前的值，并将其设置为新值：newValue 3public final int getAndIncrement(int i)//获取 index=i 位置元素的值，并让该位置的元素自增 4public final int getAndDecrement(int i) //获取 index=i 位置元素的值，并让该位置的元素自减 5public final int getAndAdd(int delta) //获取 index=i 位置元素的值，并加上预期的值 6boolean compareAndSet(int expect, int update) //如果输入的数值等于预期值，则以原子方式将 index=i 位置的元素值设置为输入值（update） 7public final void lazySet(int i, int newValue)//最终 将index=i 位置的元素设置为newValue,使用 lazySet 设置之后可能导致其他线程在之后的一小段时间内还是可以读到旧的值。 8​``` 9#### 3.2 AtomicIntegerArray 常见方法使用 10 11​```java 12 13import java.util.concurrent.atomic.AtomicIntegerArray; 14 15public class AtomicIntegerArrayTest { 16 17\tpublic static void main(String[] args) { 18\t// TODO Auto-generated method stub 19\tint temvalue = 0; 20\tint[] nums = { 1, 2, 3, 4, 5, 6 }; 21\tAtomicIntegerArray i = new AtomicIntegerArray(nums); 22\tfor (int j = 0; j \u0026lt; nums.length; j++) { 23\tSystem.out.println(i.get(j)); 24\t} 25\ttemvalue = i.getAndSet(0, 2); 26\tSystem.out.println(\u0026#34;temvalue:\u0026#34; + temvalue + \u0026#34;; i:\u0026#34; + i); 27\ttemvalue = i.getAndIncrement(0); 28\tSystem.out.println(\u0026#34;temvalue:\u0026#34; + temvalue + \u0026#34;; i:\u0026#34; + i); 29\ttemvalue = i.getAndAdd(0, 5); 30\tSystem.out.println(\u0026#34;temvalue:\u0026#34; + temvalue + \u0026#34;; i:\u0026#34; + i); 31\t} 32 33} 34​``` 35 36### 4 引用类型原子类 37 38#### 4.1 引用类型原子类介绍 39 40基本类型原子类只能更新一个变量，如果需要原子更新多个变量，需要使用 引用类型原子类。 41 42- AtomicReference：引用类型原子类 43- AtomicStampedReference：原子更新引用类型里的字段原子类 44- AtomicMarkableReference ：原子更新带有标记位的引用类型 45 46上面三个类提供的方法几乎相同，所以我们这里以 AtomicReference 为例子来介绍。 47 48#### 4.2 AtomicReference 类使用示例 49 50​```java 51import java.util.concurrent.atomic.AtomicReference; 52 53public class AtomicReferenceTest { 54 55\tpublic static void main(String[] args) { 56\tAtomicReference\u0026lt;Person\u0026gt; ar = new AtomicReference\u0026lt;Person\u0026gt;(); 57\tPerson person = new Person(\u0026#34;SnailClimb\u0026#34;, 22); 58\tar.set(person); 59\tPerson updatePerson = new Person(\u0026#34;Daisy\u0026#34;, 20); 60\tar.compareAndSet(person, updatePerson); 61\t62\tSystem.out.println(ar.get().getName()); 63\tSystem.out.println(ar.get().getAge()); 64\t} 65} 66 67class Person { 68\tprivate String name; 69\tprivate int age; 70 71\tpublic Person(String name, int age) { 72\tsuper(); 73\tthis.name = name; 74\tthis.age = age; 75\t} 76\t77\tpublic String getName() { 78\treturn name; 79\t} 80\t81\tpublic void setName(String name) { 82\tthis.name = name; 83\t} 84\t85\tpublic int getAge() { 86\treturn age; 87\t} 88\t89\tpublic void setAge(int age) { 90\tthis.age = age; 91\t} 92 93} 94​``` 95上述代码首先创建了一个 Person 对象，然后把 Person 对象设置进 AtomicReference 对象中，然后调用 compareAndSet 方法，该方法就是通过通过 CAS 操作设置 ar。如果 ar 的值为 person 的话，则将其设置为 updatePerson。实现原理与 AtomicInteger 类中的 compareAndSet 方法相同。运行上面的代码后的输出结果如下： Daisy 20 ​```\n4.3 AtomicStampedReference 类使用示例 1import java.util.concurrent.atomic.AtomicStampedReference; 2 3public class AtomicStampedReferenceDemo { 4 public static void main(String[] args) { 5 // 实例化、取当前值和 stamp 值 6 final Integer initialRef = 0, initialStamp = 0; 7 final AtomicStampedReference\u0026lt;Integer\u0026gt; asr = new AtomicStampedReference\u0026lt;\u0026gt;(initialRef, initialStamp); 8 System.out.println(\u0026#34;currentValue=\u0026#34; + asr.getReference() + \u0026#34;, currentStamp=\u0026#34; + asr.getStamp()); 9 10 // compare and set 11 final Integer newReference = 666, newStamp = 999; 12 final boolean casResult = asr.compareAndSet(initialRef, newReference, initialStamp, newStamp); 13 System.out.println(\u0026#34;currentValue=\u0026#34; + asr.getReference() 14 + \u0026#34;, currentStamp=\u0026#34; + asr.getStamp() 15 + \u0026#34;, casResult=\u0026#34; + casResult); 16 17 // 获取当前的值和当前的 stamp 值 18 int[] arr = new int[1]; 19 final Integer currentValue = asr.get(arr); 20 final int currentStamp = arr[0]; 21 System.out.println(\u0026#34;currentValue=\u0026#34; + currentValue + \u0026#34;, currentStamp=\u0026#34; + currentStamp); 22 23 // 单独设置 stamp 值 24 final boolean attemptStampResult = asr.attemptStamp(newReference, 88); 25 System.out.println(\u0026#34;currentValue=\u0026#34; + asr.getReference() 26 + \u0026#34;, currentStamp=\u0026#34; + asr.getStamp() 27 + \u0026#34;, attemptStampResult=\u0026#34; + attemptStampResult); 28 29 // 重新设置当前值和 stamp 值 30 asr.set(initialRef, initialStamp); 31 System.out.println(\u0026#34;currentValue=\u0026#34; + asr.getReference() + \u0026#34;, currentStamp=\u0026#34; + asr.getStamp()); 32 33 // [不推荐使用，除非搞清楚注释的意思了] weak compare and set 34 // 困惑！weakCompareAndSet 这个方法最终还是调用 compareAndSet 方法。[版本: jdk-8u191] 35 // 但是注释上写着 \u0026#34;May fail spuriously and does not provide ordering guarantees, 36 // so is only rarely an appropriate alternative to compareAndSet.\u0026#34; 37 // todo 感觉有可能是 jvm 通过方法名在 native 方法里面做了转发 38 final boolean wCasResult = asr.weakCompareAndSet(initialRef, newReference, initialStamp, newStamp); 39 System.out.println(\u0026#34;currentValue=\u0026#34; + asr.getReference() 40 + \u0026#34;, currentStamp=\u0026#34; + asr.getStamp() 41 + \u0026#34;, wCasResult=\u0026#34; + wCasResult); 42 } 43} 44​``` 45 46输出结果如下： 47​``` 48currentValue=0, currentStamp=0 49currentValue=666, currentStamp=999, casResult=true 50currentValue=666, currentStamp=999 51currentValue=666, currentStamp=88, attemptStampResult=true 52currentValue=0, currentStamp=0 53currentValue=666, currentStamp=999, wCasResult=true 54​``` 55 56#### 4.4 AtomicMarkableReference 类使用示例 57 58​``` java 59import java.util.concurrent.atomic.AtomicMarkableReference; 60 61public class AtomicMarkableReferenceDemo { 62 public static void main(String[] args) { 63 // 实例化、取当前值和 mark 值 64 final Boolean initialRef = null, initialMark = false; 65 final AtomicMarkableReference\u0026lt;Boolean\u0026gt; amr = new AtomicMarkableReference\u0026lt;\u0026gt;(initialRef, initialMark); 66 System.out.println(\u0026#34;currentValue=\u0026#34; + amr.getReference() + \u0026#34;, currentMark=\u0026#34; + amr.isMarked()); 67 68 // compare and set 69 final Boolean newReference1 = true, newMark1 = true; 70 final boolean casResult = amr.compareAndSet(initialRef, newReference1, initialMark, newMark1); 71 System.out.println(\u0026#34;currentValue=\u0026#34; + amr.getReference() 72 + \u0026#34;, currentMark=\u0026#34; + amr.isMarked() 73 + \u0026#34;, casResult=\u0026#34; + casResult); 74 75 // 获取当前的值和当前的 mark 值 76 boolean[] arr = new boolean[1]; 77 final Boolean currentValue = amr.get(arr); 78 final boolean currentMark = arr[0]; 79 System.out.println(\u0026#34;currentValue=\u0026#34; + currentValue + \u0026#34;, currentMark=\u0026#34; + currentMark); 80 81 // 单独设置 mark 值 82 final boolean attemptMarkResult = amr.attemptMark(newReference1, false); 83 System.out.println(\u0026#34;currentValue=\u0026#34; + amr.getReference() 84 + \u0026#34;, currentMark=\u0026#34; + amr.isMarked() 85 + \u0026#34;, attemptMarkResult=\u0026#34; + attemptMarkResult); 86 87 // 重新设置当前值和 mark 值 88 amr.set(initialRef, initialMark); 89 System.out.println(\u0026#34;currentValue=\u0026#34; + amr.getReference() + \u0026#34;, currentMark=\u0026#34; + amr.isMarked()); 90 91 // [不推荐使用，除非搞清楚注释的意思了] weak compare and set 92 // 困惑！weakCompareAndSet 这个方法最终还是调用 compareAndSet 方法。[版本: jdk-8u191] 93 // 但是注释上写着 \u0026#34;May fail spuriously and does not provide ordering guarantees, 94 // so is only rarely an appropriate alternative to compareAndSet.\u0026#34; 95 // todo 感觉有可能是 jvm 通过方法名在 native 方法里面做了转发 96 final boolean wCasResult = amr.weakCompareAndSet(initialRef, newReference1, initialMark, newMark1); 97 System.out.println(\u0026#34;currentValue=\u0026#34; + amr.getReference() 98 + \u0026#34;, currentMark=\u0026#34; + amr.isMarked() 99 + \u0026#34;, wCasResult=\u0026#34; + wCasResult); 100 } 101} 102​``` 103 104输出结果如下： 105​``` 106currentValue=null, currentMark=false 107currentValue=true, currentMark=true, casResult=true 108currentValue=true, currentMark=true 109currentValue=true, currentMark=false, attemptMarkResult=true 110currentValue=null, currentMark=false 111currentValue=true, currentMark=true, wCasResult=true 112​``` 113 114### 5 对象的属性修改类型原子类 115 116#### 5.1 对象的属性修改类型原子类介绍 117 118如果需要原子更新某个类里的某个字段时，需要用到对象的属性修改类型原子类。 119 120- AtomicIntegerFieldUpdater:原子更新整形字段的更新器 121- AtomicLongFieldUpdater：原子更新长整形字段的更新器 122- AtomicStampedReference ：原子更新带有版本号的引用类型。该类将整数值与引用关联起来，可用于解决原子的更新数据和数据的版本号，可以解决使用 CAS 进行原子更新时可能出现的 ABA 问题。 123 124要想原子地更新对象的属性需要两步。第一步，因为对象的属性修改类型原子类都是抽象类，所以每次使用都必须使用静态方法 newUpdater()创建一个更新器，并且需要设置想要更新的类和属性。第二步，更新的对象属性必须使用 public volatile 修饰符。 125 126上面三个类提供的方法几乎相同，所以我们这里以 `AtomicIntegerFieldUpdater`为例子来介绍。 127 128#### 5.2 AtomicIntegerFieldUpdater 类使用示例 129 130​```java 131import java.util.concurrent.atomic.AtomicIntegerFieldUpdater; 132 133public class AtomicIntegerFieldUpdaterTest { 134\tpublic static void main(String[] args) { 135\tAtomicIntegerFieldUpdater\u0026lt;User\u0026gt; a = AtomicIntegerFieldUpdater.newUpdater(User.class, \u0026#34;age\u0026#34;); 136 137\tUser user = new User(\u0026#34;Java\u0026#34;, 22); 138\tSystem.out.println(a.getAndIncrement(user));// 22 139\tSystem.out.println(a.get(user));// 23 140\t} 141} 142 143class User { 144\tprivate String name; 145\tpublic volatile int age; 146 147\tpublic User(String name, int age) { 148\tsuper(); 149\tthis.name = name; 150\tthis.age = age; 151\t} 152\t153\tpublic String getName() { 154\treturn name; 155\t} 156\t157\tpublic void setName(String name) { 158\tthis.name = name; 159\t} 160\t161\tpublic int getAge() { 162\treturn age; 163\t} 164\t165\tpublic void setAge(int age) { 166\tthis.age = age; 167\t} 168 169} 170​``` 171 172输出结果： 22 23 ​```\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/interview/JavaNote/Automic-%E5%8E%9F%E5%AD%90%E7%B1%BB/","summary":"Automic 原子类 1 Atomic 原子类介绍 Atomic 是指一个操作是不可中断的。即使是在多个线程一起执行的时候，一个操作一旦开始，就不会被其他线程干扰。\n所以，所谓原子类说简单点就是具有原子/原子操作特征的类。\n并发包 java.util.concurrent 的原子类都存放在java.util.concurrent.atomic下,如下图所示。\n根据操作的数据类型，可以将JUC包中的原子类分为4类\n基本类型\n使用原子的方式更新基本类型\nAtomicInteger：整型原子类 AtomicLong：长整型原子类 AtomicBoolean ：布尔型原子类 数组类型\n使用原子的方式更新数组里的某个元素\nAtomicIntegerArray：整型数组原子类 AtomicLongArray：长整型数组原子类 AtomicReferenceArray ：引用类型数组原子类 引用类型\nAtomicReference：引用类型原子类 AtomicReferenceFieldUpdater：原子更新引用类型里的字段 AtomicMarkableReference ：原子更新带有标记位的引用类型 对象的属性修改类型\nAtomicIntegerFieldUpdater:原子更新整型字段的更新器 AtomicLongFieldUpdater：原子更新长整型字段的更新器 AtomicStampedReference ：原子更新带有版本号的引用类型。该类将整数值与引用关联起来，可用于解决原子的更新数据和数据的版本号，可以解决使用 CAS 进行原子更新时可能出现的 ABA 问题。 AtomicMarkableReference：原子更新带有标记的引用类型。该类将 boolean 标记与引用关联起来，也可以解决使用 CAS 进行原子更新时可能出现的 ABA 问题。 CAS ABA 问题\n描述: 第一个线程取到了变量 x 的值 A，然后巴拉巴拉干别的事，总之就是只拿到了变量 x 的值 A。这段时间内第二个线程也取到了变量 x 的值 A，然后把变量 x 的值改为 B，然后巴拉巴拉干别的事，最后又把变量 x 的值变为 A （相当于还原了）。在这之后第一个线程终于进行了变量 x 的操作，但是此时变量 x 的值还是 A，所以 compareAndSet 操作是成功。 例子描述(可能不太合适，但好理解): 年初，现金为零，然后通过正常劳动赚了三百万，之后正常消费了（比如买房子）三百万。年末，虽然现金零收入（可能变成其他形式了），但是赚了钱是事实，还是得交税的！ 代码例子（以AtomicInteger为例） 1import java.","tags":null,"title":"「Java」"},{"categories":null,"contents":"自动补齐json Format 通过SFTP同步本地与远端代码 Preference\u0026gt;Build,Execution,Deployment\u0026gt;SFTP\nGo 远程Debug https://github.com/derekparker/delve\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/tips/goland/","summary":"自动补齐json Format 通过SFTP同步本地与远端代码 Preference\u0026gt;Build,Execution,Deployment\u0026gt;SFTP\nGo 远程Debug https://github.com/derekparker/delve","tags":null,"title":"「JetBrains」 GoLand技巧"},{"categories":null,"contents":"环境准备 K8s 只能基于Linux环境部署，用Win/Mac的小伙伴们怎么在自己的PC上Setup环境呢。此时就推荐Canonical家的Multipass了，Canonical 是谁，当然是Ubuntu的母公司了。\n安装 kubelet kubeadm kubectl 官方文档\n1sudo apt-get update \u0026amp;\u0026amp; sudo apt-get install -y apt-transport-https curl 2curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add - 3cat \u0026lt;\u0026lt;EOF | sudo tee /etc/apt/sources.list.d/kubernetes.list 4deb https://apt.kubernetes.io/ kubernetes-xenial main 5EOF 6sudo apt-get update 7sudo apt-get install -y kubelet kubeadm kubectl 8sudo apt-mark hold kubelet kubeadm kubectl # 设置为不再更新 初始化 1swapoff -a 2kubeadm init ctl 3# kubeadm config images pull --v=10 4 # 国内正常网络不能从k8s.grc.io拉取镜像, 所以从docker.io拉取, 然后重新打上一个符合k8s的tag: 5docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/kube-apiserver:v1.20.1 6docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/kube-apiserver:v1.20.1 k8s.gcr.io/kube-apiserver:v1.20.1 7 8docker pull mirrorgooglecontainers/kube-apiserver:v1.12.2 9docker pull mirrorgooglecontainers/kube-controller-manager:v1.12.2 10docker pull mirrorgooglecontainers/kube-scheduler:v1.12.2 11docker pull mirrorgooglecontainers/kube-proxy:v1.12.2 12docker pull mirrorgooglecontainers/pause:3.1 13docker pull mirrorgooglecontainers/etcd:3.2.24 14docker pull coredns/coredns:1.2.2 15 16docker tag docker.io/mirrorgooglecontainers/kube-apiserver:v1.12.2 k8s.gcr.io/kube-apiserver:v1.12.2 17docker tag docker.io/mirrorgooglecontainers/kube-controller-manager:v1.12.2 k8s.gcr.io/kube-controller-manager:v1.12.2 18docker tag docker.io/mirrorgooglecontainers/kube-scheduler:v1.12.2 k8s.gcr.io/kube-scheduler:v1.12.2 19docker tag docker.io/mirrorgooglecontainers/kube-proxy:v1.12.2 k8s.gcr.io/kube-proxy:v1.12.2 20docker tag docker.io/mirrorgooglecontainers/pause:3.1 k8s.gcr.io/pause:3.1 21docker tag docker.io/mirrorgooglecontainers/etcd:3.2.24 k8s.gcr.io/etcd:3.2.24 22docker tag docker.io/coredns/coredns:1.2.2 k8s.gcr.io/coredns:1.2.2 23 24docker rmi mirrorgooglecontainers/kube-apiserver:v1.12.2 25docker rmi mirrorgooglecontainers/kube-controller-manager:v1.12.2 26docker rmi mirrorgooglecontainers/kube-scheduler:v1.12.2 27docker rmi mirrorgooglecontainers/kube-proxy:v1.12.2 28docker rmi mirrorgooglecontainers/pause:3.1 29docker rmi mirrorgooglecontainers/etcd:3.2.24 30docker rmi coredns/coredns:1.2.2 安装成功\n1Your Kubernetes control-plane has initialized successfully! 2 3To start using your cluster, you need to run the following as a regular user: 4 5 mkdir -p $HOME/.kube 6 sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config 7 sudo chown $(id -u):$(id -g) $HOME/.kube/config 8 9Alternatively, if you are the root user, you can run: 10 11 export KUBECONFIG=/etc/kubernetes/admin.conf 12 13You should now deploy a pod network to the cluster. 14Run \u0026#34;kubectl apply -f [podnetwork].yaml\u0026#34; with one of the options listed at: 15 https://kubernetes.io/docs/concepts/cluster-administration/addons/ 16 17Then you can join any number of worker nodes by running the following on each as root: 18 19kubeadm join 10.227.4.115:6443 --token 3hf7uz.3stfkg430pppne10 \\ 20 --discovery-token-ca-cert-hash sha256:14d0a3cd33e86dc80081d806499a95366c4f0bdfd83d364c1e6576864684d3d7 安装网络组件 1# sysctl net.bridge.bridge-nf-call-iptables=1 2# https://kubernetes.io/docs/concepts/cluster-administration/addons/ 3kubectl apply -f \u0026#34;https://cloud.weave.works/k8s/net?k8s-version=$(kubectl version | base64 | tr -d \u0026#39;\\n\u0026#39;)\u0026#34; 检查集群状态 1kubectl get nodes 2kubectl get pod --all-namespaces -o wide 3kubectl get pod --all-namespaces 4kubectl get pods -n kube-system # 指定命名空间 参考文档 概念\nhttp://www.dockone.io/article/932\nhttps://www.zhihu.com/question/37498459/answer/826736487\n安装文档\nhttps://kubernetes.io/zh/docs/setup/production-environment/tools/kubeadm/install-kubeadm/\nhttps://www.hangge.com/blog/cache/detail_2414.html\nhttps://zhuanlan.zhihu.com/p/46341911\ninit ubuntu as a k8s node\n1sudo su 2apt update \u0026amp;\u0026amp; apt -y upgrade 3apt install -y apt-transport-https curl net-tools 4curl -fsSLo /usr/share/keyrings/kubernetes-archive-keyring.gpg https://packages.cloud.google.com/apt/doc/apt-key.gpg 5echo \u0026#34;deb [signed-by=/usr/share/keyrings/kubernetes-archive-keyring.gpg] https://apt.kubernetes.io/ kubernetes-xenial main\u0026#34; | sudo tee /etc/apt/sources.list.d/kubernetes.list 6apt update 7apt install -y kubelet kubeadm kubectl docker.io How completely uninstall kubernetes 1#!/bin/sh 2# Kube Admin Reset 3kubeadm reset 4 5# Remove all packages related to Kubernetes 6apt remove -y kubeadm kubectl kubelet kubernetes-cni 7apt purge -y kube* 8 9# Remove docker containers/ images ( optional if using docker) 10docker image prune -a 11systemctl restart docker 12apt purge -y docker-engine docker docker.io docker-ce docker-ce-cli containerd containerd.io runc --allow-change-held-packages 13 14# Remove parts 15 16apt autoremove -y 17 18# Remove all folder associated to kubernetes, etcd, and docker 19rm -rf ~/.kube 20rm -rf /etc/cni /etc/kubernetes /var/lib/dockershim /var/lib/etcd /var/lib/kubelet /var/lib/etcd2/ /var/run/kubernetes ~/.kube/* 21rm -rf /var/lib/docker /etc/docker /var/run/docker.sock 22rm -f /etc/apparmor.d/docker /etc/systemd/system/etcd* 23 24# Delete docker group (optional) 25groupdel docker 26 27# Clear the iptables 28iptables -F \u0026amp;\u0026amp; iptables -X 29iptables -t nat -F \u0026amp;\u0026amp; iptables -t nat -X 30iptables -t raw -F \u0026amp;\u0026amp; iptables -t raw -X 31iptables -t mangle -F \u0026amp;\u0026amp; iptables -t mangle -X ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/cloudnative/Kubernates/KubernatesInstall/","summary":"环境准备 K8s 只能基于Linux环境部署，用Win/Mac的小伙伴们怎么在自己的PC上Setup环境呢。此时就推荐Canonical家的Multipass了，Canonical 是谁，当然是Ubuntu的母公司了。\n安装 kubelet kubeadm kubectl 官方文档\n1sudo apt-get update \u0026amp;\u0026amp; sudo apt-get install -y apt-transport-https curl 2curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add - 3cat \u0026lt;\u0026lt;EOF | sudo tee /etc/apt/sources.list.d/kubernetes.list 4deb https://apt.kubernetes.io/ kubernetes-xenial main 5EOF 6sudo apt-get update 7sudo apt-get install -y kubelet kubeadm kubectl 8sudo apt-mark hold kubelet kubeadm kubectl # 设置为不再更新 初始化 1swapoff -a 2kubeadm init ctl 3# kubeadm config images pull --v=10 4 # 国内正常网络不能从k8s.","tags":null,"title":"「K8s」Kubernates 安装"},{"categories":null,"contents":"1 1 package main 2 3import \u0026#34;fmt\u0026#34; 4 5func main() { 6\tfmt.Println(twoSum([]int{2, 7, 11, 15}, 9)) 7} 8 9func twoSum(nums []int, target int) []int { 10 11\tmaps := make(map[int]int) 12 13\tfor i, value := range nums { 14\tmid := target - value 15 16\tres, ok := maps[mid] 17\tif ok { 18\treturn []int{res, i} 19\t} else { 20\tmaps[value] = i 21\t} 22\t} 23\treturn []int{} 24} 120. 三角形最小路径和 给定一个三角形 triangle ，找出自顶向下的最小路径和。\n每一步只能移动到下一行中相邻的结点上。相邻的结点 在这里指的是 下标 与 上一层结点下标 相同或者等于 上一层结点下标 + 1 的两个结点。也就是说，如果正位于当前行的下标 i ，那么下一步可以移动到下一行的下标 i 或 i + 1 。\n示例 1：\n1输入：triangle = [[2],[3,4],[6,5,7],[4,1,8,3]] 2输出：11 3解释：如下面简图所示： 4 2 5 3 4 66 5 7 74 1 8 3 8自顶向下的最小路径和为 11（即，2 + 3 + 5 + 1 = 11）。 示例 2：\n1输入：triangle = [[-10]] 2输出：-10 提示：\n11 \u0026lt;= triangle.length \u0026lt;= 200 2triangle[0].length == 1 3triangle[i].length == triangle[i - 1].length + 1 4-104 \u0026lt;= triangle[i][j] \u0026lt;= 104 进阶：\n你可以只使用 O(n) 的额外空间（n 为三角形的总行数）来解决这个问题吗？\n方法一：动态规划 自底向上递推\n状态定义： 当前位置到叶子节点的最小值 DP[i.j]\n状态转移方程： DP[i,j] = min(DP[i+1,j], DP[i+1,j+1])+Triangle[i,j] ​\n1func minimumTotal(triangle [][]int) int { 2 3\t// checkout input value 4\tif len(triangle) == 0 { 5\treturn 0 6\t} 7\tif len(triangle) == 1 { 8\treturn triangle[0][0] 9\t} 10\t// algorithm 11\traw := len(triangle) 12\tstatus := make([][]int, raw+1) 13\tstatus[raw] = make([]int, raw+1) 14\tfor i := raw; i \u0026gt; 0; i-- { 15\tstatus[i-1] = make([]int, i) 16\tfor j := 0; j \u0026lt; i; j++ { 17\tstatus[i-1][j] = getMin(status[i][j], status[i][j+1]) + triangle[i-1][j] 18\t} 19\t} 20\treturn status[0][0] 21} 22 23func getMin(a, b int) int { 24\tif a \u0026gt; b { 25\treturn b 26\t} 27\treturn a 28} 29 30func TestSolution(t *testing.T) { 31\tprintln(minimumTotal([][]int{ 32\t{2}, {3, 4}, {6, 5, 7}, {4, 1, 8, 3}, 33\t})) 34} 上述解法的时间复杂度为O(mn), 空间复杂度为O(mn),nm为行列数\n空间复杂度可优化，状态只需保存前一行的状态即可，优化后代码如下\n1func minimumTotal(triangle [][]int) int { 2\t// algorithm 3\traw := len(triangle) 4\tstatus := make([]int, raw+1) 5\tfor i := raw; i \u0026gt; 0; i-- { 6\tfor j := 0; j \u0026lt; i; j++ { 7\tstatus[j] = getMin(status[j], status[j+1]) + triangle[i-1][j] 8\t} 9\t} 10\treturn status[0] 11} ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/DataStruct/LeetCode/","summary":"1 1 package main 2 3import \u0026#34;fmt\u0026#34; 4 5func main() { 6\tfmt.Println(twoSum([]int{2, 7, 11, 15}, 9)) 7} 8 9func twoSum(nums []int, target int) []int { 10 11\tmaps := make(map[int]int) 12 13\tfor i, value := range nums { 14\tmid := target - value 15 16\tres, ok := maps[mid] 17\tif ok { 18\treturn []int{res, i} 19\t} else { 20\tmaps[value] = i 21\t} 22\t} 23\treturn []int{} 24} 120.","tags":null,"title":"「LeetCode」LeetCode"},{"categories":null,"contents":"守护进程\nhttp://www.ruanyifeng.com/blog/2016/02/linux-daemon.html\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/linux/systemd/","summary":"守护进程\nhttp://www.ruanyifeng.com/blog/2016/02/linux-daemon.html","tags":null,"title":"「Linux」Systemd"},{"categories":null,"contents":"\r","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/linux/xorgs/","summary":"\r","tags":null,"title":"「Linux」xargs"},{"categories":null,"contents":"文本工具 Typora 效率相关 Karabiner 开发相关 goland Brew go git iterm2 Alfred ohmyzsh vim docker Kitematic .virmrc 1syntax on 2set nu 3inoremap jj \u0026lt;ESC\u0026gt; git\n1git config --global init.defaultBranch main ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/tips/mac_init/","summary":"文本工具 Typora 效率相关 Karabiner 开发相关 goland Brew go git iterm2 Alfred ohmyzsh vim docker Kitematic .virmrc 1syntax on 2set nu 3inoremap jj \u0026lt;ESC\u0026gt; git\n1git config --global init.defaultBranch main ","tags":null,"title":"「Mac」Mac初始化"},{"categories":null,"contents":"https://blog.csdn.net/u013594528/article/details/80859443?utm_medium=distribute.pc_relevant_bbs_down.none-task-blog-baidujs-1.nonecase\u0026depth_1-utm_source=distribute.pc_relevant_bbs_down.none-task-blog-baidujs-1.nonecase\nhttps://blog.csdn.net/u013594528/article/details/80859443?utm_medium=distribute.pc_relevant_bbs_down.none-task-blog-baidujs-1.nonecase\u0026depth_1-utm_source=distribute.pc_relevant_bbs_down.none-task-blog-baidujs-1.nonecase\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/tips/web_mvc_pattern/","summary":"https://blog.csdn.net/u013594528/article/details/80859443?utm_medium=distribute.pc_relevant_bbs_down.none-task-blog-baidujs-1.nonecase\u0026depth_1-utm_source=distribute.pc_relevant_bbs_down.none-task-blog-baidujs-1.nonecase\nhttps://blog.csdn.net/u013594528/article/details/80859443?utm_medium=distribute.pc_relevant_bbs_down.none-task-blog-baidujs-1.nonecase\u0026depth_1-utm_source=distribute.pc_relevant_bbs_down.none-task-blog-baidujs-1.nonecase","tags":null,"title":"「MVC」 Web服务的MVC设计模式"},{"categories":null,"contents":"NIO\nepoll linux\nmac\nwindows\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/interview/cs_basic/net_io/","summary":"NIO\nepoll linux\nmac\nwindows","tags":null,"title":"「NIO」网络IO"},{"categories":null,"contents":"1.操作系统概述 什么是操作系统？\n操作系统就是组织所有的硬件，为用户程序提供调用接口的代码。是计算机硬件与应用之间的一层软件。封装了对硬件调用的实现，以及进程的管理。\n硬件管理分类：\nCPU管理、内存管理、终端管理、磁盘管理、文件管理\n网络管理、电源管理、多核管理\n计算机硬件组成如图\n我们学习一门编程语言，最先学习的就是打印“Hello World”。\n计算机把代码加载到内存，通过PCI总线将数据写入显存地址，图形控制器将数据显示到面板。\n对操作系统的学习需要掌握以下几点\n系统调用: 使用显示器 print； 使用CPU：fork； 使用文件： open、read\n一段文字是如何写到磁盘上的\n成为掌握计算机关键技术的工程师，而不是仅仅调用API的工程师。\nLab1: 扩展线程 实现线程调度 Lab2: 实现系统调用 将整个接口剥掉，添加 Lab3: 实现虚存管理 扩展实现内存管理 Lab4: 扩展文件系统 扩展实现一个文件管理 知名计算机高校\nCMU Carnegie Mellon University: 卡内基·梅隆大学\nMIT Massachusetts Institute of Technology： 麻省理工学院\nLeland Stanford Junior University 斯坦福大学\n\u0026ldquo;Learn OS concepts by coding them!!!\u0026rdquo;\n2. 操作系统引导 从打开电源开始，操作系统做了什么？\n计算机怎么工作的\n不要总等着别人告诉你答案，尽量自己去寻找\n从知识和常识出发进行推理，思索\n图灵机-\u0026gt; 通用图灵机\n前缀表达式\n后缀表达式\n自动机\nPC program counter\n取指执行\n、\nBIOS： Basic Input Output System\nCS 段寄存器\ncs \u0026laquo; 4 +IP\n一个扇区512Byte\n0 磁道0扇区 引导扇区\nc 编译后int i 无法确定内存地址\n段寄存器，段内偏移\n宏定义\nBochsis a highly portable open source IA-32 (x86) PC emulator written in C++, that runs on most popular platforms. It includes emulation of the Intel x86 CPU, common I/O devices, and a custom BIOS. Bochs can be compiled to emulate many different x86 CPUs, from early 386 to the most recent x86-64 Intel and AMD processors which may even not reached the market yet.\nThe GNU Compiler Collection includes front ends for C, C++, Objective-C, Fortran, Ada, Go, and D, as well as libraries for these languages (libstdc++,\u0026hellip;). GCC was originally written as the compiler for the GNU operating system. The GNU system was developed to be 100% free software, free in the sense that it respects the user\u0026rsquo;s freedom.\nGDB, the GNU Project debugger, allows you to see what is going on `inside\u0026rsquo; another program while it executes \u0026ndash; or what another program was doing at the moment it crashed.\nCMU\n斯坦福\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/os/base_of_os/","summary":"1.操作系统概述 什么是操作系统？\n操作系统就是组织所有的硬件，为用户程序提供调用接口的代码。是计算机硬件与应用之间的一层软件。封装了对硬件调用的实现，以及进程的管理。\n硬件管理分类：\nCPU管理、内存管理、终端管理、磁盘管理、文件管理\n网络管理、电源管理、多核管理\n计算机硬件组成如图\n我们学习一门编程语言，最先学习的就是打印“Hello World”。\n计算机把代码加载到内存，通过PCI总线将数据写入显存地址，图形控制器将数据显示到面板。\n对操作系统的学习需要掌握以下几点\n系统调用: 使用显示器 print； 使用CPU：fork； 使用文件： open、read\n一段文字是如何写到磁盘上的\n成为掌握计算机关键技术的工程师，而不是仅仅调用API的工程师。\nLab1: 扩展线程 实现线程调度 Lab2: 实现系统调用 将整个接口剥掉，添加 Lab3: 实现虚存管理 扩展实现内存管理 Lab4: 扩展文件系统 扩展实现一个文件管理 知名计算机高校\nCMU Carnegie Mellon University: 卡内基·梅隆大学\nMIT Massachusetts Institute of Technology： 麻省理工学院\nLeland Stanford Junior University 斯坦福大学\n\u0026ldquo;Learn OS concepts by coding them!!!\u0026rdquo;\n2. 操作系统引导 从打开电源开始，操作系统做了什么？\n计算机怎么工作的\n不要总等着别人告诉你答案，尽量自己去寻找\n从知识和常识出发进行推理，思索\n图灵机-\u0026gt; 通用图灵机\n前缀表达式\n后缀表达式\n自动机\nPC program counter\n取指执行\n、","tags":null,"title":"「OS」操作系统之基础"},{"categories":null,"contents":"正则表达式主要用来进行字符串匹配操作\n1^[0-9]+abc$ 2# ^ 表示以xxx开头的字符串 3# [0-9] 表示匹配0-9之间的一个数字，例如 8； [0-9]+表示匹配0-9之间的多个数字，例如：867 4# abc$ 表示以abc结尾的字符串，$表示以xxx结尾 1^[a-z0-9_-]{5,16}$ 2# 只能含有小写字母，数字，下划线,减号，且长度为5-16的字符串 字符 Description . 除了\\r \\n以外的任何单字符 \\w 匹配字母、数字、下划线，等价于[A-Za-Z0-9_] * 匹配前面的子表达式零次或者多次 ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/linux/regex/","summary":"正则表达式主要用来进行字符串匹配操作\n1^[0-9]+abc$ 2# ^ 表示以xxx开头的字符串 3# [0-9] 表示匹配0-9之间的一个数字，例如 8； [0-9]+表示匹配0-9之间的多个数字，例如：867 4# abc$ 表示以abc结尾的字符串，$表示以xxx结尾 1^[a-z0-9_-]{5,16}$ 2# 只能含有小写字母，数字，下划线,减号，且长度为5-16的字符串 字符 Description . 除了\\r \\n以外的任何单字符 \\w 匹配字母、数字、下划线，等价于[A-Za-Z0-9_] * 匹配前面的子表达式零次或者多次 ","tags":null,"title":"「Regex」正则表达式"},{"categories":null,"contents":"1sudo vi /etc/ssh/ssh_config 2 3# 增加如下两行 4ServerAliveInterval 50 #每隔50秒就向服务器发送一个请求 5ServerAliveCountMax 3 #允许超时的次数，一般都会响应 6 7vim /etc/ssh/sshd_config 8，找到ClientAliveInternal 将后面的数字0改为60 ，注意去掉前面的#，因为如果最前面是井号的话是注释掉的 Iterm ssh 导致卡死\n1vi /etc/ssh/ssh_config 2# 增加如下两行 3ServerAliveInterval 60 4ServerAliveCountMax 2 ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/tips/ssh_stuck/","summary":"1sudo vi /etc/ssh/ssh_config 2 3# 增加如下两行 4ServerAliveInterval 50 #每隔50秒就向服务器发送一个请求 5ServerAliveCountMax 3 #允许超时的次数，一般都会响应 6 7vim /etc/ssh/sshd_config 8，找到ClientAliveInternal 将后面的数字0改为60 ，注意去掉前面的#，因为如果最前面是井号的话是注释掉的 Iterm ssh 导致卡死\n1vi /etc/ssh/ssh_config 2# 增加如下两行 3ServerAliveInterval 60 4ServerAliveCountMax 2 ","tags":null,"title":"「SSH」Iterm ssh长时间卡死"},{"categories":null,"contents":" Telegraf is an agent for collecting metrics and writing the to InfluxDB or other outputs.\nInstall\n1docker run -d --name telegraf --net=container:influxdb telegraf ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/component/TimeSeries/telegraph/","summary":" Telegraf is an agent for collecting metrics and writing the to InfluxDB or other outputs.\nInstall\n1docker run -d --name telegraf --net=container:influxdb telegraf ","tags":null,"title":"「Telegraf」 Telegraf"},{"categories":null,"contents":" ​\t当使用ssh 连接一台远程计算机的时候，如果此时正在执行一个进程，突然断网了，那么这个进程也会被迫中断了。当重新ssh连接到这台远程计算机的时候，已经找不到之前正在执行的进程了。因为上一次连接的会话(Session)已经终止， 这次的重新连接又新建了一个会话。如果你遇到过这种问题你就会发现： 会话和进程是绑定的，会话终止，当前正在执行的进程也会终止。\n​\t为了解决上述问题，你可以尝试使用下Tmux。\n安装及基本使用 1# 安装在需要远程连接的远程服务器上 2apt install tmux 1# 新建 2tmux new -s \u0026lt;session name\u0026gt; 3 4# 切换到某个session 5tmux attach -t \u0026lt;session name\u0026gt; 6 7# 退出某个session，依旧保留进程 8tmux detach 9 10# 分隔窗口 11tmux split-window 12tmux split-window -h # 水平分隔 13 14# 切换窗口 【Ctrl】+【b】 然后按下 【；】 快捷键 前缀键 【Ctrl】+【b】。先按下前缀键后，在使用功能键。\ncopy-mode use vi shortcuts 1cat \u0026lt;\u0026lt;EOF | tee -a ~/.tmux.conf 2setw -g mode-keys vi 3set -g @plugin \u0026#39;tmux-plugins/tpm\u0026#39; 4set -g @plugin \u0026#39;tmux-plugins/tmux-sensible\u0026#39; 5set -g @plugin \u0026#39;tmux-plugins/tmux-resurrect\u0026#39; 6 7run \u0026#39;~/.tmux/plugins/tpm/tpm\u0026#39; 8EOF 插件管理 Tmux Plugin Manager Tmux需要安装插件可以通过Tmux Plugin Manager 这个插件进行安装， 这个插件相当于一个插件管理系统。\n1git clone https://github.com/tmux-plugins/tpm ~/.tmux/plugins/tpm 2 3 4# vi .tmux.conf 5# List of plugins 6set -g @plugin \u0026#39;tmux-plugins/tpm\u0026#39; 7set -g @plugin \u0026#39;tmux-plugins/tmux-sensible\u0026#39; 8 9# Initialize TMUX plugin manager (keep this line at the very bottom of tmux.conf) 10run \u0026#39;~/.tmux/plugins/tpm/tpm\u0026#39; 11 12 13# 重新加载配置文件 14 # type this in terminal if tmux is already running 15 tmux source ~/.tmux.conf 然后就可以在Tmux中使用prefix+I(大写I)安装配置文件.tmux.conf中定义的插件了。\nTmux Resurrect 当我们重启系统后Tmux的session会被清除，导致每次重启之后都要重建一堆session并且重建Pane。\nTmux Resurrect插件可以解决这个问题，保存和恢复Tmux Session\n1# 1st, add config 2set -g @plugin \u0026#39;tmux-plugins/tmux-resurrect\u0026#39; 3# 2nd, instlal 4prefix +I 重启电脑之前先执行，保存 session ： prefix + Ctrl-s\n重启之后，首先打开 tmux 然后 Restore Session： prefix + Ctrl-r\n如果有多个session可以使用prefix +s 选择 session。\n参考文档 http://www.ruanyifeng.com/blog/2019/10/tmux.html\nhttps://www.scutmath.com/tmux_session_save_restore.html\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/linux/tmux/","summary":"​\t当使用ssh 连接一台远程计算机的时候，如果此时正在执行一个进程，突然断网了，那么这个进程也会被迫中断了。当重新ssh连接到这台远程计算机的时候，已经找不到之前正在执行的进程了。因为上一次连接的会话(Session)已经终止， 这次的重新连接又新建了一个会话。如果你遇到过这种问题你就会发现： 会话和进程是绑定的，会话终止，当前正在执行的进程也会终止。\n​\t为了解决上述问题，你可以尝试使用下Tmux。\n安装及基本使用 1# 安装在需要远程连接的远程服务器上 2apt install tmux 1# 新建 2tmux new -s \u0026lt;session name\u0026gt; 3 4# 切换到某个session 5tmux attach -t \u0026lt;session name\u0026gt; 6 7# 退出某个session，依旧保留进程 8tmux detach 9 10# 分隔窗口 11tmux split-window 12tmux split-window -h # 水平分隔 13 14# 切换窗口 【Ctrl】+【b】 然后按下 【；】 快捷键 前缀键 【Ctrl】+【b】。先按下前缀键后，在使用功能键。\ncopy-mode use vi shortcuts 1cat \u0026lt;\u0026lt;EOF | tee -a ~/.tmux.conf 2setw -g mode-keys vi 3set -g @plugin \u0026#39;tmux-plugins/tpm\u0026#39; 4set -g @plugin \u0026#39;tmux-plugins/tmux-sensible\u0026#39; 5set -g @plugin \u0026#39;tmux-plugins/tmux-resurrect\u0026#39; 6 7run \u0026#39;~/.","tags":null,"title":"「tmux」虚拟终端"},{"categories":null,"contents":" 什么是时序数据？\n时序数据的应用场景和特征？\n时序数据库？\n时序数据 时序数据，就是与时间强相关度的一系列数据。关注的是某一时刻的数据值，而不是最终的数据。是一个过程而不是一个结果。时序数据描述的是一个数据（指标）在时间维度上的变化。例如： 股票K线、环境监测。\n时序数据的特征：\n数据以一定的时间间隔产生，生产速率稳定。 写入多，查询少 时序数据不允许更新 时序数据主要是按时间范围查询 时序数据库 传统的数据库并不适合存储时序数据，针对时序数据的特征，时序数据库的基本要求如下：\n支持高并发、高吞吐量的写入 支持海量数据存储 高可用（时序数据在互联网公司常用作报警数据源） 支持复杂的多维度的查询 易于横向扩展 常见的时序数据库\n时序数据基本概念 一条时序数据是由多个DataPoint构成的。每个DataPoint包含以下几个方面\nmetric： 一般也叫metric name，是时序数据的指标名\ntags: 一个或者多个tag组合，用户描述metric的不同维度。每个Tag由tagk\u0026amp;tagv组成。例如：一个请求的来源 host=10.20.178.23，dc=cn。tags标明数据的维度。\nvalue： 表示对应的数值。例如：请求的latency 或者qps等。\ntimestamp： 时序数据的具体时间，可以是秒级或者毫秒级别的Unix时间戳。\n例如： JVM_Heap_Memory_Usage_MB{host=127.0.0.1, instanceId=jvm01}\nDownsampling\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/component/TimeSeries/opentsdb_introduction/","summary":"什么是时序数据？\n时序数据的应用场景和特征？\n时序数据库？\n时序数据 时序数据，就是与时间强相关度的一系列数据。关注的是某一时刻的数据值，而不是最终的数据。是一个过程而不是一个结果。时序数据描述的是一个数据（指标）在时间维度上的变化。例如： 股票K线、环境监测。\n时序数据的特征：\n数据以一定的时间间隔产生，生产速率稳定。 写入多，查询少 时序数据不允许更新 时序数据主要是按时间范围查询 时序数据库 传统的数据库并不适合存储时序数据，针对时序数据的特征，时序数据库的基本要求如下：\n支持高并发、高吞吐量的写入 支持海量数据存储 高可用（时序数据在互联网公司常用作报警数据源） 支持复杂的多维度的查询 易于横向扩展 常见的时序数据库\n时序数据基本概念 一条时序数据是由多个DataPoint构成的。每个DataPoint包含以下几个方面\nmetric： 一般也叫metric name，是时序数据的指标名\ntags: 一个或者多个tag组合，用户描述metric的不同维度。每个Tag由tagk\u0026amp;tagv组成。例如：一个请求的来源 host=10.20.178.23，dc=cn。tags标明数据的维度。\nvalue： 表示对应的数值。例如：请求的latency 或者qps等。\ntimestamp： 时序数据的具体时间，可以是秒级或者毫秒级别的Unix时间戳。\n例如： JVM_Heap_Memory_Usage_MB{host=127.0.0.1, instanceId=jvm01}\nDownsampling","tags":["TSDB","OpenTSDB"],"title":"「TSDB」时序数据\u0026时序数据库简介"},{"categories":null,"contents":"https://geek-docs.com/vscode/vscode-tutorials/vscode-workspace-switch.html\nhttps://zhuanlan.zhihu.com/p/188499395\nCtrl +K Ctrl +S Keyboard Shortcuts\n切换区域的快捷键 -\u0026gt; Focus on\n区域 key Focus on folders view Ctrl + K L Focus on Open Editors View Ctrl + K E Focun on Terminal View Ctrl +K K Extensions Usage Extension Spell checker Code spell checker ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/tips/vscode/","summary":"https://geek-docs.com/vscode/vscode-tutorials/vscode-workspace-switch.html\nhttps://zhuanlan.zhihu.com/p/188499395\nCtrl +K Ctrl +S Keyboard Shortcuts\n切换区域的快捷键 -\u0026gt; Focus on\n区域 key Focus on folders view Ctrl + K L Focus on Open Editors View Ctrl + K E Focun on Terminal View Ctrl +K K Extensions Usage Extension Spell checker Code spell checker ","tags":null,"title":"「VSCode」Vs Code 使用技巧"},{"categories":null,"contents":"PCB设计 ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/life/xiaokr/","summary":"PCB设计 ","tags":null,"title":"「XiaoKr」小氪机器人"},{"categories":null,"contents":" 编码过程中首先要校验输入数据的合法性。\n写代码之前首先想好有哪些测试用例，要提高代码的测试覆盖率。\n3. 数组中重复的数字 找出数组中重复的数字。\n在一个长度为 n 的数组 nums 里的所有数字都在 0～n-1 的范围内。数组中某些数字是重复的，但不知道有几个数字重复了，也不知道每个数字重复了几次。请找出数组中任意一个重复的数字。\n2 \u0026lt;= n \u0026lt;= 100000\n如果使用Map，则时间复杂度为O(n), 空间复杂度为O(n)。题目中的关键信息为长度为n的数组，且所有数字都在0~n-1的范围内，所以可以不用额外开辟空间。\n1func findRepeatNumber(nums []int) int { 2\tvar tmp int 3\tfor i, v := range nums { 4\tif v != i { 5\tif nums[v] == v { 6\treturn v 7\t} 8\ttmp = nums[v] 9\tnums[v] = v 10\tnums[i] = tmp 11\t} 12\t} 13\treturn -1 14} 15 16// 时间复杂度为O(n),空间复杂读为O(1) 4. 二维数组中的查找 在一个 n * m 的二维数组中，每一行都按照从左到右递增的顺序排序，每一列都按照从上到下递增的顺序排序。请完成一个高效的函数，输入这样的一个二维数组和一个整数，判断数组中是否含有该整数。\n示例:\n现有矩阵 matrix 如下：\n1[ 2 [1, 4, 7, 11, 15], 3 [2, 5, 8, 12, 19], 4 [3, 6, 9, 16, 22], 5 [10, 13, 14, 17, 24], 6 [18, 21, 23, 26, 30] 7] 给定 target = 5，返回 true。\n给定 target = 20，返回 false。\n限制：\n0 \u0026lt;= n \u0026lt;= 1000\n0 \u0026lt;= m \u0026lt;= 1000\n矩阵从左到右递增，从上到下递增。如果右上角看，则往左递减，往下递增，很像一棵搜索二叉树。\n[思考]： 递增 or 非递减\n1func findNumberIn2DArray(matrix [][]int, target int) bool { 2\tn := len(matrix) 3\tif n == 0 { 4\treturn false 5\t} 6\tm := len(matrix[0]) 7\tif m == 0 { 8\treturn false 9\t} 10\tfor j, i := m-1, 0; j \u0026gt;= 0 \u0026amp;\u0026amp; i \u0026lt; n; { 11\ttmp := matrix[i][j] 12\tif tmp == target { 13\treturn true 14\t} else if tmp \u0026gt; target { 15\tj-- 16\t} else { 17\ti++ 18\t} 19\t} 20\treturn false 21} 22 23// 时间复杂度为O(m+n)，空间复杂度为O(1) 5. 替换空格 请实现一个函数，把字符串 s 中的每个空格替换成\u0026quot;%20\u0026quot;。\n示例 1：\n1输入：s = \u0026#34;We are happy.\u0026#34; 2输出：\u0026#34;We%20are%20happy.\u0026#34; 限制：\n0 \u0026lt;= s 的长度 \u0026lt;= 10000\n直接使用内置函数 1func replaceSpace(s string) string { 2 return strings.ReplaceAll(s,\u0026#34; \u0026#34;,\u0026#34;%20\u0026#34;) 3} 使用bytes.Buffer 1func replaceSpace(s string) string { 2\tl := len(s) 3\tnewStr := bytes.Buffer{} 4\tfor i := 0; i \u0026lt; l; i++ { 5\tv := s[i] 6\tif v == \u0026#39; \u0026#39; { 7\tnewStr.WriteString(\u0026#34;%20\u0026#34;) 8\tcontinue 9\t} 10\tnewStr.WriteByte(v) 11\t} 12\treturn newStr.String() 13} 6. 从尾到头打印链表 输入一个链表的头节点，从尾到头反过来返回每个节点的值（用数组返回）。\n示例 1：\n1输入：head = [1,3,2] 2输出：[2,3,1] 限制：\n0 \u0026lt;= 链表长度 \u0026lt;= 10000\n使用栈, 先入后出 1func reversePrint(head *ListNode) []int { 2 res := make([]int, 0) 3 for head != nil { 4 res = append(res, head.Val) 5 head = head.Next 6 } 7 for i, j := 0, len(res)-1; i \u0026lt; j; i, j = i+1, j-1 { 8 res[i],res[j] = res[j], res[i] 9 } 10 return res 11} 链表反转 7. 重建二叉树 输入某二叉树的前序遍历和中序遍历的结果，请重建该二叉树。假设输入的前序遍历和中序遍历的结果中都不含重复的数字。\n例如，给出\n1前序遍历 preorder = [3,9,20,15,7] 2中序遍历 inorder = [9,3,15,20,7] 返回如下的二叉树：\n1 3 2 / \\ 3 9 20 4/ \\ 515 7 限制：\n0 \u0026lt;= 节点个数 \u0026lt;= 5000\n1//* Definition for a binary tree node. 2type TreeNode struct { 3\tVal int 4\tLeft *TreeNode 5\tRight *TreeNode 6} 7 8func buildTree(preorder []int, inorder []int) *TreeNode { 9 10\tif len(preorder) == 0 { 11\treturn nil 12\t} 13 14\tif len(preorder) == 1 { 15\treturn \u0026amp;TreeNode{ 16\tVal: preorder[0], 17\tLeft: nil, 18\tRight: nil, 19\t} 20\t} 21 22\tval := preorder[0] // root val 23\tindex := 0 // inorder root index 24\tfor i, v := range inorder { 25\tif val == v { 26\tindex = i 27\tbreak 28\t} 29\t} 30\troot := TreeNode{ 31\tVal: val, 32\tLeft: buildTree(preorder[1:index+1], inorder[0:index]), 33\tRight: buildTree(preorder[index+1:], inorder[index+1:]), 34\t} 35\treturn \u0026amp;root 36} 9. 用两个栈实现队列 用两个栈实现一个队列。队列的声明如下，请实现它的两个函数 appendTail 和 deleteHead ，分别完成在队列尾部插入整数和在队列头部删除整数的功能。(若队列中没有元素，deleteHead 操作返回 -1 )\n示例 1：\n输入：\n1[\u0026#34;CQueue\u0026#34;,\u0026#34;appendTail\u0026#34;,\u0026#34;deleteHead\u0026#34;,\u0026#34;deleteHead\u0026#34;] 2[[],[3],[],[]] 3输出：[null,null,3,-1] 示例 2：\n输入：\n1[\u0026#34;CQueue\u0026#34;,\u0026#34;deleteHead\u0026#34;,\u0026#34;appendTail\u0026#34;,\u0026#34;appendTail\u0026#34;,\u0026#34;deleteHead\u0026#34;,\u0026#34;deleteHead\u0026#34;] 2[[],[],[5],[2],[],[]] 3输出：[null,-1,null,null,5,2] 提示：\n11 \u0026lt;= values \u0026lt;= 10000 2最多会对 appendTail、deleteHead 进行 10000 次调用 使用 List的Double List作为Stack\n1type CQueue struct{ 2 stack1, stack2 *list.List 3} 4 5func Constructor() CQueue{ 6 return CQueue{ 7 list.New(), 8 list.New(), 9 } 10} 11 12func (q *CQueue) AppendTail(value int){ 13 q.stack1.PushBack(value) 14} 15 16func (q *CQueue) DeleteHead() int{ 17 if q.stack2.Len() == 0{ 18 for this.stack1.Len() \u0026gt; 0{ 19 this.stack2.PushBack(this.stack1.Remove(this.stack1.Back())) 20 } 21 } 22} 自定义Stack\n1type CQueue struct{ 2 stack1, stack2 Stack 3} 4 5func Constructor() CQueue{ 6 return CQueue{ 7 Stack{}, 8 Stack{}, 9 } 10} 11 12func (q *CQueue) AppendTail(value int){ 13 q.stack1.Push(value) 14} 15 16func (q *CQueue) DeleteHead() int{ 17 if q.stack2.Len== 0{ 18 for q.stack1.Len \u0026gt; 0 { 19 q.stack2.Push(q.stack1.Pop()) 20 } 21 } 22 if q.stack2.Len != 0{ 23 return q.stack2.Pop() 24 } 25 return -1 26} 27 28 29type Stack struct { 30 Values []int 31 Len int 32} 33 34func(s *Stack) Push(value int){ 35 if len(s.Values) \u0026lt; (s.Len+1){ 36 s.Values = append(s.Values,0) 37 } 38 s.Values[s.Len] = value 39 s.Len++ 40} 41 42func(s *Stack) Pop()int{ 43 e := s.Values[s.Len-1] 44 s.Len-- 45 return e 46} 53. 在排序数组中查找数字 59. 滑动窗口的最大值 给定一个数组 nums 和滑动窗口的大小 k，请找出所有滑动窗口里的最大值。\n示例:\n1输入: nums = [1,3,-1,-3,5,3,6,7], 和 k = 3 2输出: [3,3,5,5,6,7] 3解释: 4 5 滑动窗口的位置 最大值 6--------------- ----- 7[1 3 -1] -3 5 3 6 7 3 8 1 [3 -1 -3] 5 3 6 7 3 9 1 3 [-1 -3 5] 3 6 7 5 10 1 3 -1 [-3 5 3] 6 7 5 11 1 3 -1 -3 [5 3 6] 7 6 12 1 3 -1 -3 5 [3 6 7] 7 提示：\n你可以假设 k 总是有效的，在输入数组不为空的情况下，1 ≤ k ≤ 输入数组的大小。\n1package main 2 3import ( 4\t\u0026#34;container/heap\u0026#34; 5\t\u0026#34;sort\u0026#34; 6) 7 8var a []int 9 10type hp struct{ sort.IntSlice } 11 12func (h hp) Less(i, j int) bool { return a[h.IntSlice[i]] \u0026gt; a[h.IntSlice[j]] } 13func (h *hp) Push(v interface{}) { h.IntSlice = append(h.IntSlice, v.(int)) } 14func (h *hp) Pop() interface{} { a := h.IntSlice; v := a[len(a)-1]; h.IntSlice = a[:len(a)-1]; return v } 15 16func maxSlidingWindow(nums []int, k int) []int { 17\ta = nums 18\tq := \u0026amp;hp{make([]int, k)} 19\tfor i := 0; i \u0026lt; k; i++ { 20\tq.IntSlice[i] = i 21\t} 22\theap.Init(q) 23 24\tn := len(nums) 25\tans := make([]int, 1, n-k+1) 26\tans[0] = nums[q.IntSlice[0]] 27\tfor i := k; i \u0026lt; n; i++ { 28\theap.Push(q, i) 29\tfor q.IntSlice[0] \u0026lt;= i-k { 30\theap.Pop(q) 31\t} 32\tans = append(ans, nums[q.IntSlice[0]]) 33\t} 34\treturn ans 35} 36 37func main() { 38\tmaxSlidingWindow([]int{1, 3, 9, -3, 5, 3, 6, 7}, 3) 39} ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/DataStruct/%E5%89%91%E6%8C%87offer/","summary":"编码过程中首先要校验输入数据的合法性。\n写代码之前首先想好有哪些测试用例，要提高代码的测试覆盖率。\n3. 数组中重复的数字 找出数组中重复的数字。\n在一个长度为 n 的数组 nums 里的所有数字都在 0～n-1 的范围内。数组中某些数字是重复的，但不知道有几个数字重复了，也不知道每个数字重复了几次。请找出数组中任意一个重复的数字。\n2 \u0026lt;= n \u0026lt;= 100000\n如果使用Map，则时间复杂度为O(n), 空间复杂度为O(n)。题目中的关键信息为长度为n的数组，且所有数字都在0~n-1的范围内，所以可以不用额外开辟空间。\n1func findRepeatNumber(nums []int) int { 2\tvar tmp int 3\tfor i, v := range nums { 4\tif v != i { 5\tif nums[v] == v { 6\treturn v 7\t} 8\ttmp = nums[v] 9\tnums[v] = v 10\tnums[i] = tmp 11\t} 12\t} 13\treturn -1 14} 15 16// 时间复杂度为O(n),空间复杂读为O(1) 4.","tags":null,"title":"「剑指offer」 Go语言版本"},{"categories":null,"contents":"永远不要让别人影响你的心晴\n学习好的地方，\n摒弃坏的地方，\n不要被同化\nTo Be A Nice Person.\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/life/do_not_mazy/","summary":"永远不要让别人影响你的心晴\n学习好的地方，\n摒弃坏的地方，\n不要被同化\nTo Be A Nice Person.","tags":null,"title":"「心晴」"},{"categories":null,"contents":"例题 【简单】n个活动时间，选择可以参与最多的活动\n优先选择结束最早的活动\n1package main 2 3import ( 4\t\u0026#34;fmt\u0026#34; 5\t\u0026#34;sort\u0026#34; 6) 7 8type node struct { 9\tstartAt int 10\tendAt int 11} 12 13var ( 14\ttotal int 15\tnow int 16\tres int 17\tnodeList = make([]node, 0) 18) 19 20func main() { 21\t_, _ = fmt.Scanf(\u0026#34;%d\u0026#34;, \u0026amp;total) 22\tnodeList = make([]node, total) 23\tfor i := 0; i \u0026lt; total; i++ { 24\t_, _ = fmt.Scanf(\u0026#34;%d\u0026#34;, \u0026amp;nodeList[i].startAt) 25\t_, _ = fmt.Scanf(\u0026#34;%d\u0026#34;, \u0026amp;nodeList[i].endAt) 26\t} 27 28\tsort.Slice(nodeList, func(i, j int) bool { 29\treturn nodeList[i].endAt \u0026lt; nodeList[j].endAt 30\t}) 31 32\tnow = 0 33\tres = 1 34\tfor i := 1; i \u0026lt; total; i++ { 35\tif nodeList[now].endAt \u0026lt;= nodeList[i].startAt { 36\tnow = i 37\tres++ 38\tfmt.Printf(\u0026#34;%v\\n\u0026#34;, nodeList[i]) 39\t} 40\t} 41 42\tfmt.Printf(\u0026#34;%v\u0026#34;, res) 43} 44 45/* Input 464 471 3 484 6 492 5 501 7 51 52*/ [简单]种树问题，居民要求一定\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/DataStruct/ds_greed/","summary":"例题 【简单】n个活动时间，选择可以参与最多的活动\n优先选择结束最早的活动\n1package main 2 3import ( 4\t\u0026#34;fmt\u0026#34; 5\t\u0026#34;sort\u0026#34; 6) 7 8type node struct { 9\tstartAt int 10\tendAt int 11} 12 13var ( 14\ttotal int 15\tnow int 16\tres int 17\tnodeList = make([]node, 0) 18) 19 20func main() { 21\t_, _ = fmt.Scanf(\u0026#34;%d\u0026#34;, \u0026amp;total) 22\tnodeList = make([]node, total) 23\tfor i := 0; i \u0026lt; total; i++ { 24\t_, _ = fmt.","tags":null,"title":"「算法」贪心算法"},{"categories":null,"contents":" 单链表的查询时间复杂度是O(n)\n跳表\n树\n图\nLinked List 是特殊化的Tree\nTree 是特殊化的图\n斐波那契， 状态树，递归树\n状态树空间\n决策树空间\n二叉树 满二叉树：一个二叉树的所有非叶子节点都存在左右孩子，并且所有叶子节点都在同一层级上。\n完全二叉树:\n存储结构:\n链式存储\n1// golang 2type Node struct { 3\tData int64 4\tLeftNode *Node 5\tRightNode *Node 6} // C++ struct TreeNode{ int val; TreeNode *left; TreeNode *right; TreeNode(int x): val(x), left(NULL), right(NULL){} }\n1 23. ```java 3public class TreeNode{ 4 public int val; 5 public TreeNode left,right; 6 public TreeNode(int val){ 7\tthis.val=val; 8 this.left=NULL; 9 this.right=NULL; 10 } 11} 数组: 适用于表示完全二叉树，对于稀疏二叉树是非常浪费空间的。\n1\tTree := make([]int64,1000) 2\t// 一般情况下，0 为root节点。 对于n位置的节点 左孩子 Tree[2*n-1]， 右孩子为Tree[2*n] 中序遍历，前序遍历\n1import java.util.*; 2 3public class Solutions { 4 5 public class TreeNode { 6 int val; 7 TreeNode left; 8 TreeNode right; 9 TreeNode(int x) { val = x; } 10 } 11 public TreeNode Solutions(int [] pre,int [] in) { 12 if(pre == null || in == null || pre.length == 0){ 13 return null; 14 } 15 int rootValue = pre[0]; 16 TreeNode node = new TreeNode(rootValue); 17 for(int i = 0; i \u0026lt; in.length; i++){ 18 if(in[i] == rootValue ){ 19 if(pre.length \u0026gt; 1){ 20 node.left = Solutions(Arrays.copyOfRange(pre, 1, i+1), 21 Arrays.copyOfRange(in, 0,i)); 22 node.right = Solutions(Arrays.copyOfRange(pre,i+1,pre.length), 23 Arrays.copyOfRange(in,i+1,in.length)); 24 }else{ 25 node.left = null; 26 node.right = null; 27 } 28 29 } 30 } 31 32 return node; 33 } 34 35 36 public static void main(String[] args) { 37 int[] a = new int[]{1,2,3,4,5,6,7}; 38 int[] b = new int[]{3,2,4,1,6,5,7}; 39 40 Solutions solution = new Solutions(); 41 TreeNode node = solution.Solutions(a,b); 42 System.out.println(\u0026#34;result\u0026#34;); 43 44 int i = 0; 45 46 //int s = i++ + i; 47 int tmp = i; 48 i = i +1; 49 i = tmp +i; 50 51 System.out.println( (byte)129); 52 } 53} 二叉搜索树 二叉排序树（Binary Sort Tree），又称二叉查找树（Binary Search Tree），亦称二叉搜索树。\n定义\n二叉排序树或者是一个棵空树，或者具有下列性质的二叉树\n若左子树不空，则左子树上所有节点的值均小于它的根节点的值； 若右子树不空，则右子树上所有节点的值均大于它的根节点的值； 左、右子树也分别为二叉排序树； 没有键值相等的节点。 中序遍历 ：升序排列\n左子树始终要小于右子树\n查找 时间复杂度：O(logn) 步骤：\n若根结点的关键字值等于查找的关键字，成功。 否则，若小于根结点的关键字值，递归查左子树。 若大于根结点的关键字值，递归查右子树。 若子树为空，查找不成功。 插入 首先执行查找算法，找出被插结点的父亲结点。 判断被插结点是其父亲结点的左、右儿子。将被插结点作为叶子结点插入。 若二叉树为空。则首先单独生成根结点。 注意：新插入的结点总是叶子结点。\n删除 在二叉排序树删去一个结点，分三种情况讨论：\n若*p结点为叶子结点，即PL(左子树)和PR(右子树)均为空树。由于删去叶子结点不破坏整棵树的结构，则可以直接删除此子结点。 若*p结点只有左子树PL或右子树PR，此时只要令PL或PR直接成为其双亲结点*f的左子树（当*p是左子树）或右子树（当*p是右子树）即可，作此修改也不破坏二叉排序树的特性。 若*p结点的左子树和右子树均不空。在删去*p之后，为保持其它元素之间的相对位置不变，可按中序遍历保持有序进行调整，可以有两种做法： 其一是令*p的左子树为*f的左/右(依*p是*f的左子树还是右子树而定)子树，*s为*p左子树的最右下的结点，而*p的右子树为*s的右子树； 其二是令*p的直接前驱（或直接后继）替代*p，然后再从二叉排序树中删去它的直接前驱（或直接后继）－即让*f的左子树(如果有的话)成为*p左子树的最左下结点(如果有的话)，再让*f成为*p的左右结点的父结点。 在二叉排序树上删除一个结点的算法如下： 二叉树顺序存储结构 https://www.jianshu.com/p/74490c570cc1\nhttps://blog.csdn.net/u012469528/article/details/81475824\n二叉树的遍历 深度优先遍历（前/中/后序遍历） 1# pre-order In-order Post-order 2 3func() preOrder(root TreeNode){ 4\tif root != nil{ 5\tprint(root.val) 6\tpreOrder(root.left) 7\tpreOrder(root.right) 8\t} 9} 递归遍历 1/** 2 * Definition for a binary tree node. 3 * type TreeNode struct { 4 * Val int 5 * Left *TreeNode 6 * Right *TreeNode 7 * } 8 */ 9func inorderTraversal(root *TreeNode) []int { 10 11 tmp := make([]int,0,0) 12 if root == nil{ 13 return tmp 14 } 15 if root.Left != nil{ 16 tmp = append(tmp,inorderTraversal(root.Left)... ) 17 } 18 tmp = append(tmp, root.Val) 19 if root.Right != nil{ 20 tmp = append(tmp,inorderTraversal(root.Right)... ) 21 } 22 return tmp 23} 非递归遍历 广度优先遍历（层序遍历） 优先队列（最大堆，最小堆） 平衡二叉树 平衡树，即平衡二叉树（Balanced Binary Tree），具有以下性质：它是一棵空树或它的左右两个子树的高度差的绝对值不超过1，并且左右两个子树都是一棵平衡二叉树。 平衡二叉树的常用算法有红黑树、AVL、Treap、伸展树、SBT等。\n对一棵查找树（search tree）进行查询/新增/删除 等动作, 所花的时间与树的高度h 成比例, 并不与树的容量 n 成比例。如果可以让树维持矮矮胖胖的好身材, 也就是让h维持在O(lg n)左右, 完成上述工作就很省时间。能够一直维持好身材, 不因新增删除而长歪的搜寻树, 叫做balanced search tree（平衡树）。 平衡树有很多种, 其中有几类树维持平衡的方法。\n二叉左旋 二叉右旋 红黑树 AVL 树的面试题一般都是递归，为什么\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/DataStruct/06_ds_tree/","summary":"单链表的查询时间复杂度是O(n)\n跳表\n树\n图\nLinked List 是特殊化的Tree\nTree 是特殊化的图\n斐波那契， 状态树，递归树\n状态树空间\n决策树空间\n二叉树 满二叉树：一个二叉树的所有非叶子节点都存在左右孩子，并且所有叶子节点都在同一层级上。\n完全二叉树:\n存储结构:\n链式存储\n1// golang 2type Node struct { 3\tData int64 4\tLeftNode *Node 5\tRightNode *Node 6} // C++ struct TreeNode{ int val; TreeNode *left; TreeNode *right; TreeNode(int x): val(x), left(NULL), right(NULL){} }\n1 23. ```java 3public class TreeNode{ 4 public int val; 5 public TreeNode left,right; 6 public TreeNode(int val){ 7\tthis.","tags":null,"title":"「算法与数据结构」Tree"},{"categories":null,"contents":"组合 1import java.util.*; 2 3public class Mains{ 4 public static List\u0026lt;List\u0026lt;Integer\u0026gt;\u0026gt; resultss = new ArrayList\u0026lt;\u0026gt;(); 5 6 public void combinations(List\u0026lt;Integer\u0026gt; selected, List\u0026lt;Integer\u0026gt; data, int num){ 7 if(num == 0){ 8 resultss.add(new ArrayList\u0026lt;Integer\u0026gt;(selected)); 9 return; 10 } 11 if(data.size() == 0 ){ 12 System.out.print(\u0026#34;\u0026#34;); 13 return; 14 } 15 selected.add(data.get(0)); 16 combinations(selected, data.subList(1, data.size()), num -1); 17 selected.remove(data.get(0)); 18 combinations(selected, data.subList(1, data.size()), num ); 19 } 20 public static void main(String[] args) { 21 Mains combin = new Mains(); 22 int[] nums = new int[]{1,2,3,4,5}; 23 combin.combinations(new ArrayList\u0026lt;Integer\u0026gt;(),Arrays.asList(1,2,3,4),3); 24 for (List\u0026lt;Integer\u0026gt; res : Mains.resultss) { 25 System.out.println(res.toString()); 26 } 27 } 28} 29 30/* 31Output 32 33[1, 2, 3] 34[1, 2, 4] 35[1, 3, 4] 36[2, 3, 4] 37 38*/ ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/DataStruct/ds_combine/","summary":"组合 1import java.util.*; 2 3public class Mains{ 4 public static List\u0026lt;List\u0026lt;Integer\u0026gt;\u0026gt; resultss = new ArrayList\u0026lt;\u0026gt;(); 5 6 public void combinations(List\u0026lt;Integer\u0026gt; selected, List\u0026lt;Integer\u0026gt; data, int num){ 7 if(num == 0){ 8 resultss.add(new ArrayList\u0026lt;Integer\u0026gt;(selected)); 9 return; 10 } 11 if(data.size() == 0 ){ 12 System.out.print(\u0026#34;\u0026#34;); 13 return; 14 } 15 selected.add(data.get(0)); 16 combinations(selected, data.subList(1, data.size()), num -1); 17 selected.remove(data.get(0)); 18 combinations(selected, data.subList(1, data.size()), num ); 19 } 20 public static void main(String[] args) { 21 Mains combin = new Mains(); 22 int[] nums = new int[]{1,2,3,4,5}; 23 combin.","tags":null,"title":"「算法与数据结构」排列组合"},{"categories":null,"contents":"排序算法 术语说明 稳定：如果a原本在b前面，而a=b，排序之后a仍然在b的前面；\n不稳定：如果a原本在b的前面，而a=b，排序之后a可能会出现在b的后面；\n内部排序：待排序的数据可以全部放入内存中；\n外部排序：待排序数据的数量很大，以致于内存不能一次容纳全部记录，所以在排序过程中需要对外存(磁盘)进行访问；\n时间复杂度： 一个算法执行所耗费的时间。\n空间复杂度：运行完一个程序所需内存的大小。\n排序算法总结 排序算法 平均时间复杂度 最好情况 最坏情况 空间复杂度 排序方式 稳定性 冒泡排序 O(n^2^) O(n) O(n^2^) O(1) In-place 稳定 选择排序 O(n^2^) O(n^2^) O(n^2^) O(1) In-place 不稳定 插入排序 O(n^2^) O(n) O(n^2^) O(1) In-place 稳定 希尔排序 O(n logn) O(nlog^2^n) O(nlog^2^n) O(1) In-place 不稳定 归并排序 O(n logn) O(n logn) O(n logn) O(n) Out-place 稳定 快速排序 O(n logn) O(n logn) O(n^2^) O(n logn) In-place 不稳定 堆排序 O(n logn) O(n logn) O(n logn) O(1) In-place 不稳定 计数排序 O(n+k) O(n+k) O(n+k) O(k) Out-place 稳定 桶排序 O(n+k) O(n+k) O(n^2^) O(n+k) Out-place 稳定 基数排序 O(n*k) O(n*k) O(n*k) O(n+k) Out-place 稳定 n:数据规模；k:\u0026ldquo;桶\u0026quot;的个数；n-place:占用常数内存，不占用额外内存；Out-place:占用额外内存\n算法分类 时间分类\n非线性时间比较类排序：通过比较来决定元素间的相对次序，由于其时间复杂度不能突破O(nlogn)，因此称为非线性时间比较类排序。 线性时间非比较类排序：不通过比较来决定元素间的相对次序，它可以突破基于比较排序的时间下界，以线性时间运行，因此称为线性时间非比较类排序。 比较分类\n比较：快速排序、归并排序、堆排序、冒泡排序 在排序的最终结果里，元素之间的次序依赖于它们之间的比较。每个数都必须和其他数进行比较，才能确定自己的位置。\n非比较：计数排序、基数排序、桶排序 非比较排序是通过确定每个元素之前，应该有多少个元素来排序。针对数组arr，计算arr之前有多少个元素，则唯一确定了arr在排序后数组中的位置。\n非线性时间比较类排序\n交换排序\n冒泡排序 快速排 插入排序\n简单插入排序 希尔排序 选择排序\n简单选择排序 堆排序 归并排序\n二路归并排序\n多路归并排序\n线性时间非比较类排序\n计数排序 桶排序 基数排序 冒泡排序 (Bubble Sort) 冒泡排序是一种简单的排序算法。它重复地走访过要排序的数列，一次比较两个元素，如果它们的顺序错误就把它们交换过来。走访数列的工作是重复地进行直到没有再需要交换，也就是说该数列已经排序完成。这个算法的名字由来是因为越小的元素会经由交换慢慢“浮”到数列的顶端。\n算法描述 比较相邻的元素。如果第一个比第二个大，就交换它们两个； 对每一对相邻元素作同样的工作，从开始第一对到结尾的最后一对，这样在最后的元素应该会是最大的数； 针对所有的元素重复以上的步骤，除了最后一个； 重复步骤1~3，直到排序完成。 动图演示 代码实现 1public class BubbleSort { 2 public static void bubbleSort(int[] arr) { 3 int n = arr.length; 4 int tmp; 5 for (int i = 0; i \u0026lt; n - 1; i++) { 6 for (int j = 0; j \u0026lt; n - i - 1; j++) { 7 if (arr[j] \u0026gt; arr[j + 1]) { // 相邻元素两两对比 8 tmp = arr[j]; // 元素交换 9 arr[j] = arr[j + 1]; 10 arr[j + 1] = tmp; 11 } 12 } 13 } 14 } 15 16 public static void main(String[] args) { 17 int[] arr = { 6, 1, 2, 7, 9, 3, 4, 5, 10, 8 }; 18 bubbleSort(arr); 19 for (int i = 0; i \u0026lt; arr.length; i++) { 20 System.out.print(arr[i] + \u0026#34; \u0026#34;); 21 } 22 } 23} 24 25/* Output 261 2 3 4 5 6 7 8 9 10 27*/ 选择排序（Selection Sort） 选择排序(Selection-sort)是一种简单直观的排序算法。它的工作原理：首先在未排序序列中找到最小（大）元素，存放到排序序列的起始位置，然后，再从剩余未排序元素中继续寻找最小（大）元素，然后放到已排序序列的末尾。以此类推，直到所有元素均排序完毕。\n算法描述 n个记录的直接选择排序可经过n-1趟直接选择排序得到有序结果。具体算法描述如下：\n初始状态：无序区为R[1..n]，有序区为空； 第i趟排序(i=1,2,3…n-1)开始时，当前有序区和无序区分别为R[1..i-1]和R(i..n）。该趟排序从当前无序区中-选出关键字最小的记录 R[k]，将它与无序区的第1个记录R交换，使R[1..i]和R[i+1..n)分别变为记录个数增加1个的新有序区和记录个数减少1个的新无序区； n-1趟结束，数组有序化了。 动图演示 代码实现 1public class SelectionSort { 2 public static void selectionSort(int[] arr) { 3 int n = arr.length; 4 int tmp, minIndex; 5 for (int i = 0; i \u0026lt; n - 1; i++) { 6 minIndex = i; 7 for (int j = i + 1; j \u0026lt; n; j++) { 8 if (arr[minIndex] \u0026gt; arr[j]) { 9 minIndex = j; 10 } 11 } 12 tmp = arr[i]; 13 arr[i] = arr[minIndex]; 14 arr[minIndex] = tmp; 15 } 16 } 17 18 public static void main(String[] args) { 19 int[] arr = { 6, 1, 2, 7, 9, 3, 4, 5, 10, 8 }; 20 selectionSort(arr); 21 for (int i = 0; i \u0026lt; arr.length; i++) { 22 System.out.print(arr[i] + \u0026#34;, \u0026#34;); 23 } 24 } 25} 插入排序（Insertion Sort） 插入排序（Insertion-Sort）的算法描述是一种简单直观的排序算法。它的工作原理是通过构建有序序列，对于未排序数据，在已排序序列中从后向前扫描，找到相应位置并插入。\n算法描述 一般来说，插入排序都采用in-place在数组上实现。具体算法描述如下：\n从第一个元素开始，该元素可以认为已经被排序； 取出下一个元素，在已经排序的元素序列中从后向前扫描； 如果该元素（已排序）大于新元素，将该元素移到下一位置； 重复步骤3，直到找到已排序的元素小于或者等于新元素的位置； 将新元素插入到该位置后； 重复步骤2~5。 动图演示 代码实现 1public class InsertionSort { 2 public static void insertionSort(int[] arr) { 3 int n = arr.length; 4 int preIndex, current; 5 for (int i = 1; i \u0026lt; n; i++) { 6 preIndex = i - 1; 7 current = arr[i]; 8 while (preIndex \u0026gt;= 0 \u0026amp;\u0026amp; current \u0026lt; arr[preIndex]) { 9 arr[preIndex + 1] = arr[preIndex]; 10 preIndex--; 11 } 12 arr[preIndex + 1] = current; 13 } 14 } 15 16 public static void main(String[] args) { 17 int[] arr = { 6, 1, 2, 7, 9, 3, 4, 5, 10, 8 }; 18 insertionSort(arr); 19 for (int i = 0; i \u0026lt; arr.length; i++) { 20 System.out.print(arr[i] + \u0026#34; \u0026#34;); 21 } 22 } 23} 算法分析 插入排序在实现上，通常采用in-place排序（即只需用到O(1)的额外空间的排序），因而在从后向前扫描过程中，需要反复把已排序元素逐步向后挪位，为最新元素提供插入空间。\n希尔排序（Shell Sort） 1959年Shell发明，第一个突破O(n2)的排序算法，是简单插入排序的改进版。它与插入排序的不同之处在于，它会优先比较距离较远的元素。希尔排序又叫缩小增量排序。\n算法描述 先将整个待排序的记录序列分割成为若干子序列分别进行直接插入排序，具体算法描述：\n选择一个增量序列t1，t2，…，tk，其中ti\u0026gt;tj，tk=1； 按增量序列个数k，对序列进行k 趟排序； 每趟排序，根据对应的增量ti，将待排序列分割成若干长度为m 的子序列，分别对各子表进行直接插入排序。仅增量因子为1 时，整个序列作为一个表来处理，表长度即为整个序列的长度。 动图演示 代码实现 1public class ShellSort { 2 public static void shellSort(int[] arr) { 3 int n = arr.length; 4 for (int gap = Math.floorDiv(n, 2); gap \u0026gt; 0; gap = Math.floorDiv(gap, 2)) { 5 // 注意：这里和动图演示的不一样，动图是分组执行，实际操作是多个分组交替执行 6 for (int i = gap; i \u0026lt; n; i++) { 7 int j = i; 8 int current = arr[i]; 9 while (j - gap \u0026gt;= 0 \u0026amp;\u0026amp; current \u0026lt; arr[j - gap]) { 10 arr[j] = arr[j - gap]; 11 j = j - gap; 12 } 13 arr[j] = current; 14 } 15 } 16 } 17 18 public static void main(String[] args) { 19 int[] arr = { 6, 1, 2, 7, 9, 3, 4, 5, 10, 8 }; 20 shellSort(arr); 21 for (int i = 0; i \u0026lt; arr.length; i++) { 22 System.out.print(arr[i] + \u0026#34; \u0026#34;); 23 } 24 } 25} 26/* Output 271 2 3 4 5 6 7 8 9 10 28*/ 算法分析 希尔排序的核心在于间隔序列的设定。既可以提前设定好间隔序列，也可以动态的定义间隔序列。动态定义间隔序列的算法是《算法（第4版）》的合著者Robert Sedgewick提出的。　归并排序（Merge Sort） 归并排序是建立在归并操作上的一种有效的排序算法。该算法是采用分治法（Divide and Conquer）的一个非常典型的应用。将已有序的子序列合并，得到完全有序的序列；即先使每个子序列有序，再使子序列段间有序。若将两个有序表合并成一个有序表，称为2-路归并。\n算法描述 把长度为n的输入序列分成两个长度为n/2的子序列； 对这两个子序列分别采用归并排序； 将两个排序好的子序列合并成一个最终的排序序列。 动图演示 代码实现 1import java.util.Arrays; 2 3public class MergeSort { 4 public static void main(String[] args) { 5 int[] arr = { 9, 8, 7, 6, 5, 4, 3, 2, 1 }; 6 sort(arr); 7 System.out.println(Arrays.toString(arr)); 8 } 9 10 public static void sort(int []arr){ 11 int[] temp = new int[arr.length];//在排序前，先建好一个长度等于原数组长度的临时数组，避免递归中频繁开辟空间 12 sort(arr,0,arr.length-1,temp); 13 } 14 15 private static void sort(int[] arr, int left, int right, int[] temp) { 16 if (left \u0026lt; right) { 17 int mid = (left + right) / 2; 18 sort(arr, left, mid, temp);// 左边归并排序，使得左子序列有序 19 sort(arr, mid + 1, right, temp);// 右边归并排序，使得右子序列有序 20 merge(arr, left, mid, right, temp);// 将两个有序子数组合并操作 21 } 22 } 23 24 private static void merge(int[] arr, int left, int mid, int right, int[] temp) { 25 int i = left;// 左序列指针 26 int j = mid + 1;// 右序列指针 27 int t = 0;// 临时数组指针 28 while (i \u0026lt;= mid \u0026amp;\u0026amp; j \u0026lt;= right) { 29 if (arr[i] \u0026lt;= arr[j]) { 30 temp[t++] = arr[i++]; 31 } else { 32 temp[t++] = arr[j++]; 33 } 34 } 35 while (i \u0026lt;= mid) {// 将左边剩余元素填充进temp中 36 temp[t++] = arr[i++]; 37 } 38 while (j \u0026lt;= right) {// 将右序列剩余元素填充进temp中 39 temp[t++] = arr[j++]; 40 } 41 t = 0; 42 // 将temp中的元素全部拷贝到原数组中 43 while (left \u0026lt;= right) { 44 arr[left++] = temp[t++]; 45 } 46 } 47} 算法分析 归并排序是一种稳定的排序方法。和选择排序一样，归并排序的性能不受输入数据的影响，但表现比选择排序好的多，因为始终都是O(nlogn）的时间复杂度。代价是需要额外的内存空间。\n快速排序（Quick Sort） 快速排序的基本思想：通过一趟排序将待排记录分隔成独立的两部分，其中一部分记录的关键字均比另一部分的关键字小，则可分别对这两部分记录继续进行排序，以达到整个序列有序。\n算法描述 快速排序使用分治法来把一个串（list）分为两个子串（sub-lists）。具体算法描述如下：\n从数列中挑出一个元素，称为 “基准”（pivot）； 重新排序数列，所有元素比基准值小的摆放在基准前面，所有元素比基准值大的摆在基准的后面（相同的数可以到任一边）。在这个分区退出之后，该基准就处于数列的中间位置。这个称为分区（partition）操作； 递归地（recursive）把小于基准值元素的子数列和大于基准值元素的子数列排序。 动图演示 代码实现 1public class QuickSort { 2 public static void quickSort(int[] arr, int low, int high) { 3 int i, j, temp, t; 4 if (low \u0026gt; high) { 5 return; 6 } 7 i = low; 8 j = high; 9 // temp就是基准位 10 temp = arr[low]; 11 while (i \u0026lt; j) { 12 // 先看右边，依次往左递减 13 while (temp \u0026lt;= arr[j] \u0026amp;\u0026amp; i \u0026lt; j) { 14 j--; 15 } 16 // 再看左边，依次往右递增 17 while (temp \u0026gt;= arr[i] \u0026amp;\u0026amp; i \u0026lt; j) { 18 i++; 19 } 20 // 如果满足条件则交换 21 if (i \u0026lt; j) { 22 t = arr[j]; 23 arr[j] = arr[i]; 24 arr[i] = t; 25 } 26 27 } 28 // 最后将基准为与i和j相等位置的数字交换 29 arr[low] = arr[i]; 30 arr[i] = temp; 31 // 递归调用左半数组 32 quickSort(arr, low, j - 1); 33 // 递归调用右半数组 34 quickSort(arr, j + 1, high); 35 } 36 37 public static void main(String[] args) { 38 int[] arr = { 6, 1, 2, 7, 9, 3, 4, 5, 10, 8 }; 39 quickSort(arr, 0, arr.length - 1); 40 for (int i = 0; i \u0026lt; arr.length; i++) { 41 System.out.print(arr[i] + \u0026#34; \u0026#34;); 42 } 43 } 44} 堆排序（Heap Sort） 堆排序（Heapsort）是指利用堆这种数据结构所设计的一种排序算法。堆积是一个近似完全二叉树的结构，并同时满足堆积的性质：即子结点的键值或索引总是小于（或者大于）它的父节点。\n算法描述 将初始待排序关键字序列(R1,R2….Rn)构建成大顶堆，此堆为初始的无序区； 将堆顶元素R[1]与最后一个元素R[n]交换，此时得到新的无序区(R1,R2,……Rn-1)和新的有序区(Rn),且满足R[1,2…n-1]\u0026lt;=R[n]； 由于交换后新的堆顶R[1]可能违反堆的性质，因此需要对当前无序区(R1,R2,……Rn-1)调整为新堆，然后再次将R[1]与无序区最后一个元素交换，得到新的无序区(R1,R2….Rn-2)和新的有序区(Rn-1,Rn)。不断重复此过程直到有序区的元素个数为n-1，则整个排序过程完成。 动图演示 代码实现 计数排序（Counting Sort） 计数排序不是基于比较的排序算法，其核心在于将输入的数据值转化为键存储在额外开辟的数组空间中。 作为一种线性时间复杂度的排序，计数排序要求输入的数据必须是有确定范围的整数。\n算法描述 找出待排序的数组中最大和最小的元素； 统计数组中每个值为i的元素出现的次数，存入数组C的第i项； 对所有的计数累加（从C中的第一个元素开始，每一项和前一项相加）； 反向填充目标数组：将每个元素i放在新数组的第C(i)项，每放一个元素就将C(i)减去1。 动图演示 算法分析 计数排序是一个稳定的排序算法。当输入的元素是 n 个 0到 k 之间的整数时，时间复杂度是O(n+k)，空间复杂度也是O(n+k)，其排序速度快于任何比较排序算法。当k不是很大并且序列比较集中时，计数排序是一个很有效的排序算法。\n##桶排序（Bucket Sort）\n桶排序是计数排序的升级版。它利用了函数的映射关系，高效与否的关键就在于这个映射函数的确定。桶排序 (Bucket sort)的工作的原理：假设输入数据服从均匀分布，将数据分到有限数量的桶里，每个桶再分别排序（有可能再使用别的排序算法或是以递归方式继续使用桶排序进行排）。\n算法描述? 设置一个定量的数组当作空桶； 遍历输入数据，并且把数据一个一个放到对应的桶里去； 对每个不是空的桶进行排序； 从不是空的桶里把排好序的数据拼接起来。 图片演示 代码实现 算法分析 桶排序最好情况下使用线性时间O(n)，桶排序的时间复杂度，取决与对各个桶之间数据进行排序的时间复杂度，因为其它部分的时间复杂度都为O(n)。很显然，桶划分的越小，各个桶之间的数据越少，排序所用的时间也会越少。但相应的空间消耗就会增大。\n基数排序（Radix Sort） 基数排序是按照低位先排序，然后收集；再按照高位排序，然后再收集；依次类推，直到最高位。有时候有些属性是有优先级顺序的，先按低优先级排序，再按高优先级排序。最后的次序就是高优先级高的在前，高优先级相同的低优先级高的在前。\n算法描述 取得数组中的最大数，并取得位数； arr为原始数组，从最低位开始取每个位组成radix数组； 对radix进行计数排序（利用计数排序适用于小范围数的特点）； 动图演示 算法分析 基数排序基于分别排序，分别收集，所以是稳定的。但基数排序的性能比桶排序要略差，每一次关键字的桶分配都需要O(n)的时间复杂度，而且分配之后得到新的关键字序列又需要O(n)的时间复杂度。假如待排数据可以分为d个关键字，则基数排序的时间复杂度将是O(d*2n) ，当然d要远远小于n，因此基本上还是线性级别的。\n基数排序的空间复杂度为O(n+k)，其中k为桶的数量。一般来说n\u0026raquo;k，因此额外空间需要大概n个左右。\n基数排序 vs 计数排序 vs 桶排序\n这三种排序算法都利用了桶的概念，但对桶的使用方法上有明显差异：\n基数排序：根据键值的每位数字来分配桶 计数排序：每个桶只存储单一键值 桶排序：每个桶存储一定范围的数值 参考链接 https://www.cnblogs.com/onepixel/articles/7674659.html\nhttps://www.cnblogs.com/guoyaohua/p/8600214.html\nhttps://blog.csdn.net/zhangshk_/article/details/82911093\nhttps://blog.csdn.net/meibenxiang/article/details/92796909\nhttps://www.cnblogs.com/itsharehome/p/11058010.html\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/DataStruct/ds_sort/","summary":"排序算法 术语说明 稳定：如果a原本在b前面，而a=b，排序之后a仍然在b的前面；\n不稳定：如果a原本在b的前面，而a=b，排序之后a可能会出现在b的后面；\n内部排序：待排序的数据可以全部放入内存中；\n外部排序：待排序数据的数量很大，以致于内存不能一次容纳全部记录，所以在排序过程中需要对外存(磁盘)进行访问；\n时间复杂度： 一个算法执行所耗费的时间。\n空间复杂度：运行完一个程序所需内存的大小。\n排序算法总结 排序算法 平均时间复杂度 最好情况 最坏情况 空间复杂度 排序方式 稳定性 冒泡排序 O(n^2^) O(n) O(n^2^) O(1) In-place 稳定 选择排序 O(n^2^) O(n^2^) O(n^2^) O(1) In-place 不稳定 插入排序 O(n^2^) O(n) O(n^2^) O(1) In-place 稳定 希尔排序 O(n logn) O(nlog^2^n) O(nlog^2^n) O(1) In-place 不稳定 归并排序 O(n logn) O(n logn) O(n logn) O(n) Out-place 稳定 快速排序 O(n logn) O(n logn) O(n^2^) O(n logn) In-place 不稳定 堆排序 O(n logn) O(n logn) O(n logn) O(1) In-place 不稳定 计数排序 O(n+k) O(n+k) O(n+k) O(k) Out-place 稳定 桶排序 O(n+k) O(n+k) O(n^2^) O(n+k) Out-place 稳定 基数排序 O(n*k) O(n*k) O(n*k) O(n+k) Out-place 稳定 n:数据规模；k:\u0026ldquo;桶\u0026quot;的个数；n-place:占用常数内存，不占用额外内存；Out-place:占用额外内存","tags":null,"title":"「算法与数据结构」排序算法"},{"categories":null,"contents":"二分查找 1public class BinarySearch{ 2 public static void main(String[] args) { 3 int[] arr = {1,2,3,4,5,6,7,8}; 4 int k = 8; 5 System.out.println(binarySerach(arr, k)); 6 } 7 8 public static int binarySerach(int[] arr, int k){ 9 int a = 0; 10 int b = arr.length; 11 12 while(a \u0026lt; b){ 13 int mid = a+(b-a)/2; 14 if(k \u0026lt; arr[mid]){ 15 b = mid; 16 }else if(k \u0026gt; arr[mid]){ 17 a = mid + 1; 18 }else{ 19 return mid; 20 } 21 } 22 return -1; 23 24 } 25} ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/DataStruct/ds_find/","summary":"二分查找 1public class BinarySearch{ 2 public static void main(String[] args) { 3 int[] arr = {1,2,3,4,5,6,7,8}; 4 int k = 8; 5 System.out.println(binarySerach(arr, k)); 6 } 7 8 public static int binarySerach(int[] arr, int k){ 9 int a = 0; 10 int b = arr.length; 11 12 while(a \u0026lt; b){ 13 int mid = a+(b-a)/2; 14 if(k \u0026lt; arr[mid]){ 15 b = mid; 16 }else if(k \u0026gt; arr[mid]){ 17 a = mid + 1; 18 }else{ 19 return mid; 20 } 21 } 22 return -1; 23 24 } 25} ","tags":null,"title":"「算法与数据结构」查找算法"},{"categories":null,"contents":"单向链表 1import java.util.*; 2class Node{ 3 private final int value; 4 private Node next; 5 6 public Node(int value){ 7 this.value = value; 8 this.next = null; 9 } 10 public int getValue(){ 11 return this.value; 12 } 13 public Node getNext(){ 14 return this.next; 15 } 16 public void setNext(Node next){ 17 this.next = next; 18 } 19 20 public static void printLinkedList(Node head){ 21 while(head != null){ 22 System.out.print(head.getValue()); 23 System.out.print(\u0026#34; \u0026#34;); 24 head = head.next; 25 } 26 System.out.println(\u0026#34;\u0026#34;); 27 } 28 29} 30class LinkedListCreator{ 31 public Node createLinkedList(List\u0026lt;Integer\u0026gt; data){ 32 if(data.isEmpty()){ 33 return null; 34 } 35 Node firstNode = new Node(data.get(0)); 36 firstNode.setNext(createLinkedList(data.subList(1,data.size()))); 37 return firstNode; 38 } 39} 40 41class LinkedListReverser{ 42 public Node reverseLinkedList(Node head){ 43 if(head==null || head.getNext()==null){ 44 return head; 45 } 46 Node newHead = reverseLinkedList(head.getNext()); 47 head.getNext().setNext(head); 48 head.setNext(null); 49 return newHead; 50 } 51} 52 53public class Main { 54 public static void main(String[] args) { 55 LinkedListCreator creator = new LinkedListCreator(); 56 LinkedListReverser reverser = new LinkedListReverser(); 57 58 // Node.printLinkedList(creator.createLinkedList(Arrays.asList(1))); 59 Node.printLinkedList(reverser.reverseLinkedList(creator.createLinkedList(Arrays.asList(1,2,3,4,5)))); 60 61 System.out.println(\u0026#34;Hello World!\u0026#34;); 62 } 63} 双向链表 1import java.util.*; 2 3class Node { 4 private Integer value; 5 private Node next; 6 7 public Node(Integer value) { 8 this.value = value; 9 this.next = null; 10 } 11 12 public Integer getValue() { 13 return this.value; 14 } 15 16 public void setNext(Node next) { 17 this.next = next; 18 } 19 20 public Node getNext() { 21 return this.next; 22 } 23 24 public static void printLinkedList(Node head) { 25 while (head != null) { 26 System.out.print(head.getValue()); 27 System.out.print(\u0026#34; \u0026#34;); 28 head = head.getNext(); 29 } 30 System.out.println(); 31 } 32} 33 34class LinkedListCreator { 35 public Node createLinkedList(List\u0026lt;Integer\u0026gt; data) { 36 Node head = null; 37 Node prev = null; 38 for (Integer i : data) { 39 Node node = new Node(i); 40 if (prev != null) { 41 prev.setNext(node); 42 } else { 43 head = node; 44 } 45 prev = node; 46 } 47 return head; 48 49 } 50} 51 52class LinkedListReverser { 53 public Node reverseLinkedList(Node head) { 54 Node newHead = null; 55 Node curHead = head; 56 while (curHead != null) { 57 Node node = curHead.getNext(); 58 curHead.setNext(newHead); 59 newHead = curHead; 60 curHead = node; 61 } 62 return newHead; 63 } 64} 65 66class LinkedListDeleter { 67 public Node deleteIfEqual(Node head, int value) { 68 while (head != null \u0026amp;\u0026amp; head.getValue() == value) { 69 head = head.getNext(); 70 } 71 Node curNode = head; 72 while (curNode.getNext() != null) { 73 if (curNode.getNext().getValue() == value) { 74 curNode.setNext(curNode.getNext().getNext()); 75 } else { 76 curNode = curNode.getNext(); 77 } 78 } 79 80 return head; 81 82 } 83} 84 85public class Main { 86 87 public static Node deleteNodeEquals(Node head, int value){ 88 while(head != null \u0026amp;\u0026amp; head.getValue() == value){ 89 head = head.getNext(); 90 } 91 Node curNode = head; 92 while(curNode.getNext() != null){ 93 if(curNode.getNext().getValue() == value){ 94 curNode.setNext(curNode.getNext().getNext()); 95 }else{ 96 curNode = curNode.getNext(); 97 } 98 } 99 return head; 100 } 101 public static void main(String[] args) { 102 LinkedListCreator creator = new LinkedListCreator(); 103 LinkedListReverser reverser = new LinkedListReverser(); 104 LinkedListDeleter deleter = new LinkedListDeleter(); 105 106 Node.printLinkedList(creator.createLinkedList(Arrays.asList(1, 2, 3, 4, 5, 6))); 107 Node.printLinkedList(reverser.reverseLinkedList(creator.createLinkedList(Arrays.asList(1, 2, 3, 4, 5, 6)))); 108 Node.printLinkedList(deleter.deleteIfEqual(creator.createLinkedList(Arrays.asList(1, 2, 3, 4, 5, 6)), 6)); 109 110 111 Node.printLinkedList(deleteNodeEquals(creator.createLinkedList(Arrays.asList(1,2,3,4,5,6,7)), 5)); 112 113 System.out.println(\u0026#34;Hello World!\u0026#34;); 114 } 115} ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/DataStruct/ds_linkedlist/","summary":"单向链表 1import java.util.*; 2class Node{ 3 private final int value; 4 private Node next; 5 6 public Node(int value){ 7 this.value = value; 8 this.next = null; 9 } 10 public int getValue(){ 11 return this.value; 12 } 13 public Node getNext(){ 14 return this.next; 15 } 16 public void setNext(Node next){ 17 this.next = next; 18 } 19 20 public static void printLinkedList(Node head){ 21 while(head != null){ 22 System.","tags":null,"title":"「算法与数据结构」链表"},{"categories":null,"contents":"What is the network layer? Network-to-network connections are what make the Internet possible. The \u0026ldquo;network layer\u0026rdquo; is the part of the Internet communications process where these connections occur, by sending packets of data back and forth between different networks, In the 7-layer OSI model, the network layer is layer 3. The Internet Protocol(IP) is one of the main protocols used at this layer, along with several other protocols for routing, resting and encryption.\nSuppose Bob and Alice are connected to the same local area network(LAN), and Bob wants to send Alice a message. Because Bob is on the same network with Alice, he could send it directly to her computer across the network. However, if Alice is instead on a different LAN several miles away, Bob\u0026rsquo;s message will have to be addressed and sent to Alice\u0026rsquo;s network before it can reach her computer, which is a network layer process.\nWhat is a network? A network is a group of two or more connected computing devices. Usually all devices in the network are connected to a central hub\u0026ndash; for instance, a router. A network can also include subnetworks, or smaller subdivisions of the network. Sub-networking is how very large networks, such as those provided by ISPs, are able to manage thousands of IP addresses and connected devices.\nThink of the internet ad a network of networks: computers are connected to each other within networks, and these networks connect to other networks. This enable these computers to connect with other computers both near and far.\nWhat happens at the network layer? Anything that has to do with inter-network connections takes place at the network layer. This includes setting up the routes for data packets to take, checking to see if a server in another network is up and running, and addressing and receiving IP packets from other networks. This last process is perhaps the most important, as the vast majority of the internet traffic is sent over IP.\nWhat is a packet? All data sent over the Internet is broken down into smaller chunks called \u0026ldquo;packets\u0026rdquo;. When Bob send Alice a message, for instance, his message is broken down into smaller pieces and the reassembled on Alice\u0026rsquo;s computer. A packets has two parts: the header, which contains information about the packets itself, and the body, which is the actual data being sent.\nAt the network layer, networking software attaches a header to each packet when the packet is sent out over the Internet, and on the other end, networking software can use the header to understand how to handle the packet.\nA header contains information about the content, source, and destination of each packet(somewhat link stamping an envelope with a destination and return address). For example, an IP header contains the destination IP address of each packet, the total size of the packets, an indication of weather or not the packet has been fragmented(broken up into still smaller pieces)in transit, and a count of how many networks the packets has traveled through.\nWhat is the OSI model? The Open System Interconnection(OSI) Model is a description of how the Internet works. It breaks down the functions involved in sending data over the Internet into seven layers. Each layer has some function that prepares the data to be sent over wires, cables, and radio waves ad a series of bits.\nThe server layers of the OSI model are:\n7.Application layer: Data generated by and usable by software applications. The main protocol user ad this layer is HTTP.\n6.Presentation layer: Data is translated into a form the application can accept. Some authorities consider HTTPS encryption and decryption to take place at this layer.\n5.Session layer: Controls connection between computers(this can also be handle at layer 4 by the TCP protocol).\n4.Transport layer: Provides the means for transmitting data between two connected parties, as wells as controlling the quality of service. The main protocol used here are TCP and UDP.\n3.Network layer: Handles the routing and sending of data between different networks. The most important protocols at this layer are IP and ICMP.\n2.Data link layer: Handle communications between devices on the same network. If layer 3 is like the address on a piece of mail, the layer 2 is like indicating the office number or apartment number at the address. Ethernet is the protocol most used here.\n1.Physical layer: Packets are converted into electrical, radio, or optical pulses and transmitted at bits(the smallest possible units of information) over wires, radio waves, or cables.\nIt is important to keep in mind that the OSI model is an abstract conceptualization of the process that make the Internet work, and interpreting and applying the models to the real-world Internet is sometime a subjective exercise.\nThe OSI model is useful for helping people talk about networking equipment and protocols, determining which protocols are used by which software and hardware, and showing roughly how the Internet works. But it is not a rigid step-by-step definition of how Internet connections always function.\nOSI model vs. TCP/IP model The TCP/IP model is alternative model of how the Internet works. It divides the processes involved in to four layers instead of seven. Some would argue the the TCP/IP model better reflects the way the Internet functions today, but the OSI model is still widely referenced for understanding the Internet, and both models have their strengths and weaknesses.\n4.Application layer: This corresponds, approximately, to layer 7 in the OSI model. 3.Transport layer: Corresponds to layer 4 in the OSI model. 2.Internet layer: Corresponds to layer3 in the OSI model. 1.Network access layer: Combines the process of layer 1 and 2 in the OSI model. But where are the OSI layers 5 and 6 in the TCP/IP model? Some source hold that the process at OSI layer 5 and 6 either no longer necessary in the modern Internet, or actually belong to layer 7 and 4(represented by layer 4 and 3 in the TCP/IP model).\nFor instance, since the TCP protocol opens and maintains sessions at OSI layer 4, one could consider OSI layer 5(the \u0026ldquo;session\u0026rdquo; layer) to be unnecessary \u0026ndash; and it is not represented in the TCP/IP model. Additionally, HTTPS encryption and decryption can be considered an application layer (OSI layer7 or TCP/IP layer 4) process instead of a presentation layer(OSI layer 6) process.\nWhat the difference between the network layer and the Internet layer In the TCP/IP model, there is no \u0026ldquo;network\u0026rdquo; layer. The OSI model network layer roughly corresponds to the TCP/IP model Internet layer. In the OSI model network layer is layer 3; in the TCP/IP model the Internet layer is layer 2.\nIn other words, the network layer and the Internet layer are basically the same thing, but the come from different models of how the Internet works.\nWhat the protocols are used at the network layer? A protocol is an agreed-upon way of formatting data so that two or more devices are able to communicate with and understand each other. A number of different protocols make connections, testing, routing and encryption possible at the network layer, including:\nIP IPsec ICMP IGMP GRE Because they are exposed to the rest of the Internet, network layer infrastructure is vulnerable to external attacks, especially distributed denial-of-service(DDoS) attacks. Router, switches, and other network interfaces can all be overwhelmed and compromised by malicious network traffic, and almost any of the above network protocols can be used in an attack.\nxxx protect networking infrastructure using the same technology that keeps millions of web properties up and running in the face of vulnerability exploits and DDoS attacks. It extends the protection to on-premise and data center networks, keep organizations secure from layer attacks.\nWhat is MSS(maximum segment size)? MSS, or maximum segment size, is the largest data payload that a device will accept form a network connection.\nMSS(maximum segment size) limits the size of packets, or small chunks of data, the travel sccross a network, such as the internel. All data that travels over a network is broken up into packets. Packets have serveral headers attached to them that contain information about their contents and destination. MSS measures the non-header portion of a packet, which is called the payload.\nNetwork Deivice Hub\nSwitch/ 2 layer switch/3 layer switch/ VLAN\nBridge\nRouter/NAT/SNAT/DNAT\n网络相关命令 ipstable\nifconfig/网卡up and down\nroute\n一个机器如果有连个网卡\n一个交换机下两个网段，为什么不可以互相通信\n一个交换机下连个网段是否可以独立通信\n路由器原理，使用其中的一个linux作为网关\nReference\nhttps://www.cloudflare.com/learning/network-layer/what-is-mss/\nhttps://www.cloudflare.com/learning/network-layer/what-is-the-network-layer/\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/linux/network_base/","summary":"What is the network layer? Network-to-network connections are what make the Internet possible. The \u0026ldquo;network layer\u0026rdquo; is the part of the Internet communications process where these connections occur, by sending packets of data back and forth between different networks, In the 7-layer OSI model, the network layer is layer 3. The Internet Protocol(IP) is one of the main protocols used at this layer, along with several other protocols for routing, resting and encryption.","tags":null,"title":"「网络」网络基础"},{"categories":null,"contents":"ITX机箱 详设计一个属于自己的ITX机箱\n装机清单 参考链接 ITX机箱图纸参考链接 https://sff.design/1210.html https://sff.design/15201.html ACC X11参考链接 https://item.jd.com/10024295444328.html#crumb-wrap\ngpp https://www.kyairsoft.com/4-3-desert-warrior-full-marking.html\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/life/itx_%E6%9C%BA%E7%AE%B1%E8%AE%BE%E8%AE%A1/","summary":"ITX机箱 详设计一个属于自己的ITX机箱\n装机清单 参考链接 ITX机箱图纸参考链接 https://sff.design/1210.html https://sff.design/15201.html ACC X11参考链接 https://item.jd.com/10024295444328.html#crumb-wrap\ngpp https://www.kyairsoft.com/4-3-desert-warrior-full-marking.html","tags":null,"title":"「装机」 ITX A4机箱设计"},{"categories":null,"contents":"网络硬件 双绞线 类型 五类线CAT5 超五类线CAT5e 六类线CAT6 超六类线CATT6e 七类线CAT7 频率带宽 100MHz 100MHz 200MHz 500MHz 600MHz 传输速率 100Mbps 1000Mbps 1000Mbps 1Gbps 10Gbps 最大长度 100m 100m 100m 55m 屏蔽类型 屏蔽/非屏蔽 屏蔽/非屏蔽 屏蔽/非屏蔽 屏蔽/非屏蔽 双层屏蔽 双绞线线序 直通，交叉(主要用于对等设备的通信)\n标准 1 2 3 4 5 6 7 8 EIA/TIA 568A 绿白 绿 橙白 蓝 蓝白 橙 棕白 棕 EIA/TIA 568B 橙白 橙 绿白 蓝 蓝白 绿 棕白 棕 ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/interview/cs_basic/network_basic/","summary":"网络硬件 双绞线 类型 五类线CAT5 超五类线CAT5e 六类线CAT6 超六类线CATT6e 七类线CAT7 频率带宽 100MHz 100MHz 200MHz 500MHz 600MHz 传输速率 100Mbps 1000Mbps 1000Mbps 1Gbps 10Gbps 最大长度 100m 100m 100m 55m 屏蔽类型 屏蔽/非屏蔽 屏蔽/非屏蔽 屏蔽/非屏蔽 屏蔽/非屏蔽 双层屏蔽 双绞线线序 直通，交叉(主要用于对等设备的通信)\n标准 1 2 3 4 5 6 7 8 EIA/TIA 568A 绿白 绿 橙白 蓝 蓝白 橙 棕白 棕 EIA/TIA 568B 橙白 橙 绿白 蓝 蓝白 绿 棕白 棕 ","tags":null,"title":"「计算机网络」 计算机网络串讲"},{"categories":null,"contents":"1# 通过Pid获取对应的service 2systemd status \u0026lt;Pid\u0026gt; ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/linux/linux_systemd/","summary":"1# 通过Pid获取对应的service 2systemd status \u0026lt;Pid\u0026gt; ","tags":null,"title":"【Linux】 Systemd"},{"categories":null,"contents":"1 短地址服务 将长地址缩短到一个很短的地址，用户访问这个短地址可以重定向到原本的长地址。\n如何设计HTTP Router 和handler 如何在HTTP 处理流程中加入Middleware 如何利用Go的Interface来实现可扩展的设计 如何使用redis的自增长序列生成短地址 2 主服务模块 API接口 POST /api/shorten GET /api/info?shortlink=shortlink GET /:shortlink - return 302 code 重定向 POST /api/shorten Params\nName Type Description url string Required. URL to shorten. e.g. https://www.example.com expiration_in_minutes int Required. Expiration of short link in minutes. e.g. value 0 represents permanent. Response\n1{ 2 \u0026#34;shortlink\u0026#34;:\u0026#34;P\u0026#34; 3} GET /api/info?shortlink=shortlink Params\nName Type Description shortlink string Required. Id of shortened. e.g. P Response\n1{ 2 \u0026#34;url\u0026#34;:\u0026#34;https://www.example.com\u0026#34;, 3 \u0026#34;created_at\u0026#34;: \u0026#34;2022-03-09 23:07:03\u0026#34;, 4 \u0026#34;expiration_in_minutes\u0026#34;: 60 5} GET /:shortlink - return 302 code 重定向 Redirect 302 临时重定向；301会永久保存在用户的缓存中。\n一个完整的HTTP 处理流程\nMiddleware 是一个pipeline：认证，鉴权，log\nMux中router和Handler设计 gorilla/mux 处理router 和handler\n1func main(){ 2 r := mux.NewRouter() 3 r.HandleFunc(\u0026#34;/\u0026#34;, HomeHandler) 4 r.HandleFunc(\u0026#34;/product\u0026#34;, ProductsHandler) 5 r.HandleFunc(\u0026#34;/articles\u0026#34;,ArticlesHandler) 6 http.Handle(\u0026#34;/\u0026#34;,r) 7} 实现router和handler 工程代码\n1➜ goshorten tree 2. 3├── app.go 4└── main.go main.go\n1package main 2 3func main() { 4 a := App{} 5 a.Initialize() 6 a.Run(\u0026#34;:8000\u0026#34;) 7} app.go\n1package main 2 3import ( 4\t\u0026#34;encoding/json\u0026#34; 5\t\u0026#34;fmt\u0026#34; 6\t\u0026#34;io\u0026#34; 7\t\u0026#34;log\u0026#34; 8\t\u0026#34;net/http\u0026#34; 9 10\t\u0026#34;github.com/gorilla/mux\u0026#34; 11\t\u0026#34;gopkg.in/validator.v2\u0026#34; 12) 13 14// App encapsulate Env, Router and middleware 15type App struct { 16\tRouter *mux.Router 17} 18 19type shortenReq struct { 20\tURL string `json:\u0026#34;url\u0026#34; validate:\u0026#34;nonzero\u0026#34;` 21\tExpirationInMinutes int64 `json:\u0026#34;expiration_in_minutes\u0026#34; validate:\u0026#34;min=0\u0026#34;` 22} 23 24type shortlinkResp struct { 25\tShortLink string `json:\u0026#34;shortlink\u0026#34;` 26} 27 28// Initialize is initialization of app 29func (a *App) Initialize() { 30\t// set log formatter 31\tlog.SetFlags(log.LstdFlags | log.Lshortfile) 32\ta.Router = mux.NewRouter() 33\ta.initializeRouters() 34} 35 36func (a *App) initializeRouters() { 37 38\ta.Router.HandleFunc(\u0026#34;/api/shorten\u0026#34;, a.createShortLink).Methods(\u0026#34;POST\u0026#34;) 39\ta.Router.HandleFunc(\u0026#34;/api/info\u0026#34;, a.getShortLinkInfo).Methods(\u0026#34;GET\u0026#34;) 40\ta.Router.HandleFunc(\u0026#34;/{shortlink:[a-zA-Z0-9]{1,11}}\u0026#34;, a.redirect).Methods(\u0026#34;GET\u0026#34;) 41} 42 43func (a *App) createShortLink(w http.ResponseWriter, r *http.Request) { 44\tvar req shortenReq 45\tif err := json.NewDecoder(r.Body).Decode(\u0026amp;req); err != nil { 46\treturn 47\t} 48\tif err := validator.Validate(req); err != nil { 49\treturn 50\t} 51\tdefer func(Body io.ReadCloser) { 52\t_ = Body.Close() 53\t}(r.Body) 54 55\tfmt.Printf(\u0026#34;%v\\n\u0026#34;, req) 56} 57 58func (a *App) getShortLinkInfo(w http.ResponseWriter, r *http.Request) { 59 60\tvars := r.URL.Query() 61\ts := vars.Get(\u0026#34;shortlink\u0026#34;) 62 63\tfmt.Printf(\u0026#34;%s\\n\u0026#34;, s) 64} 65 66func (a *App) redirect(w http.ResponseWriter, r *http.Request) { 67 68\tvars := mux.Vars(r) 69\tfmt.Printf(\u0026#34;%s\\n\u0026#34;, vars[\u0026#34;shortlink\u0026#34;]) 70} 71 72// Run starts listen and serve 73func (a *App) Run(addr string) { 74\tlog.Fatal(http.ListenAndServe(addr, a.Router)) 75} 测试API 1curl -X POST \\ 2 http://localhost:8000/api/shorten \\ 3 -d \u0026#39;{\u0026#34;url\u0026#34;:\u0026#34;www.baidu.com\u0026#34;,\u0026#34;expiration_in_minutes\u0026#34;:1}\u0026#39; 4 5curl -X GET \\ 6 \u0026#39;http://localhost:8000/api/info?shortlink=hi\u0026#39; 7 8curl -X GET \\ 9 http://localhost:8000/A 错误处理设计 An interface type is defined as a set of method signatures.\n一个接口是一系列方法签名的集合\nA values of interface type can hold any value that implements those methods.\n一个接口的类型 可以接受任何实现了接口方法的对象\n1// Go 的内置接口 2type error interface{ 3 Error() string 4} 1err := errors.New(\u0026#34;Error message!\u0026#34;) 2if err != nil{ 3 fmt.Print(err) 4} 工程代码\n1. 2├── app.go 3├── error.go 4└── main.go error.go\n1package main 2 3type Error interface { 4 error 5 Status() int 6} 7 8type StatusError struct { 9 Code int 10 Err error 11} 12 13func (se StatusError) Error() string { // (se *StatusError) 区别 14 return se.Err.Error() 15} 16 17func (se StatusError) Status() int { 18 return se.Code 19} app.go\n1func (a *App) createShortLink(w http.ResponseWriter, r *http.Request) { 2\tvar req shortenReq 3\tif err := json.NewDecoder(r.Body).Decode(\u0026amp;req); err != nil { 4\tresponseWithError(w, StatusError{http.StatusBadRequest, 5\tfmt.Errorf(\u0026#34;prase parameters failed %v\u0026#34;, r.Body)}) 6\treturn 7\t} 8\tif err := validator.Validate(req); err != nil { 9\tresponseWithError(w, StatusError{http.StatusBadRequest, 10\tfmt.Errorf(\u0026#34;validate parameters failed %v\u0026#34;, req)}) 11\treturn 12\t} 13\tdefer func(Body io.ReadCloser) { 14\t_ = Body.Close() 15\t}(r.Body) 16 17\tfmt.Printf(\u0026#34;%v\\n\u0026#34;, req) 18} 19 20func responseWithError(w http.ResponseWriter, err error) { 21\tswitch e := err.(type) { 22\tcase Error: 23\tlog.Printf(\u0026#34;HTTP %d - %s\u0026#34;, e.Status(), e) 24\tresponseWithJSON(w, e.Status(), e.Error()) 25\tdefault: 26\tresponseWithJSON(w, http.StatusInternalServerError, 27\thttp.StatusText(http.StatusInternalServerError)) 28\t} 29 30} 31 32func responseWithJSON(w http.ResponseWriter, code int, payload interface{}) { 33\tresp, _ := json.Marshal(payload) 34\tw.Header().Set(\u0026#34;Content-Type\u0026#34;, \u0026#34;application/json\u0026#34;) 35\tw.WriteHeader(code) 36\t_, _ = w.Write(resp) 37} 3 中间件模块 Middleware Log Middleware\nRecover Middleware\nmiddleware.go\n1package main 2 3import ( 4\t\u0026#34;log\u0026#34; 5\t\u0026#34;net/http\u0026#34; 6\t\u0026#34;time\u0026#34; 7) 8 9type Middleware struct { 10} 11 12//LoggingHandler log the time-consuming of http request 13func (m Middleware) LoggingHandler(next http.Handler) http.Handler { 14\tfn := func(w http.ResponseWriter, r *http.Request) { 15\tt1 := time.Now() 16\tnext.ServeHTTP(w, r) 17\tt2 := time.Now() 18\tlog.Printf(\u0026#34;[%s] %q %v\u0026#34;, r.Method, r.URL.String(), t2.Sub(t1)) 19\t} 20 21\t// adaptor 22\treturn http.HandlerFunc(fn) 23} 24 25// RecoverHandler recover panic 26func (m Middleware) RecoverHandler(next http.Handler) http.Handler { 27\tfn := func(w http.ResponseWriter, r *http.Request) { 28\tdefer func() { 29\tif err := recover(); err != nil { 30\tlog.Printf(\u0026#34;Recover from panic: %+v\u0026#34;, err) 31\thttp.Error(w, http.StatusText(500), 500) 32\t} 33\t}() 34\tnext.ServeHTTP(w, r) 35\t} 36\treturn http.HandlerFunc(fn) 37} Alice包的使用 Alice provide a convenient way to chain your HTTP middleware function and the app handler. 1Middleware1(Middlerware2(Middlerware3(app))) 2 3alice.New(Middlerware1, Middleware2, Middleware3).Then(app) 4 存储模块 Storage 如何生成短地址 INCR key 1redis\u0026gt; SET mykey \u0026#34;10\u0026#34; 2\u0026#34;OK\u0026#34; 3redis\u0026gt;INCR mykey 4(integer) 11 5redis\u0026gt;get mykey 6\u0026#34;11\u0026#34; 7redis\u0026gt; Redis 客户端\nMedis TablePlus\nRedis-cli\nStorage接口设计 实现Shorten, Unshort 和 ShortlinkInfo 接口 1curl -X POST \\ 2 http://localhost:8000/api/shorten \\ 3 -d \u0026#39;{\u0026#34;url\u0026#34;:\u0026#34;www.baidu.com\u0026#34;,\u0026#34;expiration_in_minutes\u0026#34;:15}\u0026#39; 4 5curl -X GET \\ 6 \u0026#39;http://localhost:8000/api/info?short_link=8\u0026#39; 7 8curl -X GET \\ 9 http://localhost:8000/2 5 单元测试 主服务测试用例\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/note_go/99_go_short_addr/","summary":"1 短地址服务 将长地址缩短到一个很短的地址，用户访问这个短地址可以重定向到原本的长地址。\n如何设计HTTP Router 和handler 如何在HTTP 处理流程中加入Middleware 如何利用Go的Interface来实现可扩展的设计 如何使用redis的自增长序列生成短地址 2 主服务模块 API接口 POST /api/shorten GET /api/info?shortlink=shortlink GET /:shortlink - return 302 code 重定向 POST /api/shorten Params\nName Type Description url string Required. URL to shorten. e.g. https://www.example.com expiration_in_minutes int Required. Expiration of short link in minutes. e.g. value 0 represents permanent. Response\n1{ 2 \u0026#34;shortlink\u0026#34;:\u0026#34;P\u0026#34; 3} GET /api/info?shortlink=shortlink Params\nName Type Description shortlink string Required. Id of shortened. e.g. P Response","tags":null,"title":"【慕课网】Go开发短地址服务"},{"categories":null,"contents":"Golang\n以下代码的输出内容 1package main 2import ( 3\t\u0026#34;fmt\u0026#34; 4) 5 6func main() { 7\tdeferCall() 8} 9func deferCall() { 10\tdefer func() { fmt.Println(\u0026#34;\u0026gt;\u0026gt;\u0026gt; before\u0026#34;) }() 11\tdefer func() { fmt.Println(\u0026#34;\u0026gt;\u0026gt;\u0026gt; in process\u0026#34;) }() 12\tdefer func() { fmt.Println(\u0026#34;\u0026gt;\u0026gt;\u0026gt; done\u0026#34;) }() 13\tpanic(\u0026#34;\u0026lt;\u0026lt;\u0026lt; panic here\u0026#34;) 14} 输出结果如下\n1\u0026gt;\u0026gt;\u0026gt; done 2\u0026gt;\u0026gt;\u0026gt; in process 3\u0026gt;\u0026gt;\u0026gt; before 4panic: \u0026lt;\u0026lt;\u0026lt; panic here defer执行的顺序是后进先出, 压栈。当出现panic的时候，会按照defer的后进先出的顺序执行，最后才会执行panic。\ndefer是一个压栈过程。\n这段代码的输出，以及原因 1package main 2 3import \u0026#34;fmt\u0026#34; 4 5func main() { 6\tslice := []int{0, 1, 2, 3} 7\tm := make(map[int]*int) 8 9\tfor key, val := range slice { 10\tm[key] = \u0026amp;val 11\t} 12 13\tfor k, v := range m { 14\tfmt.Println(k, \u0026#34;-\u0026gt;\u0026#34;, *v) 15\t} 16} 结果输出如下\n10 -\u0026gt; 3 21 -\u0026gt; 3 32 -\u0026gt; 3 43 -\u0026gt; 3 for range 循环中的key \u0026amp; val 只会初始化一次。\n所有的m[key]的取值都为变量val的地址，val 最后被赋值为3。\n如果把fmt.Println(k, \u0026quot;-\u0026gt;\u0026quot;, *v) 修改为fmt.Println(k, \u0026quot;-\u0026gt;\u0026quot;, v) 结果如下, 所有的m[key]都指向了同一地址\n10 -\u0026gt; 0xc0000b4008 21 -\u0026gt; 0xc0000b4008 32 -\u0026gt; 0xc0000b4008 43 -\u0026gt; 0xc0000b4008 ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/interview/daily/2021-03-12/","summary":"Golang\n以下代码的输出内容 1package main 2import ( 3\t\u0026#34;fmt\u0026#34; 4) 5 6func main() { 7\tdeferCall() 8} 9func deferCall() { 10\tdefer func() { fmt.Println(\u0026#34;\u0026gt;\u0026gt;\u0026gt; before\u0026#34;) }() 11\tdefer func() { fmt.Println(\u0026#34;\u0026gt;\u0026gt;\u0026gt; in process\u0026#34;) }() 12\tdefer func() { fmt.Println(\u0026#34;\u0026gt;\u0026gt;\u0026gt; done\u0026#34;) }() 13\tpanic(\u0026#34;\u0026lt;\u0026lt;\u0026lt; panic here\u0026#34;) 14} 输出结果如下\n1\u0026gt;\u0026gt;\u0026gt; done 2\u0026gt;\u0026gt;\u0026gt; in process 3\u0026gt;\u0026gt;\u0026gt; before 4panic: \u0026lt;\u0026lt;\u0026lt; panic here defer执行的顺序是后进先出, 压栈。当出现panic的时候，会按照defer的后进先出的顺序执行，最后才会执行panic。\ndefer是一个压栈过程。\n这段代码的输出，以及原因 1package main 2 3import \u0026#34;fmt\u0026#34; 4 5func main() { 6\tslice := []int{0, 1, 2, 3} 7\tm := make(map[int]*int) 8 9\tfor key, val := range slice { 10\tm[key] = \u0026amp;val 11\t} 12 13\tfor k, v := range m { 14\tfmt.","tags":null,"title":"2021-03-12"},{"categories":null,"contents":"Golang\n下面两段代码输出什么 1// 1. 2 func main() { 3 s := make([]int, 5) 4 s = append(s, 1, 2, 3) 5 fmt.Println(s) 6 } 7 8// 2. 9 func main() { 10 s := make([]int,0) 11 s = append(s,1,2,3,4) 12 fmt.Println(s) 13} 输出结果如下\n1[0 0 0 0 0 1 2 3] 2[1 2 3 4] 使用make 新建 slice 会根据初始化的容量补0\n这段代码的问题 1 func funcMui(x,y int)(sum int,error){ 2 return x+y,nil 3 } 有多个返回值的时候，返回值的名字要么全部省略，要么全部写上\nnew() 与make() 的区别 new(T)和make(T, args)是go语言的内建函数，用来分配内存，但是适用的类型不同。\nnew(T) 会为T类型分配已经置零的内存空间，并返回地址(指针)，即类型为*T的值。换句话说就是，返回一个指针，该指针指向那个新分配的，类型为T的零值。适用于值类型，如数组、结构体等。\nmake(T,args) 返回初始化之后的 T 类型的值，这个值并不是 T 类型的零值，也不是指针 *T，是经过初始化之后的 T 的引用。make() 只适用于 slice、map 和 channel.\n1func main() { 2\tfmt.Println(\u0026#34;\u0026gt;\u0026gt;\u0026gt; make: \u0026#34;) 3\tfmt.Println(make([]int, 4)) 4\tfmt.Println(make(map[string]int)) 5\tfmt.Println(make(chan int, 5)) 6 7\tfmt.Println(\u0026#34;\\n \u0026gt;\u0026gt;\u0026gt; new:\u0026#34;) 8\tfmt.Println(new(int)) 9} 1\u0026gt;\u0026gt;\u0026gt; make: 2[0 0 0 0] 3map[] 40xc0000ba000 5 6 \u0026gt;\u0026gt;\u0026gt; new: 70xc0000b4038 下面这段代码能否通过编译，不能的话原因是什么；如果能，输出什么。 1func main() { 2 list := new([]int) 3 list = append(list, 1) 4 fmt.Println(list) 5} 不能通过编译，new([]int) 之后的 list 是一个 *[]int 类型的指针，不能对指针执行 append 操作。可以使用 make() 初始化之后再用。同样的，map 和 channel 建议使用 make() 或字面量的方式初始化，不要用 new() 。\n下面这段代码能否通过编译，如果可以，输出什么？ 1func main() { 2 s1 := []int{1, 2, 3} 3 s2 := []int{4, 5} 4 s1 = append(s1, s2) 5 fmt.Println(s1) 6} 不能通过编译。append() 的第二个参数不能直接使用 slice，需使用 … 操作符，将一个切片追加到另一个切片上：append(s1,s2…)。或者直接跟上元素，形如：append(s1,1,2,3)。\n下面这段代码能否通过编译，如果可以，输出什么？ 1var( 2 size := 1024 3 max_size = size*2 4) 5 6func main() { 7 fmt.Println(size,max_size) 8} 不能通过编译。这道题的主要知识点是变量声明的简短模式，形如：x := 100。但这种声明方式有限制：\n11.必须使用显示初始化； 22.不能提供数据类型，编译器会自动推导； 33.只能在函数内部使用简短模式； ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/interview/daily/2021-03-13/","summary":"Golang\n下面两段代码输出什么 1// 1. 2 func main() { 3 s := make([]int, 5) 4 s = append(s, 1, 2, 3) 5 fmt.Println(s) 6 } 7 8// 2. 9 func main() { 10 s := make([]int,0) 11 s = append(s,1,2,3,4) 12 fmt.Println(s) 13} 输出结果如下\n1[0 0 0 0 0 1 2 3] 2[1 2 3 4] 使用make 新建 slice 会根据初始化的容量补0\n这段代码的问题 1 func funcMui(x,y int)(sum int,error){ 2 return x+y,nil 3 } 有多个返回值的时候，返回值的名字要么全部省略，要么全部写上","tags":null,"title":"2021-03-13"},{"categories":null,"contents":"Golang\n使用channel实现简单并发，注意执行顺序\n1package main 2 3import ( 4\t\u0026#34;fmt\u0026#34; 5\t\u0026#34;sync\u0026#34; 6\t\u0026#34;time\u0026#34; 7) 8 9var wg sync.WaitGroup 10 11func printer(ch chan int) { 12\tfor i := range ch { 13\tfmt.Printf(\u0026#34;Received %d \\n\u0026#34;, i) 14\t\u0026lt;-time.After(time.Second / 5) 15\tfmt.Printf(\u0026#34;Job %v done \\n\u0026#34;, i) 16\t} 17\tprintln(\u0026#34;All Jobs done\u0026#34;) 18\twg.Done() 19\tprintln(\u0026#34;Finished\u0026#34;) 20} 21 22// main is the entry point for the program. 23func main() { 24\tc := make(chan int) 25\tgo printer(c) 26\twg.Add(1) 27 28\t// Send 5 integers on the channel. 29\tfor i := 1; i \u0026lt;= 5; i++ { 30\tc \u0026lt;- i 31\t} 32\tprintln(\u0026#34;\u0026gt;\u0026gt;\u0026gt; Close chan\u0026#34;) 33\tclose(c) 34\tprintln(\u0026#34;\u0026gt;\u0026gt;\u0026gt; Closed\u0026#34;) 35\twg.Wait() 36} 执行结果如图：\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/interview/daily/2021-03-14/","summary":"Golang\n使用channel实现简单并发，注意执行顺序\n1package main 2 3import ( 4\t\u0026#34;fmt\u0026#34; 5\t\u0026#34;sync\u0026#34; 6\t\u0026#34;time\u0026#34; 7) 8 9var wg sync.WaitGroup 10 11func printer(ch chan int) { 12\tfor i := range ch { 13\tfmt.Printf(\u0026#34;Received %d \\n\u0026#34;, i) 14\t\u0026lt;-time.After(time.Second / 5) 15\tfmt.Printf(\u0026#34;Job %v done \\n\u0026#34;, i) 16\t} 17\tprintln(\u0026#34;All Jobs done\u0026#34;) 18\twg.Done() 19\tprintln(\u0026#34;Finished\u0026#34;) 20} 21 22// main is the entry point for the program. 23func main() { 24\tc := make(chan int) 25\tgo printer(c) 26\twg.","tags":null,"title":"2021-03-14"},{"categories":null,"contents":"Golang\n获取变量的数据类型\n1package main 2 3import ( 4\t\u0026#34;fmt\u0026#34; 5\t\u0026#34;reflect\u0026#34; 6) 7 8func main() { 9 10\t// string type : string 11\tvar1 := \u0026#34;hello world\u0026#34; 12 13\t// integer : int 14\tvar2 := 10 15 16\t// float : float64 17\tvar3 := 1.55 18 19\t// boolean : bool 20\tvar4 := true 21 22\t// shorthand string array declaration : []string 23\tvar5 := []string{\u0026#34;foo\u0026#34;, \u0026#34;bar\u0026#34;, \u0026#34;baz\u0026#34;} 24 25\t// map is reference datatype : map[string]string 26\tvar6 := map[int]string{100: \u0026#34;Ana\u0026#34;, 101: \u0026#34;Lisa\u0026#34;, 102: \u0026#34;Rob\u0026#34;} 27 28\t// complex64 and complex128 29\t// is basic datatype : complex128 30\tvar7 := complex(9, 15) 31 32\t// using %T format specifier to 33\t// determine the datatype of the variables 34 35\tfmt.Println(\u0026#34;Using Percent T with Printf\u0026#34;) 36 37\tfmt.Printf(\u0026#34;var1 = %T\\n\u0026#34;, var1) 38\tfmt.Printf(\u0026#34;var2 = %T\\n\u0026#34;, var2) 39\tfmt.Printf(\u0026#34;var3 = %T\\n\u0026#34;, var3) 40\tfmt.Printf(\u0026#34;var4 = %T\\n\u0026#34;, var4) 41\tfmt.Printf(\u0026#34;var5 = %T\\n\u0026#34;, var5) 42\tfmt.Printf(\u0026#34;var6 = %T\\n\u0026#34;, var6) 43\tfmt.Printf(\u0026#34;var7 = %T\\n\u0026#34;, var7) 44 45\t// using TypeOf() method of reflect package 46\t// to determine the datatype of the variables 47\tfmt.Println() 48\tfmt.Println(\u0026#34;Using reflect.TypeOf Function\u0026#34;) 49 50\tfmt.Println(\u0026#34;var1 = \u0026#34;, reflect.TypeOf(var1)) 51\tfmt.Println(\u0026#34;var2 = \u0026#34;, reflect.TypeOf(var2)) 52\tfmt.Println(\u0026#34;var3 = \u0026#34;, reflect.TypeOf(var3)) 53\tfmt.Println(\u0026#34;var4 = \u0026#34;, reflect.TypeOf(var4)) 54\tfmt.Println(\u0026#34;var5 = \u0026#34;, reflect.TypeOf(var5)) 55\tfmt.Println(\u0026#34;var6 = \u0026#34;, reflect.TypeOf(var6)) 56\tfmt.Println(\u0026#34;var7 = \u0026#34;, reflect.TypeOf(var7)) 57 58\t// using ValueOf() method of reflect package 59\t// to determine the value of the variable 60\t// Kind() method returns the datatype of the 61\t// value fetched by the ValueOf() method 62\tfmt.Println() 63\tfmt.Println(\u0026#34;Using reflect.ValueOf.Kind() Function\u0026#34;) 64 65\tfmt.Println(\u0026#34;var1 = \u0026#34;, reflect.ValueOf(var1).Kind()) 66\tfmt.Println(\u0026#34;var2 = \u0026#34;, reflect.ValueOf(var2).Kind()) 67\tfmt.Println(\u0026#34;var3 = \u0026#34;, reflect.ValueOf(var3).Kind()) 68\tfmt.Println(\u0026#34;var4 = \u0026#34;, reflect.ValueOf(var4).Kind()) 69\tfmt.Println(\u0026#34;var5 = \u0026#34;, reflect.ValueOf(var5).Kind()) 70\tfmt.Println(\u0026#34;var6 = \u0026#34;, reflect.ValueOf(var6).Kind()) 71\tfmt.Println(\u0026#34;var7 = \u0026#34;, reflect.ValueOf(var7).Kind()) 72 73} ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/interview/daily/2021-03-15/","summary":"Golang\n获取变量的数据类型\n1package main 2 3import ( 4\t\u0026#34;fmt\u0026#34; 5\t\u0026#34;reflect\u0026#34; 6) 7 8func main() { 9 10\t// string type : string 11\tvar1 := \u0026#34;hello world\u0026#34; 12 13\t// integer : int 14\tvar2 := 10 15 16\t// float : float64 17\tvar3 := 1.55 18 19\t// boolean : bool 20\tvar4 := true 21 22\t// shorthand string array declaration : []string 23\tvar5 := []string{\u0026#34;foo\u0026#34;, \u0026#34;bar\u0026#34;, \u0026#34;baz\u0026#34;} 24 25\t// map is reference datatype : map[string]string 26\tvar6 := map[int]string{100: \u0026#34;Ana\u0026#34;, 101: \u0026#34;Lisa\u0026#34;, 102: \u0026#34;Rob\u0026#34;} 27 28\t// complex64 and complex128 29\t// is basic datatype : complex128 30\tvar7 := complex(9, 15) 31 32\t// using %T format specifier to 33\t// determine the datatype of the variables 34 35\tfmt.","tags":null,"title":"2021-03-15"},{"categories":null,"contents":"Golang\n同时定义多个相关的struct, 这样写可读性更好一些\n1type ( 2\t// item defines the fields associated with the item tag 3\t// in the rss document. 4\titem struct { 5\tXMLName xml.Name `xml:\u0026#34;item\u0026#34;` 6\tPubDate string `xml:\u0026#34;pubDate\u0026#34;` 7\tTitle string `xml:\u0026#34;title\u0026#34;` 8\tDescription string `xml:\u0026#34;description\u0026#34;` 9\tLink string `xml:\u0026#34;link\u0026#34;` 10\tGUID string `xml:\u0026#34;guid\u0026#34;` 11\tGeoRssPoint string `xml:\u0026#34;georss:point\u0026#34;` 12\t} 13 14\t// image defines the fields associated with the image tag 15\t// in the rss document. 16\timage struct { 17\tXMLName xml.Name `xml:\u0026#34;image\u0026#34;` 18\tURL string `xml:\u0026#34;url\u0026#34;` 19\tTitle string `xml:\u0026#34;title\u0026#34;` 20\tLink string `xml:\u0026#34;link\u0026#34;` 21\t} 22 23\t// channel defines the fields associated with the channel tag 24\t// in the rss document. 25\tchannel struct { 26\tXMLName xml.Name `xml:\u0026#34;channel\u0026#34;` 27\tTitle string `xml:\u0026#34;title\u0026#34;` 28\tDescription string `xml:\u0026#34;description\u0026#34;` 29\tLink string `xml:\u0026#34;link\u0026#34;` 30\tPubDate string `xml:\u0026#34;pubDate\u0026#34;` 31\tLastBuildDate string `xml:\u0026#34;lastBuildDate\u0026#34;` 32\tTTL string `xml:\u0026#34;ttl\u0026#34;` 33\tLanguage string `xml:\u0026#34;language\u0026#34;` 34\tManagingEditor string `xml:\u0026#34;managingEditor\u0026#34;` 35\tWebMaster string `xml:\u0026#34;webMaster\u0026#34;` 36\tImage image `xml:\u0026#34;image\u0026#34;` 37\tItem []item `xml:\u0026#34;item\u0026#34;` 38\t} 39 40\t// rssDocument defines the fields associated with the rss document. 41\trssDocument struct { 42\tXMLName xml.Name `xml:\u0026#34;rss\u0026#34;` 43\tChannel channel `xml:\u0026#34;channel\u0026#34;` 44\t} 45) ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/interview/daily/2021-03-16/","summary":"Golang\n同时定义多个相关的struct, 这样写可读性更好一些\n1type ( 2\t// item defines the fields associated with the item tag 3\t// in the rss document. 4\titem struct { 5\tXMLName xml.Name `xml:\u0026#34;item\u0026#34;` 6\tPubDate string `xml:\u0026#34;pubDate\u0026#34;` 7\tTitle string `xml:\u0026#34;title\u0026#34;` 8\tDescription string `xml:\u0026#34;description\u0026#34;` 9\tLink string `xml:\u0026#34;link\u0026#34;` 10\tGUID string `xml:\u0026#34;guid\u0026#34;` 11\tGeoRssPoint string `xml:\u0026#34;georss:point\u0026#34;` 12\t} 13 14\t// image defines the fields associated with the image tag 15\t// in the rss document.","tags":null,"title":"2021-03-16"},{"categories":null,"contents":"Golang\n1// A map of registered matchers for searching. 2var matchers = make(map[string]Matcher) 3 4// Run performs the search logic. 5func Run(searchTerm string) { 6\t// Retrieve the list of feeds to search through. 7\tfeeds, err := RetrieveFeeds() 8\tif err != nil { 9\tlog.Fatal(err) 10\t} 11 12\t// Create an unbuffered channel to receive match results to display. 13\tresults := make(chan *Result) 14 15\t// Setup a wait group so we can process all the feeds. 16\tvar waitGroup sync.WaitGroup 17 18\t// Set the number of goroutines we need to wait for while 19\t// they process the individual feeds. 20\twaitGroup.Add(len(feeds)) 21 22\t// Launch a goroutine for each feed to find the results. 23\tfor _, feed := range feeds { 24\t// Retrieve a matcher for the search. 25\tmatcher, exists := matchers[feed.Type] 26\tif !exists { 27\tmatcher = matchers[\u0026#34;default\u0026#34;] 28\t} 29 30\t// Launch the goroutine to perform the search. 31\tgo func(matcher Matcher, feed *Feed) { 32\tMatch(matcher, feed, searchTerm, results) 33\twaitGroup.Done() 34\t}(matcher, feed) 35\t} 36 37\t// Launch a goroutine to monitor when all the work is done. 38\tgo func() { 39\t// Wait for everything to be processed. 40\twaitGroup.Wait() 41 42\t// Close the channel to signal to the Display 43\t// function that we can exit the program. 44\tclose(results) 45\t}() 46 47\t// Start displaying results as they are available and 48\t// return after the final result is displayed. 49\tDisplay(results) 50} 51 52// Register is called to register a matcher for use by the program. 53func Register(feedType string, matcher Matcher) { 54\tif _, exists := matchers[feedType]; exists { 55\tlog.Fatalln(feedType, \u0026#34;Matcher already registered\u0026#34;) 56\t} 57 58\tlog.Println(\u0026#34;Register\u0026#34;, feedType, \u0026#34;matcher\u0026#34;) 59\tmatchers[feedType] = matcher 60} 通过Register()方法更新 matchers\nwg.Wait() 如果wg.Add(n)没有完成对应的wg.Done()就会一直hang在这里\nfor v:=range chan 只要chan没有关闭，就会一直hang在这里\nDisplay()这样用会不会易读一点\n1\t// Start displaying results as they are available and 2\t// return after the final result is displayed. 3\tgo Display(results) 4 5\t// Wait for everything to be processed. 6\twaitGroup.Wait() 7 8\t// Close the channel to signal to the Display 9\t// function that we can exit the program. 10\tclose(results) ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/interview/daily/2021-03-17/","summary":"Golang\n1// A map of registered matchers for searching. 2var matchers = make(map[string]Matcher) 3 4// Run performs the search logic. 5func Run(searchTerm string) { 6\t// Retrieve the list of feeds to search through. 7\tfeeds, err := RetrieveFeeds() 8\tif err != nil { 9\tlog.Fatal(err) 10\t} 11 12\t// Create an unbuffered channel to receive match results to display. 13\tresults := make(chan *Result) 14 15\t// Setup a wait group so we can process all the feeds.","tags":null,"title":"2021-03-17"},{"categories":null,"contents":"Golang\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/interview/daily/2021-03-xxxx/","summary":"Golang","tags":null,"title":"2021-03-xx"},{"categories":null,"contents":"Flush\n清空缓冲区\n首先，咱们设想要给鱼缸换水，所以需要一个水泵，水泵是连接鱼缸和下水道的，咱们的任务就是将鱼缸里面水全抽干，这时，我们就可以把水管当做缓冲区。如果咱们一见鱼缸里面水抽干了就立马关了水泵，这时会发现水管里还有来不及通过水泵流向下水道的残留水，我们可以把抽水当做读数据，排水当做写数据，水管当做缓冲区，这样就容易明白了。\n那么这样一来我们如果中途调用close()方法，输出区也还是有数据的，就像水缸里有水，只是在缓冲区遗留了一部分，这时如果我们先调用flush()方法，就会强制把数据输出，缓存区就清空了，最后再关闭读写流调用close()就完成了。\n缓冲区可以简单地理解为一段内存区域。可以简单地把缓冲区理解为一段特殊的内存。某些情况下，如果一个程序频繁地操作一个资源（如文件或数据库），则性能会很低，此时为了提升性能，就可以将一部分数据暂时读入到内存的一块区域之中，以后直接从此区域中读取数据即可，因为读取内存速度会比较快，这样可以提升程序的性能。\nhttps://blog.csdn.net/qq_38129062/article/details/87115620\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/interview/daily/2021-04-20/","summary":"Flush\n清空缓冲区\n首先，咱们设想要给鱼缸换水，所以需要一个水泵，水泵是连接鱼缸和下水道的，咱们的任务就是将鱼缸里面水全抽干，这时，我们就可以把水管当做缓冲区。如果咱们一见鱼缸里面水抽干了就立马关了水泵，这时会发现水管里还有来不及通过水泵流向下水道的残留水，我们可以把抽水当做读数据，排水当做写数据，水管当做缓冲区，这样就容易明白了。\n那么这样一来我们如果中途调用close()方法，输出区也还是有数据的，就像水缸里有水，只是在缓冲区遗留了一部分，这时如果我们先调用flush()方法，就会强制把数据输出，缓存区就清空了，最后再关闭读写流调用close()就完成了。\n缓冲区可以简单地理解为一段内存区域。可以简单地把缓冲区理解为一段特殊的内存。某些情况下，如果一个程序频繁地操作一个资源（如文件或数据库），则性能会很低，此时为了提升性能，就可以将一部分数据暂时读入到内存的一块区域之中，以后直接从此区域中读取数据即可，因为读取内存速度会比较快，这样可以提升程序的性能。\nhttps://blog.csdn.net/qq_38129062/article/details/87115620","tags":null,"title":"2021-04-20"},{"categories":null,"contents":"Flush\n清空缓冲区\n首先，咱们设想要给鱼缸换水，所以需要一个水泵，水泵是连接鱼缸和下水道的，咱们的任务就是将鱼缸里面水全抽干，这时，我们就可以把水管当做缓冲区。如果咱们一见鱼缸里面水抽干了就立马关了水泵，这时会发现水管里还有来不及通过水泵流向下水道的残留水，我们可以把抽水当做读数据，排水当做写数据，水管当做缓冲区，这样就容易明白了。\n那么这样一来我们如果中途调用close()方法，输出区也还是有数据的，就像水缸里有水，只是在缓冲区遗留了一部分，这时如果我们先调用flush()方法，就会强制把数据输出，缓存区就清空了，最后再关闭读写流调用close()就完成了。\n缓冲区可以简单地理解为一段内存区域。可以简单地把缓冲区理解为一段特殊的内存。某些情况下，如果一个程序频繁地操作一个资源（如文件或数据库），则性能会很低，此时为了提升性能，就可以将一部分数据暂时读入到内存的一块区域之中，以后直接从此区域中读取数据即可，因为读取内存速度会比较快，这样可以提升程序的性能。\nhttps://blog.csdn.net/qq_38129062/article/details/87115620\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/interview/daily/2021-03-21/","summary":"Flush\n清空缓冲区\n首先，咱们设想要给鱼缸换水，所以需要一个水泵，水泵是连接鱼缸和下水道的，咱们的任务就是将鱼缸里面水全抽干，这时，我们就可以把水管当做缓冲区。如果咱们一见鱼缸里面水抽干了就立马关了水泵，这时会发现水管里还有来不及通过水泵流向下水道的残留水，我们可以把抽水当做读数据，排水当做写数据，水管当做缓冲区，这样就容易明白了。\n那么这样一来我们如果中途调用close()方法，输出区也还是有数据的，就像水缸里有水，只是在缓冲区遗留了一部分，这时如果我们先调用flush()方法，就会强制把数据输出，缓存区就清空了，最后再关闭读写流调用close()就完成了。\n缓冲区可以简单地理解为一段内存区域。可以简单地把缓冲区理解为一段特殊的内存。某些情况下，如果一个程序频繁地操作一个资源（如文件或数据库），则性能会很低，此时为了提升性能，就可以将一部分数据暂时读入到内存的一块区域之中，以后直接从此区域中读取数据即可，因为读取内存速度会比较快，这样可以提升程序的性能。\nhttps://blog.csdn.net/qq_38129062/article/details/87115620","tags":null,"title":"2021-04-21"},{"categories":null,"contents":" 1package main 2 3import \u0026#34;fmt\u0026#34; 4 5var testMap = map[string]map[string]struct { 6\tName string 7}{ 8\t\u0026#34;first\u0026#34;: {\u0026#34;second\u0026#34;: {Name: \u0026#34;12312\u0026#34;}}, 9\t\u0026#34;second\u0026#34;: {\u0026#34;second\u0026#34;: {\u0026#34;12312\u0026#34;}}, 10} 11 12func main() { 13\td := testMap[\u0026#34;first\u0026#34;][\u0026#34;second\u0026#34;].Name 14\tfmt.Printf(\u0026#34;++-%v-++\\n\u0026#34;, d) 15 16 17 // map 不会报 nil 18\tc := testMap[\u0026#34;first22\u0026#34;][\u0026#34;second\u0026#34;].Name 19\tfmt.Printf(\u0026#34;++-%v-++\\n\u0026#34;, c) 20} 结果\n1++-12312-++ 2++--++ ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/interview/daily/2021-05-20/","summary":" 1package main 2 3import \u0026#34;fmt\u0026#34; 4 5var testMap = map[string]map[string]struct { 6\tName string 7}{ 8\t\u0026#34;first\u0026#34;: {\u0026#34;second\u0026#34;: {Name: \u0026#34;12312\u0026#34;}}, 9\t\u0026#34;second\u0026#34;: {\u0026#34;second\u0026#34;: {\u0026#34;12312\u0026#34;}}, 10} 11 12func main() { 13\td := testMap[\u0026#34;first\u0026#34;][\u0026#34;second\u0026#34;].Name 14\tfmt.Printf(\u0026#34;++-%v-++\\n\u0026#34;, d) 15 16 17 // map 不会报 nil 18\tc := testMap[\u0026#34;first22\u0026#34;][\u0026#34;second\u0026#34;].Name 19\tfmt.Printf(\u0026#34;++-%v-++\\n\u0026#34;, c) 20} 结果\n1++-12312-++ 2++--++ ","tags":null,"title":"2021-05-20"},{"categories":null,"contents":"rwarestse ewartawe\n-gcflags=-l\n1. 线上的配置文件写在了哪里 1GOMAXPROCS = 8 2TSDB_HOST = bytetsd-query-server-prod-ppe-va.byted.org 3 4 5# influxdb 配置 本地如何调试 一些特殊的token的解析 NaNAsZero, not_sliteral_or, nullAsZero 是否还可以rebase bosun开源版本 ui fenbu cs Trace bytetrace\nexpr （context） trace 对齐其他语言的框架， 例如ginex context\nstate \u0026ndash;\u0026gt; context\ninf.bytesd.bosun\nLog slog\nError errors 业务状态码\nerr\n静态\n非200\n5001 执行失败，动态参数解析失败， duration， 计算错误\n5002 runtime panic\n5003 panic string\n对齐trace\n新加的一些函数 funcs.go\npprof 8071\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/interview/daily/2021-05-26/","summary":"rwarestse ewartawe\n-gcflags=-l\n1. 线上的配置文件写在了哪里 1GOMAXPROCS = 8 2TSDB_HOST = bytetsd-query-server-prod-ppe-va.byted.org 3 4 5# influxdb 配置 本地如何调试 一些特殊的token的解析 NaNAsZero, not_sliteral_or, nullAsZero 是否还可以rebase bosun开源版本 ui fenbu cs Trace bytetrace\nexpr （context） trace 对齐其他语言的框架， 例如ginex context\nstate \u0026ndash;\u0026gt; context\ninf.bytesd.bosun\nLog slog\nError errors 业务状态码\nerr\n静态\n非200\n5001 执行失败，动态参数解析失败， duration， 计算错误\n5002 runtime panic\n5003 panic string\n对齐trace\n新加的一些函数 funcs.go\npprof 8071","tags":null,"title":"2021-05-26"},{"categories":null,"contents":"rwarestse ewartawe\n-gcflags=-l\n1. 线上的配置文件写在了哪里 1GOMAXPROCS = 8 2TSDB_HOST = bytetsd-query-server-prod-ppe-va.byted.org 3 4 5# influxdb 配置 本地如何调试 一些特殊的token的解析 NaNAsZero, not_sliteral_or, nullAsZero 是否还可以rebase bosun开源版本 ui fenbu ssssTrace bytetrace\nexpr （context） trace 对齐其他语言的框架， 例如ginex context\nstate \u0026ndash;\u0026gt; context\ninf.bytesd.bosun\nLog slog\nError errors 业务状态码\nerr\n静态\n非200\n5001 执行失败，动态参数解析失败， duration， 计算错误\n5002 runtime panic\n5003 panic string\n对齐trace\n新加的一些函数 funcs.go\npprof 8071\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/interview/daily/2021-05-27/","summary":"rwarestse ewartawe\n-gcflags=-l\n1. 线上的配置文件写在了哪里 1GOMAXPROCS = 8 2TSDB_HOST = bytetsd-query-server-prod-ppe-va.byted.org 3 4 5# influxdb 配置 本地如何调试 一些特殊的token的解析 NaNAsZero, not_sliteral_or, nullAsZero 是否还可以rebase bosun开源版本 ui fenbu ssssTrace bytetrace\nexpr （context） trace 对齐其他语言的框架， 例如ginex context\nstate \u0026ndash;\u0026gt; context\ninf.bytesd.bosun\nLog slog\nError errors 业务状态码\nerr\n静态\n非200\n5001 执行失败，动态参数解析失败， duration， 计算错误\n5002 runtime panic\n5003 panic string\n对齐trace\n新加的一些函数 funcs.go\npprof 8071","tags":null,"title":"2021-05-26"},{"categories":null,"contents":"sync.pool\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/interview/daily/2021-06-01/","summary":"sync.pool","tags":null,"title":"2021-06-01"},{"categories":null,"contents":" Telegraf is an agent for collecting metrics and writing the to InfluxDB or other outputs. 使用bosun之前首先要了解什么是时序数据，时序数据的组成部分以及时序数据的常用查询\n时序数据的类型 counter\nguage(store)\nBosun的数据类型 Scalar NumberSet： Group+Scalar Bosun 查询语法 简单查询 查询过去10分钟到过去1分钟之间的时序数据\navg是时序数据库的的运算，对不同的tag set的数据求平均\n最外面的avg 是对这段时间内的时序数据做一个平均，得到一个数值\n宏替换 运算的时候会对变量进行宏替换\nOpenTSDB\n如果没有数据的时候会导致bosun查询失败，可以采取不上\n1avg(100*q(\u0026#34;avg:1m-avg-zero:store:toutiao.tce.sysprobe.aweme.recommend.predict.cpu.usage.pod{sidecar_psm=ad.qa.java_sidecar,pod_name=dp-cb2f23ec64-6987c9d65d-ds7j5}\u0026#34;,\u0026#34;1h\u0026#34;,\u0026#34;\u0026#34;)/q(\u0026#34;avg:1m-avg:store:toutiao.tce.sysprobe.aweme.recommend.predict.cpu.limit.pod{sidecar_psm=ad.qa.java_sidecar,pod_name=dp-cb2f23ec64-6987c9d65d-ds7j5}\u0026#34;,\u0026#34;1h\u0026#34;,\u0026#34;\u0026#34;)) Streak 连续非0 数据的最大长度\nhttps://blog.csdn.net/lslxdx/article/details/79454916\n转置\nInfluxDB 1influx(\u0026#34;iaas_metrics\u0026#34;, \u0026#39;\u0026#39;\u0026#39;SELECT sum(value) FROM \u0026#34;host_CpuSystem\u0026#34; group by \u0026#34;resource_id\u0026#34; \u0026#39;\u0026#39;\u0026#39;, \u0026#34;7d\u0026#34;, \u0026#34;2m\u0026#34;, \u0026#34;1m\u0026#34;) Bosun, Time Series, and OpenTSDB\u0026rsquo;s DataModel An introduction to the data model of Bosun\u0026rsquo;s Primary time series backend OpenTSDB. Time Series, Metircs and Tags, Aggregation, Rate Calculation, and Downsampling are covered. These features are demoed using Bosun\u0026rsquo;s graphing interface.\nTime Series A Series of observations , each recorded as a Time and Date with an associated Value.\n1Observation on 08-22-2015 10:20:01 of 10 2Observation on 08-22-2015 10:20:15 of 20 3Observation on ... of ... Open TSDB Time Series Database\nEach Time Series in the Database in Uniquely Identified by:\nA Metric Name\nA Set of Tags\nA Tag is made of : A Tag Key \u0026amp; A Tag Value\n参考文档 https://blog.csdn.net/lslxdx/article/details/79454916\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/component/TimeSeries/bosun/","summary":"Telegraf is an agent for collecting metrics and writing the to InfluxDB or other outputs. 使用bosun之前首先要了解什么是时序数据，时序数据的组成部分以及时序数据的常用查询\n时序数据的类型 counter\nguage(store)\nBosun的数据类型 Scalar NumberSet： Group+Scalar Bosun 查询语法 简单查询 查询过去10分钟到过去1分钟之间的时序数据\navg是时序数据库的的运算，对不同的tag set的数据求平均\n最外面的avg 是对这段时间内的时序数据做一个平均，得到一个数值\n宏替换 运算的时候会对变量进行宏替换\nOpenTSDB\n如果没有数据的时候会导致bosun查询失败，可以采取不上\n1avg(100*q(\u0026#34;avg:1m-avg-zero:store:toutiao.tce.sysprobe.aweme.recommend.predict.cpu.usage.pod{sidecar_psm=ad.qa.java_sidecar,pod_name=dp-cb2f23ec64-6987c9d65d-ds7j5}\u0026#34;,\u0026#34;1h\u0026#34;,\u0026#34;\u0026#34;)/q(\u0026#34;avg:1m-avg:store:toutiao.tce.sysprobe.aweme.recommend.predict.cpu.limit.pod{sidecar_psm=ad.qa.java_sidecar,pod_name=dp-cb2f23ec64-6987c9d65d-ds7j5}\u0026#34;,\u0026#34;1h\u0026#34;,\u0026#34;\u0026#34;)) Streak 连续非0 数据的最大长度\nhttps://blog.csdn.net/lslxdx/article/details/79454916\n转置\nInfluxDB 1influx(\u0026#34;iaas_metrics\u0026#34;, \u0026#39;\u0026#39;\u0026#39;SELECT sum(value) FROM \u0026#34;host_CpuSystem\u0026#34; group by \u0026#34;resource_id\u0026#34; \u0026#39;\u0026#39;\u0026#39;, \u0026#34;7d\u0026#34;, \u0026#34;2m\u0026#34;, \u0026#34;1m\u0026#34;) Bosun, Time Series, and OpenTSDB\u0026rsquo;s DataModel An introduction to the data model of Bosun\u0026rsquo;s Primary time series backend OpenTSDB.","tags":null,"title":"Bosun"},{"categories":null,"contents":"1# g++ Linux 2g++ -std=c++17 -W -Wall -Wfatal-errors \u0026lt;file_name\u0026gt; 3# Clang MacOS 4clang++ -std=c++17 -W -Wall -Wfatal-errors \u0026lt;file_name\u0026gt; Makefile AutoMake 1sudo apt install autoconf autopoint pkg-config libffi-dev libtool libtasn1-6-dev gettext libtasn1-bin cmake 为了跨平台实现。\n创建 CMakeLists.txt, 使用cmake ,生成 Makefile, 然后再使用make 或者 cmake --build . -j\nhttps://www.cnblogs.com/52php/p/5681725.html\nhttps://stackoverflow.com/questions/1516609/difference-between-cc-gcc-and-g\nMeson https://mesonbuild.com/\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/note_c/C++/","summary":"1# g++ Linux 2g++ -std=c++17 -W -Wall -Wfatal-errors \u0026lt;file_name\u0026gt; 3# Clang MacOS 4clang++ -std=c++17 -W -Wall -Wfatal-errors \u0026lt;file_name\u0026gt; Makefile AutoMake 1sudo apt install autoconf autopoint pkg-config libffi-dev libtool libtasn1-6-dev gettext libtasn1-bin cmake 为了跨平台实现。\n创建 CMakeLists.txt, 使用cmake ,生成 Makefile, 然后再使用make 或者 cmake --build . -j\nhttps://www.cnblogs.com/52php/p/5681725.html\nhttps://stackoverflow.com/questions/1516609/difference-between-cc-gcc-and-g\nMeson https://mesonbuild.com/","tags":null,"title":"C Build Tool"},{"categories":null,"contents":"Client-go The Client Library\u0026ndash; k8s.io/client-go The kubernetes programming interface in Go mainly consists of the k8s.io/client-go library (for brevity we will just call it client-go going foward).\nk8s.io/client-go is a typical web service client library that supports all API types that are officially part of Kubernetes. It can be used to execute the usual REST verbs.\nCreate Get List Update Delete Patch Watch For each Kubernetes 1.x.y release, there is a client-go release with a matching tag kubernetes-1.x.y.\nMost of your code that speaks to Kubernetes APIs will use tools/clientcmd/ to set up a client from a kubeconfig file, and kubernetes/ for the actual Kubernetes API clients.\nKubernetes API Types\u0026ndash;k8s.io/api As we have seen, client-go holds the client interfaces. The Kubernetes API Go types for objects like pods, services, and deployments are located in their oven repository. It is accessed as ki8.io/api in Go code.\nPods are part of the legacy API group(often also called the \u0026ldquo;core\u0026rdquo; group) version v1 Hence, the Pod Go types is found in k8s.io/api/core/v1, and similarly for all other API types in Kubernetes. The actual Go types are contained in a type.go file. In addition, there are other files, most of them automatically generated by a code generator.\n1# k8s.io/api/core/v1 2Pod 3Service 4ReplicaSet API Machinery\u0026ndash;k8s.io/apimachinery Last but not least, there is a third repository called API Machinery, which is used as k8s.io/apimachinery in Go. It include all the generic building blocks to implement a Kubernetes-like API. API machinery is not restricted to container management, so, for example, it could be used to build APIs for an online shop or any other business-specific domain.\nNevertheless, you\u0026rsquo;ll meet a lot of API Machinery packages in Kubernetes-native Go code. An important one is k8s.io/apimachinery/pkg/api/meta/v1. It contains many of the generic API types such as ObjectMeta, TypeMeta, GetOptions, and ListOptions.\n1# pkg/apis/meta/v1 2ObjectMeta 3TypeMeta 4ListOptions 5DeleteOptions 6GetOptions 7Status 8Events Create and Using a client when running a binary inside of a pod in a cluster, the kubelet will automatically mount a service account into the container at /var/run/secrets/kuberntes.io/serviceaccount. It replaces the kubeconfig file just mentioned and can easily be turned into a rest.Config via the rest.InClusterConfig() method.\n1package main 2 3import ( 4\t\u0026#34;context\u0026#34; 5\t\u0026#34;encoding/json\u0026#34; 6\t\u0026#34;flag\u0026#34; 7\t\u0026#34;fmt\u0026#34; 8\t\u0026#34;os\u0026#34; 9\t// \u0026#34;path/filepath\u0026#34; 10 11\tmetav1 \u0026#34;k8s.io/apimachinery/pkg/apis/meta/v1\u0026#34; 12\t\u0026#34;k8s.io/client-go/kubernetes\u0026#34; 13\t// \u0026#34;k8s.io/client-go/rest\u0026#34; 14\t\u0026#34;k8s.io/client-go/tools/clientcmd\u0026#34; 15) 16 17func main() { 18\tkubeconfig := flag.String(\u0026#34;kubeconfig\u0026#34;, \u0026#34;./config\u0026#34;, \u0026#34;kubeconfig file\u0026#34;) 19\tflag.Parse() 20 21\t//************ Running a Binary Inside of a Pod in Cluster ***************** 22\t// config, err := rest.InClusterConfig() 23\t// if err != nil { 24\t// // fallback to kubeconfig 25\t// kubeconfig2 := filepath.Join(\u0026#34;~\u0026#34;, \u0026#34;.kube\u0026#34;, \u0026#34;config\u0026#34;) 26\t// if envvar := os.Getenv(\u0026#34;KUBECONFIG\u0026#34;); len(envvar) \u0026gt; 0 { 27\t// kubeconfig2 = envvar 28\t// } 29\t// } 30 31\t// Import clientcmd from client-go in order to parse the kubernetes config. 32\t// The client configuration with server name, credentials. 33\t// Retrun a rest.Config 34\tconfig, err := clientcmd.BuildConfigFromFlags(\u0026#34;\u0026#34;, *kubeconfig) 35\tif err != nil { 36\tfmt.Printf(\u0026#34;The kuber config can not be loaded: %v\\n\u0026#34;, err) 37\tos.Exit(1) 38\t} 39 40\t// You can enable protobuf for native kubernetes resource cliensts by modifying 41\tconfig.AcceptContentTypes = 42\t\u0026#34;application/vnd.kubernetes.protobuf,application/json\u0026#34; 43 44\tconfig.ContentType = \u0026#34;application/vnd.kubernetes.protobuf\u0026#34; 45 46\t// Clinetset contains multiple clients for all native kubernetes resources. 47\t// Create actual kubernetes client set. 48\tclientset, err := kubernetes.NewForConfig(config) 49\tif err != nil { 50\tfmt.Printf(\u0026#34;create clientset failed: %v\u0026#34;, err) 51\tos.Exit(1) 52\t} 53 54\t// The Get call send and HTTP GET request to 55\t// /api/v1/namespace/calico-apiserver/pods/calico-apiserver-xxx 56\tpod, err := clientset.CoreV1().Pods(\u0026#34;calico-apiserver\u0026#34;).Get(context.TODO(), 57\t\u0026#34;calico-apiserver-5b68b6b54-ngfdw\u0026#34;, metav1.GetOptions{}) 58 59\tif err != nil { 60\tos.Exit(1) 61\t} 62 63\tstrByte, _ := json.Marshal(pod) 64\tfmt.Println(string(strByte)) 65 66} group ?\nVersioning and Compatibility We have seen in the previous section that pods are in v1 of core group. The core group actually exists in only one version today. There are other groups, though\u0026ndash; for example, the apps groups, which exists in v1, v1beta2, and v1beta1.\n​\nClients are hardcode to a version, and the application developer has to select the right API group version in order to speak to the cluster at hand.\nA second aspect of compatibility is the meta API features of the API server that client-go is speaking to.\nThere are options structs for CURD verbs, like CreateOptions,GetOptions,UpdateOptions, and DeleteOptions. Another important one is ObjectMeta, which part of every kind. All of these are frequently extended with new features; we usually call them API machinery features.\n1// k8s.io/apimachinery/pkg/apis/meta/v1/types.go 2// Delete options may be provided when deleting an API object 3type DeleteOptions struct{ 4\tTypeMeta 5\tGracePeriodSeconds *int64 6\tPreconditions *Preconditions 7\tOrphanDependents *bool 8 PropagationPolicy *DeletePropagation 9 10 // When present, indicates that modifications should not be 11\t// persisted. An invalid or unrecognized dryRun directive will 12\t// result in an error response and no further processing of the 13\t// request. Valid values are: 14\t// - All: all dry run stages will be processed 15\t// +optional 16 DryRun []string 17 // Was added in Kubernetes in 1.12. 18} API versions and Compatibility Guarantees Kubernetes versions all API Groups. A common Kubernetes-style versioning scheme is used, which consists of alpha, beta, and GA(general availability) versions.\nalpha versions\nv1alpha1, v1alpha2, v2alpha1\nbeta versions\nv1beta1, v1beta2, v2beta1\nv1, v2\nGA\nIn connections to API group versions, there are two important points to keep in mind.\nAPI groups versions apply to API resources as a whole, like the format of pods or service. Furthermore, API groups versions play a role in accessing the API. Kubernetes Objects in Go From the type system point of view, Kubenetes objects fulfill a Go interface called runtime.Object form the package k8s.io/apimachinery/pkg/runtime.\n1// Object interface must be support by all API types registered with Scheme. 2// Since Objects in a scheme are expected to be serialized to the wire, the interface an Object 3// must provide to the Scheme allows serializers to set the kind, version, and group the object 4// is represented as. An Object may choose to return a no-op ObjectKindAccessor in case where 5// it is not expected to be serialized. 6type Object interface{ 7\tGetObjectKind() schema.ObjectKind 8\tDeepCopyObject() Object 9} Here, scheme.ObjectKind is a another simple interface from k8s.io/apimachinery/pkg/runtime/schema.\n1// All objects that are serialized form a Scheme encode their type information. 2// This interface is used by serialization to set type information from the Scheme onto the 3// serialized version of an Object. For objects that cannot be serialized or have unique 4// requirements, this interface may be no-op. 5type ObjectKind interface{ 6 SetGroupVersionKind(kind GroupVersionKind) 7 GroupVersionKind() GroupVersionKind 8} In other words, a Kubernetes Object in Go is a data structure that can:\nReturn and set the GroupVersionKind Be deep-copied A deep copy is a clone of the data structure such that it does not share any memory the the original object. It is used wherever code has to mutate an object without modifying the original.\nTypeMeta Kubernetes objects form k8s.io/api implement the type getter and setter of scheme.ObjectKind by embedding the metav1.TypeMeta struct form the package k8s.io/apimachinery/apis/meta/v1.\n1// TypeMeta describes an individual object in an API response or request 2// with strings representing the type of the object and its API schema version. 3// Structures that are versioned or persisted should inline TypeMeta. 4// 5// +k8s:deepcopy-gen=false 6type TypeMeta struct { 7\t// Kind is a string value representing the REST resource this object represents. 8\t// Servers may infer this from the endpoint the client submits requests to. 9\t// Cannot be updated. 10\t// In CamelCase. 11\t// More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds 12\t// +optional 13\tKind string `json:\u0026#34;kind,omitempty\u0026#34; protobuf:\u0026#34;bytes,1,opt,name=kind\u0026#34;` 14 15\t// APIVersion defines the versioned schema of this representation of an object. 16\t// Servers should convert recognized schemas to the latest internal value, and 17\t// may reject unrecognized values. 18\t// More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources 19\t// +optional 20\tAPIVersion string `json:\u0026#34;apiVersion,omitempty\u0026#34; protobuf:\u0026#34;bytes,2,opt,name=apiVersion\u0026#34;` 21} with this, a pod declaration in Go looks like this form package k8s.io/api/core/v1/types.go.\n1// Pod is a collection of containers that can run on a host. This resource is created 2// by clients and scheduled onto hosts. 3type Pod struct { 4\tmetav1.TypeMeta `json:\u0026#34;,inline\u0026#34;` 5\t// Standard object\u0026#39;s metadata. 6\t// More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata 7\t// +optional 8\tmetav1.ObjectMeta `json:\u0026#34;metadata,omitempty\u0026#34; protobuf:\u0026#34;bytes,1,opt,name=metadata\u0026#34;` 9 10\t// Specification of the desired behavior of the pod. 11\t// More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#spec-and-status 12\t// +optional 13\tSpec PodSpec `json:\u0026#34;spec,omitempty\u0026#34; protobuf:\u0026#34;bytes,2,opt,name=spec\u0026#34;` 14 15\t// Most recently observed status of the pod. 16\t// This data may not be up to date. 17\t// Populated by the system. 18\t// Read-only. 19\t// More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#spec-and-status 20\t// +optional 21\tStatus PodStatus `json:\u0026#34;status,omitempty\u0026#34; protobuf:\u0026#34;bytes,3,opt,name=status\u0026#34;` 22} As you can see, TypeMeta is embedded. Moreover, the pod type has JSON tags that also declare TypeMeta as being inlined.\nThis match the YAML representation of a Pod.\n1apiVersion: v1 2kind: Pod 3metadata: 4\tnamespace: default 5\tname: example 6spec: 7\tcontainers: 8\t- name: hello 9\timages: debian:latest 10\tcommand: 11\t- /bin/sh 12\targs: 13\t- -c 14\t- echo \u0026#34;hello world\u0026#34;; sleep 10000 The version is stored in TypeMeta.APIVersion, the kind in TypeMeta.Kind.\nThe Core Group is different for historic reasons\nPods and many other types that were added to Kubernetes very early on are part of the core group\u0026ndash; often also called the legacy group \u0026ndash; which is represented by the empty string. Hence, apiVersion is just set to \u0026ldquo;v1\u0026rdquo;.\nEventually API groups were added to Kubernetes, and the group name separated by slash, was prepended to apiVersion. In the case of apps, the version would be apps/v1. Hence, the apiVersion field is actually misnamed; it stores the API group name and the version string. This is for historic reasons because apiVersion was defined when only the core group\u0026ndash;and none of these other API groups\u0026ndash;existed.\nObjectMeta most top-level objects have a field of type metav1.ObjectMeta, again from the package k8s.io/apimachinery/pkgs/meta/v1.\n1// ObjectMeta id metadata that all persisted resources must have, which includes all objects user must create. 2type ObjectMeta struct{ 3 // Name must be unique within a namespace. 4 Name string 5 GenerateName string 6 // Namespace defines the space within which each name must be unique. 7 Namespace string 8 SelfLink string 9 UID types.UID 10 // An opaque value that represents the internel version of this object that can be used by 11 // clients to determine when objects have changes. corresponds to a key in etcd. 12 ResourceVersion string 13 Generation int64 14 CreateTimestamp Time 15 DeleteTimestamp *Time 16 DeleteGracePeriodSeconds *int64 17 // Map of string keys and values that can be used to organize and categorize objects. 18 Labels map[string]string 19 // Annotations is an unstructrued key value map stored with a resource that may be set 20 // by externel tools to store and retrieve arbitrary metadata. 21 Annotations map[string]string 22 OwnerReferences []OwnerReference 23 // Finalizers must be empty before the object is deleted from the registry. 24 Finalizers []string 25 // The name of cluster which the object belongs to. 26 ClusterName string 27 ManagedFields []ManagedFieldsEntry 28} spec and status Finally, nearly every top-level object has a spec and a status section. This conventions comes from the declarative nature of the Kubernetes API: spec is the user desire, and status it the outcome of that desire, usually filled by a controller in the system.\nThere are only a few exception to the spec and status convention in the system-for example, endpoints in the core groups, or RBAC objects like ClusterRole.\nClient Set A client set gives access to clients for multiple API groups and resources. In the case of kubernetes.NewForConfig(config) from k8s.io/client-go/kubernetes, we get access to all API groups and resources defined in k8s.io/api. This is, with a few exception\u0026ndash;such as APIService and CustomerResourcesDefinition\u0026ndash; the whole set of resources served by the Kubernetes API server.\nThe client set main interface in k8s.io/client-go/kubernetes/clientset.go for Kubernetes-native resources like this:\n1type Interface interface{ 2 Discover() discover.DiscoverInterface 3 AppsV1() appsv1.AppsV1Interface 4 AppsV1beta1() appsv1beta1.AppsV1beta1Interface 5 AppsV1beta2() appsv1beta2.AppsV1beta2Interface 6 AuthenticationV1() authenticationv1.AuthenticationV1Interface 7 AuthenticationV1beta1() authenticationv1beta1.AuthenticationV1betaInterface 8 AuthorizationV1() authorizationv1.AuthorizationV1Interface 9 AuthorizationV1beta1() authorizationv1beta1.AuthorizationV1beta1Interface 10 ... 11} Behind each GroupVersion method, we find the resource of the API group.\n1type AppsV1beta1Interface interface { 2 RESTClinet() rest.Interface 3 ControllerRevisionGetter 4 DeploymentsGetter 5 StatefulSetsGetter 6} With RESTClinet being a generic REST client, and one interface per resource, as in:\n1// DeploymentsGetter has a method to return a DeploymentInterface. 2// A group\u0026#39;s client should implement this interface. 3type DeploymentsGetter interface{ 4 Deployments(name string) DeploymentInterface 5} 6 7// DeploymentInterface has methods to work with Deployment resources. 8type DeploymentInterface interface { 9\tCreate(ctx context.Context, deployment *v1beta1.Deployment, opts v1.CreateOptions) (*v1beta1.Deployment, error) 10\tUpdate(ctx context.Context, deployment *v1beta1.Deployment, opts v1.UpdateOptions) (*v1beta1.Deployment, error) 11\tUpdateStatus(ctx context.Context, deployment *v1beta1.Deployment, opts v1.UpdateOptions) (*v1beta1.Deployment, error) 12\tDelete(ctx context.Context, name string, opts v1.DeleteOptions) error 13\tDeleteCollection(ctx context.Context, opts v1.DeleteOptions, listOpts v1.ListOptions) error 14\tGet(ctx context.Context, name string, opts v1.GetOptions) (*v1beta1.Deployment, error) 15\tList(ctx context.Context, opts v1.ListOptions) (*v1beta1.DeploymentList, error) 16\tWatch(ctx context.Context, opts v1.ListOptions) (watch.Interface, error) 17\tPatch(ctx context.Context, name string, pt types.PatchType, data []byte, opts v1.PatchOptions, subresources ...string) (result *v1beta1.Deployment, err error) 18\tApply(ctx context.Context, deployment *appsv1beta1.DeploymentApplyConfiguration, opts v1.ApplyOptions) (result *v1beta1.Deployment, err error) 19\tApplyStatus(ctx context.Context, deployment *appsv1beta1.DeploymentApplyConfiguration, opts v1.ApplyOptions) (result *v1beta1.Deployment, err error) 20\tDeploymentExpansion 21} Depending on the scope of the resource\u0026ndash;that is , whether it is cluster or namespace scoped\u0026ndash; the accessor(here DeploymentsGetter) may or may not have a namespace argument.\nStatus Subresources: UpdateStatus Deployments have a so-called status subresource. This means that UpdateStatus uses an additional HTTP endpoint suffixed with /status. While updates on the /api/apps/v1beta1/namespace/ns/deployments/name endpoints can change only the spce of the deployment, the endpoint /api/apps/v1beta1/namespace/ns/deployments/name/status can change only the status of the object.\nBy default the client-gen generates the UpdateStatus() method.\nListings and Deletions DeleteCollections allows us to delete multiple objects of namespace at once. The ListOptions parameters allows us to define which objects should be deleted using a filed or label selector:\n1// k8s.io/apimachinery/pkg/apis/meta/v1/types.go 2// ListOptions is the query options to a standard REST list call. 3type ListOptions struct{ 4 TypeMeta 5 // A selector to restrict the list of returned objects by their labels. 6 LabelSelector string 7 // A selector to restrict the list of returned objects by their fields. 8 FieldSelector string 9 Watch bool 10 AllowWatchBookmarks bool 11 ResourceVersion string 12 ResourceVersionMatch ResourceVersionMatch 13 TimeSecond *int64 14 Limit int64 15 Continue string 16} Watches Watch gives an event interface for all changes(adds, removes, and updates) to objects. The returned watch.Interface form k8s.io/apimachinery/pkg/watch/watch.go.\n1// Interface can be implemented by anything that knows how to watch and report changes. 2type Interface interface{ 3 // Stop watching. Will close the channel returned by ResoultChan(). Release any resources 4 // used by watch. 5 Stop() 6 // Returns a chan which will receive all the events. If an errors occurs or Stop() 7 // is canceled, the implementation will close this channel and release any resources 8 // used by watch. 9 ResultChan() \u0026lt;-chan Event 10} The result channel of watch interface returns three kinds of events.\n1// EventType defines the possible types of events 2type EventTypes string 3const ( 4\tAdded EventType = \u0026#34;ADDED\u0026#34; 5 Modified EventType = \u0026#34;MODIFIED\u0026#34; 6 Deleted EventType = \u0026#34;DELETED\u0026#34; 7 Bookmark EventType = \u0026#34;BOOKMARK\u0026#34; 8 Error EventType = \u0026#34;ERROR\u0026#34; 9) 10 11// Event represents a single event to watched resource. 12Type Event struct{ 13 Type EventType 14 15 Object runtime.Object 16} While it is tempting to use this interface directly, in practice it is actually discouraged in favor of informers.\nInformers are a combination of this event interface and in-memory cache with indexed lookup. This is by far the most common use case for watches. Under the hood informers first call List on the client to get the set of all objects(as a baseline for the cache) and then Watch to update the cache.\nClient Expansion DeploymentExpansion is actually an empty interface. It is used to add custom client behavior, but it\u0026rsquo;s hardly used in Kubernetes nowdays. Instead, the client generator allows up to add custom methods in a declarative way.\nNote again that all of those methods in DeploymentInterface neither expect valid information in the TypeMeta fields Kind and APIVersion, nor set those fields on Get() and List(). These fields are filled with real values only on the wire.\nClient Options Client-go What is clientset?\nClientSet: every Resource has their own client, and ClientSet is a client set for different Resources. ClientSet on handle the k8s internal resource, generate by client-gen.\nDynamicClient is for CRD resources.\nDiscoverClient： find all api-resources\n获取kube conf的方式：\nfile path ~/.kube/config KUBECONFIG 合并多个kubeconfig 信息\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/kubernetes/k8s_dev_3_clinet_go/","summary":"Client-go The Client Library\u0026ndash; k8s.io/client-go The kubernetes programming interface in Go mainly consists of the k8s.io/client-go library (for brevity we will just call it client-go going foward).\nk8s.io/client-go is a typical web service client library that supports all API types that are officially part of Kubernetes. It can be used to execute the usual REST verbs.\nCreate Get List Update Delete Patch Watch For each Kubernetes 1.x.y release, there is a client-go release with a matching tag kubernetes-1.","tags":null,"title":"client-go"},{"categories":null,"contents":"4C8G 70%-80% 虚拟化浪费掉了\n裸金属\n2001 VMware虚拟化技术\n2006 AWS推出EC2服务\n2010 Openstack社区成立。 虚拟化技术，管理操作系统\n2011.04 第一个 开源PaaS平台 CloudFoundry\n2013.03 开源Docker发布。 操作系统之上的应用容器化。\n2014.06 Google 发布Kubernetes, 应用编排\n2015.07 Google 宣布成立CNCF基金会\nBuilding sustainable ecosystems for cloud native software.\nIaaS Infrastructure-as-a-service 基础设施即服务\nPaaS Platform as a service\nSaaS Software as a service\nCaaS container as a service\n优势 ：\n稳定性： 几个9 SLA 0.999 年宕机时间\n弹性扩展\n安全性\n成本\n易用性\nIDC\n单体架构\n集群架构阶段（单集群，同时只有一个实例提供服务）\n分布式架构阶段（负载均衡，同时提供服务）\n微服务架构， 以业务天然分库\nServiceMesh： 网格化架构\nRPC 远程调用/ Gateway 负载均衡-\u0026gt; 服务与IP映射 facade pattern ： 真正想做一件事，对外暴露统一访问接口：负载均衡、协议抓换、用户鉴权\nNginx 和API Gateway， 有交集，动态决定\nNginx：反向代理、负载均衡\nGateway： 鉴权，协议转换， 牵扯到业务代码的相关东西， 可以做更多的业务融合服务\n分布式 和集群的区别？\n分布式：把一个大型应用拆分出很多功能模块，各个功能部署再不同服务器上，所有的这些服务器联合起来提供完成服务。\n集群： 很多一模一样的服务\n软件 部署机器\nA 5 -\u0026gt; 集群\nB 4\nC 8\nD 7\n很多机器都可以叫做集群；不同服务部署到不同服务器，才能称为分布式；\n异地多活：\nIP 漂移， keep alive\n云上挑战\n云机器的资源编排\n云存储方案： 文件存储\n云负载均衡方案\n云缓存方案：CDN，数据库，中间件\n云持久化： Mysql\n云运维\n云监控：\n云容器技术：\n云DevOps\n云安全防护\n技术变革：\n动态扩容-\u0026gt; 水平扩容\n应用上云无关语言\ndocker \u0026ndash; docker shim-\u0026gt; k8s\n因为 docker 没有实现CRI（Container Runtime Interface）， 之前是通过docker shim 调用，实现CRI interface，还是干掉 docker。\n2021年底的最后一次更新会替换掉\ndocker-\u0026gt; 容器的封装层， containd(runc)?\n容器的所有思想都是通用的。容器，镜像。。。\n应用上云的新型架构： Kubernetes + serviceMesh\n云原生的生态系统 CloudNative\nMicroservice Containers Continuous Delivery DevOps 常见技术:\n基础研究量\nServiceMesh\nserverless：\n云原生的术语 graceful shutdown\n蓝绿部署，绿色环境为实验环境\ncka, ckad, cks 考证\npipeline\ndocker containerd runc 之间的关系\nhttps://zhuanlan.zhihu.com/p/87602649\nhttps://www.huweihuang.com/kubernetes-notes/runtime/runtime.html\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/blog/CloudNative/","summary":"4C8G 70%-80% 虚拟化浪费掉了\n裸金属\n2001 VMware虚拟化技术\n2006 AWS推出EC2服务\n2010 Openstack社区成立。 虚拟化技术，管理操作系统\n2011.04 第一个 开源PaaS平台 CloudFoundry\n2013.03 开源Docker发布。 操作系统之上的应用容器化。\n2014.06 Google 发布Kubernetes, 应用编排\n2015.07 Google 宣布成立CNCF基金会\nBuilding sustainable ecosystems for cloud native software.\nIaaS Infrastructure-as-a-service 基础设施即服务\nPaaS Platform as a service\nSaaS Software as a service\nCaaS container as a service\n优势 ：\n稳定性： 几个9 SLA 0.999 年宕机时间\n弹性扩展\n安全性\n成本\n易用性\nIDC\n单体架构\n集群架构阶段（单集群，同时只有一个实例提供服务）\n分布式架构阶段（负载均衡，同时提供服务）\n微服务架构， 以业务天然分库\nServiceMesh： 网格化架构\nRPC 远程调用/ Gateway 负载均衡-\u0026gt; 服务与IP映射 facade pattern ： 真正想做一件事，对外暴露统一访问接口：负载均衡、协议抓换、用户鉴权","tags":null,"title":"Cloud Native"},{"categories":null,"contents":"Patent Cloud-Native HSM is a cloud-native Hardware Security Module(HSM) service that allows you to host encryption keys in the Intel Software Guard extension enclave and perform cryptographic operations accelerated by QAT in a cluster of HSM. You can manage the HSM resource with the Kubernetes customer resources, so you do not need to worry about scaling, managing, and clustering. You can leverage the Kubernetes\u0026rsquo; function to provide the HSM to your service.\nThis is the architecture of the Cloud Native HSM.\nIf the application needs an HSM device to create a secure connection with a remote host, you can deploy an HSM agent as a sidecar to work with the application Pod. And then, the application can call the HSM controller to generate a Key Pair and a CSR. The HSM controller received the request and then call the corresponding HSM manager to really create a Key Pair and Generate a CSR from the CTK for Intel SGX. After that, the application can take the CSR to the remote CA center to get a certificate. The application can put the received certificate to the SGX enclave and cross the HSM controller through the HSM manager. After getting the certificate, the Application can call the Crypoki through the PKCS#11 client and PKCS#11 server to the CTK. Advantage:\nHSM agent works as a sidecar, and it won\u0026rsquo;t need to make any change in the application code. The application can use the Unix socket to involve the HSM. It keeps the safety of the HSM. HSM controller leverages the Kubernetes function to manage the HSM cluster, it\u0026rsquo;s convenient The SGX enhances the security of the data and private key. If they use the CTK for Intel SGX as a sidecar, and use the Unix socket to forward the PKCS#11 service between the Pod they will hit the patent.\nAWS Cloud HSM What is Cloud Hardware Security Module(HSM)?\nA hardware security module(HSM) is a computing device that processes cryptographic operations and provides secure storage for cryptographic keys.\nAWS Cloud HSM is a cloud-based hardware security module (HSM) that enables you to genereate and use you own encryption keys.\nCloud HSM is a compliant with FIPS 140-2 level 3 (The Federal Information Processing Stanard Publication 140-2)\nIt automates administrative tasks like hardware provisioning, sofeware pathcing, high-availability, and backups\nApplications can integrate with Cloud HSM using PKCS#11, Java Cryptography Extensions(JCE), and Microsoft CryptoNG (CNG) API libraries.\nCloudHSM can scale quickly on-demand with no up-front costs.\nCloud HSM Cluster AWS Cloud HSM provides hardware securtiy modules (HSM) in a cluster.\nA cluster is one logical HSM.\nTo interact with the HSMs in a cluster, you need the AWS Cloud HSM Client software.\nClient can be installed on Amazon EC2 instances, known as client instances, that reside in the same VPC as the HSM ENIs.\nWhen you perform a task or operation on the one HSM in a cluster, the other HSM in that cluster are automatically updated.\nYou can create a cluster that has from 1 to 28 HSMs (the defaut limit is 6 HSMs per AWS account per AWS region.)\nBenefits Generate and manager cryptographic keys Cluster based makes it easy to load balance and scale API based integration for Applications Integrates with AWS KMS to create custom key stores Google Cloud HSM Cloud HSM Cavium Liquid Security HSM\nWhy Cloud HSM\nComplicance\nFIPS 140-2 level 3 certified HSMs Regionalization\nHSM keys are cryptographically bound to region Avaiable in all GCP Regions Support for multi-regions No application changes for Cloud KMS customers\nSame API and client libraries as Cloud KMS It leverages the exact same API as Cloud KMS, what that mean is that if you know how to use cloud KMS, then you know howe to use Cloud HSM.\nKey Fearures:\nGlobal and multi-region support Attestation statement confidence your keys are hardware protected Cryptographically signed statement provided by the HSM verifying the creation of the key si within an HSM boundary and non-exportable statement can be verified manually or through a script verify key attriburtes CMEK integration The HSM is bind with Vm not bind with application Pod\nTenant Separation\nSummary Cloud HSM provides a scalable, reliable, and low-maintenance service Provides a modern, intergrated approach to administrative control and tenant isolation Keys can be effortlessly created in multi-regions or event a global region. HSM keys can be used to seamlessly protect your data-at-rest with CMEK services Look for an upcomming Cloud HSM white paper What is a Cloud Hardware Security Module The CloudHSM helps you meet corporate, contractual and regulatory compliance requirements for data security by using dedicated Hardware Secutiry Module(HSM) applicances withing the cloud.\nvery critical area in the cryptography, Stand out on CV, fundamental topic to learn for cloud security role.\n1. Title of the invention Cloud Native HSM based on Intel Software Guard Extension (SGX) And QAT\n2. names of the inventors Ren, Qiang 11717682\nYing, Ruoyu\nHuang, Jiahao\n3. TECHNOLOGY BACKGROUND 3.1 Problem Definition - What technical problem did you solve? There are many scenarios that need Hardware security module (HSM) to protect transactions, identities, and applications. HSM is excel at storing cryptographic keys and provisioning encryption, decryption, authentication, and digital signing service for a wide range of applications. The dilemma here is that most cloud native services are hard to co-work with the traditional HSM that are physical devices. In the cloud native scenario, most applications need the capability of scaling and dynamic migration, but the physical HSM is hard to meet the requirement.\nCloud-Native HSM is a cloud-native Hardware Security Module service that allows you to host encryption keys or data in the Intel Software Guard extensions (SGX) enclave and perform cryptographic operations accelerated by Quick Assistant Technology (QAT) in a cluster of HSM. You can manage the HSM resource with the Kubernetes customer resources, so you do not need to worry about scaling, managing, and clustering. You can leverage the IA (Intel Architecture) features which are SGX to keep the private data security and QAT to accelerate the data encryption.\n3.2 Previous Solutions (if any): Currently, there are two main types of cloud HSM. One is to provide users with the right to use HSM as a single tenant on the physical level, such as Microsoft Azure Dedicated HSM. The cloud providers deploy HSM in different data centers. When the customer needs it, the cloud providers preconfigure HSM and connect it to the customer\u0026rsquo;s virtual network as a cloud HSM so that only the customer can access it. After the customer accesses the cloud HSM for the first time and changes the password, the cloud providers will no longer have the management rights of this cloud HSM. The customer can have full control and management rights.\nThis is a highly specialized service. This service is very secure and easy to migrate programs that directly access physical HSM. The service can meet the unique needs of some large organizations. However, due to excessive cost, complex configuration, inconvenient scaling, and resource waste, it is not suitable for many customers.\nThe second is to provide virtual HSM for users, such as AWS Cloud HSM. The cloud providers generate multiple virtual HSM on the physical HSM through virtualization technology, and users can obtain the access permission of the virtual HSM as a single tenant. Users can easily start and stop virtual HSM, build Cloud HSM clusters, and automatically synchronize virtual HSM by using relevant Cloud HSM API in their own virtual network. The users configure the corresponding client on their own virtual machine instances, and then applications on the virtual machine instances can use the virtual HSM cluster through a secure network connection between client and server.\nThis is the current mainstream service. Customers can quickly build virtual HSM clusters through the various APIs provided by cloud providers. In addition to this, customers can quickly scale clusters on demand. However, this service will also bring a lot of costs, which is often unacceptable for those who want to use the cloud to reduce costs. Secondly, the solution provides services to virtual machine instances through a virtual HSM cluster, which does not conform to the idea of cloud native. Managing virtual HSM clusters and secure Internet connections requires the use of dedicated resources and integration, so the operation capability has also proved to be a problem.\n​\nFigure 1: Architecture of AWS Cloud HSM\n4. OVERVIEW OF THE INVENTION 4.1 Short summary – In 1-3 sentences, describe the core of your solution. a. Cloud-Native HSM provides HSM service for applications only with SGX feature of CPU, and the QAT is optional for acceleration, do not need to plug in another physical device to the machine.\nb. HSM agents work as a sidecar to provide Cryptoki for users’ application, which work as a usual physical device without code change for the application.\nc. The private key and sensitive data stored in the SGX enclave, it’s safety.\nd. The cryptographic operations can leverage the QAT to accelerate the process.\ne. Cloud-Native HSM is a Kubernetes native service which has capability of scaling, migrating and reliability.\n4.2 Advantages – In 1-3 sentences, describe the value of the invention to Intel or to our customers. In general, the Cloud Native HSM agent provides HSM service based on the Intel Software Guard Extensions (SGX) that keep the private key in the enclave and only the applications pod can access it which keeps the sensitive data’s security. And the HSM agent can scale and migrate with the application pod, which is convenient. What’s more, Cloud Native HSM can leverage the QAT to accelerate the cryptographic operations.\nCompared with the Cloud HSM, there is a risk for the transport between the application and the Cloud HSM. But, when using the Cloud HSM, the data will not leave the application Pod.\nCloud native HSM is especially suitable for the pod whose life cycle is consistent with that of confidential information, such as protecting the private key for a mutual SSL connection between to pod in service mesh from administrator attacks.\nCloud native HSM can also be used in combination with other security devices. For example, we can copy an existing private key from a Cloud HSM to the Cloud Native HSM, but not suggested.\nFor customers, the Cloud Native HSM provides them with a flexibility HSM device which can be managed by Kubernetes customer resources. It makes it much more convenient to use HSM in the cloud native application and much more secure for their application. The application can involve the Cloud Native HSM without code change.\nFor Intel, it is a good chance to promote the SGX technology to provide security service for most cloud native applications and promote the QAT technology to accelerate the encryption and decryption process. Thus, it is also helpful to promote our Sapphire Rapids Platform.\n5. Detectability 5.1 Please describe in detail how your invention is detectable in a final product. A. If your invention results in a specific structural feature please describe the appearance of that feature (e.g., include SEM/TEMs of actual features if available). B. If there are visual inspection and/or reverse engineering techniques that can be used to identify the feature, please describe them. If they use CTK for SGX work as a sidecar pod and forward the HSM token to the application pod through the Unix socket.\nC. If documentation such as product literature would show usage of the invention, please let us know what to look for in that regard. The cloud native application that wants to use HSM to provide a dedicated, secure, tamper-resistant environment to protect cryptographic keys and data, and to automate the lifecycle of those same keys. For example, the mutual SSL connection between to pod in service mesh like Istio.\n6. DETAILS OF THE INVENTION 6.1 Provide details that help us fully understand your invention, including details on how you solved the technical problem, and at least one figure. You may also provide flowcharts, graphs, slides, or data to support your description. Where appropriate, please provide and explain any empirical support, such as experimental data or) simulation results, that can demonstrate the viability of your invention.\nSoftHSM with Intel SGX/QAT: This works as a software HSM to provide enhancing the security of data and key protection applications by exposing interfaces. That runs the key generation and cryptographic operations securely inside an Intel Software Guard Extensions (SGX) enclave. And this can leverage the QAT to accelerate the cryptographic operations.\nHSM Agent: HSM Agent is an operator of the HSM customer resource which aims at managing the local SoftHSM, to create tokens, create key pairs, generate CSR, add certificate to the SGX enclave, and even add an existing private key to the SoftHSM.\nHSM Controller: The HSM Controller monitors the changing of the customer resource of HSM and calls the HSM Agent to apply the change of the resources.\nPKCS#11 Client/Server: PKCS#11 Server is used to forward the HSM token in the HSM agent container to the application pod through Unix socket. PKCS#11 Client connects to the PKCS#11 Server by the Unix socket and provides Cryptoki API for the application. For the application, the PKCS#11 Client and server is transparent. The application calls the HSM token through the PKCS#11 API like locally.\nFigure 2: Architecture of Cloud Native HSM\nFigure 1 is the architecture of the Cloud Native HSM.\nThe default workflow is as follows.\n\\1. If the application needs an HSM device to create a secure connection with a remote host, you can deploy an HSM agent as a sidecar reside the application Pod.\n\\2. And then, the application can call the Kubernetes API to create a customer resource of HSM Key Pair as follows.\n1apiVersion: soft-hsm-sgx.intel.com/v1alpha1 2kind: SoftHSMKeyPair 3metadata: 4 name: keypair-1 5 namespace: default 6spec: 7 name: keypair-1 8 applicationPod: application-1 9 token: 10 lable: \u0026#34;token-1\u0026#34; 11 slot: 0 12 soPin: 12345678 13 pin: 12345678 14 cert: 15 keyPair: 16 keyType: \u0026#34;rsa:2048\u0026#34; 17 lable: \u0026#34;keypair-1\u0026#34; 18 id: \u0026#34;0001\u0026#34; 19 subject: \u0026#34;/CN=application-1\u0026#34; 20 21 22apiVersion: soft-hsm-sgx.intel.com/v1alpha1 23kind: SoftHSMKeyPair 24metadata: 25 name: keypair-1 26 namespace: default 27spec: 28 name: keypair-1 29 applicationPod: application-1 30 token: 31 lable: \u0026#34;token-1\u0026#34; 32 slot: 0 33 soPin: 12345678 34 pin: 12345678 35 cert: 36 keyPair: 37 keyType: \u0026#34;rsa:2048\u0026#34; 38 lable: \u0026#34;keypair-1\u0026#34; 39 id: \u0026#34;0001\u0026#34; 40subject: \u0026#34;/CN=application-1\u0026#34; 41csr: CZ01fouDJIXLehgw62ol7TsuKC1CvUkVUiI= apiVersion: soft-hsm-sgx.intel.com/v1alpha1 kind: SoftHSMKeyPair metadata: name: keypair-1 namespace: default spec: name: keypair-1 applicationPod: application-1 token: lable: \u0026ldquo;token-1\u0026rdquo; slot: 0 soPin: 12345678 pin: 12345678 cert: keyPair: keyType: \u0026ldquo;rsa:2048\u0026rdquo; lable: \u0026ldquo;keypair-1\u0026rdquo; id: \u0026ldquo;0001\u0026rdquo; subject: \u0026ldquo;/CN=application-1\u0026rdquo;\n\\3. After creating the customer resource, the HSM controller will call the specific HSM agent according the applicationPod field to generate a Key Pair in the SGX enclave, and a CSR is created write back the SoftHSMKeyPair for the certificate request, which is a base64 encode string.\napiVersion: soft-hsm-sgx.intel.com/v1alpha1 kind: SoftHSMKeyPair metadata: name: keypair-1 namespace: default spec: name: keypair-1 applicationPod: application-1 token: lable: \u0026ldquo;token-1\u0026rdquo; slot: 0 soPin: 12345678 pin: 12345678 cert: keyPair: keyType: \u0026ldquo;rsa:2048\u0026rdquo; lable: \u0026ldquo;keypair-1\u0026rdquo; id: \u0026ldquo;0001\u0026rdquo; subject: \u0026ldquo;/CN=application-1\u0026rdquo; csr: CZ01fouDJIXLehgw62ol7TsuKC1CvUkVUiI=\n\\4. When the application pod found the CSR field is not empty, the applications can call the remote CA center to get a certificate for themselves.\n\\5. The application can put the received certificate to the pem filed with base64 encode in the customer resource of SoftHSMKeyPair. And then, the HSM controller will write the cert to the SoftHSM in SGX enclave cross the HSM controller and the HSM manager.\napiVersion: soft-hsm-sgx.intel.com/v1alpha1 kind: SoftHSMKeyPair metadata: name: keypair-1 namespace: default spec: name: keypair-1 applicationPod: application-1 token: lable: \u0026ldquo;token-1\u0026rdquo; slot: 0 soPin: 12345678 pin: 12345678 cert: keyPair: keyType: \u0026ldquo;rsa:2048\u0026rdquo; lable: \u0026ldquo;keypair-1\u0026rdquo; id: \u0026ldquo;0001\u0026rdquo; subject: \u0026ldquo;/CN=application-1\u0026rdquo; csr: CZ01fouDJIXLehgw62ol7TsuKC1CvUkVUiI= pem: y9EelphCnI2MFUvbVZ3YUl3aHhwcHRaY2g2OFQ2TGJyQml2dk9xSFA\n\\6. Finally, the application can call the Cryptoki through the PKCS#11 client and PKCS#11 server to the SoftHSM. The PKCS#11 client and PKCS#11 server are connected by the Unix socket mounted in a shared point. The application can offload the cryptographic operations to the HSM Agent container which use SGX for keep the security and QAT for acceleration.\nIf you already have an existing keypair and cert, you can use the Cloud Native HSM as follows.\n\\1. If the application needs an HSM device to create a secure connection with a remote host, you can deploy an HSM agent as a sidecar reside the application Pod.\n\\2. The application can call the Kubernetes api to create a customer resource SoftHSMKeyPair with existing keypair and cert which are base64 encoded like as follows:\napiVersion: soft-hsm-sgx.intel.com/v1alpha1 kind: SoftHSMKeyPair metadata: name: keypair-1 namespace: default spec: name: keypair-1 applicationPod: application-1 token: lable: \u0026ldquo;token-1\u0026rdquo; slot: 0 soPin: 12345678 pin: 12345678 privateKey: VZ3YUl3aHhwcHRaY2g2OFQ2 publicKey: 7TsuKC1CvUkVUi cert: keyPair: keyType: \u0026ldquo;rsa:2048\u0026rdquo; lable: \u0026ldquo;keypair-1\u0026rdquo; id: \u0026ldquo;0001\u0026rdquo; subject: \u0026ldquo;/CN=application-1\u0026rdquo; csr: CZ01fouDJIXLehgw62ol7TsuKC1CvUkVUiI= pem: y9EelphCnI2MFUvbVZ3YUl3aHhwcHRaY2g2OFQ2TGJyQml2dk9xSFA\n\\3. After creating the customer resource, the HSM controller will call the specific HSM agent according the applicationPod field to create a Key Pair with the existing key, and save the certificate in the SGX enclave.\n\\4. Finally, the application can call the Cryptoki through the PKCS#11 client and PKCS#11 server to the SoftHSM. The PKCS#11 client and PKCS#11 server are connected by the Unix socket mounted in a shared point. The application can offload the cryptographic operations to the HSM Agent container which use SGX for keep the security and QAT for acceleration.\nTODO:\n- Add load balance to this architecture\n- QAT accelerate\n- Attestation\n- Dedicated Device is expensive\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/sdewan/SGX-HSM/","summary":"Patent Cloud-Native HSM is a cloud-native Hardware Security Module(HSM) service that allows you to host encryption keys in the Intel Software Guard extension enclave and perform cryptographic operations accelerated by QAT in a cluster of HSM. You can manage the HSM resource with the Kubernetes customer resources, so you do not need to worry about scaling, managing, and clustering. You can leverage the Kubernetes\u0026rsquo; function to provide the HSM to your service.","tags":null,"title":"Cloud-Native HSM based on Intel Software Guard(SGX)"},{"categories":null,"contents":"Cluster Net Test Environment Access method 1# this machine is out of intel, please use the socks proxy: 2# proxy-prc.intel.com:1080 3# use this private key to access this the relay machine: 4# first login to 5ssh -p 3302 airren@124.223.99.93 # passwd: 123- 6# next login to 7ssh airren@node-1 # passwd:123- PreRequisites Kind Create cluster\n1# create cluster one node 2 3 4# create cluster multinode 5 6# create cluster with configuration Delete cluster\n1kind delete cluster --name=\u0026lt;clustername\u0026gt; Setup mcs-api demo Re-setup 4 cluster. This will create 4 K8s clusters by Kind. parent, child1,child2,child3.\n1cd ~/clusternet/hack 2./local-running.sh 3 4export KUBECONFIG=${HOME}/.kube/clusternet.config After that, you will see 4 clusters\u0026rsquo; contexts.\nCheck Clusters status\nDeploy application to child-clusters by kubectl clusternet.\nChange the cluster id in subscription.yaml to what you want to be deployed. 1cd ~/clusternet/examples/scheduling-with-mcs-api/scheduling 2vi subscription.yaml Deploy the applicaton(deployment, servcie, service-export) to the child-cluster\n1cd ~/clusternet/examples/scheduling-with-mcs-api/ 2k clusternet apply -f scheduling/ Deploy the service import in the Parent-Cluster\n1k apply -f service-import.yaml Check the deploy result.\nsuccessfullycreated a service.and then, find the endpointslice bind with this service\nThe service port name shoule be same with the endpoint slice Name.\nArchtecture Clusternet is a lightweight addon that consists of three components, clusternet-agent, clusternet-scheduler andclusternet-hub.\nClusternet-agent is responsible for:\nAuto-registering current cluster to parent cluster as a child cluster. Report heartbeats of current cluster, including kubernetes version, running platform, health/readyz/livez status,etc; setting up websocket connection that provides full-duplex communication channels over a single TCP connection to parent cluster. Clusternet-scheduler is responsible for\nscheduling resources/feeds to marched child clusters based on SchedulingStrategy. Clusternet-hub is responsible for\napproving cluster registration request and creating dedicated resources, suce as namespaces, servceaccounts and RBAC rules, for each child cluster;\nServing ad an aggregated apiserver(AA),which is used to provide shadow APIs and serve as a websocket server that maintain multiple active webscoket connections form child clusters;\nproviding Kubernetes-styled API to redirect/proxy/upgrade request to each child cluster.\ncoordinating and deploying applications to multiple clusters from a single set of APIs;\nClusterRegistrationRequest: This is cluster-agent created in parent-cluster for child-cluster.\n1k get clsrr ManagedCluseter: clusternet-hub approved the clsrr and created this object\n1k get mcls -A HelmChart: helm chart configuration\nSubscription: the resource for the child cluster. with a Base Object in corresponding namespace\nLocalization and Globalization\nBase\nDescription\nMultiCluster API ServiceExport ServiceExport, used to specify which service should be exposed across all clusters in the clusterset. ServiceExport must be created in each cluster that the underlying Service reside in. Creation of a ServiceExport in a cluster will signify that Service with the same name and namespace as the export should be visible to other clusters in the clusterset.\nServiceImport ServcieImport is introduced to act as the in-cluster representation of a multi-cluster service in each importing cluster. This is analogous to the traditional Service type in Kubernetes, Importing clusters will have a corresponding ServiceImport for each uniquely named Service that has been exported within the clusterset, referenced by namespaced name. ServiceImport resources will be managed by the MCS implementation\u0026rsquo;s mcs-controller.\nDebug of Clusternet Reference https://github.com/clusternet/clusternet/tree/main/examples/scheduling-with-mcs-api\nhttps://github.com/kubernetes/community/tree/master/sig-multicluster\nhttps://github.com/kubernetes/enhancements/tree/master/keps/sig-multicluster/1645-multi-cluster-services-api\n1$env:HTTP_PROXY=\u0026#34;proxy-prc.intel.com:913\u0026#34; 2$env:HTTPS_PROXY=\u0026#34;proxy-prc.intel.com:913\u0026#34; ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/sdewan/clusternet/","summary":"Cluster Net Test Environment Access method 1# this machine is out of intel, please use the socks proxy: 2# proxy-prc.intel.com:1080 3# use this private key to access this the relay machine: 4# first login to 5ssh -p 3302 airren@124.223.99.93 # passwd: 123- 6# next login to 7ssh airren@node-1 # passwd:123- PreRequisites Kind Create cluster\n1# create cluster one node 2 3 4# create cluster multinode 5 6# create cluster with configuration Delete cluster","tags":null,"title":"clusternet"},{"categories":null,"contents":"Docker CNM What is CNI?\nHow CNI plugin works?\nWhat a CNI plugin is made of?\nHow a CNI plugin is being used in K8s?\nHow a CNI plugin is executed?\nAnatomy of Pod networking\nWhat is CNI CNI stands for Container Networking Interface\nAn interface between container runtime and the network implementation\nConfigure the network interfaces and routes\nConcern itself only with the netwrok connectivity.\nHow CNI plugin works? A CNI binary Handle connectivity - configures the network interface of the Pod /opt/cni/bin A daemon Handle reachability - manager routings across the cluster What a CNI plugin is made of ? Part 1 /etc/cni/net.d contains the CNI configuration. The name decide the order.\nPart2 1# cat /opt/cni/bin/my-cni.demo 2case $CNI_COMMAND in 3ADD) 4 # configure networking for a new container 5;; 6DEL) 7 # cleanup when container is stopped 8;; 9GET) 10;; 11VERSION) 12 # get the version of CNI 13;; 14esac How CNI plugin is executed? 1CNI_COMMAND=ADD 2CNI_CONTAINERID=123456780 3CIN_NETNS=/proc/123456/netns 4CNI_IFNAME=eth0 1Container Info ---- env vars --- 2 3 ---\u0026gt; CNI 4CNI config ------ stdin -------- Anatomy of Pod Netwroking veth pair\n1case $CNI_COMMAND in 2ADD) 3 podcidr=$(cat /dev/stdin | jq -r \u0026#34;.podcidr\u0026#34;) # 10.240.0.0/24 4 podcidr_gw=$(echo $podcidr| sed \u0026#34;s:0/24:1/g\u0026#34;) # 10.240.0.1 5 btctl addbr cni0 # create a new bridge(if doesnt exist),cni0 6 ip link set cni0 up 7 ip addr add \u0026#34;$(podcidr_gw)/24\u0026#34; dev cni0 # assign 10.230.0.1/24 to cni0 8 9 10 host_ifname=\u0026#34;veth$n\u0026#34; # n = 1,2,3.. 11 ip link add $CNI_IFNAMW type veth peer name $host_ifname 12 ip link set $host_ifname up 13 14 ip link set $host_ifname master cni0 # connect veth1 to bridge 15 ln -sfT $CNI_NETNS /var/run/netns/$CNI_CONTAINERID 16 ip link set $CNI_IFNAME netns $CNI_CONTAINERID # move eth0 to Pod ns 17 18 # calculate $ip 19 ip netns exec $CNI_CONTAINERID ip link set $CNI_IFNAME up 20 ip netns exec $CNI_CONTAINERID ip link addr add $ip/24 dev $CNI_IFNAME 21 ip netns exec $CNI_CONTAINERID ip route add default via $podcidr_gw dev $CNI_IFNAME 22 23;; 1if [ -f /tmp/last_allocated_ip ]; then 2 n=`cat /tmp/last_allocated_ip` 3else 4 n =1 5fi 6ip=$(echo $podcidr| sed \u0026#34;s:0/24:$(($n+1)):g\u0026#34;) 7echo $(($n+1)) \u0026gt; /tmp/last_allocated_ip If the pod-to-pod communactaion is doesn\u0026rsquo;t work\n1iptables -A FORWARD -s 10.240.0.0/16 -j ACCEPT 2iptables -A FORWARD -d 10.240.0.0/16 -j ACCEPT connect to another node\n1# node-1 2ip route add 10.240.1.0/24 via 10.10.10.11 dev enp0s9 3# node-2 4ip route add 10.240.0.0/24 via 10.10.10.11 dev enp0s9 5# and enable ipv4-forward Pod to publice network need a SNAT\n1iptables -t nat -A POSTROUTING -s 10.240.0.0/24 -o cni0 -j MASQUERADE expose pod\n1kubectl expose pod nginx2 --port=8080 --target-port=80 2# this will create service with cluster IP CNI Kubernetes Networking Requirements\nEach Pod get their own IP addresss\nContainers within a Pod share network namespace All pod can communicate with all other pods without NAT(Network Address Translation)\nAll nodes can communicate with all pods without NAT\nThe IP of the Pod is same throughout the cluster\nruntime is the program responwsible for executing CNI plugins.\nplugin is a program that applies a specified network configuration.\nCNI generic parameters 1{ 2 \u0026#34;cniVersion\u0026#34;: \u0026#34;0.2.0\u0026#34;, 3 \u0026#34;name\u0026#34;: \u0026#34;mybridge\u0026#34;, 4 \u0026#34;type\u0026#34;: \u0026#34;bridge\u0026#34;, 5 \u0026#34;bridge\u0026#34;: \u0026#34;cni_bridge0\u0026#34;, 6 \u0026#34;isGateway\u0026#34;: true, 7 \u0026#34;ipMasq\u0026#34;: true, 8 \u0026#34;ipam\u0026#34;: { 9 \u0026#34;type\u0026#34;: \u0026#34;host-local\u0026#34;, 10 \u0026#34;subnet\u0026#34;: \u0026#34;10.15.20.0/24\u0026#34;, 11 \u0026#34;routes\u0026#34;: [ 12 { 13 \u0026#34;dst\u0026#34;: \u0026#34;0.0.0.0/0\u0026#34; 14 }, 15 { 16 \u0026#34;dst\u0026#34;: \u0026#34;1.1.1.1/32\u0026#34;, 17 \u0026#34;gw\u0026#34;: \u0026#34;10.15.20.1\u0026#34; 18 } 19 ] 20 } 21} cniVersion: The version of the CNI spec in thich the definition works with name: The network name type: The name of the plugin you wish to use. In this case, the actual name of the plugin executable args: Optinal additional parameters ipMasq: Configure outbound masquerade (source NAT) for this network ipam type: The name of the IPAM plugin executable subnet: The subnet to allocate out of (this is actually part of the IPAM plugin) routes: dst: The subnet you wish to reach gw: The IP address of the next hop to reach the dst. If not specified the default fateway for the subnet is assumed dns: nameservers: A list of nameservers you wish to use with this network domain: The search domain to use for DNS requests search: A list of search domains options: A list of options to be passed to the receiver Plugin (bridge) specific paramters isgateway: If true, assigns an IP address to the bridge so containers connected to it may use is as a gateway. isdefaultgateway: If true, sets the assigned IP address as the default route. forceAddress: Tell the plugin to allocate a new IP address if the previous value has changed. mtu: define the MTU of the bridge hairpinMode: Set hairpin mode for the interfaces on the bridge. These variables are passed to the plugin via environmental variables.\n1sudo CNI_COMMAND=ADD CNI_CONTAINERID=1234567890 CNI_NETNS=/var/run/netns/1234567890 CNI_IFNAME=eth12 CNI_PATH=`pwd` ./bridge \u0026lt; mybridge.conf CNI_COMMAND=ADD we are telling CNI that we want to add a connection CNI_CONTAINERID=1234567890 We\u0026rsquo;re telling CNI that the network namespace we want to work CNI_NETNS=/var/run/netns/1234567890 The path to the namspace CNI_IFNAME=eth12 The name of the interface we wish to use on the container side of the connection CNI_PATH=pwd We always need to tell CNI where the plugin executables live. In this [7/15/2022 10:33 AM] Ramakrishnan, Kuralamudhan https://www.dasblinkenlichten.com/understanding-cni-container-networking-interface/ [7/15/2022 10:36 AM] Ramakrishnan, Kuralamudhan https://github.com/containernetworking/cni/blob/main/SPEC.md [7/15/2022 10:36 AM] Ramakrishnan, Kuralamudhan https://github.com/containernetworking/plugins/tree/main/plugins/main/bridge [7/15/2022 10:37 AM] Ramakrishnan, Kuralamudhan https://github.com/containernetworking/plugins/blob/main/plugins/main/bridge/bridge.go\nhttps://www.youtube.com/watch?v=zmYxdtFzK6s\u0026ab_channel=CNCF%5BCloudNativeComputingFoundation%5D\nhttps://github.com/eranyanay/cni-from-scratch\nQuestion: the CNI configuration default path is /etc/cni/net.d/. If there are multiple configuration file in this path, for example, In SDEWAN project, there are as following:\n1root@pull-edge-1:/etc/cni/net.d# ll 2total 32 3drwxr-xr-x 4 root root 4096 Jul 12 14:09 ./ 4drwxr-xr-x 3 root root 4096 Jul 12 14:08 ../ 5-rw------- 1 root root 857 Jul 12 14:08 00-multus.conf 6-rw-r--r-- 1 root root 804 Jul 12 14:08 10-calico.conflist 7-rw-r--r-- 1 root root 88 Jul 12 14:09 20-network.conf 8-rw------- 1 root root 2854 Jul 19 09:11 calico-kubeconfig 9drwxr-xr-x 2 root root 4096 Jul 12 14:08 multus.d/ 10drwxr-xr-x 2 root root 4096 Jul 12 14:09 ovn4nfv-k8s.d/ ​ How kublet know which one is the default CNI? Does it depend on the file name numberic perfix ?\nI found all the CNI binary in this Path /opt/cni/bin. Is this a default PATH for CNI spec ? If any CNI will put the binary in this path. In the Service Function Chain Demo Archtecture. Is the brown box represent a virtual switch? And except the brown box, does it still need another CNI interface as the default CNI interface for kubelet to manager the pod. Does kubernetes support any versoin of CNI SPEC.For example, does kubernetest support all of the CNI SPEC version. Reference https://wiki.ith.intel.com/display/containers/Nodus\nHow kubelet find which one is the primariy CNI.\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/nodus/k8s-network-cni/","summary":"Docker CNM What is CNI?\nHow CNI plugin works?\nWhat a CNI plugin is made of?\nHow a CNI plugin is being used in K8s?\nHow a CNI plugin is executed?\nAnatomy of Pod networking\nWhat is CNI CNI stands for Container Networking Interface\nAn interface between container runtime and the network implementation\nConfigure the network interfaces and routes\nConcern itself only with the netwrok connectivity.\nHow CNI plugin works? A CNI binary Handle connectivity - configures the network interface of the Pod /opt/cni/bin A daemon Handle reachability - manager routings across the cluster What a CNI plugin is made of ?","tags":null,"title":"CNI Container Networking Interface"},{"categories":null,"contents":"openWRT Cross compile 1export STAGING_DIR=/home/airren/openwrt/staging_dir/toolchain-x86_64_gcc-8.4.0_musl 2 3 4export TOOLCHAIN_DIR=$STAGING_DIR 5export TOOLCHAIN_PATH=$TOOLCHAIN_DIR/bin 6export CXX=$TOOLCHAIN_PATH/g++-uc 7export AR=$TOOLCHAIN_PATH/x86_64-openwrt-linux-musl-ar 8export CXXFLAGS=\u0026#34;-O2\u0026#34; 9 10 11export CROSSCOMPILE_PATH=$TOOLCHAIN_DIR/usr 12# export CFLAGS=\u0026#34;-I$CROSSCOMPILE_PATH/jhhhhinclude\u0026#34; 13 14 15export LDCFLAGS=\u0026#34;-L$TOOLCHAIN_DIR/usr/lib -lz\u0026#34; 16export LD_LIBRARY_PATH=$TOOLCHAIN_DIR/usr/lib 17export PATH=$TOOLCHAIN_PATH:$PATH 1./autogen.sh --build=x86_64-pc-linux-gnu --host=i486-openwrt-linux 2./autogen.sh --build=x86_64-pc-linux-gnu --host=x86_64-openwrt-linux 3 4make CC=i486-openwrt-linux-gcc LD=i486-openwrt-linux-ld 5make CC=x86_64-openwrt-linux-gcc LD=x86_64-openwrt-linux-ld build openwrt in a docker\n1apt update 2apt install -y git wget build-essential gawk gcc-multilib flex git gettext libncurses5-dev libssl-dev python3-distutils rsync unzip zlib1g-dev 3 4apt update 5apt install build-essential ccache ecj fastjar file g++ gawk \\ 6gettext git java-propose-classpath libelf-dev libncurses5-dev \\ 7libncursesw5-dev libssl-dev python python2.7-dev python3 unzip wget \\ 8python-distutils-extra python3-setuptools python3-dev rsync subversion \\ 9swig time xsltproc zlib1g-dev 10 11 12 13 14# Update the feeds 15./scripts/feeds update -a 16./scripts/feeds install -a 17 18# Configure the firmware image and the kernel 19make menuconfig ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/blog/openwrt_cross_compile/","summary":"openWRT Cross compile 1export STAGING_DIR=/home/airren/openwrt/staging_dir/toolchain-x86_64_gcc-8.4.0_musl 2 3 4export TOOLCHAIN_DIR=$STAGING_DIR 5export TOOLCHAIN_PATH=$TOOLCHAIN_DIR/bin 6export CXX=$TOOLCHAIN_PATH/g++-uc 7export AR=$TOOLCHAIN_PATH/x86_64-openwrt-linux-musl-ar 8export CXXFLAGS=\u0026#34;-O2\u0026#34; 9 10 11export CROSSCOMPILE_PATH=$TOOLCHAIN_DIR/usr 12# export CFLAGS=\u0026#34;-I$CROSSCOMPILE_PATH/jhhhhinclude\u0026#34; 13 14 15export LDCFLAGS=\u0026#34;-L$TOOLCHAIN_DIR/usr/lib -lz\u0026#34; 16export LD_LIBRARY_PATH=$TOOLCHAIN_DIR/usr/lib 17export PATH=$TOOLCHAIN_PATH:$PATH 1./autogen.sh --build=x86_64-pc-linux-gnu --host=i486-openwrt-linux 2./autogen.sh --build=x86_64-pc-linux-gnu --host=x86_64-openwrt-linux 3 4make CC=i486-openwrt-linux-gcc LD=i486-openwrt-linux-ld 5make CC=x86_64-openwrt-linux-gcc LD=x86_64-openwrt-linux-ld build openwrt in a docker\n1apt update 2apt install -y git wget build-essential gawk gcc-multilib flex git gettext libncurses5-dev libssl-dev python3-distutils rsync unzip zlib1g-dev 3 4apt update 5apt install build-essential ccache ecj fastjar file g++ gawk \\ 6gettext git java-propose-classpath libelf-dev libncurses5-dev \\ 7libncursesw5-dev libssl-dev python python2.","tags":null,"title":"cross complile"},{"categories":null,"contents":"对称加密 非对称加密 RSA 由于计算非常复杂，只适用于小数据加密。\nHTTPS 非对称加密+对称加密\nmTLS 数字证书 数字证书的颁发过程一般为： 用户首先产生自己的密钥对，并将公共密钥以及部分个人身份信息传送给认证中心。认证中心在核实身份后，执行一些必要的步骤，以确认请求确实是由用户发送来的。然后，认证中心将发给用户一个数字证书。该证书内包含用户的个信息和他的公钥信息。同时还附有认证中心的签名信息。\n加密通信 Alice [Decode message by Alice\u0026rsquo;s private key] \u0026lt;\u0026mdash;- send message \u0026mdash; [message encrypted with Alice\u0026rsquo;s public key] Bob\n公钥加密，私钥解密\n数字签名 Bob 给Alice发送的文件需要携带数字签名。\nBob使用自己的私钥 以及文件的哈希值， 通过签名算法 计算出 数字签名\nAlice 收到文件后， 通过文件哈希值，Bob的数字签名，以及Bob的公钥 进行签名验证\n数字签名主要有以下三个作用：认证，确认收到的数据的身份信息；防止抵赖，文件一旦签名后不能反悔；防止篡改，保证文件在传输过程中的完整性。\n比特币其实就是数字签名\nX.509 数字证书 证书版本信息\n证书的序列号，每个证书都有一个唯一的证书序列号\n证书所使用的签名算法；\n证书的发行机构名称，命名规则一般采用X.500格式；\n证书的有效期，现在通用的证书一般采用UTC时间格式，它的计时范围1950-2049；\n证书所有人的名称，命名规则一般采用X.500格式；\n证书所有人的公开密钥；\n证书发行者对证书的签名；\nOpenssl 创建一个 root certificates 和 private key 用来为服务签署 certificates\n1openssl req -x509 -sha256 -nodes -days 365 -newkey rsa:2048 -subj \u0026#39;/O=example Inc./CN=example.com\u0026#39; -keyout root.key -out root.crt 创建一个 certificate 和 private for service\n1openssl req -out service.csr -newkey rsa:2048 -nodes -keyout service.key -subj \u0026#34;/CN=service/O=some organization\u0026#34; 2openssl x509 -req -days 365 -CA root.crt -CAkey root.key -set_serial 0 -in service.csr -out service.crt 创建一个client的certificate 和 private key\n1openssl req -out client.csr -newkey rsa:2048 -nodes -keyout client.key -subj \u0026#34;/CN=client/O=client organization\u0026#34; 2openssl x509 -req -days 365 -CA root.crt -CAkey root.key -set_serial 1 -in client.csr -out client.crt 1cert$ tree 2. 3├── root.crt # CERTIFICATE 4├── root.key # PRIVATE KEY 5├── client.crt 6├── client.csr # CERTIFICATE REQUEST 7├── client.key 8├── service.crt 9├── service.csr 10└── service.key 查看证书详情\n1openssl x509 -text -noout -in xxx.crt Step by Step Generate Keys, CSR \u0026amp; Self Signed Certificates Generate Key-Pair -\u0026gt; Extract Public Key -\u0026gt; Generate CSR File -\u0026gt; Generate Self-signed Certificate\n1# get key pair, contains private key and public key 2openssl genrsa -out demo.key 2048 # RSA PRIVATE KEY 3# extrace public frm above 4openssl rsa -in demo.key -pubout -out demo_pub.key # PUBLIC KEY 5# create CSR 6openssl req -new -key demo.key -out demo.csr 7# verify CSR 8openssl req -text -in demo.csr -noout -verify 9# self signed certificate 10openssl x509 -in demo.csr -out demo.crt -req -signkey demo.key -days 365 When create CSR need to fill some details.\nVerify the CRS created above.\nRSA - public key \u0026amp; private key\nuse private key to create CSR, and use CSR and sign-key to sign a certificate.\nPSCK#11 接口解析： https://blog.csdn.net/zhubeifen_521/article/details/89360027\nhttps://blog.csdn.net/wan706364166/article/details/8617293?spm=1001.2101.3001.6650.12\u0026utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7Edefault-12.no_search_link\u0026depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7Edefault-12.no_search_link\n在密码系统中，PKCS#11 时公钥加密标准(PKCS, Public-Key Cryptography Standards)的一份子,由RSA实验室发布，它为加密平台定义了一组平台无关的API，如硬件安全模块HSM和智能卡。\n由于没有一个真正的标准加密令牌，这个API已经发展成为一个通用的加密令牌的抽象层。PKCS#11 API定义最常用的加密对象类型(RSA密钥，X.509证书，DES/三重DES密钥等)和所有需要使用的功能，创建/生成，修改和删除这些对象。PKCS#11只提供了接口的定义，不包括接口的实现，一般接口的实现是由设备提供商提供的，如usbkey的生产商会提供符合PKCS#11接口标准的API实现。这样你只要通过接口调用API函数就可以实现其功能。\n本标准为那些保存密码信息，执行密码函数的设备确定一种程序设计接口(API)，该接口称作Cryptoki. 音“Crypto-Key”，cryptographic token interface(密码令牌接口), 它遵循一种基于对象的简单方法，提出技术独立性(各种各样的设备)和资源共享(多个应用程序访问多个设备)的目标，把设备的一种通用逻辑试图，即密码令牌，提供给应用程序。\nPKCS#11主要是应用于智能卡和HSM。大多数商业证书颁发机构软件使用PKCS#11访问CA的签名密钥或注册用户证书。\nmount /dev/sda1 /mnt/boot/efi\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/blog/1_cryptography/","summary":"对称加密 非对称加密 RSA 由于计算非常复杂，只适用于小数据加密。\nHTTPS 非对称加密+对称加密\nmTLS 数字证书 数字证书的颁发过程一般为： 用户首先产生自己的密钥对，并将公共密钥以及部分个人身份信息传送给认证中心。认证中心在核实身份后，执行一些必要的步骤，以确认请求确实是由用户发送来的。然后，认证中心将发给用户一个数字证书。该证书内包含用户的个信息和他的公钥信息。同时还附有认证中心的签名信息。\n加密通信 Alice [Decode message by Alice\u0026rsquo;s private key] \u0026lt;\u0026mdash;- send message \u0026mdash; [message encrypted with Alice\u0026rsquo;s public key] Bob\n公钥加密，私钥解密\n数字签名 Bob 给Alice发送的文件需要携带数字签名。\nBob使用自己的私钥 以及文件的哈希值， 通过签名算法 计算出 数字签名\nAlice 收到文件后， 通过文件哈希值，Bob的数字签名，以及Bob的公钥 进行签名验证\n数字签名主要有以下三个作用：认证，确认收到的数据的身份信息；防止抵赖，文件一旦签名后不能反悔；防止篡改，保证文件在传输过程中的完整性。\n比特币其实就是数字签名\nX.509 数字证书 证书版本信息\n证书的序列号，每个证书都有一个唯一的证书序列号\n证书所使用的签名算法；\n证书的发行机构名称，命名规则一般采用X.500格式；\n证书的有效期，现在通用的证书一般采用UTC时间格式，它的计时范围1950-2049；\n证书所有人的名称，命名规则一般采用X.500格式；\n证书所有人的公开密钥；\n证书发行者对证书的签名；\nOpenssl 创建一个 root certificates 和 private key 用来为服务签署 certificates\n1openssl req -x509 -sha256 -nodes -days 365 -newkey rsa:2048 -subj \u0026#39;/O=example Inc.","tags":null,"title":"Cryptography"},{"categories":null,"contents":"K8sStudy:\nDocker Node: Jenkins, Mysql, casbin_allinone, portioner,hemidall (1 node 4 core, 8G)\nODMS with NFS. (3 node, 1 NFS node)\nK8s node for CNI study\nK8s node for others, DPDK?\nDev node for source code and dev\nmove Openwrt and VM to a same node\nApplication Casdoor 1docker run -d --restart=always --name casdoor \\ 2-p 8001:8000 \\ 3casbin/casdoor-all-in-one Heimdall 1docker volume create heimdall 2docker run -d --restart unless-stopped --name=heimdall \\ 3-e PUID=1000 -e PGID=1000 -e TZ=Europe/London \\ 4-p 8086:80 -p 8463:443 \\ 5-v heimdall:/config \\ 6linuxserver/heimdall:latest CI\u0026amp;CD Jenkins 1docker volume create jenkins_data 2docker run -d --restart=always --name jenkins \\ 3-u 0 --privileged \\ 4-p 8080:8080 -p 50000:50000 \\ 5-v jenkins_data:/var/jenkins_home \\ 6-v /var/run/docker.sock:/var/run/docker.sock -v $(which docker):/usr/bin/docker \\ 7jenkins/jenkins:lts-jdk11 8 9# -v /var/run/docker.sock:/var/run/docker.sock -v $(which docker):/usr/bin/docker \\ 10 11# must ubuntu20.04 Docker pipeline configuration\n1 script{ 2 docker.withRegistry( \u0026#39;\u0026#39;, registryCredential ) { 3 dockerImage.push() 4 } 5 } https://octopus.com/blog/jenkins-docker-ecr\nhttps://medium.com/@gustavo.guss/jenkins-building-docker-image-and-sending-to-registry-64b84ea45ee9\nDatabase Mysql 1docker volume create mysql_data 2 3docker run -d --restart=always --name mysql \\ 4-p 3306:3306 \\ 5-e MYSQL_ROOT_PASSWORD=1q2w3e4r%T \\ 6-v mysql_data=/var/lib/mysql \\ 7mysql:8.0.30 Elastic Search 1docker run -d --name es01 \\ 2--net elastic -e ES_JAVA_OPTS=\u0026#34;-Xms1g -Xmx1g\u0026#34; \\ 3-p 9200:9200 -p 9300:9300 -it \\ 4docker.elastic.co/elasticsearch/elasticsearch:8.4.1 5 6# /usr/share/elasticsearch/config/certs/http_ca.crt 7# /usr/share/elasticsearch/bin/elasticsearch-reset-password -u elastic Cerebro 1docker volume create cerebro_data 2docker run -d --restart=always --name cerebro \\ 3-p 9001:9000 --net elastic \\ 4-v cerebro_data:/opt/cerebro \\ 5lmenezes/cerebro:0.9.4 Add host configration to cerebro\n1# /opt/cerebro/conf 2hosts = [ 3 { 4 host = \u0026#34;https://10.105.61.90:9200\u0026#34; 5 name = \u0026#34;ES Cluster\u0026#34; 6 auth = { 7 username = \u0026#34;elastic\u0026#34; 8 password = \u0026#34;MyPassword\u0026#34; 9 } 10 } 11] 12 13play.ws.ssl { 14 trustManager = { 15 stores = [ 16 { type = \u0026#34;PEM\u0026#34;, path = \u0026#34;/opt/cerebro/conf/http_ca.crt\u0026#34; } 17 ] 18 } 19 loose = { 20 disableHostnameVerification=true } 21} 22 23# Disabling certificate validation 24# #play.ws.ssl.loose.acceptAnyCertificate=true MinIO 1docker volume create minio_data 2 3docker run -d --restart=always --name minio \\ 4 -p 9000:9000 \\ 5 -p 9099:9099 \\ 6 -v minio_data:/data \\ 7 -e \u0026#34;MINIO_ROOT_USER=admin\u0026#34; \\ 8 -e \u0026#34;MINIO_ROOT_PASSWORD=1q2w3e4r%T\u0026#34; \\ 9 minio/minio server /data --console-address \u0026#34;:9099\u0026#34; what is S3\nDocker manager Portainer 1docker volume create portainer_data 2docker run -d --restart=always --name portainer \\ 3-p 8000:8000 -p 9443:9443 -p 9090:9000 \\ 4-v /var/run/docker.sock:/var/run/docker.sock \\ 5-v portainer_data:/data \\ 6portainer/portainer-ce:latest Jira 1 docker volume create jira_data 2 docker run -d --restart=always --name jira \\ 3 -p 8082:8080 -v jira_data:/var/jira -e TZ=\u0026#39;Asia/Shanghai\u0026#39;\\ 4 haxqer/jira:9.5.0 5 6 7 docker exec jira java -jar /var/agent/atlassian-agent.jar \\ 8 -p jira \\ 9 -m haxqer666@gmail.com \\ 10 -n haxqer666@gmail.com \\ 11 -o http://echo-bio.cn:8082 \\ 12 -s B2GJ-KD5D-6V6J-KCK7 13 14 15 configure ubuntu as a router 1sudo iptables -t nat -A POSTROUTING -o eth1 -j MASQUERADE 2sudo iptables -A FORWARD -i eth1 -o eth0 -m state --state RELATED,ESTABLISHED -j ACCEPT 3sudo iptables -A FORWARD -i eth0 -o eth1 -j ACCEPT 4 5 6 7sudo iptables -t nat -A POSTROUTING -s 10.8.0.0/24 -o ens160 -j MASQUERADE 8sudo iptables -t nat -A POSTROUTING -s 10.0.12.0/24 -o ens160 -j MASQUERADE 9 10 11 12vi /etc/sysctl.conf 13 14net.ipv4.ip_forward = 1 # 没有则添加，有修改为1（0禁止，1开启） 15 16sysctl -p ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/component/deployment/","summary":"K8sStudy:\nDocker Node: Jenkins, Mysql, casbin_allinone, portioner,hemidall (1 node 4 core, 8G)\nODMS with NFS. (3 node, 1 NFS node)\nK8s node for CNI study\nK8s node for others, DPDK?\nDev node for source code and dev\nmove Openwrt and VM to a same node\nApplication Casdoor 1docker run -d --restart=always --name casdoor \\ 2-p 8001:8000 \\ 3casbin/casdoor-all-in-one Heimdall 1docker volume create heimdall 2docker run -d --restart unless-stopped --name=heimdall \\ 3-e PUID=1000 -e PGID=1000 -e TZ=Europe/London \\ 4-p 8086:80 -p 8463:443 \\ 5-v heimdall:/config \\ 6linuxserver/heimdall:latest CI\u0026amp;CD Jenkins 1docker volume create jenkins_data 2docker run -d --restart=always --name jenkins \\ 3-u 0 --privileged \\ 4-p 8080:8080 -p 50000:50000 \\ 5-v jenkins_data:/var/jenkins_home \\ 6-v /var/run/docker.","tags":null,"title":"Deploy essential components by Docker"},{"categories":null,"contents":"GitHub: Intel Device plugins for Kubernetes\nDevice Plugins Device Plugins\nUse the Kubernetes device plugin framework to implement plugins for GPUs, NICs, FPGAs, InfiniBand, and similar resources that require vendor-specific setup.\nInstead of customizing the code for Kubernetes itself, vendors can implements a device plugin that you deploy either manually or as a DaemonSet. The targeted device include GPUs, high-performance NICs, FPGAs, InfiniBand adapters, and other similar computing resources that may require vendor specific initialization and setup.\nDevice plugin registration The kubelet exports a Registration RPC service:\n1service Registration{ 2 rpc Register(RegisterRequest) return (Empty){} 3} Then, user can request devices in a Container specification as they request other types of resources, with the following limitations:\nExtended resources are only supported as integer resources and cannot be overcommitted. Devices cannot be shared among Containers. Here is an example of a pod requesting this resource to run a demo workload.\n1--- 2apiVersion: v1 3kind: Pod 4metaData: 5\tname: demo-pod 6spec: 7\tcontainers: 8\t- name: demo-container-1 9\timages: k8s.gcr.io/pause:2.0 10\tresource: 11\tlimit: 12\thardware-vendor.example/foo: 2 13# This Pod need 2 of the hardware-vendor.example/foo devices and can only schedule onto a Node 14# that\u0026#39;s able to satisfy the need. 15# If the Node has more than 2 of those device avaiable, the remainder would be available for 16# other Pods to use. ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/kubernetes/k8s_ops_device_plugin/","summary":"GitHub: Intel Device plugins for Kubernetes\nDevice Plugins Device Plugins\nUse the Kubernetes device plugin framework to implement plugins for GPUs, NICs, FPGAs, InfiniBand, and similar resources that require vendor-specific setup.\nInstead of customizing the code for Kubernetes itself, vendors can implements a device plugin that you deploy either manually or as a DaemonSet. The targeted device include GPUs, high-performance NICs, FPGAs, InfiniBand adapters, and other similar computing resources that may require vendor specific initialization and setup.","tags":null,"title":"Device Plugin"},{"categories":null,"contents":"镜像仓库 Linux 本地镜像仓库：/var/lib/docker/image\n镜像应该是分层存储的。\nDocker images 是存储在镜像仓库服务Images Registry。Docker 客户端的镜像仓库服务是可配置的，默认使用的是Docker Hub。\n镜像仓库服务包含多个镜像仓库 Image Repository（同一个镜像的不同版本）。一个镜像仓库中包含多个镜像Image。\nDocker Hub 也分为Official Repository 和 Unofficial Repository。\n1docker pull \u0026lt;repository\u0026gt;:\u0026lt;tag\u0026gt; 2// 如果省略tag默认会pull tag 为 latest的image。但是latest并不保证这是仓库中最新的镜像。 如果希望从第三方镜像服务仓库获取镜像(not Docker Hub)，则需要在镜像仓库名称前加上第三方镜像仓库服务的DNS名称。\n1# gcr.io -\u0026gt; Google Container Images Registry. 2docker pull gcr.io/k8s-staging-nfd/node-feature-discovery:master Image Tag 不同的Images Tag可以绑定同一个Image ID\n通过--filter 来过滤docker image ls 返回的内容\n1docker image ls --filter dangling=true dangling image -\u0026gt; with out name \u0026amp; tag :.\n通常因为构建新的镜像，为该镜像打了一个已经存在的标签。Docker会remove old image上的标签，将该标签标在新Image上。Old Image 就会变成 dangling image。\n可以通过docker image prune 移除所有的Dangling images。如果添加下了-a参数，Docker会移除所有没有使用的镜像。\ndocker image 格式化输出 go text template\n1docker images --format \u0026#34;{{.Repository}}:{{.Tag}}:{{.Size}}\u0026#34; 从容器创建一个镜像 1docker commit [OPTIONS] CONTAINER [REPOSITORY[:TAG]] 2docker commit -a \u0026#34;bytegopher.com\u0026#34; -m \u0026#34;first commit\u0026#34; a404c6c174a2 mymysql:v1 3# -a 提交镜像的作者 4# -m 提交信息 Re-Tag The image\n1docker tag images:tag new-image:new-tag 镜像分层 Docker 是由一些松耦合的只读镜像层组成，Docker负责堆叠这些层，并将他们表示为单个统一的对象。\ndocker pull images 的时候可以看到是逐层下载的。\nBuilder Image WORKDIR: 如果没有文件夹，会创建并进入。\nDocker Build Use Proxy\n1 2docker build -f Dockerfile ./ -t image-name:tag --build-arg http_proxy=$(HTTP_PROXY) --build-arg https_proxy=$(HTTPS_PROXY) 3 4 5--build-arg http_proxy=http://proxy-prc.intel.com:913 --build-arg https_proxy=http://proxy-prc.intel.com:913 ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/cloudnative/Docker/docker_build_image/","summary":"镜像仓库 Linux 本地镜像仓库：/var/lib/docker/image\n镜像应该是分层存储的。\nDocker images 是存储在镜像仓库服务Images Registry。Docker 客户端的镜像仓库服务是可配置的，默认使用的是Docker Hub。\n镜像仓库服务包含多个镜像仓库 Image Repository（同一个镜像的不同版本）。一个镜像仓库中包含多个镜像Image。\nDocker Hub 也分为Official Repository 和 Unofficial Repository。\n1docker pull \u0026lt;repository\u0026gt;:\u0026lt;tag\u0026gt; 2// 如果省略tag默认会pull tag 为 latest的image。但是latest并不保证这是仓库中最新的镜像。 如果希望从第三方镜像服务仓库获取镜像(not Docker Hub)，则需要在镜像仓库名称前加上第三方镜像仓库服务的DNS名称。\n1# gcr.io -\u0026gt; Google Container Images Registry. 2docker pull gcr.io/k8s-staging-nfd/node-feature-discovery:master Image Tag 不同的Images Tag可以绑定同一个Image ID\n通过--filter 来过滤docker image ls 返回的内容\n1docker image ls --filter dangling=true dangling image -\u0026gt; with out name \u0026amp; tag :.\n通常因为构建新的镜像，为该镜像打了一个已经存在的标签。Docker会remove old image上的标签，将该标签标在新Image上。Old Image 就会变成 dangling image。","tags":null,"title":"Docker Images"},{"categories":null,"contents":"Docker networking is based on an open-source pluggable architecture called the Container Network Model(CNM). libnetwork is Docker\u0026rsquo;s real-work implementation of the CNM, adn it provides all of the Docker\u0026rsquo;s core networking capabilities. Drivers plug into libnework to provide specifice network topologies.\nThe theory At the highest level, Docker networking comprise three major components.\nSingle-host bridge network ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/cloudnative/Docker/docker_networking/","summary":"Docker networking is based on an open-source pluggable architecture called the Container Network Model(CNM). libnetwork is Docker\u0026rsquo;s real-work implementation of the CNM, adn it provides all of the Docker\u0026rsquo;s core networking capabilities. Drivers plug into libnework to provide specifice network topologies.\nThe theory At the highest level, Docker networking comprise three major components.\nSingle-host bridge network ","tags":null,"title":"Docker networking"},{"categories":null,"contents":"Dockerfile 中的entrypoint 和CMD的区别\n1CMD executable param1 param2 # 不用使用这种shell表示法，1 号进程为shell 2CMD [\u0026#34;executable\u0026#34;,\u0026#34;param1\u0026#34;,\u0026#34;param2\u0026#34;] EntryPoint 和CMD都可以在执行的时候被覆盖。\n组合使用ENTRYPOINT和CMD, ENTRYPOINT指定默认的运行命令, CMD指定默认的运行参数. 例子如下:\n1FROM ubuntu:trusty 2ENTRYPOINT [\u0026#34;/bin/ping\u0026#34;,\u0026#34;-c\u0026#34;,\u0026#34;3\u0026#34;] 3CMD [\u0026#34;localhost\u0026#34;] docker 会把CMD的命令拼接到Entrypoint之后\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/blog/docker_dockerfile/","summary":"Dockerfile 中的entrypoint 和CMD的区别\n1CMD executable param1 param2 # 不用使用这种shell表示法，1 号进程为shell 2CMD [\u0026#34;executable\u0026#34;,\u0026#34;param1\u0026#34;,\u0026#34;param2\u0026#34;] EntryPoint 和CMD都可以在执行的时候被覆盖。\n组合使用ENTRYPOINT和CMD, ENTRYPOINT指定默认的运行命令, CMD指定默认的运行参数. 例子如下:\n1FROM ubuntu:trusty 2ENTRYPOINT [\u0026#34;/bin/ping\u0026#34;,\u0026#34;-c\u0026#34;,\u0026#34;3\u0026#34;] 3CMD [\u0026#34;localhost\u0026#34;] docker 会把CMD的命令拼接到Entrypoint之后","tags":null,"title":"Dockerfile"},{"categories":null,"contents":"We have a sever for code test, but with the test case growth, the Disk space is not enough for use.\nFortunately, we use ubuntu LVM to manage the Disk.\n1fdisk /dev/sdb 1pvdisplay https://gyazo.com/40b3c078d6bb755f9cca318b3c28b2cf\n1vgextend ubuntu-vg /dev/sdc1 1vgdisplay 1lvdisplay 1lvextend -l +100%FREE /dev/ubuntu-vg/ubuntu-lv 2resize2fs /dev/ubuntu-vg/ubuntu-lv Multipass extend VM disk size.\nMultipass uses qemu to create the VM instance. So you can modify the qemu image manually to change the VM disk size.\nStop the VM 1multipass stop vm-name Find the VM image 1/var/snap/multipass/common/data/multipassd/vault/instances Expand the size of the image 1qemu-img resize xxx.img 200G 2# qemu-img resize xxx.img +100G Restart the VM 1multipass start vm-name https://blog.yqxpro.com/2021/10/31/%E9%80%9A%E8%BF%87LVM%E7%BB%99Ubuntu%E6%B7%BB%E5%8A%A0%E7%A1%AC%E7%9B%98%E7%A9%BA%E9%97%B4/\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/linux/linux-ubuntu-lvm/","summary":"We have a sever for code test, but with the test case growth, the Disk space is not enough for use.\nFortunately, we use ubuntu LVM to manage the Disk.\n1fdisk /dev/sdb 1pvdisplay https://gyazo.com/40b3c078d6bb755f9cca318b3c28b2cf\n1vgextend ubuntu-vg /dev/sdc1 1vgdisplay 1lvdisplay 1lvextend -l +100%FREE /dev/ubuntu-vg/ubuntu-lv 2resize2fs /dev/ubuntu-vg/ubuntu-lv Multipass extend VM disk size.\nMultipass uses qemu to create the VM instance. So you can modify the qemu image manually to change the VM disk size.","tags":null,"title":"Extend Disk Space without shutdown"},{"categories":null,"contents":" type desc total physical mem used used = total- free-buffers-cache free Free/Unused memory shared It is here only for backward comopatibility buff/cache The combined memory used by the kernel buffers and page cache ans slabs. This memory can be reclaimed at any time if needed by the applicaitons. If you want buffers and cache to displayed in two separate columns, use -w options. available An estimate of the amount of memory that is availablew for starting new applications, without swaping. https://linuxize.com/post/free-command-in-linux/\nhttps://www.cnblogs.com/peida/archive/2012/12/25/2831814.html\nhttps://www.jianshu.com/p/2ffeb3a3aa90\nhttps://www.codenong.com/jsafe796ceec93/\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/cloudnative/Linux/free/","summary":"type desc total physical mem used used = total- free-buffers-cache free Free/Unused memory shared It is here only for backward comopatibility buff/cache The combined memory used by the kernel buffers and page cache ans slabs. This memory can be reclaimed at any time if needed by the applicaitons. If you want buffers and cache to displayed in two separate columns, use -w options. available An estimate of the amount of memory that is availablew for starting new applications, without swaping.","tags":null,"title":"free命令"},{"categories":null,"contents":"1# git cache user and passwd 2git config --global credential.helper cache ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/cloudnative/Linux/git/","summary":"1# git cache user and passwd 2git config --global credential.helper cache ","tags":null,"title":"Git"},{"categories":null,"contents":"Golang的汇编是基于Plan9的的汇编，是一个中间汇编的方式，这样可以忽略底层CPU架构的差别。\n汇编主要了解各种寄存器的使用以及寻址方式。根据Golang的汇编我们可以深入理解Golang的底层实现。比如内存如何分配，栈如何扩张，接口如何转变。\n如何从go语言获取对应的汇编\n1go build -gcflags \u0026#34;-N -l\u0026#34; -ldflags=-compressdwarf=false =o main.out main.g 2go tool objdump -s \u0026#34;main.main\u0026#34; main.out \u0026gt; main.S 3# or 4go tool compile -S main.go 5# or 6go build -gcflags -S main.go 汇编基础语法 通用寄存器 寄存器与物理机架构有关，不同的架构有不同的物理寄存器。\n在amd64架构上提供了16个通用寄存器给用户使用。\nPlan9汇编语言提供了如下映射，这样就可以在汇编语言中这几应用就可以使用物理寄存器了。\nx64架构中所有的寄存器都是64位\namd64 Plan9 rax AX rbx BX rcx CX rdx DX rdi DI rsi SI rbp BP rsp SP r8 R8 r9 R9 r10 R10 r11 R11 r12 R12 r13 R13 r14 R14 rip PC 虚拟寄存器 伪寄存器不是真正的寄存器，而是由工具链维护的虚拟寄存器，例如帧指针。\nFP: Frame pointer: arguements and locals。 帧指针，快速访问函数的参数和返回值\n0(FP) represent the first arguement, 8(FP) represents the second parameter(AMD64 arch). first_arg+0(FP)表示把第一个参数地址绑定到符号first_arg\nSP: Stack pointer: the highest address within the local stack frame. 指向当前栈顶。栈指针，指向局部变量。\nlocalvar0-8(SP)在plan9中表示函数的第一个局部变量。物理寄存器中也有SP,硬件SP才是真正表示栈顶的位置。所以为了区分SP到底是指硬件SP还是虚拟寄存器。Plan9代码中需要以特定的格式来区分。\nsymbol+offset(SP)表示虚拟寄存器SP。offset(SP)表示硬件SP.\nPC: Program counter: jumps and branchs。 程序计数器，指向下一条指令的地址。在amd64时其实就是rip寄存器。\n除了个别跳转治理，一般用不到\nSB: Static base pointer: global symbols。静态基址指针，全局符号。\n表示全局内存起点。foo(SB)表示符号foo作为内存地址使用。这种形式用于声明全局函数、数据。foo+4(SB)表示foo往后4字节的地址。\u0026lt;\u0026gt;限制符号只能在当前源文件使用。\n所有用户定义的符号都作为偏移量写入伪寄存器 FP 和 SB。\n汇编代码中需要表示用户定义的符号(变量)时，可以通过 SP 与偏移还有变量名的组合，比如x-8(SP) ，因为 SP 指向的是栈顶，所以偏移值都是负的，x则表示变量名\n寻址模式 汇编语言的一个很重要的概念就是它的寻址模式，Plan 9 汇编也不例外，它支持如下寻址模式：\n1R0 数据寄存器 2A0 地址寄存器 3F0 浮点寄存器 4CAAR, CACR, 等 特殊名字 5$con 常量 6$fcon 浮点数常量 7name+o(SB) 外部符号 8name\u0026lt;\u0026gt;+o(SB) 局部符号 9name+o(SP) 自动符号 10name+o(FP) 实际参数 11$name+o(SB) 外部地址 12$name\u0026lt;\u0026gt;+o(SB) 局部地址 13(A0)+ 间接后增量 14-(A0) 间接前增量 15o(A0) 16o()(R0.s) symbol+offset(SP) 引用函数的局部变量，offset 的合法取值是 [-framesize, 0) 局部变量都是 8 字节，那么第一个局部变量就可以用 localvar0-8(SP) 来表示\n如果是 symbol+offset(SP) 形式，则表示伪寄存器 SP 如果是 offset(SP) 则表示硬件寄存器 SP\nAssembler Directives DATA\u0026amp;GLOBL Fomat: Declare a global variable using DATA and GLOBL\n全局数据符号以DATA指令起始和一个GLOBL指令定义。每个DATA指定初始化相应内存的一部分。未初始化的内存为零。一般形式为\n1DATA sysbol+offset(SP)/width, value 在给定的offset和width处初始化该符号的内存为value。DATA必须通过增加的偏移量来写入给定符号的指令。\nGLOBL指令声明符号是全局的。参数是可选标志，并且数据的大小被声明为全局，除非DATA指令已初始化，否则初始值将为全0.\n1DATA divtab\u0026lt;\u0026gt;+0x00(SB)/4, $0xf4f8fcff # set value for divtab from 0 to 4 2DATA divtab\u0026lt;\u0026gt;+0x04(SB)/4, $0xf3f4f8f9 3.... 4DATA divtab\u0026lt;\u0026gt;+0x3c(SB)/4, $0xf3f4f8f9 # divtab 64bytes 5GLOBL divtab\u0026lt;\u0026gt;(SB),RODATA,$64 # add flag RODATA means readonly, 6 #$64 is the var\u0026#39;s length 64byte 7 8GLOBL runtime.tlsoffset(SB),NOPTR,$4 # NOPTR This data contains no pointers. Rumtime Flag\nTEXT 1TEXT runtime.profileloop(SB),NOSPLIT,$8 # NOSPIT // Don\u0026#39;t insert stack check preamble. 2\tMOVQ $runtime.profileloop(SB),CX 3\tMOVQ CX, 0(SP) 4\tCALL runtime.externalthreadhandler(SB) 5\tRET 这段代码成为一个TEXT block，runtime.profileloop(SB)后面有一个NOSPLIT flag，紧随其后的$8表示frame_size, 通常frame_size的构成都是形如$8-24,表示这个text block运行需要占用8byte的内存空间，参数和返回值要占用24Byte的内存空间。(这24个字节占用的是调用方栈帧里的空间)。\n如果有NOSPLIT这个flag，则可以忽略参数和返回值占用的空间，如上述例子，只有一个$8。表示frame_zise只有8字节大小。这从汇编中也可以看出来 MOVQ CX,0(SP)， 因为MOVQ表示这个操作的操作数是8Bytes.\nFUNCDATA 和PCDATA指令包含了有垃圾回收器使用的信息，由编译器引入\nInstruction 常用指令有以下几类：数据移动类，例如MOV；跳转，无条件跳转或者有条件跳转；逻辑运算和算数运算；还有指令的prefix, 例如LOCK\nInstructoin Size MOVB 1 Bytes MOVW 2 Bytes MOVL 4 Bytes MOVQ 8 Bytes JMP MOVEQ LEAQ SUBQ ANDQ CALL PUSHQ POPQ CLD CMPQ CPUID JEQ ​\n运行时协调 为保证垃圾回收的正确运行，在大多数的栈帧中，运行时必须知道所有的全局数据的指针。Go编译器会将这一部分信息耦合到Go源码文件中，但是汇编程序必须进行显式的定义。\n被标记为 NOPTR 标志的数据符号会视为不包含指向运行时分配数据的指针。 带有 R0DATA 标志的数据符号在只读存储器中分配，因此被隐式标记为 NOPTR。 总大小小于指针的数据符号也被视为隐式标记 NOPTR。 在一份汇编源文件中是无法定义包含指针的符号的，因此这种符号必须定义在 Go 源文件中。 一个良好的经验法则是 R0DATA 在 Go 中定义所有非符号而不是在汇编中定义。\n每个函数还需要注释，在其参数，结果和本地堆栈框架中给出实时指针的位置。 对于没有指针结果且没有本地堆栈帧或没有函数调用的汇编函数， 唯一的要求是在同一个包中的 Go 源文件中为函数定义 Go 原型。 汇编函数的名称不能包含包名称组件 （例如，syscall 包中的函数 Syscall 应使用名称 ·Syscall 而不是 syscall·Syscall 其 TEXT 指令中的等效名称）。 对于更复杂的情况，需要显式注释。 这些注释使用标准 #include 文件中定义的伪指令 funcdata.h。\n如果函数没有参数且没有结果，则可以省略指针信息。这是由一个参数大小 $n-0 注释指示 TEXT 对指令。 否则，指针信息必须由 Go 源文件中的函数的 Go 原型提供，即使对于未直接从 Go 调用的汇编函数也是如此。 （原型也将 go vet 检查参数引用。）在函数的开头，假定参数被初始化但结果假定未初始化。 如果结果将在调用指令期间保存实时指针，则该函数应首先将结果归零， 然后执行伪指令 GO_RESULTS_INITIALIZED。 此指令记录结果现在已初始化，应在堆栈移动和垃圾回收期间进行扫描。 通常更容易安排汇编函数不返回指针或不包含调用指令; 标准库中没有汇编函数使用 GO_RESULTS_INITIALIZED。\n如果函数没有本地堆栈帧，则可以省略指针信息。这由 TEXT 指令上的本地帧大小 $0-n 注释表示。如果函数不包含调用指令，也可以省略指针信息。否则，本地堆栈帧不能包含指针，并且汇编必须通过执行伪指令 TEXTNO_LOCAL_POINTERS 来确认这一事实。因为通过移动堆栈来实现堆栈大小调整，所以堆栈指针可能在任何函数调用期间发生变化：甚至指向堆栈数据的指针也不能保存在局部变量中。\n汇编函数应始终给出 Go 原型，既可以提供参数和结果的指针信息，也可以 go vet 检查用于访问它们的偏移量是否正确。\nDemo Runtime CAS 接下来，我们一起阅读 asm_amd64.s中的汇编\n第一个汇编：实现 CAS 操作\n1// asm_amd64.s 2 3// bool Cas(int32 *val, int32 old, int32 new) 4// Atomically: 5//\tif(*val == old){ 6//\t*val = new; 7//\treturn 1; 8//\t} else 9//\treturn 0; 10TEXT runtime∕internal∕atomic.Cas(SB),NOSPLIT,$0-17 11\tMOVQ\tptr+0(FP), BX 12\tMOVL\told+8(FP), AX 13\tMOVL\tnew+12(FP), CX 14\tLOCK 15\tCMPXCHGL\tCX, 0(BX) 16\tSETEQ\tret+16(FP) 17\tRET 我们先看第一个汇编，使用汇编实现 CAS (compare and swap)操作\n我们一条一条的看，先看TEXT runtime∕internal∕atomic·Cas(SB),NOSPLIT,$0-17 。$0-17表示的意思是这个TEXT block运行的时候，需要开辟的栈帧大小是 0 ，而17 = 8 + 4 + 4 + 1 = sizeof(pointer of int32) + sizeof(int32) + sizeof(int32) + sizeof(bool) （返回值是 bool ，占据 1 个字节\n然后我们再看 block 内的第一条指令 ， 这里的 FP，是伪寄存器(pseudo) ，里边存的是 Frame Pointer, FP 配合偏移 可以指向函数调用参数或者临时变量\nMOVQ ptr+0(FP), BX 这一句话是指把函数的第一个参数ptr+0(FP)移动到 BX 寄存器中\nMOVQ 代表移动的是 8 个字节,Q 代表 64bit ，参数的引用是 参数名称+偏移(FP),可以看到这里名称用了 ptr,并不是 val,变量名对汇编不会有什么影响，但是语法上是必须带上的，可读性也会更好些。\n后边两条 MOVL 不再赘述\nLOCK 并不是指令，而是一个指令的前缀 (instruction prefix)，是用来修饰 CMPXCHGL CX,0(BX) 的\nThe LOCK prefix ensures that the CPU has exclusive ownership of the appropriate cache line for the duration of the operation, and provides certain additional ordering guarantees. This may be achieved by asserting a bus lock, but the CPU will avoid this where possible. If the bus is locked then it is only for the duration of the locked instruction\nCMPXCHGL 有两个操作数，CX 和 0(BX) ,0(BX) 代表的是 val 的地址 offset(BX) 是一种 addressing model , 把寄存器里存的值 + offset 作为目标地址\nCMPXCHGL 指令做的事情，首先会把 destination operand(也就是 0(BX))里的值 和 AX 寄存器里存的值做比较，如果一样的话会把 CX 里边存的值保存到 0(BX) 这块地址里 (虽然这条指令里并没有出现 AX，但是还是用到了，汇编里还是有不少这样的情况) CMPXCHGL 最后的那个 L 应该表示的是操作长度是 32 bit ，从函数的定义来看 old 和 new 都是 int32 函数返回一个 Bool 占用 8bit ，SETEQ 会在 AX 和 CX 相等的时候把 1 写进 ret+16(FP) (否则写 0\nAVX512 Reference\nhttps://programmer.ink/think/introduction-to-golang-assembly.html\nhttps://golang.design/under-the-hood/zh-cn/part1basic/ch01basic/asm/\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/note_go/0_go_assambely/","summary":"Golang的汇编是基于Plan9的的汇编，是一个中间汇编的方式，这样可以忽略底层CPU架构的差别。\n汇编主要了解各种寄存器的使用以及寻址方式。根据Golang的汇编我们可以深入理解Golang的底层实现。比如内存如何分配，栈如何扩张，接口如何转变。\n如何从go语言获取对应的汇编\n1go build -gcflags \u0026#34;-N -l\u0026#34; -ldflags=-compressdwarf=false =o main.out main.g 2go tool objdump -s \u0026#34;main.main\u0026#34; main.out \u0026gt; main.S 3# or 4go tool compile -S main.go 5# or 6go build -gcflags -S main.go 汇编基础语法 通用寄存器 寄存器与物理机架构有关，不同的架构有不同的物理寄存器。\n在amd64架构上提供了16个通用寄存器给用户使用。\nPlan9汇编语言提供了如下映射，这样就可以在汇编语言中这几应用就可以使用物理寄存器了。\nx64架构中所有的寄存器都是64位\namd64 Plan9 rax AX rbx BX rcx CX rdx DX rdi DI rsi SI rbp BP rsp SP r8 R8 r9 R9 r10 R10 r11 R11 r12 R12 r13 R13 r14 R14 rip PC 虚拟寄存器 伪寄存器不是真正的寄存器，而是由工具链维护的虚拟寄存器，例如帧指针。","tags":null,"title":"Go Assembly"},{"categories":null,"contents":"n\nhttps://zhuanlan.zhihu.com/p/343562661\nhttps://draveness.me/golang/docs/part3-runtime/ch06-concurrency/golang-sysmon/\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/note_go/0_go_compile/","summary":"n\nhttps://zhuanlan.zhihu.com/p/343562661\nhttps://draveness.me/golang/docs/part3-runtime/ch06-concurrency/golang-sysmon/","tags":null,"title":"Go compile"},{"categories":null,"contents":"安装Go 开始写Golang之前，你首先需要下载并且安装Golang开发工具。可以在Golang的官方网站下载最新的安装包。根据你的开发平台选择下载对应的版本。对于Mac用户(或者Windows用户)来说.pkg(或msi)安装包会自动把Golang安装到合适的位置，并将命令加入到环境变量，并且自动移除老版本。如果使用Mac更加推荐直接使用brew install go， 使用brew 可以方便的管理Go多个版本。\n对于Linux或者FreeBSD用户可以直接下载对应的.tar.gz, 并解压到文件名为go的目录中。把这个文件Copy到/usr/local/下。然后把/usr/local/go/bin添加到$PATH中。\n1tar -C /usr/local -xzvf go1.17.3.linux-amd64.tar.gz 2# change .profile to .bashrc or.zsh depend on you evnironment 3echo \u0026#34;export PATH=$PATH:/usr/local/go/bin\u0026#34; \u0026gt;\u0026gt;$HOME/.profile Go 程序编译完成后是一个独立的二进制文件，不需要依赖任何运行软件(例如，Python需要Python解释器，Java需要JVM)。仅在需要编译Go代码的环境上安装Go即可。\n安装完成后，打开Terminal(Window 打开CMD)，验证Go是否安装成功。\n1go version 在所有的配置都正确的情况下，可以看到输出的版本信息\n1# mac intel cpu 64bit 2go version go1.17.3 darwin/amd64 从上述信息中可以看出，Go的版本是1.17.3,使用的开发机器是 Mac(Darwin 是MacOS的Kernel Name, amd64 是指64-bit的x86 CPU架构)。\n如果你没有得到正确的版本信息，很有可能是你没有把go加入到环境变量，或者有其他的程序名称也为go。对于Mac或者Unix-like用户，可以使用which go查看当前环境下的go的是否正确关联到/usr/local/go/bin。如果路径正确，也有可能是下载错了安装包，检查下安装包的位数是否与当前操作系统匹配，有可能在64-bit的系统上下载了32-bit的安装包。另外，也有可能是芯片架构选错了。\nGo 工作空间 从2009年Go开始使用，在开发者如果组织代码和管理依赖上经历了几次变化。在Go 1.11所有的代码必须保存在GOPATH之下，之后的版本用户可以在任意目录下存储自己的代码。但是Go依然希望有一个独立的工作空间可以存储通过go install安装额第三方包。默认的工作空间是$HOME/go, 下载的第三方包默认存储在$HOME/go/src,编译的二进制文件存储在$HOME/go/bin。你可以直接使用这个默认的工作空间，或者通过设置$GOPAHT指定一个工作空间。\n无论你是否使用默认的wokespace，建议你把$GOPATH/bin加入到$PATH中。 通过指定$GOPATH可以清楚地描述当前环境的Go工作空间，把$GOPATH/bin加入到可执行路径中可以直接使用go install 安装的第三方包。\n如果是Unix-like的开发环境可以把下面几行加入到$HOME/.profile中。\n1# if use ubuntu you should add to .bashrc,if yuo use zsh, suggest add to .zshrc 2export GOPATH=$HOME/go 3export PATH=$PATH:$GOPATH/bin 添加完成之后需要执行source $HOME/.profil使当前窗口的terminal加载配置。\n如果是Window 系统，可以运行如下两条命令,也可以通过环境变量管理界面配置。\n1set GOPATH %USERPROFILE%\\go 2set path \u0026#34;%path%;%GOPATH%\\bin\u0026#34; 运行完这两条指令后你需要关闭当前cmd窗口，重新打开后即可生效。\n还有其他很多Go需要用到的环境变量，可以通过go env查看所有的变量列表。\n1➜ ~ go env 2# 是否启用go mod,建议设置为 auto，兼容老的project 3GO111MODULE=\u0026#34;\u0026#34; 4# cpu architecture for cross-compilation 5GOARCH=\u0026#34;amd64\u0026#34; 6GOBIN=\u0026#34;/Users/airren/go/bin\u0026#34; 7# os type for cross-compilation 8GOOS=\u0026#34;darwin\u0026#34; 9GOPATH=\u0026#34;/Users/airren/go:/tmp/goc2p\u0026#34; 10GOPROXY=\u0026#34;https://goproxy.cn,direct\u0026#34; 11GOROOT=\u0026#34;/usr/local/Cellar/go/1.17.3/libexec\u0026#34; 12GOSUMDB=\u0026#34;sum.golang.org\u0026#34; 13GOVERSION=\u0026#34;go1.17.3\u0026#34; 14GCCGO=\u0026#34;gccgo\u0026#34; 15AR=\u0026#34;ar\u0026#34; 16CC=\u0026#34;clang\u0026#34; 17CXX=\u0026#34;clang++\u0026#34; 18CGO_ENABLED=\u0026#34;1\u0026#34; 19GOMOD=\u0026#34;/dev/null\u0026#34; 20····· Go 常用命令 go提供了很多命令，这些命令包含compiler(编译)、code formatter(书写格式化)、linter(静态检查)、dependency manager(依赖管理)、test runner等等。\ngo run 和 go build 这两个命令go run和go build非常相似，每个命令后面都可以跟一个或者多个Go文件，或者Go package。接下来我们创建一个简单的程序来看下这连个命令如何使用。\ngo run\n任意路径下，新建一个目录hello，然后创建一个hello.go 的文件\n1# ~/hello/hello.go 2package main 3import \u0026#34;fmt\u0026#34; 4func main(){ 5\tfmt.Println(\u0026#34;Hello Golang!\u0026#34;) 6} 保存后，在terminal中进入hello这个目录下，执行\n1# usage: go run [build flags] [-exec xprog] package [arguments...] 2go run hello.go 你可以在console中看到打印的Hello Golang!。运行完成后，如果你查看hello这个目录下，你会发现只有我们创建的hello.go这个文件。你可能会想，go是一个编译型语言，为什么没有产生编译后的二进制文件呢？\n实际上，go run确实编译了我们的源码文件。然而，这个源码文件是保存在一个临时目录中的，当运行结束之后，编译出来的二进制文件也就被删除了。这种方式很适合用来测试一些比较小的程序，也让Go用起来像是一种脚本语言。\ngo build\n大多数情况下我们都会选择把程序编译成二进制来执行。我们使用go build来编译Go 源码文件。\n1# in hello directory 2go build hello.go 执行完这条命令后，我们可以在当前目录下看到多了一个hello(或hello.exe)文件。运行这个文件，我们就可以看到\u0026quot;Hello Golang!\u0026ldquo;输出在屏幕上。\n这个二进制文件的名字和你传递给go run的文件名字或者package名字是一致的。如果你想使用一个不同的名字或者存储到不同的路径可以使用-o参数。例如，我们把当前文件编译成为一个名为 \u0026ldquo;hello_golang\u0026quot;的二进制文件。\n1# usage: go build [-o output] [build fl ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/note_go/1_SettingUpGoEnv/","summary":"安装Go 开始写Golang之前，你首先需要下载并且安装Golang开发工具。可以在Golang的官方网站下载最新的安装包。根据你的开发平台选择下载对应的版本。对于Mac用户(或者Windows用户)来说.pkg(或msi)安装包会自动把Golang安装到合适的位置，并将命令加入到环境变量，并且自动移除老版本。如果使用Mac更加推荐直接使用brew install go， 使用brew 可以方便的管理Go多个版本。\n对于Linux或者FreeBSD用户可以直接下载对应的.tar.gz, 并解压到文件名为go的目录中。把这个文件Copy到/usr/local/下。然后把/usr/local/go/bin添加到$PATH中。\n1tar -C /usr/local -xzvf go1.17.3.linux-amd64.tar.gz 2# change .profile to .bashrc or.zsh depend on you evnironment 3echo \u0026#34;export PATH=$PATH:/usr/local/go/bin\u0026#34; \u0026gt;\u0026gt;$HOME/.profile Go 程序编译完成后是一个独立的二进制文件，不需要依赖任何运行软件(例如，Python需要Python解释器，Java需要JVM)。仅在需要编译Go代码的环境上安装Go即可。\n安装完成后，打开Terminal(Window 打开CMD)，验证Go是否安装成功。\n1go version 在所有的配置都正确的情况下，可以看到输出的版本信息\n1# mac intel cpu 64bit 2go version go1.17.3 darwin/amd64 从上述信息中可以看出，Go的版本是1.17.3,使用的开发机器是 Mac(Darwin 是MacOS的Kernel Name, amd64 是指64-bit的x86 CPU架构)。\n如果你没有得到正确的版本信息，很有可能是你没有把go加入到环境变量，或者有其他的程序名称也为go。对于Mac或者Unix-like用户，可以使用which go查看当前环境下的go的是否正确关联到/usr/local/go/bin。如果路径正确，也有可能是下载错了安装包，检查下安装包的位数是否与当前操作系统匹配，有可能在64-bit的系统上下载了32-bit的安装包。另外，也有可能是芯片架构选错了。\nGo 工作空间 从2009年Go开始使用，在开发者如果组织代码和管理依赖上经历了几次变化。在Go 1.11所有的代码必须保存在GOPATH之下，之后的版本用户可以在任意目录下存储自己的代码。但是Go依然希望有一个独立的工作空间可以存储通过go install安装额第三方包。默认的工作空间是$HOME/go, 下载的第三方包默认存储在$HOME/go/src,编译的二进制文件存储在$HOME/go/bin。你可以直接使用这个默认的工作空间，或者通过设置$GOPAHT指定一个工作空间。\n无论你是否使用默认的wokespace，建议你把$GOPATH/bin加入到$PATH中。 通过指定$GOPATH可以清楚地描述当前环境的Go工作空间，把$GOPATH/bin加入到可执行路径中可以直接使用go install 安装的第三方包。\n如果是Unix-like的开发环境可以把下面几行加入到$HOME/.profile中。\n1# if use ubuntu you should add to .","tags":null,"title":"Go 设置Golang开发环境"},{"categories":null,"contents":" Introduce SIMD 单指令数据-\u0026gt; VNNI/INT8\nIntrinsics for Intel(R) Advanced Matrix Extension Instructions Intel Advanced Matrix Extension is a new 64-bit programming paradigm consisting of two components:\nA set of 2-dimensional registers(tiles) representing sub-arrays from a larger 2-dimensional memory image Am accelerator that is able to operate on tiles; the first implementation of this accelerator is called TMUL(tile matrix multiply unit) Intrinsic for Intel Advanced Matrix Extension AMX-BF16 Instructions This intrinsic supports tile computational operations on bfloat16 number.\n_tile_dpbf16ps Synopsis\n1void _tile_dpbf16ps (__tile dst, __tile a, __tile b) Description\nCompute dot-product of BF16(16-bit) floating-point pairs in tiles \u0026ldquo;a\u0026rdquo; and \u0026ldquo;b\u0026rdquo;, accumulating the intermediate single-precision(32-bit) floating-point elements with elements with elements in \u0026ldquo;dst\u0026rdquo;, and store the 32-bit result back to tile \u0026ldquo;dst\u0026rdquo;.\nOperation\nAVX Advanced Vector Extension\nAVX 也是SIMD指令， 单指令多数据\nSIMD Single Instruction Multi Data\n寄存器位宽 演示图\nhttps://gyazo.com/51d14424f81c80ae77ea790bfcc92d0d\nHow AVX Solve it AVX2 AVX256 8*32 8个32位浮点书运算 16FLOPs/cycle/FMA（运算器，cpu架构） 32 FLOps/cycle/core 16 个32位浮点数运算， 2x 16 个32位的浮点运算 BF16 就是 16位的浮点数\nSapphire Rapids with high Bandwidth Memory 内存带宽需求较高的负载有卓越的性能提高. 提高了Cache的利用率。\nAVX2 is enough\nAVX 512 授权AMD\n浮点数学运算，\n更多的是通过GPU实现2\n2008 年，英特尔在 Sandy Bridge 酷睿 CPU 架构推出的同时发布了 AVX 指令集（Advanced Vector Extension，高级矢量扩展指令集），聚焦矢量运算，AVX 很快形成了一套完整的单指令多数据指令集规范，一些版本也得到了 AMD 的支持。\n2013 年，英特尔发布了 AVX-512 指令集，其指令宽度扩展为 512bit，每个时钟周期内可打包 32 次双精度或 64 次单精度浮点运算，因此在图像 / 音视频处理、数据分析、科学计算、数据加密和压缩和深度学习等应用场景中，会带来更强大的性能表现，理论上浮点性能翻倍，整数计算则增加约 33% 的性能。\nIntel 新一代 CPU 将限制包括 AVX-512 在内的指令集只能运行在大核芯片上\n单指令数据流\n$$X* Y$$\n多指令数据流\n英特尔AVX-512VNNI(VectorNeural NetworkInstructions)是英特尔深度学习加速一项重要的内容，也是对标准英特尔AVX-512指令集的扩展。可以将三条指令合并成一条指令执行，更进一步的发挥新一代英特尔至强可扩展处理器的计算潜能，提升INT8模型的推理性能。目前第2代和第3代英特尔至强可扩展处理器均支持英特尔VNNI。\nAVX 引入了一种称为 VEX 编码方案的三操作数 SIMD 指令格式，其中目标寄存器与两个源操作数不同。例如，使用传统的双操作数形式 a ← a + b 的 SSE 指令现在可以在 a + b ←使用非破坏性三操作数形式 c，从而保留两个源操作数。最初，AVX 的三操作数格式仅限于具有 SIMD 操作数 （YMM） 的指令，并且不包括具有通用寄存器（例如 EAX）的指令。它后来用于在后来的扩展（如BMI）中的通用寄存器上编码新指令。VEX 编码还用于在 AVX-512 中引入的 k0-k7 掩码寄存器上运行的指令。\n8维及以下的64位双精度浮点矢量或者16维及以下的单精度浮点矢量。也支持8维的64位整数矢量，16维的32位整数矢量 作者：硬件老哥哥 https://www.bilibili.com/read/cv9689142 出处：bilibili\n浮点性能提升\n提高整数和浮点运算性能。\n解压缩，排序算法\n视频编码，3D建模，浮点运算性能\nAVX512 16个32bit 或者 8 个64bit的数据\n双发射AVX 512，\n但发射 AVX512，\nhttps://gyazo.com/88d101c5bb5ae241144f37fdddd0c02f\n深度学习 图片降噪\n高性能计算 250 万位圆周率计算\n最大寄存器位宽\nAMX 的release的time是2022， 估计现在市面上还没有support的CPU可以用来测试。\n所有找了一个AVX512 的code demo. 然后通过AVX512 介绍一下SIMD的使用\n再这个示例中是计算两个向量，并把结果写道第三个向量中。\n这里定义了ABC3个向量，每个向量都是8个64位浮点数。刚好是512 bit. 每个向量刚好存入一个AVX512寄存器。\n右边的这个汇编就是 AVX512 计算两个向量和的实现。 第一行就是把向量A从内存中加载到寄存器0，第二行，就是计算zmm0和内存中向量B的和，并存入zmm0中。第三行就是把zmm0寄存器的值写入到向量C。 这样就得到了计算结果。如果使用SISD命令，就需要对每一个数据单独相加。\n接下来我们看下通过调试器来看下 AVX512 寄存器中zmm0中的数据情况，向量A 加载到zmm0的时候，这里可以看到AVX512 支持 的数据类型要远远多于AMX。\n接下来我们看一个AMX的指令。_tile_spbf16()\n这条指令就是计算两个BF16的点成\nAVX 和AMX现在大部分应用场景都是用在机器学习，深度学习 领域，处理一些大规模的矩阵计算。这部分已经有很多人做了很多工作，所以 如果在这方面去做一些基于AMX的或AVX的专利和改进会比较困难。于是我们选择了数据处理这个方向。\n在数据处理这个方向。我想简单介绍一下时序数据。通过这张图，大家可能会对时序数据有个初步的概念。\n时序数据的吞吐量是非常大的，尤其是IoT设备，设备的规模可能达到千万上亿，数据自动生成，假设1s采样一次，每秒千万、亿级别的数据写入。\n在大写入吞吐量的情况下，数据的实时性要求也很高。例如，将时序数据的统计量关联做监控、报警，能容忍的延迟可能在秒级\n需要做降频采样、插值、实时计算、聚合等操作，关心的是一段时间的趋势，而不是某一特定时间的值等。\n目前我们还没有具体明确要对哪一种具体的算法或者应用场景进行基于AMX的改进。只是看到了这个事情的可能性。例如说我要计算一个指标在一段时间内的均值。这个算法在将采样的过程中非常常见。这一段时间内的时序是指标。\n关于这个应用场景的，大家gan\n参考文献\nhttps://baijiahao.baidu.com/s?id=1672265837981500533\u0026wfr=spider\u0026for=pc\nhttps://baijiahao.baidu.com/s?id=1729339781120838964\u0026wfr=spider\u0026for=pc\nhttps://www.prowesscorp.com/what-is-intel-avx-512-and-why-does-it-matter/\nhttps://www.elecfans.com/d/1812270.html\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/blog/intel_spx_AMX/","summary":"Introduce SIMD 单指令数据-\u0026gt; VNNI/INT8\nIntrinsics for Intel(R) Advanced Matrix Extension Instructions Intel Advanced Matrix Extension is a new 64-bit programming paradigm consisting of two components:\nA set of 2-dimensional registers(tiles) representing sub-arrays from a larger 2-dimensional memory image Am accelerator that is able to operate on tiles; the first implementation of this accelerator is called TMUL(tile matrix multiply unit) Intrinsic for Intel Advanced Matrix Extension AMX-BF16 Instructions This intrinsic supports tile computational operations on bfloat16 number.","tags":null,"title":"Intel AMXAV"},{"categories":null,"contents":"概述 https://www.intel.com/content/www/us/en/developer/tools/software-guard-extensions/overview.html\nhttps://blog.quarkslab.com/overview-of-intel-sgx-part-1-sgx-internals.html\nIntel Software Guard Extensions(Intel SGX) 保护选定的代码和数据不被泄露的和修改。开发者可以把应用程序划分到CPU强化的enclave中或者内存中可执行的保护区域，即使在受攻击的平台中也可以提高安全性。使用这种新的应用层可信执行环境，开发者能够启用身份和记录隐私，安全浏览和数据保护(DRM)或者任何需要安全存储机密或者保护数据的高保障安全应用场景中。\n机密性和完整性， 即使在OS、BIOS、VMM或者SMM层存在特权恶意软件的情况下也可以保证安全。 低学习曲线，和父应用程序类似的OS编程模型，并且在主CPU上执行 远程认证 远程部分能够认证一个应用程序的enclave的身份，并且安全的将密钥、凭据和敏感数据提供为enclave 最小的可能攻击面， CPU边界成为攻击面外围，所有的数据、内存、外围之外的IO都是加密的。 最小攻击面的硬件辅助可信执行环境。\nintel SGX保护的应用程序 Intel SGX应用程序由两个部分组成： 不可信代码和可信Enclave. 开发者可以创建一对多的可信enclave用来支持分布式体系结构。\n常用应用有密钥，专有算法，生物识别数据和CSR生成等。\n程序运行时， Intel SGX指令在一个特定的保护内存区域中创建和执行enclave，该区域有由开发者定义的受限入口和出口函数。能够防止数据泄露。在CPU范围中的enclave和数据运行在一个clean的环境中， enclave数据写入到磁盘会被加密，并且校验其完整性。\n上图中的流程\nApplication由可信和不可信部分构成 App运行和创建evclave， enclave放入到可信内存中 可信函数被调用，执行会转换到enclave中 enclave可以访问所有进程数据，外部要访问enclave数据被禁止 可信函数返回enclave数据 对enclave有未授权的访问和内存侦听是有可能的\n认证Enclave和加密数据 当前，ODM(原始设备制造上)和ISV(独立软件提供商) 通常在制造时或通过无法以机密方式证明XXX。\nIntel SGX使用enclave之间本地认证或者第三方远程认证的方式来保证应用程序没有受到破坏。\n应用程序受保护的部分会加载到一个Enclave，它的代码和数据都会收到监测。会发送一个请求到远端服务器，用来验证这个Enclave是否是可靠的Intel 处理器生成的。 如果认证了Enclave的身份，远端就会信任Enclave并安全的提供密钥，凭证和数据.\nIntel SGX 包括一个生成CPU和Enclave特定“密封密钥”的指令。密钥能够用来安全的存储和取回可鞥你需要保存在磁盘中的敏感信息。\nIntel SGX 实现新的安全模型 Intel SGX 是在很多公司、大学的安全研究人员以及政府安全机构的支持下创建的，上百家ISV与Intel合作，使用Intel SGX来保护关键任务应用程序。\nSet up SGX develop environment Install SGX driver\nInstall SGX SDK\nInstall SGX PSW\n直接按照官方文档依次安装上述3个组件\nSample Enclave Demo 1############# SGX SDK Setting 2# 编译平台和模式配置 3 4############## APP Setting 5# 主要是指定 6# App_Cpp_Files 需要编译的cpp文件 7# App_Include_Paths 包含目录 8# App_Cpp_Objects 输出 9 10############### Enclave setting 11# Enclave_Cpp_Files 12# Enclave_Include_Paths 13# Enclave_Cpp_Objects 14 15# eld 编译配置 16################ App Object 17################ Enclave Object Enclave 相关开发流程 使用edl文件定义不可信app和enclave之间的接口 实现app和enclave函数 编译 app 和enclave。编译中 Edger8r生成可信和不可信的代理/桥函数，Enclave签名工具生成enclave的metadata和签名 在模拟和硬件模式下运行和调试app，详细看debug enclave的内容 准备发布app 和enclave 编写Enclave函数 在app角度，使用不可信代理函数调用enclave函数(ECALL)跟调用其他函数没有区别。Enclave函数只是有些显示的c/c++函数。\n开发者只能使用c和c++(Native)开发enclave函数，其他不支持。\nEnclave函数依赖特定版本的c/c++运行时库,STL,同步和几个其他可信库。这些依赖库时Intel SGX SDK的一部分。\n开发者也可以使用其他可信的库，但必须保证这些库遵循内置Enclave函数的规则：\nEnclave函数不能使用所有可用的32位或64位指令。查看Intel Software Guard Extensions Programming Reference 文档中Enclave合法指令列表。 Enclave函数只运行在用户态。使用需要cpu特权的指令会造成enclave出错。 如果被调用函数静态链入了Enclave，那么是可以在Enclave中调用这个函数(函数需要在enclave image中)。linux的共享对象(shared object)不支持。 在编译时，如果Enclave Image还有找不到的依赖，那么Enclave签名会失败。\n在Enclave中调用外面的函数叫做OCALLs.\nIntel SGX 规则和限制\nFeature Supported Description 语言 部分 Native C/C++。 Enclave 接口函数只能使用c C/C++调用其他共享对象 不支持 可以用OCALL来调用外部函数 C/C++调用系统提供的C/C++/STL标准库 不支持 Intel SGX SDK中提供了替代的可信版本 系统API调用 不支持 使用OCALL C++框架 不支持 包括MFC，QT，Boost* 调用C++类函数 支持 包括C++类，静态和inline函数 内置函数 部分 如果这些内置函数使用的是支持的指令。Intel SGX SDK提供的函数运行。 内联汇编 部分 和内置函数一样 模板函数 部分 只支持Enclave的内置函数 Ellipse() 部分 只支持Enclave的内置函数 Varargs(va_list) 部分 只支持Enclave的内置函数 同步 部分 Intel SGX SDK提供了同步的函数/对象集合，spin-lock，mutex和condition variable 线程支持 部分 不支持在Enclave内创建线程。Enclave内运行的线程是不可信的app创建的。spin-lock、mutex和条件变量API可以在Enclave内用于线程同步。 TLS 部分 Only implicitly via__thread 动态内存分配 支持 Enclave内存是有限的资源，在Enclave创建时，制定了最大Heap的大小 C++异常 支持 虽然有些影响性能 SEH异常 不支持 Intel SGX SDK 提供了API用于注册函数或者异常句柄来处理部分硬件异常(详细可见 Customer Exception Handling) 信号 不支持 Enclave内不支持signal 调用Enclave内函数 Enclave加载成功之后，可以获得一个Enclave的ID,在使用ECALL时作为参数使用。有时候，可以在ECALL内部使用OCALL。比如需要在Enclave中计算某些秘密信息，edl文件如下\n1//demo.edl 2enclave{ 3\t// Add your definition of \u0026#34;secret_t\u0026#34; here 4\ttrusted{ 5\tpublic void get_secret([out] secret_t* secret); 6\t}; 7\tuntrusted{ 8\t// This OCALL if for illustration purposed only, 9\t// It should not be used in a real enclave, 10\t// unless it is during the development phare for debuging purposes. 11\tvoid dump_secret((in) const secret_t* secret); 12\t}; 13} sgx_edger8r 使用上面的edl会生成不可信的代理函数，用于ECALL和OCALL的可信代理函数\n1// untursted agent function (for app) 2sgx_status_t get_secret(sgx_enclave_id_t eid, secret_t* secret); 3// trusted agent function () 4sgx_status_t dump_secret(const secret_t* secret); 使用不可信的代理函数调用时，会自动调入Enclave，将参数传给真正可信的get_secret()。 在APP中使用一个ECALL\n1// An enclave call(ECALL) will happen here 2secret_t secret; 3sgx_status_t status = get_secret(eid, \u0026amp;secret); Enclave 中的可信函数可以使用OCALL调用可信代理函数dump_secret 来dump秘密信息。它会自动jiang-参数传给Enclave外真正的dump_secret 函数。Enclave外的这个函数需要开发者实现链入APP中。\n可信和不可信函数都会返回一个 sgx_status_t 类型的返回值。如果代理函数成功了，会返回SGX_SUCCESS，否则会返回指定的错误值。\n调用Enclave外函数 有些时候，Enclave内代码需要调用外部不可信内存中的函数来使用操作系统的功能，比如系统调用，I/O 操作等等。这种调用就叫做OCALL。\n这些函数需要在EDL文件的untrusted 中声明。\nEnclave的加载非常类似与系统加载dll。app的函数地址空间共享给了Enclave，所有Enclave可以直接调用创建该Enclave的app的函数. ??\n不使用OCALL，直接调用app的函数会在运行时发生异常。\n包装函数(代理函数)会从保护内存(Enclave)中拷贝参数到未保护内存中，因为外部函数不能直接访问保护内存区域。实际上就是 OCALL删除被copy到不可信的堆栈中，根据OCALL的参数个数，有可能会引起栈溢出。\nOCALL函数必须遵循一下限制\nOCALL函数必须是C函数，或者C链接的C++函数。 引用Enclave内数据的指针必须在EDL文件中注释为pointer direction属性，包装函数会对这些指针做浅拷贝(一层)。 Enclave内不会捕捉异常，需要开发者在不可信包装函数中处理这些异常。 OCALL函数原型中不能有ellipse(\u0026hellip;)或va_list 举个栗子：\n1// Step 1 - Add a declaration for foo in the EDL file 2// foo.edl 3enclave{ 4 untrusted{ 5 [cdecl] void foo(int param); 6 } 7} 8// Step 2 (optional but highly recommended ) - write a trusted, user-friendly wrapper. This function is part of the enclave\u0026#39;s trusted code. 9// The wrapper function ocall_foo function will look like: 10// Enclave\u0026#39;s trusted code 11#include \u0026#34;foo_t.h\u0026#34; 12void ocall_foo(int parm){ 13 // it is necessary to check the return value of foo() 14 if (foo(param) != SGX_SUCCESS){ 15 abort(); 16 } 17} 18 19// Setp 3 - write an untrusted foo function 20// untrusted code 21void foo(int param){ 22 // the implementation of foo 23} sgx_edger8r 将会生成调用不可信函数foo的不可信桥函数，这两个函数都是app的部分，不是在Enclave中。\n在Enclave 中链接库 动态链接库 Enclave不可以依赖一个动态链接库。Enclave加载器特意设计成禁止Enclave中使用动态链接库。Enclave的保护依赖于加载时，计算机的Enclave中所有代码和数据的准确测量值，因此，动态链接库链入会增加复杂度。\nEnclave 文件如果有任何未识别的依赖，Enclave的签名过程都会失败。所以Enclave必须有一个空的IAT。\n静态库 只有静态库，没有任何依赖你就可以链接它。\nIntel SGX SDK提供下面这些可信的库\nName Description State sgx_trts.lib Intel SGX 内部组件 在HW模式下运行必须链接 sgx_trts_sim.lib Intel SGX 内部组件(仿真模式) 仿真模式下必须链接 sgx_tstdc.lib 标准c库(math string 等) 必须链接 sgx_tcxx.lib, sgx_tstdcxx.lib 标准C++库,STL 可选 sgx_tsrevice.lib 数据封装/解封(加密), 可信架构Enclave支持，Elliptic Curve Diffie-Hellman(EC HD)库等 HW模式下必须链接 sgx_tsrevice_sim.lib sgx_tsrevice.lib 对应的仿真模式库 仿真模式下必须链接 sgx_tcrypto.lib 加密算法库 必须链接 sgx_tkey_exchange.lib 可信密钥交换库 可选 sgx_tprotected_fd.lib Intel 保护文件系统库 可选 仿真库 Intel SGX SDK提供仿真库让软件运行在仿真模式下(不许要Intel SGX硬件支持)。有一个可信仿真库和一个不可信仿真库。不可信仿真库提供不可信运行时库来管理连接了可信仿真库的Enclave功能。包括在Enclave外仿真执行Intel SGX指令：ECREATE，EADD，EEXTENED, EINT, EREMOVE 和EENTER。可信仿真库住哟啊负责Enclave内使用的Intel SGX指令的仿真：EEXIT, EGETKEY, EREPORT.\n仿真模式不需要CPU支持Intel SGX。然而处理器至少支持SSE 4.1 指令。\n加载不可信SGXDLL SGX DDL安装在系统目录中，附带PSW(sgx_urts.dll 和sgx_ae_service.dll)。你必须锁定SGX app的安装目录，否则就要显式的加载这两个dll(全路径)。\n假设攻击者获得app安装目录的控制权，插入了一个恶意的sgx dll到这个目录，如果app隐式的加载sgx dll，这个恶意的dll 会优先于系统目录原始sgx dll被加载。(DLL 劫持)\n为了确保SGX app从系统目录中加载SGX dll， app必须显式架子加载这两个dll，顺序是\nsgx_uae_servcie.dll\nsgx_urts.sll\nEncalve 配置文件 Enclave配置文件是一个XML文件，包含了用户定义的Enclave参数。XML文件是Enclave工程的一部分，sgx_sign会用这个配置文件作为输入来创建Enclave的签名和元数据。\n下表为配置文件各个参数的定义，所有的参数都是可选的，如果没有定义就会使用默认值。\nTag Description Default ProdID ISV assigned Product ID 0 ISVSVN ISV assigned SVN 0 TCSNum The number of TCS. Muster greater than 0 1 TCSPolicy TCS management policy. 0 - TCS is bound to the untrusted thread. 1 - TCS is not bound to the untrusted thread. 1 StackMaxSize The maximum stack size per thread. Must be 4k aligned. 0x40000 256k HeapMaxSize The maximun heap size for the process. Must be 4k aligned. 0x100000 1MB DisableDebug Enclave can not be debug . 0 - Enclabe can be debug 0 MiscSelect The desired Misc feature 0 MiscMask The mask bit for the Misc Feature 0xFFFFFFFF MiscSelect 和MiscMask 是为了未来功能扩展使用的。目前MiscSelect必须是0，否则Enclave不会加载成功。\n为了不浪费重要的保护内存资源，你可以使用sgx_emmt 测量工具适当的设置StackMaxSize 和HeapMaxSize。 可以看看Enclave Memory Measurement工具的详细说明。\n如果enclave中没有足够的Stack空间，ECALL会返回SGX_ERROR_STACK_OVERRUN的错误代码。提示需要分配更多的StackMaxSize。\nEnclave Project Configuration 仿真\n仿真模式下工作方式和调试模式一样，仿真模式不需要有硬件支持。使用Intel SGX 指令来进行软件模拟。单步签名是对仿真Enclave签名的默认方式\n调试\n如果设置了Debug选项，Enclave编译为调式模式，编译出来的Enclave包含有调试信息和符号信息。 通过SGX_DEBUG_FLAG传递给sgx_create_enclave。 允许Enclave加载到 Enclave 调试模式。单步签名是这个工程的默认签名方式。用于这种模式的签名密钥不需要使用白名单中的值。\n预发行版\n编译器会使用最优化编译Enclave为发行模式。在这种模式下Enclave加载到Enclave调试模式。这种模式下Project会定义预处理器标记EDEBUG在预处理器配置中。当EDEBUG预处理器标记定义了，它会Enable SGX_DEBUG_FLAG, 会加载Enclave到Enclave调试模式。这种模式下也是单步签名作为签名方式。签名密钥不需要再白名单中。\n发行版\n加载Enclave到Enclave发行模式下。会禁用SGX_DEBUG_FLAG标记。只有再NDEBUG未定义或者EDEBUG定义了之后SGX_DEBUG_FLAG才可用。调试模式下NDEBUG没有定义，所以SGX_DEBUG_FLAG可用。发行模式下配置中NDEBUG已定义，SGX_DEBUG_FLAG不可用，所以加载Enclave到Enclave发行模式。Two-Step签名是这种模式下的默认签名方式，Enclave需要使用白名单中的签名密钥。\n加载/卸载Enclave Enclave源码会编译为动态连接库。使用Enclave，需要调用 sgx_create_enclave()来加载enclave.dll 到保护内存中。enclave.dll 必须使用sgx_sign.exe 来签名。当第一次加载Enclave时，加载会获取以个launch token， 然后保存用于后续in/out参数。开发者可以使用launch token到文件中，然后第二次加载enclave时，app可以从token保存的文件中获取token。准备一个有效的launch token来提高加载性能。开发者必须使用sgx_destory_enclave()并传递sgx_enclave_id_t作为参数来卸载Enclave。\n下面时加载和卸载Enclave的示例代码\n1#include \u0026lt;stdio.h\u0026gt; 2#include \u0026lt;tchar.h\u0026gt; 3#include \u0026#34;sgx_urts.h\u0026#34; 4#define ENCLAVE_FILE_T(\u0026#34;Enclave.signed.dll\u0026#34;) 5int main(int argc,char* argv[]){ 6 sgx_enclave_id_t eid; 7 sgx_status_t ret = SGX_SUCCESS; 8 sgx_launch_token_t token = {0}; 9 int updated = 0; 10 11 // Create the Enclave with above launch token. 12 ret = sgx_create_enclave(ENCLAVE_FILE, SGX_DEBUG_FLAG, \u0026amp;token,\u0026amp;updated，\u0026amp;eid, NULL); 13 if (ret != SGX_SUCCESS){ 14 printf(\u0026#34;App: error %#x, failed to create enclave.\\n\u0026#34;,ret); 15 return -1; 16 } 17 // A bunch of Enclave calls(ECALL) will happen here. 18 // Destory the encalve when all Encalve calls finished 19 if (SGX_SUCCESS != sgx_destory_enclave(eid)) 20 return -1; 21 return 0; 22} 处理电源事件\n保护内存加密密钥保存在支持SGX的cpu中，每次电源事件(suspend 和休眠)会销毁。因此当电源发生改变时，Enclave内存会被移除，所有enclave数据将不可访问。所以，当系统恢复了之后，任何后续的ECALL都会返回错误SGX_ERROR_ENCLAVE_LOST. 这个错误表示SGX enclave在断电时丢失了。\nSGX secure Enclaves Software Guard Extensions: Non-hierarchical Trust Model Secure Enclave:\nApplication can instantiate CPU-based trusted execution environment. Shielded from all other running software: confidentiality and integrity. Direct access to enclave memory is disallowed even form OS/Hypervisor since they are untrusted. Reduced Trusted Computing Base Enclave Identity\nFully measured (hash) at creation time Measurement establishes enclave idgentity Used for attestation: allows a remote entity to establish trust on an enclave. Enclave Page Cache (EPC)\nStores running enclaves Reserved by firmer at boot time Treated specially by CPU Memory traffic goes through encryption engine Not accessible when CPU not in enclave mode An enclave can only assess its own EPC pages Managed by OS/VMM Allocation, mapping, eviction K8s SGX Device Plugin This video demonstrates the Intel(R) Software Guard Extensions ECDSA Quote Generation in Kuberntes\nThe key building blocks are:\nIntel(R) Software Guard Extensions (SGX) Flexible Launch Control capable system(registered) Intel(R) SGX driver(RFC v41) for the host kernel Intel(R) SGX PCKID Certificate Caching Service configured Let\u0026rsquo;s get started!\nCheck the Kubernetes Cluster is in good shape\n1kubectl get nodes 2# Check all pods status 3# certmanager x 3 4# coredns x 2 5# weave 6kubectl get pods -A 7# create the demo namespace 8kubectl create ns sgx-ecdsa-quote 9 10# Pull: devel images and tag them as 0.23.0 11sudo ctr -n k8s.io i pull docker.io/intel/intel-sgx-plugin:devel 12sudo ctl -n k8s.io i pull docker.io/intel/intel-sgx-initcontainer:devel Deploy node-feature-discovery for Kubernetes\nIt\u0026rsquo;s used to label SGX capable nodes and register SGX EPC as an extened resource\n1kubectl apply -k intel-device-plugins-for-kubernetes/deployments/sgx_nfd 2 3# Check its pod is running 4kubectl wait --for=condition=Ready pod/nfd-worker-vcm4z -n node-feature-discovery Deploy Intel Device Plugin Operator as a DaemonSet\n1kubectl apply -k intel-device-plugins-for-kubernetes/deployments/sgx_plugin/overlays/epc-nfd/ Verify node resource\n1kubectl describe node \u0026lt;node name\u0026gt; | grep sgx.intel.com Both node labels and resources for SGX are in place\nRun Intel(R) SGX DCAP ECDSA Quote Generation(out-of-proc)\n1# Make the pre-built images available (from docker save) 2sudo ctr -n k8s.io i import sgx-aesmd.tar 3sudo ctr -n k8s.io i import sgx-demo.tar 4# Deploy Intel(R) AESMD 5kubectl apply -k intel-device-plugins-for-kubernetes/deployments/sgx_aesmd/ 6# Deploy Intel(R) SGX DCAP ECDSA Quote Genetation 7 k apply -k intel-device-plugins-for-kubernetes/deployments/sgx_enclave_apps/overlays/sgx_ecdsa_aesmd_quote/ 8 9kubectl logs ecdsa-quote-intelsgx-demo-job-npwvf -n sgx-ecdsa quote 10 11 12# Intel(R) SGX DCAP QuoteGenerationSample successfully requested a quote from Intel(R) AESMD 13 14# Delete the deployment 15 k delete -k intel-device-plugins-for-kubernetes/deployments/sgx_enclave_apps/overlays/sgx_ecdsa_aesmd_quote/ Run Intel(R) SGX DCAP ECDSA Quote Generation(in-proc)\n1# Deploy Intel(R) SGX DACP ECDSA Quote Generation 2kubectl apply -k intel-device-plugins-for-kubernetes/deployments/sgx_enclave_apps/overlays/sgx_ecdsa_aesmd_quote 3 4kubectl logs inproc-ecdsa-quote-intelsgx-demo-job 5 6# Intel(R) SGX DCAP QuoteGenerationsSmaple successfully generated a quote using DCAP Quote Provider Library. This video demonstrated the Intel(R) Sofrware Guard Extensions in Kubernetes\nThe following topics were covered:\nSGX Kubernetes Device Plugin deployment with an Operator Intel(R) SGX node resource and featured label registration to Kubernetes* Intel(R) SGX DCAP ECDSA Quote Generation I encountered a problem with the hardware when trying to enable the SGX device plugin demo. This feature needs the CPU support FLC, but mine doesn’t support that. If anyone has a supported NUC, can you exchange it with mine NUC11TVHv7 32G\nCheck Method : https://www.intel.com/content/www/us/en/support/articles/000057420/software/intel-security-products.html\nOn a Linux* system, execute cpuid in a terminal\nOpen a terminal and run: $ cpuid | grep -i sgx Look for output: SGX_LC: SGX launch config supported = true\nDevice Plugin Pod\n1apiVersion: v1 2kind: Pod 3metadata: 4 name: ubuntu-sgx-demo 5spec: 6 containers: 7 - 8 name: ubuntu-sgx 9 image: airren/ubuntu-sgx:v0.0.1 10 imagePullPolicy: IfNotPresent 11 workingDir: \u0026#34;/\u0026#34; 12 command: [\u0026#34;sleep\u0026#34;,\u0026#34;3600\u0026#34;] 13 resources: 14 limits: 15 sgx.intel.com/epc: \u0026#34;512Ki\u0026#34; Deploy SGX Plugin Quickly 1 k apply -k deployments/nfd/overlays/sgx 2 k apply -k deployments/nfd/overlays/node-feature-rules 3 k apply -k deployments/sgx_plugin/overlays/epc-nfd server mesh controller\nclusternet. use the latested version image\nservice discovery , A Bhow to find the the server in a\n参考资料\nhttps://zhuanlan.zhihu.com/p/39976702\nhttps://zhuanlan.zhihu.com/p/39912478\nprotobuf\n800-810-1972 Toll-free\n400-810-1972 Local Toll (For Mobile)\nMonday to Friday 08:00 - 18:00 GMT +8\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/blog/3_intel_sgx/","summary":"概述 https://www.intel.com/content/www/us/en/developer/tools/software-guard-extensions/overview.html\nhttps://blog.quarkslab.com/overview-of-intel-sgx-part-1-sgx-internals.html\nIntel Software Guard Extensions(Intel SGX) 保护选定的代码和数据不被泄露的和修改。开发者可以把应用程序划分到CPU强化的enclave中或者内存中可执行的保护区域，即使在受攻击的平台中也可以提高安全性。使用这种新的应用层可信执行环境，开发者能够启用身份和记录隐私，安全浏览和数据保护(DRM)或者任何需要安全存储机密或者保护数据的高保障安全应用场景中。\n机密性和完整性， 即使在OS、BIOS、VMM或者SMM层存在特权恶意软件的情况下也可以保证安全。 低学习曲线，和父应用程序类似的OS编程模型，并且在主CPU上执行 远程认证 远程部分能够认证一个应用程序的enclave的身份，并且安全的将密钥、凭据和敏感数据提供为enclave 最小的可能攻击面， CPU边界成为攻击面外围，所有的数据、内存、外围之外的IO都是加密的。 最小攻击面的硬件辅助可信执行环境。\nintel SGX保护的应用程序 Intel SGX应用程序由两个部分组成： 不可信代码和可信Enclave. 开发者可以创建一对多的可信enclave用来支持分布式体系结构。\n常用应用有密钥，专有算法，生物识别数据和CSR生成等。\n程序运行时， Intel SGX指令在一个特定的保护内存区域中创建和执行enclave，该区域有由开发者定义的受限入口和出口函数。能够防止数据泄露。在CPU范围中的enclave和数据运行在一个clean的环境中， enclave数据写入到磁盘会被加密，并且校验其完整性。\n上图中的流程\nApplication由可信和不可信部分构成 App运行和创建evclave， enclave放入到可信内存中 可信函数被调用，执行会转换到enclave中 enclave可以访问所有进程数据，外部要访问enclave数据被禁止 可信函数返回enclave数据 对enclave有未授权的访问和内存侦听是有可能的\n认证Enclave和加密数据 当前，ODM(原始设备制造上)和ISV(独立软件提供商) 通常在制造时或通过无法以机密方式证明XXX。\nIntel SGX使用enclave之间本地认证或者第三方远程认证的方式来保证应用程序没有受到破坏。\n应用程序受保护的部分会加载到一个Enclave，它的代码和数据都会收到监测。会发送一个请求到远端服务器，用来验证这个Enclave是否是可靠的Intel 处理器生成的。 如果认证了Enclave的身份，远端就会信任Enclave并安全的提供密钥，凭证和数据.\nIntel SGX 包括一个生成CPU和Enclave特定“密封密钥”的指令。密钥能够用来安全的存储和取回可鞥你需要保存在磁盘中的敏感信息。\nIntel SGX 实现新的安全模型 Intel SGX 是在很多公司、大学的安全研究人员以及政府安全机构的支持下创建的，上百家ISV与Intel合作，使用Intel SGX来保护关键任务应用程序。\nSet up SGX develop environment Install SGX driver\nInstall SGX SDK\nInstall SGX PSW\n直接按照官方文档依次安装上述3个组件\nSample Enclave Demo 1############# SGX SDK Setting 2# 编译平台和模式配置 3 4############## APP Setting 5# 主要是指定 6# App_Cpp_Files 需要编译的cpp文件 7# App_Include_Paths 包含目录 8# App_Cpp_Objects 输出 9 10############### Enclave setting 11# Enclave_Cpp_Files 12# Enclave_Include_Paths 13# Enclave_Cpp_Objects 14 15# eld 编译配置 16################ App Object 17################ Enclave Object Enclave 相关开发流程 使用edl文件定义不可信app和enclave之间的接口 实现app和enclave函数 编译 app 和enclave。编译中 Edger8r生成可信和不可信的代理/桥函数，Enclave签名工具生成enclave的metadata和签名 在模拟和硬件模式下运行和调试app，详细看debug enclave的内容 准备发布app 和enclave 编写Enclave函数 在app角度，使用不可信代理函数调用enclave函数(ECALL)跟调用其他函数没有区别。Enclave函数只是有些显示的c/c++函数。","tags":null,"title":"Intel SGX"},{"categories":null,"contents":"IPsec is a group of networking protocols used for setting up secure encrypted connections, such VPNs, across publicly shared networks.\nWhat is IPsec IPsec is a group of protocols that are used together to set up encrypted connections between devices. It helps keep data send over public networks secure. IPsec is often used to set up VPNs, and it works by encrypting IP packets, along with authenticating the source where the packets come from.\nWithin the term \u0026ldquo;IPsec\u0026rdquo;, \u0026ldquo;IP\u0026rdquo; stands for \u0026ldquo;Internet Protocol\u0026rdquo; and \u0026ldquo;sec\u0026rdquo; for \u0026ldquo;secure\u0026rdquo;. The Internet protocol is the main routing protocol used on the Internet; it designates where data will go using IP addresses. IPsec is secure because it adds encryption and authentication to this process.\nEncryption is the process of concealing information by mathematically alerting data so that it appears random. In simpler terms, encryption is the use of a \u0026ldquo;secret code\u0026rdquo; that only authorized parties can interpret.\nHow does IPsec Work? IPsec connections include the following steps:\nKey exchanges: Keys are the necessary for encryption; a key is a string of random characters that can be used to \u0026ldquo;lock\u0026rdquo;(encrypt) and \u0026ldquo;unlock\u0026rdquo;(decrypt) messages. IPsec set up keys with a key exchange between the connection devices, so that each device can decrypt the other device\u0026rsquo;s messages.\nPacket headers and trailers: All data that is sent over a network is broken down into smaller pieces call packets. Packets contain both a payload, or actual data being sent, and headers, or information about that data so that computers receiving the packets know what to do with them. IPsec add several headers to data packets containing authentication and encryption information. IPsec also add trailers, which go after each packet\u0026rsquo;s payload instead of before.\nAuthentication: IPsec providers authentication for each packets, like a stamp of authenticity on a collection item. This ensures that packets are from a trusted source and not an attacker.\nEncryption: IPsec encrypts the payloads within each packets and each packet\u0026rsquo;s IP header(unless transport mode is used instead of tunnel mode). This keeps data sent over IPsec secure and private.\nTransmission: Encrypted IPsec packets travel across one or more networks to their destination using a transport protocol. At this stage, IPsec traffic differs from regular IP traffic in that it most often uses UDP as its transport protocol, rather than TCP. TCP the transmission Control Protocol,set up dedicated connections between devices and ensures that all packets arrive. UDP, the User Datagram Protocol, does not set up these dedicated connections. IPsec uses UDP because this allows IPsec packets to get through firewalls.\nDecryption: At the other end of the communication, the packets are decrypted, and applications can now use the delivered data.\nWhat protocols are used in IPsec In networking, a protocol is specified way of formatting data so that any networked computer can interpret the data. IPsec is not one protocol, but a suite of protocols. The following protocol make up the IPsec suite.\nAuthentication Header(AH): The AH protocol ensures that data packets are form a trusted source and that the data has not been tampered with, link a temper-proof seal on a consumer product. These header do not provider any encryption; the do not help conceal the data from attackers.\nEncapsulating Security Protocol(ESP): ESP encrypts the IP header and the payload for each packet - unless transport mode is used, in which case it only encrypts the payload. ESP add its own header and a trailer to each data packet.\nSecurity Association(SA): SA refers to a number of protocols used for negotiating encryption keys and algorithm. One of the most common SA protocols is Internet Key Exchange(IKE).\nFinally, while the Internet Protocol(IP) is not part of the IPsec suite, IPsec runs directly on top of IP.\nWhat is the difference between IPsec tunnel mode and IPsec transport mode? IPsec tunnel mode is used between two dedicated routers, with each router acting as one end of a virtual \u0026ldquo;tunnel\u0026rdquo; through a public network. In IPsec tunnel mode, the original IP header containing the final destination of the packet is encrypted, in addition to the packet payload. To tell intermediary routers where to forward the packets, IPsec adds a new IP header. At each end of the tunnel, the router decrypt the IP headers to deliver the packets to their destination.\nIn transport mode, the payload of each packet is encrypted, but the original IP header is not. Intermediary routes thus able view the final destination of each packet\u0026ndash; unless a separate tunneling protocol(such as GER) is used.\nWhat port does IPsec use? A network port is the virtual location where data goes in a computer. Ports are how computers keep track of difference processes and connections; if data goes a certain port, the computer\u0026rsquo;s operating system knows which process it belongs to. IPsec usually uses port 500.\nHow does IPsec impact MSS and MTU? MSS and MTU are two measurements of packet size. Packets can only reach a certain size(measures in bytes) before computers, routers and switches cannot handle them. MSS measures the size of each packet\u0026rsquo;s payload, while MTU measures the entire packets, including headers. Packets that exceed a network\u0026rsquo;s MTU may be fragmented, meaning broken up into smaller packets and then reassembled. Packets that exceed the MSS are simply dropped.\nIPsec protocols add several headers and trailers to packets, all of which take up several bytes. For networks that use IPsec, either the MSS and MTU have to adjusted accordingly, or packets will be fragmented and slightly delayed. Usually, the MTU for a network is 1,500 bytes. A normal IP header is 20 bytes long, and a TCP header is also 20 bytes long, meaning each packet can contain 1,460 bytes of payload. However, IPsec add an Authentication Header, and ESP header, and associated trailers. These add 50-60 types to a packets, or more.\n1sudo iptables -t mangle -I POSTROUTING -p tcp -m tcp -j TCPMSS --tcp-flags SYN,RST SYN --set-mss 1280 2 3 4sudo iptables -t mangle -I POSTROUTING -p tcp -m tcp -j TCPMSS --tcp-flags SYN,RST SYN --set-mss 60 Challenge To secure traffic, IPsec requires an SA to be set up between two points, creating a tunnel for the traffic to travel through. Depending on the implementation model, this can introduce some challenges. For example, in a mesh model, all nodes(or locations) are connected to each other by dedicated tunnels. However, this requires creating managing several IPsec tunnels, which is difficult to scale.\nIKE Negotiating IPsec\u0026rsquo;s IKE Phase1. The best way to make sure you site-to-site tunnels get built is to remember to HAGLE: make sure you hash, Authentication, Group, Lifetime and Encryption are negotiated and agreed on.\nBefore the device establish the tunnel, you need to negotiate IPsec\u0026rsquo;s IKE Phase1. There are 5 times. To remember each step, Keith\u0026rsquo;s Recommend method is \u0026ldquo;HAGLE\u0026rdquo;.\nH: Hashing algorithm to verify data integrity A: Authentication to verify one another /PSK G: Groups to generate secret keys (DH, diffie helman Group Asymmetric) L：Lifetime to determine how long the tunnel stands up E: Encryption to agree which algorithm to use(AES symmetric ) With these five items, you ASAs can stand up an IKE Phase1 and connect you site securely across the Internet.\nMD5\nIPsec is a protocol suit to authenticate and encrypt the packets being exchanged between two points.\nVPN is a private connection over a public network - Layer 2 or Layer 3\nIPsec is standard by IETF to create a VPN tunnel at layer 3(Network Layer)\nIPsec provides:\nIntegrity: It indicates that the received message is same message that was sent [MD5, SHA]\nAuthentication: refers to verifying identity of a network entity like user/device [PSK, RSA], Make sure the user is we expected.\nConfidentiality: it is used to hide information [DES, 3DES, AES,SEAL]\nKey Management: To agree on key used for authentication and other purpose [Manual or automatic]\nTo achieve the goal of creating a secure tunnel, two peers needs to negotiate all the required parameters.\nIPsec use following protocols:\nAuthentication Header(AH): It provides authentication and integrity Encapsulation Security Protocol(ESP): It provides authentication, integrity and confidentiality Internet Key Exchange(IKE): Key management protocol, used to negotiate Security Association(SA), SA are security polices for communication between peers. IKE performs it jobs using ISAKMP framework using two phases\nPhase-1 is used to negotiate ISAKMP policy by exchange 5 parameters referred to as HAGLE. In this phase, Peers authenticate each other and calculate a shared secret key. Phase-1 gives a secure tunnel to be used in second IKE phase.\nAfter the negotiation , then IKE Policy Set. then get a tunnel.\nthe tunnel for the second IKE phase.\nPhase 1 can run in two modes\nMain mode. identity of peers is protected using encryption Aggressive mode. identity of peers is not protected. Phase-2 is used to negotiate IPsec security parameters [negotiate protocols and algorithm]\nEncapsulation protocol(AH, ESP) Encryption Hashing Tunnel mode( Transport mode) When then have done that, IPsec Transform Set, IPsec policy for sending our data\nAuthentication Header IPsec use two main protocols - AH and/or ESP\nAuthentication Header(AH): It provides authentication and integrity(no confidentiality,no encryption to hide the message)\nAuthentication : both side authenticate each other\nIntegrity: The message from one side to another can not be changed. If change will be discard. can provide security against replay attack using sliding window. Replay attack allows a bad guy to resend the intercepted contents between two points.\nEncapsulation Security Protocol(ESP): It provides authentication, integrity and confidentiality\ncan provide security against replay attack using sliding window.\n参考资料\nhttps://www.cloudflare.com/learning/network-layer/what-is-ipsec/\nhttps://www.youtube.com/watch?v=tapoOQ-MkPU\u0026ab_channel=GDNetworkingNewbie\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/linux/network_ipsec/","summary":"IPsec is a group of networking protocols used for setting up secure encrypted connections, such VPNs, across publicly shared networks.\nWhat is IPsec IPsec is a group of protocols that are used together to set up encrypted connections between devices. It helps keep data send over public networks secure. IPsec is often used to set up VPNs, and it works by encrypting IP packets, along with authenticating the source where the packets come from.","tags":null,"title":"IPSec"},{"categories":null,"contents":"防火墙 逻辑上，防火墙可以分为主机防火墙和网络防火墙。主机防火墙针对单个主机进行防护；网络防火墙往往处于网络入口或者边缘，针对网络入口进行防护，服务于防火墙背后的本地局域网。\n物理上，防火墙可以分为硬件防火墙和软件防火墙。硬件防火墙在硬件级别实现部分防火墙功能，另一部分基于软件实现，性能高，成本高；软件防火墙应用软件处理逻辑运行于通用计算平台之上的防火墙，性能低，成本低。\niptables/netfilter iptables其实不是真正的防火墙，可以把它理解陈伟一个客户端代理，用户通过iptables这个代理，将用户的安全设定执行到对应的“安全框架”中，这个“安全框架”才是真正的防火墙， 这个框架的名字叫netfilter。\nnetfilter才是防火墙真正的安全框架，位于内核空间。iptables其实是一个命令行工具， 位于用户空间，我们使用iptables这个工具操作真正的框架netfilter。\nnetfilter/iptables组成的linux平台下的包过滤防火墙，是免费的，具有以下功能：\n网络地址转换(NAT, Network Address Translate) 数据包内容修改 数据包过滤(防火墙功能) 我们虽然可以使用service iptables start启用iptables服务，但其实准确的来说iptables并没有一个守护进程，不能算是真正意义上的服务，而算是内核提供的功能。\niptables是按照规则(rules)来办事的, rules 就是我们预定义的条件。规则一般定义为“如果数据包头符合这样的条件，就这样处理这个数据包”。规则存储在内核空间的信息包过滤表中。这些规则分别指定了源地址、目的地址、传输协议(如TCP、UDP、ICMP)和服务类型(如HTTP、FTP和SMTP)等。当数据包与规则匹配时，iptables就根据规则所定义的方法来处理这些数据包， 如放行(accept)、拒绝(reject)和丢弃(drop)等。配置防火墙主要工作就是添加、修改和删除这些规则。\newctl\nhubDevice Objcet true 默认hub\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/linux/network_iptables/","summary":"防火墙 逻辑上，防火墙可以分为主机防火墙和网络防火墙。主机防火墙针对单个主机进行防护；网络防火墙往往处于网络入口或者边缘，针对网络入口进行防护，服务于防火墙背后的本地局域网。\n物理上，防火墙可以分为硬件防火墙和软件防火墙。硬件防火墙在硬件级别实现部分防火墙功能，另一部分基于软件实现，性能高，成本高；软件防火墙应用软件处理逻辑运行于通用计算平台之上的防火墙，性能低，成本低。\niptables/netfilter iptables其实不是真正的防火墙，可以把它理解陈伟一个客户端代理，用户通过iptables这个代理，将用户的安全设定执行到对应的“安全框架”中，这个“安全框架”才是真正的防火墙， 这个框架的名字叫netfilter。\nnetfilter才是防火墙真正的安全框架，位于内核空间。iptables其实是一个命令行工具， 位于用户空间，我们使用iptables这个工具操作真正的框架netfilter。\nnetfilter/iptables组成的linux平台下的包过滤防火墙，是免费的，具有以下功能：\n网络地址转换(NAT, Network Address Translate) 数据包内容修改 数据包过滤(防火墙功能) 我们虽然可以使用service iptables start启用iptables服务，但其实准确的来说iptables并没有一个守护进程，不能算是真正意义上的服务，而算是内核提供的功能。\niptables是按照规则(rules)来办事的, rules 就是我们预定义的条件。规则一般定义为“如果数据包头符合这样的条件，就这样处理这个数据包”。规则存储在内核空间的信息包过滤表中。这些规则分别指定了源地址、目的地址、传输协议(如TCP、UDP、ICMP)和服务类型(如HTTP、FTP和SMTP)等。当数据包与规则匹配时，iptables就根据规则所定义的方法来处理这些数据包， 如放行(accept)、拒绝(reject)和丢弃(drop)等。配置防火墙主要工作就是添加、修改和删除这些规则。\newctl\nhubDevice Objcet true 默认hub","tags":null,"title":"iptables"},{"categories":null,"contents":"Multicluster Replicated Control Plane is an uses case to enable communication between two service in difference service mesh without using Ingress and can enable mutual TLS between the service.\nIstio 1.8 Upgrade Notes\nMulticluster .global Stub Domain Deprecation As part of this release, Istio has switched to a new configuration for multi-primary (formerly “replicated control planes”). The new configuration is simpler, has fewer limitations, and has been thoroughly tested in a variety of environments. As a result, the .global stub domain is now deprecated and no longer guaranteed to work going forward.\nhttps://istio.io/v1.9/docs/setup/install/multicluster/multi-primary_multi-network/\nControl plane models 多集群部署也可以共享控制面(control plane)服务实例。在这种情况下，控制面实例可以被一个或者多个primary cluster发现。\nReference\nhttps://zufardhiyaulhaq.com/istio-multicluster-replicated-control-plane/\nhttps://istio.io/latest/docs/setup/install/multicluster/\nIsito 是对Service进行管理\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/blog/4_istio_multicluster/","summary":"Multicluster Replicated Control Plane is an uses case to enable communication between two service in difference service mesh without using Ingress and can enable mutual TLS between the service.\nIstio 1.8 Upgrade Notes\nMulticluster .global Stub Domain Deprecation As part of this release, Istio has switched to a new configuration for multi-primary (formerly “replicated control planes”). The new configuration is simpler, has fewer limitations, and has been thoroughly tested in a variety of environments.","tags":null,"title":"Istio MultiCluster"},{"categories":null,"contents":"Kubenetes生产落地全程实践\n核心概念\n架构设计\n认证授权\n高可用集群搭建\n二进制\u0026amp; kubeadm\n3台master两台2 node\ncalico、coredns、dashboard\n业务迁移到Kubenetes\nHarbor\n服务发现策略\nIngressNginx\nDocker 化服务、K8s、服务发现\nCICD\nnamespace、resources、label\n服务的调度与编排\n健康检查\n调度策略\n部署策略\n日志与监控\n第2章 kubernetes快速入门 本章中将从核心概念、架构设计、认证授权以及集群搭建方案对比几方面，带领大家快速掌握kubernetes的重要知识点，助力快速入门。\n2-1 了解kubernetes 舵手： 渔网、渔船 docker : 鲸鱼，集装箱 🐳\nKubernetes is an open-source system for automating deployment, scaling, and management of containerized applications.\nIt groups containers that makeup application in to logical units for easy management and discovery.Kubernetes builds upon 15 years of experience of running production workloads at Google, combined with best-of-breed ideas and practices from the community.\nkubernetes的主要特征\n以服务为中心 自动化， 自动扩缩容，更新、负载均衡、实例状态 kubernetes vs docker\n以docker 容器技术技术的标准为基础，CRI K8s架构设计\npod： pause 作为根容器，共享网络文件等资源\nlabel： deploy/pod/container\n2-2 kubernetes的核心概念 2-3 kubernetes的架构设计 master (APIServer/Scheduler(资源、内存、cpu)/controller(k8s资源rs,service)) etcd\nworker worker (kubelet维护pod的生命周期，网络、volume/ docker )\n2-4 kubernetes认证的密码学原理 (15:30) 认证(Authentication) 防止有人入侵\n授权(Authorization)\nAPIserver\nA \u0026ndash;8 篡改\u0026ndash; \u0026gt; B\n对称加密：小姐姐好可爱 \u0026ndash;\u0026gt; 对称加密 abc123\u0026mdash;\u0026gt; wqerjqwoeurfasdhjfskalj -\u0026gt; 对称解密abc123 \u0026mdash;\u0026gt; 小姐姐好可爱\n非对称加密: 小姐姐好可爱 \u0026ndash;\u0026gt; 非对称加密 abc123(公钥 public key)\u0026mdash;\u0026gt; wuqyieruzsxchjfvash -\u0026gt; 非对称解密cde987(私钥 private key) \u0026mdash;\u0026gt; 小姐姐好可爱\n发送一个hello\nserviceA \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-\u0026gt; ServiceB\nserviceA \u0026mdash;\u0026mdash;\u0026ndash;asdfqwefwsadfasd 密文\u0026mdash;\u0026mdash;\u0026mdash;-\u0026gt; serviceB\nA 使用 serverB的pubkey进行加密，然后发送到serverB。 c截获后也解不开。只有B用自己的私钥才可以解开。非对称加密算法的消耗比较大。对称加密的算法消耗较低。\n结合非对称加密和对称加密。\n使用非对称加密，加密对称加密要使用的密钥。可以把对称加密需要的密钥安全带的送到B。接下来双方就可以使用对称加密进行通信。\n性能和安全性都得到了解决。\nSSL/TLS协议 \u0026mdash;\u0026gt; HTTPS\n目前可能存在的风险就是B 在返回pubkey的时候，有可能被C截获，C截获后返回C的公钥给A，这样A就拿到了C的公钥。\nCA 认证机构，让A可以验证拿到的B的pubkey 确实是B的，确实是合法的，是CA颁发的。\n2-5 kubernetes的认证与授权 认证\n1. 客户端证书认证(TLS双向认证)\nCA 自己的认证机构\n给各个组件颁发证书\nkubectl \u0026mdash;\u0026gt; API server\n双向认证 ： 互相验证证书是否为CA颁发\nAPI server是否是kubectl 需要访问的\nkubectl 客户端是否是一个合法的客户端\n2.BearerToken\n3.ServcieAccount\nPod与API server打交道\n(namespace，token，ca) 挂载到pod的文件系统中\n授权\nABAC\nwebhook\nRBAC(Role Based Access Control)\nUser \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-\u0026gt; Role \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-\u0026gt; Authority(Resource, Verbs:Curd)\n|_ User\n|_ ServiceAccount\nRoleBinding\nAdmisionControl: 准入控制\nAlwaysAdmit、AlwaysDeny、ServiceAccount、DenyEscolatingExec\n2-6 集群搭建方案对比 社区方案\nKubeadm：\nBinary：\n易于维护\niterm 级联功能\n第3章 容器运行时-Docker or Containerd 本章主要讲解Docker or Containerd如何选择和全面上手实践Containerd。\n3-1 Docker or Containerd如何选择 (07:40)\n3-2 Containerd全面上手实践 (26:18) 第4章 高可用集群搭建\u0026mdash;kubespray方式【集群落地方案1】6 节 | 52分钟 本章中将讲解kubespray集群搭建方案。带领大家一起分析kubespray部署方案、基础环境、kubespray的安装配置、用kubespray一键部署生产级K8s集群等，全面系统学会kubespray的集群落地方案。\n4-1 分析kubespray部署方案，准备基础环境 (08:42)\n4-2 kubespray的安装、配置 (15:13)\n4-3 用kubespray一键部署生产级k8s集群 (08:28)\n4-4 集群冒烟测试 (06:52)\n4-5 访问dashboard (04:41)\n4-6 基于kubespray的集群运维 (07:20) 第5章 高可用集群搭建\u0026mdash;二进制方式【集群落地方案2】9 节 | 73分钟 本章中将讲解，如何使用二进制的方式，搭建最新版本的kubernetes高可用集群。同样会以三个master，两个worker节点为例，会针对集群可用性进行的测试，并完成dashboard的搭建和使用。并在本章结尾，通过文档方式，针对前面内容进行总结，便于同学们回顾查阅。\u0026hellip;\n5-1 基础环境准备 (13:58)\n5-2 生成证书 (10:58)\n5-3 kubernetes各组件的认证配置 (04:31)\n5-4 部署etcd集群 (04:08)\n5-5 部署kubernetes控制平面 (08:16)\n5-6 部署kubernetes工作节点 (13:38)\n5-7 网络插件-Calico_1 (06:00)\n5-8 DNS插件-CoreDNS (04:40)\n5-9 集群冒烟测试 (06:36) 第6章 业务系统迁移kubernetes\u0026mdash;准备工作【为平稳迁移做好储备】6 节 | 90分钟 搭建完集群还不能马上迁移业务，本章中将讲解迁移前的一些准备工作：包括镜像仓库harbor的入门和部署、对kubernetes服务发现方案的学习分析以及ingress-nginx服务发现方案的部署。\n6-1 Harbor入门 (17:06)\n6-2 Harbor高可用部署（上） (11:50)\n6-3 Harbor高可用部署（下） (12:21)\n6-4 kubernetes的服务发现 集群内部\n集群内-\u0026gt; 集群外\n集群外-\u0026gt; 集群内\n6-5 部署ingress-nginx（上） (14:52)\n6-6 部署ingress-nginx（下） (13:36) 第7章 业务系统迁移kubernetes\u0026mdash;最佳实践【多类型业务迁移落地】7 节 | 86分钟 本章中将分析如何将非docker业务迁移到docker、使docker服务运行在kubernetes中，以及在这个过程中需要注意的问题。同时也会介绍，将定时任务、传统的web服务、springboot的web服务还有dubbo服务迁移部署在kubernetes中的全过程。\n7-1 定时任务迁移kubernetes (21:56)\n服务做到镜像里\n基础镜像 搞定服务运行的相关文件 构建镜像 Dockerfile 制作K8s服务，并调度\n确定服务发现的策略 编写K8s配置 图文： 7-2 【不熟悉SpringBoot的筒子看过来】SpringBoot快速入门\n7-3 springboot的web服务迁移kubernetes (11:29) 图文： 7-4 【不熟悉Dubbo的筒子看过来】Dubbo快速入门\n7-5 传统dubbo服务迁移kubernetes（上） (16:22)\n7-6 传统dubbo服务迁移kubernetes（下） (16:08)\n7-7 传统web服务迁移kubernetes (19:40) 第8章 CICD实践【只会迁移还不够，持续集成走起】5 节 | 70分钟 本章将讲解如何让服务可以在kubernetes里面实现持续集成。逐步实现gitlab管理代码、maven构建、docker实现镜像的构建、推送到harbor仓库以及通过脚本跟kubernetes对接完成持续发布。最后还会应用jenkins通过pipeline整合整个流程实现CICD。\u0026hellip;\n8-1 kubernetes与cicd (12:41)\n8-2 cicd实践（1） (12:56)\n8-3 cicd实践（2） (13:26)\n8-4 cicd实践（3） (13:31)\n8-5 cicd实践（4） (17:18)\n第9章 深入kubernete\u0026mdash;几个重要的资源对象【透过表象看本质\u0026amp;装逼可选包】4 节 | 83分钟 本章中介绍了kubernetes的重要资源：namespace、resources和label。 讲解并实践了，命名空间对资源对象和资源配额多层面的隔离机制、pod资源限制的配置方式、pod在节点资源紧缺时的驱逐机制、label作用于不同资源对象上的不同的作用等核心知识。 \u0026hellip;\n9-1 Namespace \u0026mdash; 集群的共享与隔离 创建一个namespace\n1apiVersion: v1 2kind: Namespace 3metadata: 4 name: dev 9-2 Resources\u0026mdash;多维度集群资源管理（上） (22:45)\n9-3 Resources\u0026mdash;多维度集群资源管理（下） (22:26)\n9-4 Label\u0026mdash;小标签大作为 (19:31) 第10章 深入kubernete\u0026mdash;服务调度与编排【透过表象看本质\u0026amp;装逼可选包】6 节 | 121分钟 本章中主要围绕服务的调度与编排讲解讲解并实践了：pod的健康检查的参数配置及影响、调度器的整体工作原理以及常见的预选策略和优选策略、如何利用kubernetes本身的机制完成不同的部署方式。\n10-1 健康检查\u0026mdash;高可用的守护者 (23:06)\n10-2 Scheduler\u0026mdash; 玩转pod调度（上） (13:57)\n10-3 Scheduler \u0026mdash; 玩转pod调度（下） (13:49)\n10-4 部署策略详解 \u0026mdash; 重建、滚动、蓝绿、金丝雀 (26:11)\n10-5 深入Pod - pod相关的点点滴滴（上） (21:24)\n10-6 深入Pod - pod相关的点点滴滴（下） (22:04) 第11章 深入kubernete\u0026mdash; 落地实践深入【透过表象看本质\u0026amp;装逼可选包】7 节 | 123分钟 本章主要从kubernetes落地的角度进行深入讲解，分别介绍：ingress在落地过程可能遇到的问题与应对方式、基于glusterfs的共享存储、kubernetes api的设计，并以一个真实的示例项目让大家看到容器管理平台可以做成什么样子的。\n11-1 ingress \u0026mdash; 四层代理、session保持、定制配置、流量控制（上） (17:42)\n11-2 ingress \u0026ndash; 四层代理、session保持、定制配置、流量控制（中） (17:18)\n11-3 ingress \u0026mdash; 四层代理、session保持、定制配置、流量控制（下） (16:42)\n11-4 共享存储 \u0026mdash; PV、PVC和StorageClass（上）.mp4 (16:13)\n11-5 共享存储 \u0026mdash; PV、PVC和StorageClass（下） (16:04)\n11-6 StatefulSet \u0026mdash; 有状态应用的守护者 (18:47)\n11-7 KubernetesAPI \u0026mdash;如何开发一个基于kubernetes的容器管理平台 (19:38) 第12章 深入kubernete\u0026mdash;日志和监控【透过表象看本质\u0026amp;装逼可选包】10 节 | 131分钟 本章中将介绍K8S使用者必须考虑的重量级问题：日志与监控。课程中会分析当下主流的日志处理方案并选择一种方案进行日志从采集到展示的完整实践；会讲解主流k8s监控方案prometheus，包括它的实现原理，支持的各种指标等。\n12-1 常见日志采集问题和解决方案分析 (08:41)\n12-2 logpilot+elasticsearch+kibana日志实践 (19:26)\n12-3 监控入门\u0026mdash;从整体把握监控 (07:39)\n12-4 Prometheus入门\u0026mdash;架构和原理 (11:45)\n12-5 部署前奏 - Helm \u0026amp; Operator (10:31)\n12-6 监控部署实战 - Helm+PrometheusOperator (19:30)\n12-7 监控落地 - 指标完善、Grafana看板和邮件报警（上） (17:16)\n12-8 监控落地 - 指标完善、Grafana看板和邮件报警（中） (17:28)\n12-9 监控落地 - 指标完善、Grafana看板和邮件报警（下） (18:21) 图文： 12-10 【步骤总结，便于快速回顾】Helm部署文档\n第13章 ServiceMesh代表作istio 本章中我们会从istio的架构设计开始让你对它的实现原理有深入了解，并会部署完整的istio环境，从架构上让我们的服务自动支持istio的功能，最后使用几个istio的常见工具集实现数据展现。\n13-1 什么是ServiceMesh？什么是Istio？ (04:51)\n微服务架构\n设么是ServiceMesh\n服务网格 是概念不是产品 解决网络层面的问题 服务发现、负载均衡、路由、流量控制、服务间通信的可靠性、监控\u0026mdash;- API 网关？\nLinkerd\n始于2016年CNCF官方项目\n1.x 基于节点(虚拟机、物理机)\n2.x 基于kubernetes(conduit)\nIstio\nGoogle/IBM/Lyft 发起的开源项目，17年推出，18年7月发布1.0、多平台支持\n都是基于sidecar模式\n都分为数据层和控制层\nIstio 更受欢迎\nPilot -\u0026gt; envoy 提供信息，服务发现， AB测试\nMixer：策略(访问控制)、遥测(数据收集和汇报，服务之间流转的数据)\nGalley: 配置管理中心\nCitadel： 安全\n故障排查：\n请求在哪失败的，A有调用B吗\n为什么用户请求/页面hung住了\n为什么系统组件这么慢？那个组件最慢？\n应用容错性\n客户端没有设置timeout导致应用卡住\n没有重试机制，某个服务偶尔异常导致用户页面错误\n某些节点异常，导致服务响应时间过长\n应用升级发布\n新版本一次性升级，一旦出错影响范围很大\n无法进行AB测试，根据用户属性访问不同版本\n服务版本的依赖关系处理不当导致服务不可用\n系统安全\n服务都是HTTP而非https\n没有流量限制，任何人都可以对服务发起攻击\n13-2 Istio架构和原理 (11:41)\n13-3 部署istio\n13-4 部署BookInfo示例应用 (11:38)\n13-5 配置请求路由 (08:47)\n13-6 故障注入 (07:38)\n13-7 流量转移 (09:27)\n13-8 设置请求超时 (03:16)\n13-9 熔断 (08:44)\n13-10 流量镜像 (05:58)\n13-11 Istio中的Prometheus和Grafana (11:44)\n13-12 分布式追踪Jaeger (09:29)\n13-13 网格可视化 (10:59) 第14章 课程总结【沉淀\u0026amp;展望】1 节 | 6分钟 本章中将总结本课程所学知识，展望docker和kubernetes的发展。\nhttps://www.youtube.com/watch?v=2b7MRI6tmMo\u0026list=PLsbVibQXuLjqZwdpSBXR27gNGgtHlQLHR\u0026index=2\nhttps://www.youtube.com/watch?v=8MlW9nixkwk\u0026list=PLsbVibQXuLjqw6mCC4QMyLZ282dhdPWr3\u0026index=13\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/cloudnative/Kubernates/1-k8s-cloudnative/","summary":"Kubenetes生产落地全程实践\n核心概念\n架构设计\n认证授权\n高可用集群搭建\n二进制\u0026amp; kubeadm\n3台master两台2 node\ncalico、coredns、dashboard\n业务迁移到Kubenetes\nHarbor\n服务发现策略\nIngressNginx\nDocker 化服务、K8s、服务发现\nCICD\nnamespace、resources、label\n服务的调度与编排\n健康检查\n调度策略\n部署策略\n日志与监控\n第2章 kubernetes快速入门 本章中将从核心概念、架构设计、认证授权以及集群搭建方案对比几方面，带领大家快速掌握kubernetes的重要知识点，助力快速入门。\n2-1 了解kubernetes 舵手： 渔网、渔船 docker : 鲸鱼，集装箱 🐳\nKubernetes is an open-source system for automating deployment, scaling, and management of containerized applications.\nIt groups containers that makeup application in to logical units for easy management and discovery.Kubernetes builds upon 15 years of experience of running production workloads at Google, combined with best-of-breed ideas and practices from the community.","tags":null,"title":"K8s Cloud Native"},{"categories":null,"contents":"给Pod传递参数 通过环境变量给Pod传递参数 可以在container的描述文件中加入一个env的参数，值是一个数组，每个元素都是键值对，值是string。\n1--- 2apiVersion: v1 3kind: Pod 4metadata: 5 name: first-pod 6 labels: 7 app: nginx 8spec: 9 containers: 10 - name: 00-simple-pod-nginx 11 image: nginx:1.17.0 12 env: 13 - name: INTERVAL 14 value: 30s 通过命令行参数给Pod传递参数 加入一个args配置，命令行参数是一个字符串数组\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/cloudnative/Kubernates/9-k8s-configmap/","summary":"给Pod传递参数 通过环境变量给Pod传递参数 可以在container的描述文件中加入一个env的参数，值是一个数组，每个元素都是键值对，值是string。\n1--- 2apiVersion: v1 3kind: Pod 4metadata: 5 name: first-pod 6 labels: 7 app: nginx 8spec: 9 containers: 10 - name: 00-simple-pod-nginx 11 image: nginx:1.17.0 12 env: 13 - name: INTERVAL 14 value: 30s 通过命令行参数给Pod传递参数 加入一个args配置，命令行参数是一个字符串数组","tags":null,"title":"K8s ConfigMap"},{"categories":null,"contents":"NodeExporter 用于采集一个Host上的各种性能指标，并且暴露给Prometheus 采集。因为NodeExporter需要采集每一个Host的数据状态，所以就产生了一个需求，在每一个K8s的机器上都要运行一个Pod, 而实现这个需求的K8s资源类型就叫做DaemonSet。\nDaemonSet DaemonSet的功能就是保证每个Node都运行Pod， 但是如果某个K8s的Node下线之后，对应的Pod也下线，还是保持每个Node一个Pod。如果新增一个Node，就会在新增的Node中增加一个Pod，保证所有的Node中有且只有一个当前Pod。\n1--- 2apiVersion: apps/v1 3kind: DaemonSet 4metadata: 5 name: node-exporter 6 namespace: kube-system 7 labels: 8 k8s-app: node-exporter 9 kubernetes.io/cluster-service: \u0026#34;true\u0026#34; 10 addonmanager.kubernetes.io/mode: Reconcile 11 version: v1.2.2 12spec: 13 selector: 14 matchLabels: 15 k8s-app: node-exporter 16 version: v1.2.2 17 updateStrategy: 18 type: OnDelete 19 template: 20 metadata: 21 labels: 22 k8s-app: node-exporter 23 version: v1.2.2 24 spec: 25 priorityClassName: system-node-critical 26 containers: 27 - name: prometheus-node-exporter 28 image: \u0026#34;prom/node-exporter:v1.2.2\u0026#34; 29 imagePullPolicy: \u0026#34;IfNotPresent\u0026#34; 30 args: 31 - --path.procfs=/host/proc 32 - --path.sysfs=/host/sys 33 ports: 34 - name: metrics 35 containerPort: 9100 36 hostPort: 9100 37 volumeMounts: 38 - name: proc 39 mountPath: /host/proc 40 readOnly: true 41 - name: sys 42 mountPath: /host/sys 43 readOnly: true 44 resources: 45 limits: 46 memory: 50Mi 47 requests: 48 cpu: 100m 49 memory: 50Mi 50 hostNetwork: true 51 hostPID: true 52 volumes: 53 - name: proc 54 hostPath: 55 path: /proc 56 - name: sys 57 hostPath: 58 path: /sys NodeExporter是针对Node的Pod，需要将Host中的一些系统文件透传给Pod，并让Pod使用主机网络。\n额外需求\n虽然每个节点都运行一个Pod是一个确实存在的需求，但是有些时候，却又不是要求每个Node都有一个Pod。例如，有10台机器用于运行HDFS。 HDFS有NameNode和DataNode之分，那么DataNode可能是每个Host都要有的，但是NameNode却不是必须的，可能只要3-5台就可以了。这样一个明显的好处就是可以节约成本。\nDaemonSet 也是支持Selector的，而且是NodeSelector，通过我们给Node加上一些Label，然后给NameNode加上一些DaemonSet的NodeSelector。\n1spec: 2 selector: 3 matchLabels: 4 k8s-app: hdfs-namenode 5 updateStrategy: 6 type: OnDelete 7 template: 8 metadata: 9 labels: 10 k8s-app: hdfs-namenode 11 spec: 12 # node selector 13 nodeSelector: 14 host: high-cpu 这样就保证了Pod只会在特定的Host中以DaemonSet的特性启动\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/cloudnative/Kubernates/7-k8s-daemonset/","summary":"NodeExporter 用于采集一个Host上的各种性能指标，并且暴露给Prometheus 采集。因为NodeExporter需要采集每一个Host的数据状态，所以就产生了一个需求，在每一个K8s的机器上都要运行一个Pod, 而实现这个需求的K8s资源类型就叫做DaemonSet。\nDaemonSet DaemonSet的功能就是保证每个Node都运行Pod， 但是如果某个K8s的Node下线之后，对应的Pod也下线，还是保持每个Node一个Pod。如果新增一个Node，就会在新增的Node中增加一个Pod，保证所有的Node中有且只有一个当前Pod。\n1--- 2apiVersion: apps/v1 3kind: DaemonSet 4metadata: 5 name: node-exporter 6 namespace: kube-system 7 labels: 8 k8s-app: node-exporter 9 kubernetes.io/cluster-service: \u0026#34;true\u0026#34; 10 addonmanager.kubernetes.io/mode: Reconcile 11 version: v1.2.2 12spec: 13 selector: 14 matchLabels: 15 k8s-app: node-exporter 16 version: v1.2.2 17 updateStrategy: 18 type: OnDelete 19 template: 20 metadata: 21 labels: 22 k8s-app: node-exporter 23 version: v1.2.2 24 spec: 25 priorityClassName: system-node-critical 26 containers: 27 - name: prometheus-node-exporter 28 image: \u0026#34;prom/node-exporter:v1.","tags":null,"title":"K8s DaemonSet"},{"categories":null,"contents":"蓝绿部署 蓝绿部署是一种比较常见的部署方式，经常会用于新旧版本不兼容的情况。\n先将新版本(绿版)的服务运行起来。 将所有的流量切到新版本的服务上 删除旧版本(蓝版)的服务 创建新版本的ReplicaSet，将Service指向新的Pods，删除旧版本的ReplicaSet\n滚动升级 蓝绿部署可以有效保证业务的正确性，但是也带来了一定的风险，例如稳定性。\n假设新部署的应用是有问题的，一旦切换之后就会导致业务的崩溃，造成损失。于是就有了稍微友好的升级方式，滚动升级。\n先关闭一个旧版本的实例 开启一个新版本的实例用于替换旧版本 替换成功时候循环1和2，直到所有的实例升级完成。 在整个过程中，如果中途发现异常可以及时停手，及时止损。而且Kubernetes也在客户端中支持了这个特性。kubectl rolling-update。\n升级前后RC的Selector都被改变了 操作都是在客户端执行的？ 金丝雀发布 金丝雀发布是滚动发布的一种特例，在滚动发布中，是不会等待的，除非中间出错了。但是有些时候，我们并不想要全都升级，可能只是处于POC的一些原因，我们只希望部分实例是新的，大部分是旧的，而这种情形，我们就称之为金丝雀发布。\n升级少部分实例 查看效果，如果好，全部升级 如果不好，则不升级 声明式升级 前面介绍的这些升级发布方式在K8s上很多时候是半手工方式执行的，而Kubernetes作为一款DevOPS友好的系统，已经内置了对于部署方式的一种资源抽象，这个资源就是：Deployment。\nDeployment \u0026ndash;\u0026gt; ReplicaSet \u0026ndash;\u0026gt; Pods\nDeployment 存在的意义为：在升级应用程序时，需要引入额外的ReplicaSet，并协调新旧两个RS，使他们再根据彼此不断修改，而不会造成干扰。Deployment将这些运维过程都代码化，内置为自己的逻辑，从而让升级变得简单。\n首先我们使用Deployment创建3个实例\n1# deploy.yaml 2--- 3apiVersion: apps/v1 4kind: Deployment 5metadata: 6 name: first-deployment 7 labels: 8 app: simple-pod-deployment 9spec: 10 replicas: 3 11 selector: 12 matchLabels: 13 app: simple-pod-deployment 14 template: 15 metadata: 16 name: simple-pod-deployment 17 labels: 18 app: simple-pod-deployment 19 spec: 20 containers: 21 - name: simple-pod-de 22 image: lukelau/rest-docker:0.0.1 23 ports: 24 - containerPort: 8080 25 args: 26 - -server.addr=0.0.0.0:8080 此时创建了3个Pod，接下来我们将修改下images的版本，重新apply -f\n1# image: lukelau/rest-docker:0.0.1 2 image: lukelau/rest-docker:0.0.2 通过kubectl describe deployment first-deployment 可以看到整个升级的过程。\n可以使用record记录执行历史\n1kubectl rollout history deployment first-deployment 控制滚动升级速率\n1--- 2apiVersion: apps/v1 3kind: Deployment 4metadata: 5 name: first-deployment 6 labels: 7 app: simple-pod-deployment 8spec: 9 replicas: 3 10 minReadySeconds: 10 11 strategy: 12 type: RollingUpdate 13 rollingUpdate: 14 maxSurge: 1 15 maxUnavailable: 0 16 selector: 17 matchLabels: 18 app: simple-pod-deployment 19 template: 20 metadata: 21 name: simple-pod-deployment 22 labels: 23 app: simple-pod-deployment 24 spec: 25 containers: 26 - name: simple-pod-de 27 image: lukelau/rest-docker:0.0.2 28 ports: 29 - containerPort: 8080 30 args: 31 - -server.addr=0.0.0.0:8080 1# 停止升级 2kubectl rollout pause deployment first-deployment 3# 恢复升级 4kubectl rollout resume deployment first-deployment 5# 取消升级 6kubectl rollout undo deployment first-deployment ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/cloudnative/Kubernates/5-k8s-deployment/","summary":"蓝绿部署 蓝绿部署是一种比较常见的部署方式，经常会用于新旧版本不兼容的情况。\n先将新版本(绿版)的服务运行起来。 将所有的流量切到新版本的服务上 删除旧版本(蓝版)的服务 创建新版本的ReplicaSet，将Service指向新的Pods，删除旧版本的ReplicaSet\n滚动升级 蓝绿部署可以有效保证业务的正确性，但是也带来了一定的风险，例如稳定性。\n假设新部署的应用是有问题的，一旦切换之后就会导致业务的崩溃，造成损失。于是就有了稍微友好的升级方式，滚动升级。\n先关闭一个旧版本的实例 开启一个新版本的实例用于替换旧版本 替换成功时候循环1和2，直到所有的实例升级完成。 在整个过程中，如果中途发现异常可以及时停手，及时止损。而且Kubernetes也在客户端中支持了这个特性。kubectl rolling-update。\n升级前后RC的Selector都被改变了 操作都是在客户端执行的？ 金丝雀发布 金丝雀发布是滚动发布的一种特例，在滚动发布中，是不会等待的，除非中间出错了。但是有些时候，我们并不想要全都升级，可能只是处于POC的一些原因，我们只希望部分实例是新的，大部分是旧的，而这种情形，我们就称之为金丝雀发布。\n升级少部分实例 查看效果，如果好，全部升级 如果不好，则不升级 声明式升级 前面介绍的这些升级发布方式在K8s上很多时候是半手工方式执行的，而Kubernetes作为一款DevOPS友好的系统，已经内置了对于部署方式的一种资源抽象，这个资源就是：Deployment。\nDeployment \u0026ndash;\u0026gt; ReplicaSet \u0026ndash;\u0026gt; Pods\nDeployment 存在的意义为：在升级应用程序时，需要引入额外的ReplicaSet，并协调新旧两个RS，使他们再根据彼此不断修改，而不会造成干扰。Deployment将这些运维过程都代码化，内置为自己的逻辑，从而让升级变得简单。\n首先我们使用Deployment创建3个实例\n1# deploy.yaml 2--- 3apiVersion: apps/v1 4kind: Deployment 5metadata: 6 name: first-deployment 7 labels: 8 app: simple-pod-deployment 9spec: 10 replicas: 3 11 selector: 12 matchLabels: 13 app: simple-pod-deployment 14 template: 15 metadata: 16 name: simple-pod-deployment 17 labels: 18 app: simple-pod-deployment 19 spec: 20 containers: 21 - name: simple-pod-de 22 image: lukelau/rest-docker:0.","tags":null,"title":"K8s Deployments"},{"categories":null,"contents":"Replicas 和deployment这两类资源都是用于控制workload的。这两种类型的资源一般都是持续运行的，同时还有一些辅助方式帮助workload出现异常时恢复，以及根据情况进行动态伸缩的特性。\nJob 根据Job的定义创建出对应的Pod，然后关注Pod的状态， 直到满足定义。例如Pod执行成功了或者执行失败了，并且达到了重试次数。\n1--- 2apiVersion: batch/v1 3kind: Job 4metadata: 5 name: pi 6spec: 7 template: 8 spec: 9 containers: 10 - name: pi 11 image: perl 12 command: [\u0026#34;perl\u0026#34;, \u0026#34;-Mbignum=bpi\u0026#34;,\u0026#34;-wle\u0026#34;, \u0026#34;print bpi(2000)\u0026#34;] 13 restartPolicy: Never 14 backoffLimit: 4 Job正常执行结束后结果如上图。这是一个只执行一次的Job。它的操作方式就是创建一个Pod，然后运行一遍，然后就退出。如果想执行多次，则只需要增加一个参数\n1completions: 2 执行2次时创建了两个Pod，然后保证这两个Pod都执行成功。\n我们在使用Deployment等Workload的时候，一般会指定restartPolicy，默认都是RestartOnFail。在Job中不能这么指定，因为这个逻辑应该由Job来控制， 而不是让Pod来控制。\nCronJob 定时任务， CronJob就是在Job的基础上加上了周期定义的API\n1--- 2apiVersion: batch/v1 3kind: CronJob 4metadata: 5 name: batch-job-pi 6spec: 7 schedule: \u0026#34;0,15,30,45 * * * *\u0026#34; 8 jobTemplate: 9 spec: 10 template: 11 metadata: 12 labels: 13 app: pi-job 14 spec: 15 containers: 16 - name: pi 17 image: perl 18 command: [\u0026#34;perl\u0026#34;, \u0026#34;-Mbignum=bpi\u0026#34;,\u0026#34;-wle\u0026#34;, \u0026#34;print bpi(2000)\u0026#34;] 19 restartPolicy: Never ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/cloudnative/Kubernates/6-k8s-job/","summary":"Replicas 和deployment这两类资源都是用于控制workload的。这两种类型的资源一般都是持续运行的，同时还有一些辅助方式帮助workload出现异常时恢复，以及根据情况进行动态伸缩的特性。\nJob 根据Job的定义创建出对应的Pod，然后关注Pod的状态， 直到满足定义。例如Pod执行成功了或者执行失败了，并且达到了重试次数。\n1--- 2apiVersion: batch/v1 3kind: Job 4metadata: 5 name: pi 6spec: 7 template: 8 spec: 9 containers: 10 - name: pi 11 image: perl 12 command: [\u0026#34;perl\u0026#34;, \u0026#34;-Mbignum=bpi\u0026#34;,\u0026#34;-wle\u0026#34;, \u0026#34;print bpi(2000)\u0026#34;] 13 restartPolicy: Never 14 backoffLimit: 4 Job正常执行结束后结果如上图。这是一个只执行一次的Job。它的操作方式就是创建一个Pod，然后运行一遍，然后就退出。如果想执行多次，则只需要增加一个参数\n1completions: 2 执行2次时创建了两个Pod，然后保证这两个Pod都执行成功。\n我们在使用Deployment等Workload的时候，一般会指定restartPolicy，默认都是RestartOnFail。在Job中不能这么指定，因为这个逻辑应该由Job来控制， 而不是让Pod来控制。\nCronJob 定时任务， CronJob就是在Job的基础上加上了周期定义的API\n1--- 2apiVersion: batch/v1 3kind: CronJob 4metadata: 5 name: batch-job-pi 6spec: 7 schedule: \u0026#34;0,15,30,45 * * * *\u0026#34; 8 jobTemplate: 9 spec: 10 template: 11 metadata: 12 labels: 13 app: pi-job 14 spec: 15 containers: 16 - name: pi 17 image: perl 18 command: [\u0026#34;perl\u0026#34;, \u0026#34;-Mbignum=bpi\u0026#34;,\u0026#34;-wle\u0026#34;, \u0026#34;print bpi(2000)\u0026#34;] 19 restartPolicy: Never ","tags":null,"title":"K8s Job"},{"categories":null,"contents":"容器网络 每一个容器都可以有一个自己独立的网络栈，这个独立的网络栈是基于Linux的Network Namespace实现的。\n这个独立的网络栈包含了： Network Interface、Loopback Device、Routing Table和IPtables规则。对于一个进程来说，这些要素就构成了它发起和响应网络请求的基本环境。\n容器可以使用自己独立的网络栈(创建属于自己的Network Namespace)，也可以直接使用Host的网络栈(不创建Network Namespace)。\n1# Uset -net=host to share the host network 2docker run -d -net=host --name nginx-host nginx 直接使用Host的网络栈可以提供良好的网络性能，但是不可避免的会引入网络资源共享的问题，比如端口冲突。大多数应用场景下，我们希望容器能够有自己独立的IP地址和端口，即有自己独立的Namespace。\n这个时候，就会出现一个问题，在这个被隔离的容器进程中如何与其他的Network Namespace里的容器进程进行交互呢。\n一般我们如果希望两台主机之间的通信，直接用网线把这两台主机连接起来即可；而如果是多台主机之间通信我们可以将其连接在同一台交换机上。\n在Linux系统中，能够起到虚拟交换机作用的虚拟网络设备是Bridge，是二层网络设备。主要功能是根据MAC地址来将数据包转发到网桥的不同Port上。\n为了实现上述目的，docker项目会在Host上创建一个docker0的网桥，凡是连接在docker0网桥上的容器，就相当于在同一个二层网络。\n接下来就是如何把容器连接到docker0网桥上，这就需要veth pair的虚拟设备了。veth pair创建出来以后总是以两张虚拟网卡veth peer的形式成对出现的。并且从其中一个peer发出的数据包可以直接出现在与之对应的另一个peer上，即使veth pair的两端不在同一个Network Namespace 中。因此，veth pair常常用作连接不同Network Namespace的网线。\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/kubernetes/k8s_ops_network/","summary":"容器网络 每一个容器都可以有一个自己独立的网络栈，这个独立的网络栈是基于Linux的Network Namespace实现的。\n这个独立的网络栈包含了： Network Interface、Loopback Device、Routing Table和IPtables规则。对于一个进程来说，这些要素就构成了它发起和响应网络请求的基本环境。\n容器可以使用自己独立的网络栈(创建属于自己的Network Namespace)，也可以直接使用Host的网络栈(不创建Network Namespace)。\n1# Uset -net=host to share the host network 2docker run -d -net=host --name nginx-host nginx 直接使用Host的网络栈可以提供良好的网络性能，但是不可避免的会引入网络资源共享的问题，比如端口冲突。大多数应用场景下，我们希望容器能够有自己独立的IP地址和端口，即有自己独立的Namespace。\n这个时候，就会出现一个问题，在这个被隔离的容器进程中如何与其他的Network Namespace里的容器进程进行交互呢。\n一般我们如果希望两台主机之间的通信，直接用网线把这两台主机连接起来即可；而如果是多台主机之间通信我们可以将其连接在同一台交换机上。\n在Linux系统中，能够起到虚拟交换机作用的虚拟网络设备是Bridge，是二层网络设备。主要功能是根据MAC地址来将数据包转发到网桥的不同Port上。\n为了实现上述目的，docker项目会在Host上创建一个docker0的网桥，凡是连接在docker0网桥上的容器，就相当于在同一个二层网络。\n接下来就是如何把容器连接到docker0网桥上，这就需要veth pair的虚拟设备了。veth pair创建出来以后总是以两张虚拟网卡veth peer的形式成对出现的。并且从其中一个peer发出的数据包可以直接出现在与之对应的另一个peer上，即使veth pair的两端不在同一个Network Namespace 中。因此，veth pair常常用作连接不同Network Namespace的网线。","tags":null,"title":"K8s network"},{"categories":null,"contents":"Node 节点主要负责容器的管理，用于运行容器和保证容器的状态。默认情况下Master节点不承担Node节点的功能，但是可以通过特殊的配置让Master节点也可作为Node节点。\nEtcd用于存储Kubernetes的元数据，但是不要求一定要以容器的形式运行。\n1kubeadm init --pod-network-cidr=10.244.0.0/16 --apiserver-advertise-address=192.168.0.22 --pod-network-cidr pod 的ippool, --apiserver-advertise-address 为暴露的k8sAPI调用IP.\n节点(Node)\n一个Node是一个运行K8s的主机，作为K8s worker, 通常称之为Minion。每个节点都运行如下K8s关键组件：\nkubelet：主节点代理 kube-proxy: service使用其将链接路由到Pod docker/rocket: k8s 使用容器技术创建容器 容器组(Pod)\n一个Pod对应若干容器组成的一个容器组，同一个Pod内的容器共享一个存储卷(volume)，同一个Pod中的容器共享一个网络Namespace,可以使用localhost互相通信。\nPod是短暂的，不是持续性实体。一个Pod是一个特定的应用打包集合，包含一个或者多个容器。和运行的容器类似，一个Pod只有很短的运行周期。Pod被调度到一个Node运行，直到容器的生命周期结束或者其被删除。\n容器组生命周期(Pod Status)\n包含所有容器状态集合，包括容器组状态类型，容器组生命周期，事件，重启策略，以及replication controllers.\n标签(labels)\n标签是用来连接一组对象的，比如容器组Pod。lable可以用来组织和选择子对象。 一个Label是attach到Pod的一对键值对，用来传递用户定义的属性。\nReplication Controllers\n主要负责指定数量的Pod在同一时间一起运行。Replication controller 确保任意时间都有指定数量的Pod副本在运行。如果为某个Pod创建了Replication Controller并且指定为3副本，它会创建3个Pod,并持续监控他们。如果某个Pod不响应，那么Replication controller 会替换它，保持Pod总数为3.\n当创建Replication Controller时，需要指定两个东西。\nPod模板： 用来创建Pod副本的模板 Label：Replication Controller 需要监控的Pod的Label 现在已经创建了Pod的一些副本，那么在这些副本上如何负载均衡呢，我们需要的是service\nService：\n如果Pod是短暂的，那么重启时IP地址可能会变，怎么才能从前端容器正确可靠的指向后台容器呢。\nService是定义一系列Pod以及访问这些Pod的策略的一层抽象。Service通过Label找到Pod组。因为service是抽象的，所在在图表里通常看不到他们的存在。\n现在假定有两个后台Pod,并且定义后台service名称为“backend-service”，label选择器为(tier=backend,app=myapp)。backend-service的Service会完成如下两件重要的事情：\n会为Service创建一个本地集群的DNS入口，因此前端只需要DNS查找主机名为“backend-service”就能够解析出前端应用程序可用的IP地址 现在前端已经得到了后台服务的IP地址，但是它应该访问2个后台Pod中的哪一个呢。Service在这两个后台Pod之间提供透明的负载均衡，会将请求发给其中的任意一个。通过每个Node上运行的代理 kube-proxy完成。 Kubernetes Master\n集群拥有一个K8s Master,K8s Master 提供集群的独特视角，并拥有一系列组件，如Kubernetes API server. API server 提供可以用来和集群交互的REST 端点。Master 节点包含用来创建和复制Pod的Replication Controller.\n参考资料：\nhttps://blog.csdn.net/hahachenchen789/article/details/80506699\nhttps://liqiang.io/post/kubernetes-tutorial-part-3-pods-80a851a5\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/cloudnative/Kubernates/1-k8s-overview/","summary":"Node 节点主要负责容器的管理，用于运行容器和保证容器的状态。默认情况下Master节点不承担Node节点的功能，但是可以通过特殊的配置让Master节点也可作为Node节点。\nEtcd用于存储Kubernetes的元数据，但是不要求一定要以容器的形式运行。\n1kubeadm init --pod-network-cidr=10.244.0.0/16 --apiserver-advertise-address=192.168.0.22 --pod-network-cidr pod 的ippool, --apiserver-advertise-address 为暴露的k8sAPI调用IP.\n节点(Node)\n一个Node是一个运行K8s的主机，作为K8s worker, 通常称之为Minion。每个节点都运行如下K8s关键组件：\nkubelet：主节点代理 kube-proxy: service使用其将链接路由到Pod docker/rocket: k8s 使用容器技术创建容器 容器组(Pod)\n一个Pod对应若干容器组成的一个容器组，同一个Pod内的容器共享一个存储卷(volume)，同一个Pod中的容器共享一个网络Namespace,可以使用localhost互相通信。\nPod是短暂的，不是持续性实体。一个Pod是一个特定的应用打包集合，包含一个或者多个容器。和运行的容器类似，一个Pod只有很短的运行周期。Pod被调度到一个Node运行，直到容器的生命周期结束或者其被删除。\n容器组生命周期(Pod Status)\n包含所有容器状态集合，包括容器组状态类型，容器组生命周期，事件，重启策略，以及replication controllers.\n标签(labels)\n标签是用来连接一组对象的，比如容器组Pod。lable可以用来组织和选择子对象。 一个Label是attach到Pod的一对键值对，用来传递用户定义的属性。\nReplication Controllers\n主要负责指定数量的Pod在同一时间一起运行。Replication controller 确保任意时间都有指定数量的Pod副本在运行。如果为某个Pod创建了Replication Controller并且指定为3副本，它会创建3个Pod,并持续监控他们。如果某个Pod不响应，那么Replication controller 会替换它，保持Pod总数为3.\n当创建Replication Controller时，需要指定两个东西。\nPod模板： 用来创建Pod副本的模板 Label：Replication Controller 需要监控的Pod的Label 现在已经创建了Pod的一些副本，那么在这些副本上如何负载均衡呢，我们需要的是service\nService：\n如果Pod是短暂的，那么重启时IP地址可能会变，怎么才能从前端容器正确可靠的指向后台容器呢。\nService是定义一系列Pod以及访问这些Pod的策略的一层抽象。Service通过Label找到Pod组。因为service是抽象的，所在在图表里通常看不到他们的存在。\n现在假定有两个后台Pod,并且定义后台service名称为“backend-service”，label选择器为(tier=backend,app=myapp)。backend-service的Service会完成如下两件重要的事情：\n会为Service创建一个本地集群的DNS入口，因此前端只需要DNS查找主机名为“backend-service”就能够解析出前端应用程序可用的IP地址 现在前端已经得到了后台服务的IP地址，但是它应该访问2个后台Pod中的哪一个呢。Service在这两个后台Pod之间提供透明的负载均衡，会将请求发给其中的任意一个。通过每个Node上运行的代理 kube-proxy完成。 Kubernetes Master\n集群拥有一个K8s Master,K8s Master 提供集群的独特视角，并拥有一系列组件，如Kubernetes API server. API server 提供可以用来和集群交互的REST 端点。Master 节点包含用来创建和复制Pod的Replication Controller.\n参考资料：","tags":null,"title":"K8s Overview"},{"categories":null,"contents":"前面介绍的几种workload都有一个共性，那就是创建出来的Pod都是一致的。所谓的一致就是说，假设我们使用的是ReplicaSet，创建了3个Pod，那么这3个Pod创了名字一定不一样之外，其他属性可能都是一样的，包括运行时的参数和模式以及数据存储。\n如果是Web Service，数据保存到后端的DB中，上述逻辑是没有问题的。\n如果使用ReplicaSet来部署一个DB的多实例， 就可肯能存在问题了。\n数据持久化，一般使用PVC，当使用PVC 和PV的时候\n​\nReplicaSet -\u0026gt; Pods(3 个) -\u0026gt; 持久卷声明 -\u0026gt; 持久卷\n3个Pod的数据都写到同一个Pv中，这样肯定是不行的？？？\nStatefulSet 为了解决Pod的状态性的问题，K8s引入了StatefulSet的概念\nPod有单独的存储和固定的网络标识 需要配备一个headless Service，用于DNS 可以通过DNS快速发现其他的Pod 可以直接通过Pod DNS通信 每个Pod都可以通过DNS访问到，这种特性在其他workload中是不能实现的。通过StatefulSet可以让Pod持有状态，即使因为故障Pod重建了，那么对应的Pod的名字和数据都会保留，和重建之前没有什么区别。\n使用StatefulSet 必须建立一个HeadlessService，然后绑定这个headlessservice到StatefulSet。\n以MongoDB为例，创建一个StatefulSet，因为还没有介绍到PVC和PV的内容，所以MongoDB将使用本地存储卷。\n创建Headless Service\n创建 StatefulSet\n通过DNS访问Pod\n在StatefulSet的Pod中可以通过DNS直接访问其他Pod。\n1mongo --host mongo-1.mongo 可以通过\u0026lt;pod-name\u0026gt;.\u0026lt;service-name\u0026gt;的形式访问Pod。这其实和StatefulSet的设计是有关系的，在类似的Deployment中Pod的名字是不固定的，而在StatefulSet中，Pod的名字是固定的。\n和ReplicaSet对比\n因为有状态的Pod彼此不同，通常希望操作的是其中的特定的一个，所以StatefulSet通常要求你创建一个用来记录每个Pod网络标记的HeadlessService。通过这个Service，每个Pod都拥有独立的DNS记录，而这在ReplicaSet中是不行的？（如果为ReplicaSet创建一个Headless Service会发生啥？） 因为StatefulSet缩容任何时候只会操作一个Pod实例，所以有状态应用的缩容不会很迅速。 StatefulSet在有实例不健康的情况下，是不允许缩容的。 持久存储 一个StatefulSet可以拥有一个或者多个卷声明模板，这些声明会在创建Pod前创建出来，绑定到一个Pod的实例上。 扩容StatefulSet会创建两个API对象，一个Pod和一个卷声明；但是缩容StatefulSet却会删除一个Pod对象，而会留下PVC，因为一旦删除PVC则意味着PV会被回收。 StatefulSet at-most-one\nKubernetes 必须保证两个拥有相同标记和绑定相同持久卷声明的有状态的Pod实例不会同时运行。一个StatefulSet必须保证有状态的实例的 at-most-one 语义。也就是说StatefulSet必须保证一个Pod不再运行后，才会去创建它的替换Pod。\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/cloudnative/Kubernates/8-k8s-stafulset/","summary":"前面介绍的几种workload都有一个共性，那就是创建出来的Pod都是一致的。所谓的一致就是说，假设我们使用的是ReplicaSet，创建了3个Pod，那么这3个Pod创了名字一定不一样之外，其他属性可能都是一样的，包括运行时的参数和模式以及数据存储。\n如果是Web Service，数据保存到后端的DB中，上述逻辑是没有问题的。\n如果使用ReplicaSet来部署一个DB的多实例， 就可肯能存在问题了。\n数据持久化，一般使用PVC，当使用PVC 和PV的时候\n​\nReplicaSet -\u0026gt; Pods(3 个) -\u0026gt; 持久卷声明 -\u0026gt; 持久卷\n3个Pod的数据都写到同一个Pv中，这样肯定是不行的？？？\nStatefulSet 为了解决Pod的状态性的问题，K8s引入了StatefulSet的概念\nPod有单独的存储和固定的网络标识 需要配备一个headless Service，用于DNS 可以通过DNS快速发现其他的Pod 可以直接通过Pod DNS通信 每个Pod都可以通过DNS访问到，这种特性在其他workload中是不能实现的。通过StatefulSet可以让Pod持有状态，即使因为故障Pod重建了，那么对应的Pod的名字和数据都会保留，和重建之前没有什么区别。\n使用StatefulSet 必须建立一个HeadlessService，然后绑定这个headlessservice到StatefulSet。\n以MongoDB为例，创建一个StatefulSet，因为还没有介绍到PVC和PV的内容，所以MongoDB将使用本地存储卷。\n创建Headless Service\n创建 StatefulSet\n通过DNS访问Pod\n在StatefulSet的Pod中可以通过DNS直接访问其他Pod。\n1mongo --host mongo-1.mongo 可以通过\u0026lt;pod-name\u0026gt;.\u0026lt;service-name\u0026gt;的形式访问Pod。这其实和StatefulSet的设计是有关系的，在类似的Deployment中Pod的名字是不固定的，而在StatefulSet中，Pod的名字是固定的。\n和ReplicaSet对比\n因为有状态的Pod彼此不同，通常希望操作的是其中的特定的一个，所以StatefulSet通常要求你创建一个用来记录每个Pod网络标记的HeadlessService。通过这个Service，每个Pod都拥有独立的DNS记录，而这在ReplicaSet中是不行的？（如果为ReplicaSet创建一个Headless Service会发生啥？） 因为StatefulSet缩容任何时候只会操作一个Pod实例，所以有状态应用的缩容不会很迅速。 StatefulSet在有实例不健康的情况下，是不允许缩容的。 持久存储 一个StatefulSet可以拥有一个或者多个卷声明模板，这些声明会在创建Pod前创建出来，绑定到一个Pod的实例上。 扩容StatefulSet会创建两个API对象，一个Pod和一个卷声明；但是缩容StatefulSet却会删除一个Pod对象，而会留下PVC，因为一旦删除PVC则意味着PV会被回收。 StatefulSet at-most-one\nKubernetes 必须保证两个拥有相同标记和绑定相同持久卷声明的有状态的Pod实例不会同时运行。一个StatefulSet必须保证有状态的实例的 at-most-one 语义。也就是说StatefulSet必须保证一个Pod不再运行后，才会去创建它的替换Pod。","tags":null,"title":"K8s StafulSet"},{"categories":null,"contents":"Short Names and Categories Like native resources, custom resources might have long resources names. CRs can have short names as well.\nAgain, kubectl learns about short names via discovery information.\n1apiVersion: apiextensions.k8s.io/v1beta1 2kind: CustomResourcesDefinition 3metadata: 4\tname: ats.cnat.programming-kubernetes.info 5spec: 6\t... 7\tshortNames: 8\t- at Further, CRs\u0026ndash;as any other resources\u0026ndash;can be part of categories. The most common use is the all category, as in kubectl get all. Is lists all user-facing resources in a cluster, like pods and services.\nThe CRs define in the cluster can join a category or create their own category via the categories field.\n1apiVersion: apiextensions.k8s.io/v1beta1 2kind: CustomResourcesDefinition 3metadata: 4\tname: ats.cnat.programming-kubernetes.info 5spec: 6\t... 7\tcategories: 8\t- all Printer Cloumns The kubectl CLI tool users server-side printing to render the output of kubectl get. This means that it queries the API server for the columns to display and the values in each row.\nCustom resources support server-side printer columns as well, via additionalPrinterColumns\n1apiVersion: apiextensions.k8s.io/v1beta1 2kind: CustomResourcesDefinition 3metadata: 4\tname: ats.cnat.programming-kubernetes.info 5spec: 6\tadditionalPrinterColumns: # optional 7\t- name: kubectl column name 8\ttype: OpenAPI type for the colum 9\tformat: OpenAPI format for the column # optional 10\tdescription: human-readdable description of the column #optional 11\tpriority: integer, always zero supported by kubectl 12\tJSONPath: JSON path inside the CR for the despaly value With this, the example CRD from the introduction cloud be extend with addtionalPrinterColumns like this:\n1additionalPrinterColumns: # optional 2- name: schedule 3 type: string 4 JSONPath: .spec.schedule 5- name: command 6 type: string 7 JSONPath: .spec.command 8- name: phase 9 type: string 10 JSONPath: .status.phase Then the kubectl would render a cnat resource as follows:\n1$ kubectl get ats 2Name SCHEDULE COMMAND PHASE 3foo 2019-07-03T02:00:00Z echo \u0026#34;hello world\u0026#34; Pending A Developer\u0026rsquo;s View on Custom Resource Dynamic Client Typed Client Anatomy of a type Kinds are represented as Golang structs. Usually the struct is named as the kind and is placed in a package corresponding to the group and version of the GVK at hand. A common convention is to place the GVK group/version.Kind into a Go package pkg/apis/group/version and Define a Golang struct Kind int the file types.go.\nEvery Golang type corresponding to a GVK embeds the TypeMeta struct from the package k8s.io/apimachinery/pkg/apis/meta/v1. TypeMeta just contains of the Kind and ApiVersion fields.\n1type TypeMeta struct{ 2 APIVersion string `json:\u0026#34;apiVersion,omitempty\u0026#34; yaml:\u0026#34;apiVersion,omitempty\u0026#34;` 3 Kind string `json:\u0026#34;kind,omitempty\u0026#34; yaml:\u0026#34;kind,omitempty\u0026#34;` 4} In addition, every too-level kind\u0026ndash;that is, one that has its own endpoint and therefore one(or more) corresponding GVRs\u0026ndash;has to store a name, a namespace for namespaced resources, add a pretty long number of further metelevel fields. All these are stored in a struct called ObjectMeta in the package k8s.io/apimachinery/pkg/meta/v1:\n1type ObjectMeta struct{ 2 Name string `json:\u0026#34;name,omitempty\u0026#34;` 3 Namespace string `json:\u0026#34;namespace,omitempty\u0026#34;` 4 Labels map[string]string 5 Annotation map[string]string 6} Kubernetes top-level types look very similar to each other in the sense that they usually have a spec and a status. See this example of a deployment from k8s.io/kubernetes/apps/v1/types.go\n1type Deployment struct{ 2 metav1.TypeMeta `json:\u0026#34;,inline\u0026#34;` 3 metav1.ObjectMeta `json:\u0026#34;metadata,omitempty\u0026#34;` 4 5 Spec DeploymentSpec `json:\u0026#34;spec,ommitempty\u0026#34;` 6 Status DeploymentStatus `json:\u0026#34;status,omitempty\u0026#34;` 7} While actual content of the types for spec and status differs significantly between different types, this split into spec and status ia a common theme or event a convention in Kubernetes, though it\u0026rsquo;s not technically required. Hence, it is good practice to follow this sturcture of CRDs as well.\nGolang package structure As we have seen, the Golang types are traditionally placed in a file called types.go in the package pkg/apis/group/version. In addition to that file, there are couple more files we want to go through now. Some of them are manually written by the developer, while some are genereated with code generators.\nThe doc.go file describes the API\u0026rsquo;s purpose and includes a number of package-global code generation tags:\n1// package v1alpha1 contains the xxx v1alpha1 API Group 2 3// +k8s:deepcopy-gen=package 4// +k8s:protobuf-gen=package 5// +k8s:openapi-gen=true 6// +k8s:prerelease-lifecycle-gen=true 7// +groupName=cnat.programming-kubernetes.info 8package v1alpha1 Next, register.go includes helpers to register the custom resources Golang types into a scheme.\n1package version 2import ( 3\tmetav1 \u0026#34;k8s.io/apimachinery/pkg/apis/meta/v1\u0026#34; 4 \u0026#34;k8s.io/apimachinery/pkg/runtime\u0026#34; 5 \u0026#34;k8s.io/apimachinery/pkg/runtime/schema\u0026#34; 6 7 group \u0026#34;repo/pkg/apis/group\u0026#34; 8) 9 10// SchemeGroupVersion is group version used to register these objects 11var SchemeGroupVersion=scheme.GroupVersion{ 12 Group: group.GroupName 13 Version: \u0026#34;version\u0026#34; 14} 15 16// Kind takes an unqualified kind and retruns back a Group qualified GroupKind 17func Kind(kind string) scheme.GroupKind{ 18 return schemeGroupVersion.WithKind(kind).GroupKind 19} 20// Resource takes an unqualified resource and returns a Group qualified GroupResource 21func Resource(resource string) scheme.GroupResource{ 22 return schemeGroupVersion.WithResource(resource).GroupResource 23} 24 25var ( 26 SchemeBuilder = runtime.NewSchemeBuilder(addKnownTypes) 27 AddToScheme = SchemeBuilder.AddToScheme 28) 29 30// Adds the list of known types to Scheme 31func addKnownTypes(scheme *runtime.Scheme) error{ 32 scheme.AddKnownTypes( 33 SchemeGroupVersion, 34 \u0026amp;SomeKind{}, 35 \u0026amp;SomeKindList{} 36 ) 37 metav1.AddToGroupVersion(scheme, SchemeGroupVersion) 38 return nil 39} Then, zz_generated.deepcopy.godefines deep-copy methods on the custom resource Golang top-level types. In addition, all substruct become deep-copyable as well.\nBecause the example use the tag +k8s:deepcopy-gen=package in doc.go, the deepcopy generation is on an opt-out basis; that is, DeepCopy methods are genereaed for every type in the package that does not opt out with +k8s:deepcopy-gen=false.\nTyped Client created via client-gen With the API package pkg/apis/group/version in place, the client generator client-gen creates a typed client, in pkg/generated/clientset/versioned by default. More precisely, the generated top-level object is a client set. It subsumes a number of API groups, versions, and resources.\nThe top-level files looks like the following:\nController-runtime Client of Operator SDK and KubeBuilder The controller-runtime project provides the basis for the opetator solutions Operator SDK adn Kubebuilder.\nIt uses discovery information from the API server to map the kinds to HTTP path.\nHere is a quick example of how to use controller-runtime.\n1import ( 2\t\u0026#34;flag\u0026#34; 3 4 corev1 \u0026#34;k8s.io/api/core/v1\u0026#34; 5 metav1 \u0026#34;k8s.io/apimachinery/pkg/apis/meta/v1\u0026#34; 6 \u0026#34;k8s.io/client-go/kubernetes/scheme\u0026#34; 7 \u0026#34;k8s.io/client-go/tools/clientcmd\u0026#34; 8 9 runtimeclient \u0026#34;sig.k8s.io/controller-runtime/pkg/client\u0026#34; 10) 11 12func main(){ 13 kubeconfig = flag.String(\u0026#34;kubecofig\u0026#34;,\u0026#34;~/.kube/config\u0026#34;,\u0026#34;kubeconfig file path\u0026#34;) 14 flag.Parse() 15 config,err := clientcmd.BuildConfigFromFlag(\u0026#34;\u0026#34;,*kubeconfig) 16 cl,_ := runtimeclient.New(config, clientOptions{ 17 Scheme: sxcheme.Scheme 18 }) 19 podList := \u0026amp;corev1.PodList{} 20 err:= cl.List(context.TODO(), client.InNamespace(\u0026#34;default\u0026#34;), podList) 21} The\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/kubernetes/k8s_dev_client/","summary":"Short Names and Categories Like native resources, custom resources might have long resources names. CRs can have short names as well.\nAgain, kubectl learns about short names via discovery information.\n1apiVersion: apiextensions.k8s.io/v1beta1 2kind: CustomResourcesDefinition 3metadata: 4\tname: ats.cnat.programming-kubernetes.info 5spec: 6\t... 7\tshortNames: 8\t- at Further, CRs\u0026ndash;as any other resources\u0026ndash;can be part of categories. The most common use is the all category, as in kubectl get all. Is lists all user-facing resources in a cluster, like pods and services.","tags":null,"title":"K8s 源码阅读 4"},{"categories":null,"contents":"Following sample-controller Bootstraping Business Logic We are now in the position to implement the business logic of the custom controller. That is, we implement the state transitions between the three phases\u0026ndash;form PhasePending to PhaseRuning to PhaseDone\u0026ndash;in controller.go.\nprocessNextWorkItem() processNextWorkItem() bool will read a single work item off the workquque and attempt to process it, by calling the syncHandler.\n1func (c *Controller) processNextWorkItem() bool{ 2 obj, shutdowon := c.workqueue.Get() 3 4 if shutdown{ 5 return false 6 } 7 8 // We wrap this block in a func so we can defer c.workqueue.Done. 9 err := func(obj interface{})error{ 10 // We call Done here so the workqueue knows we have finished processing this item. 11 // We also must remeber to call Forget if we do not want this work item being 12 // re-queued. For example, we do not call Forget if a transient error occurs, instead 13 // the item it put back on the workqueue and attempted again after a back-off period. 14 defer c.workqueue.Done(obj) 15 var key string 16 var ok bool 17 // We expect strings to come off the wordqueue. There are of the form namespace/name. 18 // We do this as the delayed nature of the workqueue means the iterms in the informer 19 // cache may actually be more up to date then when the item was initially put on to 20 // the workqueue. 21 if key,ok:=obj.(string);!ok{ 22 // As the item in the workqueue is actually invalid, we call Forget here else we\u0026#39;d 23 // go into a loop of attemping to process a work item that is invalid. 24 c.workqueue.Forget(obj) 25 // %#v print struct and content 26 ultiruntime.HandleError(fmt.Errorf(\u0026#34;expected string in workqueue but got %#v\u0026#34;,obj)) 27 return nil 28 } 29 // Run the syncHandler, passing it the namespace/name string of the Foo resource to 30 // be synced. 31 if err := c.syncHandler(key); err != nil{ 32 // Put the item back on the workqueue to handle any transient errors. 33 c.workqueue.AddRateLimited(key) 34 return fmt.Errorf(\u0026#34;err sync \u0026#39;%s\u0026#39;:\u0026#39;%s\u0026#39;, requeuing\u0026#34;,key, error.Error(jj)) 35 } 36 // Finally, if no error occurs we Forget this item so it dose not get queued again 37 // until another change happens. 38 c.workqueue.Forget(obj) 39 klog.Infof(\u0026#34;Successfully synced \u0026#39;%s\u0026#39;\u0026#34;,key) 40 return nil 41 }(obj) 42 43 if err != nil { 44 utilruntime.HandleError(err) 45 return true 46 } 47 return true 48} `\nsyncHandler() syncHandler(key string) compares the actual state with the desired, and attempts to converge the two. It then updates the Status block of the Foo resource with the current status of the resource.\n1func (c *Controller) syncHandler(key string) error{ 2 // Convert the namespace/name string into a distinct namespace and name. 3 namespace, name, err := cache.SplitMetaNamespaceKey(key) 4 if err != nil{ 5 utilruntime.HandleError(fmt.Errorf(\u0026#34;invalid resource key :%s\u0026#34;,key)) 6 return nil 7 } 8 9 // Get the Foo resource with this namespace/name 10 foo, err:= c.foosLister.Foos(namespace).Get(name) 11 if err != nil{ 12 // The foo resource may no longer exist, in which case we stop processing. 13 if errors.IsNotFound(err){ 14 utilruntime.HandleError(fmt.Errorf(\u0026#34;foo \u0026#39;%s\u0026#39; in working queue no longer exists\u0026#34;)) 15 return nil 16 } 17 return err 18 } 19 20 deploymentName := foo.Spec.DeploymentName 21 if deploymentName == \u0026#34;\u0026#34;{ 22 // we choose to absord the error here as the worker would requeue 23 // the resource otherwise. Instead, the next time the resource is update the 24 // resource will be queued again. 25 return nil 26 } 27 28 // Get the deployment with the name specified in Foo.spce 29 deployment, err := c.deploymentLister.Deployments(foo.Namespace).Get(deployment) 30 // If the resource doesn\u0026#39;t exist, we\u0026#39;ll create it 31 if errors.IsNotFound(err){ 32 deployment, err = c.kubeclinetset.AppsV1().Deployments(foo.Namespace). 33 Create(context.TODO,newDeployment(foo),metav1.CreatedOptions{}) 34 } 35 if err != nil{ 36 return nil 37 } 38 39 // If the Deployment is not controllerd by this Foo resource, we should log 40 // a warning to the event recorder and return error msg. 41 if !metav1.IsControlledBy(deployment, foo){ 42 msg := fmt.Sprintf(MessageResourceExists, deployment.Name) 43 c.recorder.Event(foo, corev1.EventTypeWarning, ErrorResourceExists,msg) 44 return fmt.Errorf(\u0026#34;%s\u0026#34;,msg) 45 } 46 47 // If this number of the replicas on the Foo resource is specified, and the number 48 // does not equal the current desired replicas on the Deployment, we should updated 49 // the Deployment resource 50 if foo.Spce.Replicas != nil \u0026amp;\u0026amp; *foo.Spec.Replicas != *deployment.Spec.Replicas{ 51 deployment, err != c.kubeclientset.AppsV1().Deployments(foo.Namespase). 52 Update(context.TODO),newDeployment(foo),metav1.UpdateOptions{}) 53 } 54 if err != nil{ 55 return err 56 } 57 58 err = c.updateFooStatus(foo,deployment) 59 if err != nil{ 60 return err 61 } 62 c.recorder.Event(foo, corev1.EventTypeNormal, SuccessSynced,MessageResourceS) 63 64} Kubebuilder Create a Project 1source \u0026lt; $(kubebuilder completion zsh) 2# --repo git the git module name 3kubebuilder init --domain bytegopher.com --license apache2 --owner \u0026#34;ByteGopher\u0026#34; --repo www.github.com/airren/cnat-kubebuilder 4 5 6kubebuilder create api --group cnat --version v1alpha1 --kind CronJob 7 8# if you are editing the API definitions, generate the manifest such as Custom Resources(CRs) or Custom Resource Definitions(CRDs) using 9make manifest Architecture Concept Diagram The following diagram will help you better understand the Kubernetes concepts and architecture.\nProcess main.go One of these per cluster, or several if using HA.\nManger sigs.k8s.io/controller-runtime/pkg/manger One of these per process.\nHandles HA(leader election), exports metrics, handles webhook certs, caches events, holds clients, broadcasts events to Controllers, handles signals, and shutdown.\nClient\u0026hellip; Communicates with API server, handling authentication and protocols.\nCache\u0026hellip; Holds recently watched or GET\u0026rsquo;ed objects. Used by Controllers, and Webhooks. Uses clients.\nController sigs.k8s.io/controller-runtime/pkg/controller One of these per Kind that is reconciled (i.e. one per CRD)\nOwns resources created by it.\nUses Caches and Clients and gets events via Filters.\nThe controller calls a Reconciler each time it gets an event.\nHandles back-off and queuing and re-queuing of events.\nPredicate sigs.k8s.io/controller-runtime/pkg/predicate Filters a stream of events, passing only those that require action to the reconciler.\nReconciler sig.k8s.io/controller-runtile/pkg/reconciler User-provided logic is added to the reconciler. Reconcile Function.\nWebhook sigs.k8s.io/controller-runtime/pkg/webhook Zero or one webhooks. One per Kind that is reconciled.\nScheme Every set of controllers needs a Scheme, which provides mappings between Kinds and their corresponding Go types. The Scheme is simply a way to keep track of what Go type correspond to a given GVK.\nReconcile We return an empty result and no error, which indicates to controller-runtime that we\u0026rsquo;ve successfully reconciled this object and don\u0026rsquo;t need to try again until there\u0026rsquo;s some changes.\nkustomize controller-gen CLI What is controller-gen? Kubebuilder makes use of a tool called controller-gen for generating utility code and Kubernetes YAML. This code and config generation is controlled by the presence of special \u0026ldquo;marker comments\u0026rdquo; in Go code.\ncontroller-gen is built out of different \u0026ldquo;generators\u0026rdquo; (which specify what to generate) and \u0026ldquo;output rules\u0026rdquo;(which specify how and where to write the results). Both are configured through command line options specified in marker format.\n1controller-gen paths=./... crd:trivialVersions-true rbac:roleName=controller-perms \\ 2\toutput:crd:artifacts:config=config/crd/bases Generate CRDs and RBAC, and specifically stores the generated CRD yaml in config/crd/base. For the RBAC, it uses the default output rules(config/rbac). It considers every package in the current directory tree(as per the normal rules of the go ...wild card).\nHow to use controller-gen? Generators 1// +webhook on package 2generates(partial) {Mutating,Validating}WebhookConfiguration objects. 3// +schemapatch: on package 4pathes existing CRDs with new schemata. 5// +rbac:roleName=\u0026lt;string\u0026gt; on package 6generates ClusterRole objects 7// +object: on package 8generate code containing DeepCopy, DeepCopyInto, and DeepCopyObject method implementations. 9// +crd on package 10generates CustomResourceDefination objects. Output Rules Output rules configure how a given generator outputs its results. There is always one global \u0026ldquo;fallback\u0026rdquo; output rule(specified as output:\u0026lt;rule\u0026gt;), plus per-generator overrides(specified as output:\u0026lt;generator\u0026gt;:\u0026lt;rule\u0026gt;).\nDefault Rules: When no fallback rules is specified manually, a set of default per-generator rules are used which result in YAML going to config/\u0026lt;generator\u0026gt;, and code staying where is belongs.\nThe default rules are equivalent to output:\u0026lt;generator\u0026gt;:artifacts:config=config/\u0026lt;generator\u0026gt; for each generator.\nMarker for Config/Code Generation Makers are single-line commnets that start with a plus, followed by a marker name, optionally followed by some marker specific configuration.\n1// +kubebuilder:validation:Optional 2// +kubebuilder:validation:MaxItems=2 3// +kubebuilder:printcolumn:JSONPath=\u0026#34;.status.replicas\u0026#34;,name=Replicas, type=string CRD Generation These markers describe how to construct a custom resource definition form a series of Go types and packages. Generation of the actual validation schema is described by the validation markers.\nCalling the Generators Usually, the code generators are called in mostly the same way in every controller project.\nHere, all means to call all four standard code generators for CRs.\ndeepcopy-gen\nGenerate func(t *T)DeepCopy() *T and func(t *T)DeepCopyInfo(*T) method.\nclient-gen\nCreates typed client sets\ninformer-gen\nCreates informers for CRs that offer an event-base interface to react to changes of CRs on the server.\nlister-gen\nCreates lister for CRs that offer a read-only caching layer for GET and LIST request.\nThe last two are the basis for building controllers. These four code generator make up a powerful basis for building full-featured, production-ready controllers using the same mechanisms and packages that the Kubernetes upstream controllers are using.\nControlling the Generators with Tags While some of the code-generator behavior is controlled via command-line flags as described earlier, a lot more properties are controlled via tags in you Go files. A tag is a specially formatted Go comment in the following form.\n1// +some-tag 2// +some-other-tag=value There are to kind of tags:\nGlobal tags above the package line in a file called doc.go Local tags above a type declaration. ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/kubernetes/k8s_dev_operator_kubebuilder/","summary":"Following sample-controller Bootstraping Business Logic We are now in the position to implement the business logic of the custom controller. That is, we implement the state transitions between the three phases\u0026ndash;form PhasePending to PhaseRuning to PhaseDone\u0026ndash;in controller.go.\nprocessNextWorkItem() processNextWorkItem() bool will read a single work item off the workquque and attempt to process it, by calling the syncHandler.\n1func (c *Controller) processNextWorkItem() bool{ 2 obj, shutdowon := c.workqueue.Get() 3 4 if shutdown{ 5 return false 6 } 7 8 // We wrap this block in a func so we can defer c.","tags":null,"title":"K8s 源码阅读 6 Solutions for Writing Operators"},{"categories":null,"contents":"In this chapter we\u0026rsquo;ll discuss the operational aspects of controllers and operators, showing you how to package them, walking you through best practices for running controllers in production, and making sure that your extension points don\u0026rsquo;t break your Kubernetes cluster, security, or performance-wise.\nLifecycle Management and Packaging Let\u0026rsquo;s start with the low-hanging fruit: packaging and delivering your controllers so that a user can install it in a straightforward manner.\nPackaging: The Challenge While Kubernetes defines resources with manifest, typically written in YAML, a low-level interface to declare the state of resources, these manifest files have shortcoming. Most importantly in the context of packaging containerized apps, the YAML manifests are static; that is, all values in a YAML manifest are fixed. This means that if you want to change the container images in a deployment manifest, for example, you have to create a new manifest.\nLet\u0026rsquo;s look a concrete example, Assume you have the following Kubernetes deployment encoded in a YAML manifest called mycontroller.yaml, representing the custom controller you\u0026rsquo;d like user to install:\n1apiVersion: apps/v1beta1 2kind: Deployment 3metadata: 4\tname: mycustomcontroller 5spec: 6\treplicas: 1 7\ttemplate: 8\tmetadata: 9\tlabels: 10\tapp: customcontroller 11 spec: 12 containers: 13 - name: thecontroller 14 images: example/controller:0.1.0 15 ports: 16 - containerPort: 9999 17 env: 18 - name: REGION 19 value: eu-west-1 Imagine the environment variable REGION defines certain runtime properties of you controller, such as the availability of other service like a managed service mesh. In other words, while the default values eu-west-1 might be a sensible one, users can and likely will overwrite it, based on their own preferences or policies.\nNow, given that the YAML manifest mycontroller.yaml itself is a static file with all values defined at the time of writing \u0026ndash; and clients such as kubectl don\u0026rsquo;t inherently support variable parts in the manifest \u0026ndash; how do you enable users to supply variable values or overwrite existing values at runtime? That is, how in the preceding example can a user set REGION to, say, us-east-2 when they\u0026rsquo;re installing it, using (for example) kubeclt apply?\nTo overcome these limitations of build-time, static YAML manifest in Kubernetes, there are a few options to templatize the manifest (Helm, for example) or otherwise enable variable input (Kustomize), depending on user-provided values or runtime properties.\nHelm Helm, which touts itself as the package manager for Kubernetes, was originally developed by Deis and is now a Cloud Native Computing Foundation(CNCF) project with major contributors form Microsoft, Google, and Bitnami(now pat of VMware).\nHelm helps you to install and upgrade Kubernetes applications by defining and applying so-called charts, effectively parameterized YAML manifests. Here is an excerpt of an example chart template.\n1apiVersion: apps/v1 2kind: Deployment 3metadata: 4 name: {{ include \u0026#34;flagger.fullname\u0026#34; .}} 5... 6spec: 7\treplicas: 1 8\tstrategy: 9\ttype: Recreate 10\tselector: 11\tmatchLabels: 12\tapp.kubernetes.io/name: {{ template \u0026#34;flagger.name\u0026#34; .}} 13\tapp.kubernetes.io/instance: {{ .Release.Name }} 14\ttemplate: 15\tmetadata: 16\tlabels: 17\tapp.kubernetes.io/name: {{ template \u0026#34;flagger.name\u0026#34; .}} 18\tapp.kubernetes.io/instance: {{ .Release.Name }} 19\tsepc: 20\tserviceAccountName: {{ template \u0026#34;flagger.serviceAccountName\u0026#34; .}} 21\tcontainers: 22\t- name: flagger 23\tsecurityContext: 24\treadOnlyRootFileSystem: true 25\trunAsUser: 10001 26\timage: \u0026#34;{{ .Values.image.repository }}:{{ .Values.image.tag }}\u0026#34; 27\tAs you can see, variables are encoded in {{ ._Some.value.here_ }} format, which happens to be Go templates.\nTo install a chart, you can run the helm install command. While Helm has several ways to find and install charts, the easiest is to use on of the official stable charts:\n1# get the latest list of charts 2helm repo update 3 4# install MySQL 5helm install stable/mysql 6 7# list running apps 8helm ls 9 10# remove it 11helm delete \u0026lt;helm name\u0026gt; In order to package you controller, you will need to create a Helm Chart for it and publish it somewhere, by default to a public repository indexed and accessible through the Helm hub.\nHelm is popular, partly because of it ease of use for end users. However, some argue the current Helm architecture introduces security risks. The good news is that the community is actively working on addressing those.\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/kubernetes/k8s_dev_operator_release/","summary":"In this chapter we\u0026rsquo;ll discuss the operational aspects of controllers and operators, showing you how to package them, walking you through best practices for running controllers in production, and making sure that your extension points don\u0026rsquo;t break your Kubernetes cluster, security, or performance-wise.\nLifecycle Management and Packaging Let\u0026rsquo;s start with the low-hanging fruit: packaging and delivering your controllers so that a user can install it in a straightforward manner.\nPackaging: The Challenge While Kubernetes defines resources with manifest, typically written in YAML, a low-level interface to declare the state of resources, these manifest files have shortcoming.","tags":null,"title":"K8s 源码阅读7"},{"categories":null,"contents":"Pod\n在Kubernetes中，一切都是资源，你可以通过create/get/describe/delete 来操作这些资源。\n在操作一种资源之前，我们需要先对这个资源进行定义，在k8s中常用的是yaml配置文件配置。\n1# 00-siample-pod.yaml 2--- 3apiVersion: v1 4kind: Pod 5metadata: 6 name: first-pod 7 labels: 8 app: nginx 9spec: 10 containers: 11 - name: 00-simple-pod-nginx 12 images: nginx:1.17.0 apiVersion：资源的版本，可以理解为你要创建的是 PodV1{}还是PodVn{}\nkind: 资源的类型\nmetadata：\n​\tname： 创建出来的资源的名字\n​ labels：与其他资源粒度或者操作的关联\nspec: 资源的参数\n通过kubectl apply -f创建资源\n1kubectl apply -f 00-simple-pod.yaml 如果需要更新资源，修改yaml后，重新kubectl apply -f xxx.yaml 就可以。\n获取Pod状态\n1kubectl get pod first-pod 2# get more detail 3kubectl get pod first-pod -o wide 4# get all pods of all-namespace 5kubectl get po -A 获取Pod 详情\n1kubectl describe pod first-pod Pod 状态\nPending： K8s已经接受了Pod的配置，但是还没有创建容器，可能还在拉取镜像或者调度不成功 Running：Pod已经调度成功，并且已经和某个node绑定了，所有的容器都被创建 Succeeded: Pod中所有容器都已经成功运行完毕并退出 Failed: Pod中至少有一个容器以不正常的状态退出。 UnKnown: Pod的状态不能被kubelet汇报给kube-apiserver， 这可能是work和master的通讯出现了问题。 Container状态\nWaiting： Default state of container. If container not in Running or Terminated state, it is in Waiting state. A container in Waiting state still runs its required operations, like pulling images, applying secrets, etc. Along with this state, a message and reson about the state are dispalyed to provide more infomation. Running: Indicates that the container is executing without issues. Once a container enters into Running, postStart hook(if any) is executed. This state also displays the time when the container entered Running state. Terminated: Indicates that the container completed its execution and has stoped running. A container enters into this when it has successfully completed execution or when it has failed for some reason. Regardless, a reason and exit code is displayed, as well as the container\u0026rsquo;s start and finish time. Before a container enters into Terminated, preStop hook(if any) is executed. 日志\n1 2# 查看pod日志 3kubectl logs \u0026lt;pod-name\u0026gt; 4# 查看pod中container的日志 5kubectl logs \u0026lt;pod-name\u0026gt; -c \u0026lt;container-name\u0026gt; 每天或者每次日志到达10MB大小时，容器日志都会自动轮替。kubectl logs仅能显示最后一次轮替后的日志条目。 只能获取仍然存在的pod的日志。当一个pod被删除时，他的日志也会被移除。 外地访问pod\n将本地网络端口转发到pod中的端口\n1kubectl port-forward 注解\n向kubernetes 引入新特性时，通常也会使用注解。一般来说，新功能的alpha和beta版本不会向API对象引入任何新字段，因此使用的是注解而不是字段，一旦所有的API变更变得清晰，并且得到所有相关人员的认可，就会引入新的字段，并废弃相关注解。\n大量使用注解可以为每个pod或其他API对象添加说明。以便每个使用该集群的人都可以快速查找有关每个单独对象的信息。\nPod 探针\n三种类型的handler\nExecAction： Executes a specified sommand inside the container. The diagnostic is considered successful if the command exits with a status code of 0. CPSocketAction: Performs a TCP check against the container\u0026rsquo;s IP adress on a specified port. The diagnostic is consider successful if the port is open. TPGetAction: Performs and HTTP GET request against the Container\u0026rsquo;s IP adderess on a specified port and path. The diagnostic is considered successful if the response has a status code grater than or equal to 200 and less than 400. 三种探针结果\nSuccess: The container passed the diagnostic Failure: The container failed the diagnostic Unknown: The diagnostic failed, so no action should be taken. 重启策略\nAlways OnFailure Never ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/cloudnative/Kubernates/2-k8s-pod/","summary":"Pod\n在Kubernetes中，一切都是资源，你可以通过create/get/describe/delete 来操作这些资源。\n在操作一种资源之前，我们需要先对这个资源进行定义，在k8s中常用的是yaml配置文件配置。\n1# 00-siample-pod.yaml 2--- 3apiVersion: v1 4kind: Pod 5metadata: 6 name: first-pod 7 labels: 8 app: nginx 9spec: 10 containers: 11 - name: 00-simple-pod-nginx 12 images: nginx:1.17.0 apiVersion：资源的版本，可以理解为你要创建的是 PodV1{}还是PodVn{}\nkind: 资源的类型\nmetadata：\n​\tname： 创建出来的资源的名字\n​ labels：与其他资源粒度或者操作的关联\nspec: 资源的参数\n通过kubectl apply -f创建资源\n1kubectl apply -f 00-simple-pod.yaml 如果需要更新资源，修改yaml后，重新kubectl apply -f xxx.yaml 就可以。\n获取Pod状态\n1kubectl get pod first-pod 2# get more detail 3kubectl get pod first-pod -o wide 4# get all pods of all-namespace 5kubectl get po -A 获取Pod 详情","tags":null,"title":"Kubenetes Pod"},{"categories":null,"contents":"Controller and Operator In this section you\u0026rsquo;ll learn about controllers and operators in Kubernetes and how they work.\nThe API server has the following core responsibilities:\nTo serve the Kubernetes API. This API is used cluster-internally by the master components, the worker nodes, and you Kubernetes-native apps, as well as externally by clients such as kubectl. To proxy cluster components, such as the Kubernetes dashboard, or stream logs, services ports, or serve kubectl exec sessions. Per the Kubernetes glossary, a controller implements a control loop, watching the shared state of the cluster throught the API Server and making changes in an attempt to move the current state toward the desired state.\nBefor we dive into the controller\u0026rsquo;s inner working, let\u0026rsquo;s define our terminology:\nControllers can act on core resources such as deployments or services, which are typically part of Kubernetes controller manager in the control plane, or can watch and manipulate user-defined custome resources. Operatirs are controllers that encode some opetational knowledge, such as application lifecycle management, along with the custome resources. The Control Loop In general, the control loop looks as follows:\nRead the state of resources, preferably event-driven. Change the state of the objects in the cluster or the cluster-external world. For example, launch a pod, create a network endpoint, or query a cloud API. Update status of the resource in step 1 via the API server in etcd. Repeat cycle; return to step 1. From an architectural point of view, a controller typically uses the following data structures.\nInformers Informers watch the desired state of the resources in a scalable and sustainable fashion. They also implement a resync mechanism that enforces periodic reconciliation, and is often used to make sure that the cluster state and the assumend state cached in memory do not drift (e.g., due bugs or network issues).\nThe API Server The API server is the central management entity and the only component that talks directly with the distributed storage components etcd.\nThe API server has the following core responsibilities :\nTo server the Kubernets API. This API is used cluster-internally by the master components, the work nodes, and you Kubernetes-native apps, as well as externally by clinets such as kubectl. To proxy cluster components, such as the Kubernetes dashboard, or to stream logs, service ports, or serve kubectl exec session. Serving the API means:\nReading state: getting single objects, listing them, and streaming changes Manipulating state: creating, updating, and deleting objects State is persisted via etcd.\nThe HTTP Interface of the API Server From a clinet\u0026rsquo;s perspective, the API service expose a RESTful HTTP API with JSON or protocol buffer(protobuf for short) payload, which is used mainly for cluster-internal communication, for performance reasons.\nThe API server HTTP interface handles HTTP requests to query and manipulate Kubernetes resources using the following HTTP verbs(or HTTP methods).\n1kubectl -n THENAMESPACE get pods 2curl -XGET /api/v1/namespaces/THENAMESPACE/pods API Terminology Before we get into the API business, let\u0026rsquo;s first define the terms used in the context of the Kubernetes API server.\nKind The type of an entity. Each object has a field Kind(lowercase kind in JOSN, capitalized Kind in Golang), which tells a client such as kubectl that it represent, for example, a pod. There are three categories of kinds.\nObjects represent a persistent entity in the system \u0026ndash; for example, Pod or Endpoints. Objects have names, and many of the live in namespaces. Lists are collections of one or more kinds of entities. List have a limit set of common metadata. Examples include PodLists or NodeLists. When you do a kubectl get pods, that\u0026rsquo;s exactly what you get. Special-purpose kinds are used for specific actions on objects and for nonpersistent entities such as /binding or /scale. For discovery, Kubernetes use APIGroup and APIResource; for error results, it use Status. In Kubernetes programs, a kind directly corresponds with a Golang type. Thus, as a Golang type, kinds are singular and begin with a capital letter.\nAPI group A collection of Kinds that are logically related. For example, all batch objects like Job or ScheduledJob are in the batch API group.\nVersion Each API group can exist in multiple versions, and most of them do. For examples, a group first appears as v1alpha1 and is then promoted to v1beta1 and finally graduates to v1. An object created in one version can be retrieved in each of the supported version. The API server does the lossless conversion to return objects in the requested version. From the cluster user\u0026rsquo;s point of view, versions are just different representations of the same objects.\nTIP\nThere is no such thing as \u0026ldquo;on object is in v1 in the cluster, and another object is in v1beta1 in the cluster.\u0026rdquo; Instead, every object can be returned as v1 representation or v1alpha1 representation, as the cluster user desires.\nResource A usually lowercase, plural word(e.g., pods) identifying as a set of HTTP endpoints(paths) exposing the CRUD semantics of a certain object type in the system. Common path are:\nThe root, such as .../pods, which list all instances of that type. A path for individual named resources, such as ..../pods/nginx. Typically, each of this endpoints returns and receives one kind(a PodList in the first case, and a Pod in the second). But in other situations, a Status kind object is returned.\nIn addition to the main resource with full CRUD semantics, a resource can have further endpoints to perform specific actions(e.g., .../pod/nginx/port-forward, ../pod/nginx/exec, or .../pod/nginx/logs). We call these subresources. These usually implement custom protocols instead of REST \u0026ndash; for example, some kind of streaming connections via WebSocket or imperative APIs.\nTIP\nResources and kinds are often mixed up. Note the clear distinction:\nResources correspond to HTTP paths Kind are the type of objects returned by and received by these endpoints, as well as persisted into etcd. Resources are always part of an API group and a version, collectively referred to as GroupVersionResource(or GVR). A GVR unique defines an HTTP path.\nKubernets API Versioning Declarative State Management TIP\nState vs. Status\nState: the particular condition that someone or something is in at a specific time.\nStatus: the situation at a particular time during a process.\nState is used to describe a stage in a process (e.g. pending/dispatched).\nStatus is used to describe an outcome of an operation (e.g. success/fail).\nStatus is a final (resulting) State.\nLet\u0026rsquo;s talk a little more about spec(desired state) versus status(observed state) in the context of the API server.\nHow the API Server Processes the requests API HTTP handler -\u0026gt; authn \u0026amp; authz -\u0026gt; Mutating adminssion -\u0026gt; Object schema validation -\u0026gt; Validating admission -\u0026gt; Presisting to etcd\nSo, what actually happens now when an http requests hits the Kubernetes API? On a high level, the following interactions take place:\nK8s version v1.23.0\nname\nkind\nshortNames\ncategories\nresources\napi/v1 1k get --raw /api/v1 | jq -c \u0026#39;.resources[]|{name,kind,shortNames,categories}\u0026#39; apis/batch 1k get --raw /apis/batch/v1 | jq -c \u0026#39;.resources[]|{name,kind,shortNames,categories}\u0026#39; apis/apps/v1 1k get --raw /apis/apps/v1 | jq -c \u0026#39;.resources[]|{name,kind,shortNames,categories}\u0026#39; deepcopy-gen deepcopy-gen 是一个自动生成DeepCopy函数的代码生成器。给定一个包的目录路径作为输入源，它可以为其生成DeepCopy相关函数，这些函数可以有效的执行每种类型的深复制操作。\nGroups and Versions An API Group in Kubernetes is simply a collection of related functionality. Each group has one or more versions,\nKinds and Resources Each API group-version contains one or more API types, which we call Kinds.\nA resource is simply a use of Kind in the API. Often, there\u0026rsquo;s a one-to-one maping between Kinds and resources. For intance, the pods resource crooesponds to the Pod Kind. However, sometimes, the same Kind may be returned by multiple resources. For instances, the Scale Kind is returned by all scale subresources, like deployments/scale or replicatsets/scale. With CRD, however, each Kind will correspond to a single resource.\nWhen we refer to a kind in a particular group-version, we\u0026rsquo;ll call it a GroupVersionKind, or GVK for short. Same with resources and GVR. As we\u0026rsquo;ll see shortly, each GVK corresponds to a given root Go type in package.\nScheme The Scheme is simply a way to keep track of what Go type corresponds to a given GVK.\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/kubernetes/k8s_dev_2_api_server/","summary":"Controller and Operator In this section you\u0026rsquo;ll learn about controllers and operators in Kubernetes and how they work.\nThe API server has the following core responsibilities:\nTo serve the Kubernetes API. This API is used cluster-internally by the master components, the worker nodes, and you Kubernetes-native apps, as well as externally by clients such as kubectl. To proxy cluster components, such as the Kubernetes dashboard, or stream logs, services ports, or serve kubectl exec sessions.","tags":null,"title":"Kubernetes API Basic"},{"categories":null,"contents":"Kubernetes 1.16 正式GA了CRD。\nCRD介绍 声明式编程 在Kubernetes中我们使用了Deployment/DamenSet/tatefulSet来管理应用workdload，使用Service/Ingress来管理应用的\nhttps://zhuanlan.zhihu.com/p/34445114\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/cloudnative/Kubernates/10-k8s-crd/","summary":"Kubernetes 1.16 正式GA了CRD。\nCRD介绍 声明式编程 在Kubernetes中我们使用了Deployment/DamenSet/tatefulSet来管理应用workdload，使用Service/Ingress来管理应用的\nhttps://zhuanlan.zhihu.com/p/34445114","tags":null,"title":"Kubernetes CRD"},{"categories":null,"contents":"Replication Controller 1# replica.yaml 2--- 3apiVersion: v1 4kind: ReplicationController 5metadata: 6 name: first-replic 7spec: 8 replicas: 3 9 template: 10 metadata: 11 name: simple-pod 12 labels: 13 app: simple-pod 14 spec: 15 containers: 16 - name: timemachine 17 image: lukelau/rest-docker:0.0.1 18 args: 19 - -server.addr=0.0.0.0:8000 以上配置会保证Pod的数量稳定为3个。当我们删除一个Pod之后，Replication Controller就会创建出一个新的Pod来维持Pod的数量。\nRC之所以会发现Pod已经挂掉了，是因为探针(Container probes)的存在。在K8s中， kubelet会通过指定的探针方式去探测容器是否存活。\n三种探针方式\n三种类型的handler\nExecAction： Executes a specified sommand inside the container. The diagnostic is considered successful if the command exits with a status code of 0. CPSocketAction: Performs a TCP check against the container\u0026rsquo;s IP adress on a specified port. The diagnostic is consider successful if the port is open. TPGetAction: Performs and HTTP GET request against the Container\u0026rsquo;s IP adderess on a specified port and path. The diagnostic is considered successful if the response has a status code grater than or equal to 200 and less than 400. 当你的Pod的健康探针探测发现Pod的不健康次数超过设定的次数的时候，那么RC就会将这个有问题的Pod删除(没有restart操作)，然后再创建出一个新的来。RC还会检测Pod的当前数量，如果不足则会创建，如果小于则会关掉一些Pod。\nReplicaSet ReplicaSet 的Selector会比ReplicationController强大一些。\n1--- 2apiVersion: apps/v1 3kind: ReplicaSet 4metadata: 5 name: first-replic-set 6spec: 7 selector: 8 matchLabels: 9 app: simple-pod-set 10 replicas: 3 11 12 template: 13 metadata: 14 name: simple-pod-set 15 labels: 16 app: simple-pod-set 17 spec: 18 containers: 19 - name: timemachine 20 image: lukelau/rest-docker:0.0.1 21 args: 22 - -server.addr=0.0.0.0:8000 selector 变得复杂了，除了matchLabels之外，还支持matchExpressions。\nDeployment已经将内置的replica集从ReplicationController转成ReplicaSet了。\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/cloudnative/Kubernates/4-k8s-replic/","summary":"Replication Controller 1# replica.yaml 2--- 3apiVersion: v1 4kind: ReplicationController 5metadata: 6 name: first-replic 7spec: 8 replicas: 3 9 template: 10 metadata: 11 name: simple-pod 12 labels: 13 app: simple-pod 14 spec: 15 containers: 16 - name: timemachine 17 image: lukelau/rest-docker:0.0.1 18 args: 19 - -server.addr=0.0.0.0:8000 以上配置会保证Pod的数量稳定为3个。当我们删除一个Pod之后，Replication Controller就会创建出一个新的Pod来维持Pod的数量。\nRC之所以会发现Pod已经挂掉了，是因为探针(Container probes)的存在。在K8s中， kubelet会通过指定的探针方式去探测容器是否存活。\n三种探针方式\n三种类型的handler\nExecAction： Executes a specified sommand inside the container. The diagnostic is considered successful if the command exits with a status code of 0.","tags":null,"title":"Kubernetes Replication Controller"},{"categories":null,"contents":"Pod是最小的单元， 往往我们在运行一个应用的时候，对Pod有一些额外的要求，例如高可用或者多实例，这就意味着如果你只记住一个Pod的IP，那么很多时候时有问题的。 例如高可用，可能会因为Pod的重建而改变，这样你记住的那个IP就失效了。一个很自然的想法就是固定IP。\n为什么要使用service\n因为K8s里面的Pod是可以被调度的，并且重建的，所以没有固定的IP Pod的数量可能不只一个，当有多个Pod实例的时候负载均衡的需求。 1# service.yaml 2--- 3apiVersion: v1 4kind: Service 5metadata: 6 name: first-service 7spec: 8 type: NodePort 9 selector: 10 app: nginx 11 ports: 12 - protocol: TCP 13 port: 5580 14 targetPort: 80 15 nodePort: 32280 selector 过滤携带label app=nginx的pod\ntargetPort： pod 提供服务的端口\nservice代理Pod的内部端口为5580： 内部访问，固定IP：Port\nservice代理Pod的外部端口为32280， 通过k8s集群的IP，可以进行 外部可访问\n1# create service 2kubectl apply -f service.yaml 3# get service status 4kubectl get service first-service 外部访问service\n上面这个配置之所以可以在外部访问，是因为制定了Service的Type为NodePort， 在K8s中如果不指定这个Type的话，service时只能在K8s集群内部访问的，集群外部是访问不了的。\n集群外部访问的设置方式：\nNodePort LoadBalancer： 一般只有在共有云上使用 Ingress: 这个不是L4的代理，而是L7的方式。 内部访问service\n对于service的访问， 内部是通过DNS来进行的。也就是说，当你定义了一个service之后，K8s就相应的生成了一条DNS记录。这个service对应的内部域名就是\u0026lt;cluster-name\u0026gt;.\u0026lt;namespace\u0026gt;.svc.cluster.local,在没有贴别制定service类型的时候，他返回的时service的ClusterIP；如果你设置了service的ClusterIP为None， 那么返回的就是所有被代理的Pod的IP地址的集合。\nClusterIP模式的Service提供的是一个Pod的稳定IP地址，即VIP，这里Pod 和service的关系是通过Lab确认的。 Headless Service提供的则是一个Pod稳定的DNS名字，并且这个名字是通过Pod名字和Service名字拼接出来的。 ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/cloudnative/Kubernates/3-k8s-service/","summary":"Pod是最小的单元， 往往我们在运行一个应用的时候，对Pod有一些额外的要求，例如高可用或者多实例，这就意味着如果你只记住一个Pod的IP，那么很多时候时有问题的。 例如高可用，可能会因为Pod的重建而改变，这样你记住的那个IP就失效了。一个很自然的想法就是固定IP。\n为什么要使用service\n因为K8s里面的Pod是可以被调度的，并且重建的，所以没有固定的IP Pod的数量可能不只一个，当有多个Pod实例的时候负载均衡的需求。 1# service.yaml 2--- 3apiVersion: v1 4kind: Service 5metadata: 6 name: first-service 7spec: 8 type: NodePort 9 selector: 10 app: nginx 11 ports: 12 - protocol: TCP 13 port: 5580 14 targetPort: 80 15 nodePort: 32280 selector 过滤携带label app=nginx的pod\ntargetPort： pod 提供服务的端口\nservice代理Pod的内部端口为5580： 内部访问，固定IP：Port\nservice代理Pod的外部端口为32280， 通过k8s集群的IP，可以进行 外部可访问\n1# create service 2kubectl apply -f service.yaml 3# get service status 4kubectl get service first-service 外部访问service\n上面这个配置之所以可以在外部访问，是因为制定了Service的Type为NodePort， 在K8s中如果不指定这个Type的话，service时只能在K8s集群内部访问的，集群外部是访问不了的。","tags":null,"title":"Kubernetes Service"},{"categories":null,"contents":"nc Netcat(or nc) is a command-line utility that reads and write data across network connections, using the TCP or UDP protocols. It is one of the most powerful tools in the network and system administrators arsenal, and it as considered as a Swiss army knife of networking tools.\nNetcat is cross-platform, and it\u0026rsquo;s available for Linux, macOS, Windows , and BSD. You can use Netcat to debug and monitor network connections, scan for open ports, transfer data, as a proxy and more.\nThe Netcat package is pre-installed on macOS and popular Linux distributions like Ubuntu, Debian or CentOS.\nhttps://liugp.blog.csdn.net/article/details/118633171?spm=1001.2101.3001.6650.1\u0026utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1.pc_relevant_paycolumn_v3\u0026depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1.pc_relevant_paycolumn_v3\u0026utm_relevant_index=2\nReference https://linuxize.com/post/netcat-nc-command-with-examples/\ntelnet 命令 测试某个端口是否通\nnc 命令 nc的全名是netcat，其主要用途是建立和监听任意TCP和UDP连接，支持ipv4和ipv6。因此，它可以用来网络调试、端口扫描等等。\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/linux/network_command/","summary":"nc Netcat(or nc) is a command-line utility that reads and write data across network connections, using the TCP or UDP protocols. It is one of the most powerful tools in the network and system administrators arsenal, and it as considered as a Swiss army knife of networking tools.\nNetcat is cross-platform, and it\u0026rsquo;s available for Linux, macOS, Windows , and BSD. You can use Netcat to debug and monitor network connections, scan for open ports, transfer data, as a proxy and more.","tags":null,"title":"Linux Network Command"},{"categories":null,"contents":"Internet domain socket Unix domain socket You can forward the unix domain socket with the -R option of the ssh command.\n1ssh -R remote_socket:local_socket https://github.com/nikhilroxtomar/Multiple-Client-Server-Program-in-C-using-fork\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/linux/linux_socket/","summary":"Internet domain socket Unix domain socket You can forward the unix domain socket with the -R option of the ssh command.\n1ssh -R remote_socket:local_socket https://github.com/nikhilroxtomar/Multiple-Client-Server-Program-in-C-using-fork","tags":null,"title":"Linux socket"},{"categories":null,"contents":"HomeBrew 1/bin/bash -c \u0026#34;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\u0026#34; 1brew install wget 2 3brew install go Software Chrome\nTypora\nIstat Menus\nAlfred\nDash\nWireshark\nSublime\nModify Keys settings -\u0026gt; Keyboard -\u0026gt; modifyKeys\nTools 1apt install vim git tmux golang Vim 1# ~/.vimrc 2cat \u0026lt;\u0026lt;EOF| tee -a ~/.vimrc 3set nu 4syntax on 5inoremap jj \u0026lt;ESC\u0026gt; 6 7 8set fileencodings=utf-8,ucs-bom,gb18030,gbk,gb2312,cp936 9set termencoding=utf-8 10set encoding=utf-8 11 12\u0026#34; show existing tab with 4 spaces width 13set tabstop=4 14\u0026#34; when indenting with \u0026#39;\u0026gt;\u0026#39;, use 4 spaces width 15set shiftwidth=4 16\u0026#34; On pressing tab, insert 4 spaces 17set expandtab 18 19EOF oh my zsh 1sudo apt install zsh 2sh -c \u0026#34;$(wget https://raw.github.com/ohmyzsh/ohmyzsh/master/tools/install.sh -O -)\u0026#34; 3 4# sudo chsh -s $(which zsh) Golang 1sudo apt install golang 2 3echo \u0026#39; 4GOPATH=~/go 5GOBIN=$GOPATH/bin 6PATH=$PATH:$GOBIN 7\u0026#39;| tee -a ~/.zshrc Proxy 1echo \u0026#39;function proxy_on() { 2 export no_proxy=\u0026#34;localhost,127.0.0.1/8,arch,.localdomain.com,10.239.154.51/16\u0026#34; 3 4 local proxy=\u0026#34;http://child-prc.intel.com:913\u0026#34; 5 export http_proxy=\u0026#34;$proxy\u0026#34; \\ 6 https_proxy=$proxy \\ 7 all_proxy=$proxy \\ 8 ftp_proxy=$proxy \\ 9 rsync_proxy=$proxy \\ 10 HTTP_PROXY=$proxy \\ 11 HTTPS_PROXY=$proxy \\ 12 FTP_PROXY=$proxy \\ 13 RSYNC_PROXY=$proxy 14} 15 16function proxy_off(){ 17 unset http_proxy https_proxy all_proxy ftp_proxy rsync_proxy \\ 18 HTTP_PROXY HTTPS_PROXY FTP_PROXY RSYNC_PROXY no_proxy 19 echo -e \u0026#34;Proxy environment variable removed.\u0026#34; 20} 21 22proxy_on\u0026#39; | tee -a ~/.bashrc 23 24EOF 25 26# Install zsh 27cat \u0026lt;\u0026lt;EOF | sudo tee /etc/apt/apt.conf.d/proxy.conf 28Acquire::http::Proxy \u0026#34;http://child-prc.intel.com:913\u0026#34;; 29Acquire::https::Proxy \u0026#34;http://child-prc.intel.com:913\u0026#34;; 30EOF Font hack\nK8s for zsh 1echo \u0026#39;source \u0026lt;(kubectl completion zsh)\u0026#39; \u0026gt;\u0026gt;~/.zshrc 2echo \u0026#39;alias k=kubectl\u0026#39; \u0026gt;\u0026gt;~/.zshrc 3echo \u0026#39;compdef __start_kubectl k\u0026#39; \u0026gt;\u0026gt;~/.zshrc 4source ~/.zshrc NetWork Tools 1brew install iproute2mac ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/blog/Mac_init/","summary":"HomeBrew 1/bin/bash -c \u0026#34;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\u0026#34; 1brew install wget 2 3brew install go Software Chrome\nTypora\nIstat Menus\nAlfred\nDash\nWireshark\nSublime\nModify Keys settings -\u0026gt; Keyboard -\u0026gt; modifyKeys\nTools 1apt install vim git tmux golang Vim 1# ~/.vimrc 2cat \u0026lt;\u0026lt;EOF| tee -a ~/.vimrc 3set nu 4syntax on 5inoremap jj \u0026lt;ESC\u0026gt; 6 7 8set fileencodings=utf-8,ucs-bom,gb18030,gbk,gb2312,cp936 9set termencoding=utf-8 10set encoding=utf-8 11 12\u0026#34; show existing tab with 4 spaces width 13set tabstop=4 14\u0026#34; when indenting with \u0026#39;\u0026gt;\u0026#39;, use 4 spaces width 15set shiftwidth=4 16\u0026#34; On pressing tab, insert 4 spaces 17set expandtab 18 19EOF oh my zsh 1sudo apt install zsh 2sh -c \u0026#34;$(wget https://raw.","tags":null,"title":"Mac Init"},{"categories":null,"contents":"The marker - means ignore the err of this line command\n@ only prints the result of command.\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/linux/linux_make/","summary":"The marker - means ignore the err of this line command\n@ only prints the result of command.","tags":null,"title":"Make"},{"categories":null,"contents":"What is Multi-Clusters Multi-cluster Kubernetes is a kubernetes deployments method that consists of to or more clusters. This deployment method is highly flexible. You can have clusters on the same physical host or different hosts in the same data center. You can also create a multi-cloud environment with clusters living in different clouds and even in different countries.\ncluster network connections: https://submariner.io/getting-started/\nhttps://isovalent.com/data/multi-cluster-ebook.pdf\nMulti clusters server deployment: https://github.com/karmada-io/karmada\nhttps://github.com/clusternet/clusternet\nSubmariner Submariner allows pods to directly communicate between Kubernetes clusters\nSubmariner is secure - it uses establishes IPsec tunnels between clusters\nSubmariner is CNI-agnostic, it operator at a layer independent of you network provider.\nHandling cluseters with overlapping CIDRs Handling overlapping CIDRs is being developd by the submariner team, the implementation is based on a global overlay CIDR which will be used for colliding clusters.\nQuestion Brief introduction of Openshift?Rancher?\nReference:\nUnderstanding Multi-Cluster Kubernetes: Architecture, Benefits, and Challenges\nhttps://www.mirantis.com/cloud-native-concepts/getting-started-with-kubernetes/what-is-kubernetes-multi-cluster/\nhttps://www.cncf.io/blog/2021/04/12/simplifying-multi-clusters-in-kubernetes/\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/blog/multi-cluster/","summary":"What is Multi-Clusters Multi-cluster Kubernetes is a kubernetes deployments method that consists of to or more clusters. This deployment method is highly flexible. You can have clusters on the same physical host or different hosts in the same data center. You can also create a multi-cloud environment with clusters living in different clouds and even in different countries.\ncluster network connections: https://submariner.io/getting-started/\nhttps://isovalent.com/data/multi-cluster-ebook.pdf\nMulti clusters server deployment: https://github.com/karmada-io/karmada\nhttps://github.com/clusternet/clusternet\nSubmariner Submariner allows pods to directly communicate between Kubernetes clusters","tags":null,"title":"Multi-Cluster Kubernetes"},{"categories":null,"contents":"Image ovn4nfv-k8s-plugin NFN-Operator Exposes virtual, provider chaning CRDs to external world Programs OVN to create L2 switch Watches for PODs being coming up Assigns IP address ofr every network of the deployments Looks for replics and auto create routes for chaning to work Create LBs for distributing the load across CNF replicas OVN4NFV NFN-Agent Performs CNI operations Configuration VLAN and Routes in Linux Kernel(in case of ruotes, it cloud do it in both root and network namespace) Communicates with OVSDB to inform og provider interface. ( create ovs bridge and creates external-ids: ovn-bridge-mappings) OVN-Images OVN control plane and OVN controller take care of OVN configuration and installation in each node in Kubernetes. NFN operator runs in the Kubernetes master and NFN agent run as daemonset in each node.\n1# /usr/local/bin/ovn4nfv-k8s.sh OVN-Control-Plane / Deployment： replicas=1 1expose: 6441/ 6442 2 3command: [\u0026#34;ovn4nfv-k8s\u0026#34;, \u0026#34;start_ovn_control_plane\u0026#34;] 4 5Probe: \u0026#34;ovn4nfv-k8s\u0026#34;, \u0026#34;check_ovn_control_plane\u0026#34; OVN-Controller / DaemonSet 1command: \u0026#34;ovn4nfv-k8s\u0026#34;, \u0026#34;start_ovn_controller\u0026#34; 2Probe: \u0026#34;ovn4nfv-k8s\u0026#34;, \u0026#34;check_ovn_controller OVN command\nLibvirt install\n1sudo apt install -y qemu libvirt-bin ebtables dnsmasq-base 2sudo apt install -y libxslt-dev libxml2-dev libvirt-dev zlib1g-dev ruby-dev Open vSwitch ovs-vsctl Configures ovs-vswitchd, but really a high-level interface for database\novsdb-tool: command line for managing database file\novsdb-tool show-log [-mmm] ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/nodus/nodus-architecture/","summary":"Image ovn4nfv-k8s-plugin NFN-Operator Exposes virtual, provider chaning CRDs to external world Programs OVN to create L2 switch Watches for PODs being coming up Assigns IP address ofr every network of the deployments Looks for replics and auto create routes for chaning to work Create LBs for distributing the load across CNF replicas OVN4NFV NFN-Agent Performs CNI operations Configuration VLAN and Routes in Linux Kernel(in case of ruotes, it cloud do it in both root and network namespace) Communicates with OVSDB to inform og provider interface.","tags":null,"title":"Nodus"},{"categories":null,"contents":"SFC for IPV6 vagrant file updte:\nmount a local file to the VM\n1config.vm.synced_folder \u0026#34;/home/ubuntu/qiang/nodus-1.24/SDEWAN-SetUp/\u0026#34;, \u0026#34;/home/vagrant/mnt\u0026#34; vagrant version update to 2.2.19\n1vagrant_version=2.2.19 enable ipv4_forward in calico configuration\nupdate ovn deploy yaml: update image tag, update ovn_subnet\n1 OVN_SUBNET: \u0026#34;10.154.141.0/18\u0026#34; 2OVN_GATEWAYIP: \u0026#34;10.154.141.1/18\u0026#34; 3 4 5 privileged: true 6 mountPropagation: Bidirectional 1apiVersion: k8s.plugin.opnfv.org/v1alpha1 2kind: NetworkChaining 3metadata: 4 name: example-networkchaining 5spec: 6 # Add fields here 7 chainType: \u0026#34;Routing\u0026#34; 8 routingSpec: 9 namespace: \u0026#34;default\u0026#34; 10 networkChain: \u0026#34;net=virtual-net1,app=slb,net=dync-net1,app=ngfw,net=dync-net2,app=sdewan,net=virtual-net2\u0026#34; 11 left: 12 - networkName: \u0026#34;left-pnetwork\u0026#34; 13 gatewayIp: \u0026#34;172.30.10.2\u0026#34; 14 subnet: \u0026#34;172.30.10.0/24\u0026#34; 15 podSelector: 16 matchLabels: 17 sfc: head 18 namespaceSelector: 19 matchLabels: 20 sfc: head 21 right: 22 - networkName: \u0026#34;right-pnetwork\u0026#34; 23 gatewayIp: \u0026#34;172.30.20.2\u0026#34; 24 subnet: \u0026#34;172.30.20.0/24\u0026#34; 25 podSelector: 26 matchLabels: 27 sfc: tail 28 namespaceSelector: 29 matchLabels: 30 sfc: tail Question:\nWhat the relationship between the life/right and NetworkChaining feild?\nWhy we can have multiple left/right?\nIn the ValidateNetworkingChaining I fount the network namespce is hard code to default, is that means all of the Virtual Network should be define in default namespace?\nDoese and the networkChain feild must start and end with a VirtualNetwork. Do you have a topolody of the ProvideNetwork and VirtualNetwork?\nProvidedNetwork must combine with a host network interface.\nVirtual is just a OVN virtual switch?\nSFC : VirtualMode and ProviderMode\nas long as there is one end is not VirtualNetwork, this is ProviderMode.\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/nodus/nodus-dev/","summary":"SFC for IPV6 vagrant file updte:\nmount a local file to the VM\n1config.vm.synced_folder \u0026#34;/home/ubuntu/qiang/nodus-1.24/SDEWAN-SetUp/\u0026#34;, \u0026#34;/home/vagrant/mnt\u0026#34; vagrant version update to 2.2.19\n1vagrant_version=2.2.19 enable ipv4_forward in calico configuration\nupdate ovn deploy yaml: update image tag, update ovn_subnet\n1 OVN_SUBNET: \u0026#34;10.154.141.0/18\u0026#34; 2OVN_GATEWAYIP: \u0026#34;10.154.141.1/18\u0026#34; 3 4 5 privileged: true 6 mountPropagation: Bidirectional 1apiVersion: k8s.plugin.opnfv.org/v1alpha1 2kind: NetworkChaining 3metadata: 4 name: example-networkchaining 5spec: 6 # Add fields here 7 chainType: \u0026#34;Routing\u0026#34; 8 routingSpec: 9 namespace: \u0026#34;default\u0026#34; 10 networkChain: \u0026#34;net=virtual-net1,app=slb,net=dync-net1,app=ngfw,net=dync-net2,app=sdewan,net=virtual-net2\u0026#34; 11 left: 12 - networkName: \u0026#34;left-pnetwork\u0026#34; 13 gatewayIp: \u0026#34;172.","tags":null,"title":"Nodus Dev Note"},{"categories":null,"contents":"Home Page: https://wiki.ith.intel.com/display/ITSODMS/Observability+Data+Management+Suite+Home\n[TOC]\nOperator Prometheus-operator https://prometheus-operator.dev/\nhttps://github.com/prometheus-operator/prometheus-operator\nThe prometheus operator manages the Promentheus Clust atop Kubernetes.\nOpentelemetry-operator https://github.com/open-telemetry/opentelemetry-operator\nKubernetes reflector https://github.com/emberstack/kubernetes-reflector\nReflector is a Kubernetes addon designed to monitor changes to resources (secrets and configmaps) and reflect changes to mirror resources in the same or other namespaces.\nOpenTelemetry Agent \u0026amp; Gateway Configure by CR opentelemetrycollectors.opentelemetry.io\nAgent collect Metric, Logs, and can add labels or attributes, and finally push the data to the opentelemetry gateway.\nGateway receive the data from all of the Agent, and store the data to prometheus, jaeger and elasticsearch.\nMetrics Jaeger Metrics Exporter Telegraf\ncAdvisor\neBPF-exporter\nIPMI-exporter\nEMON-exporter\nOpenTelemetry-Collector\nPrometheus Service Discovery prometheus discovery metrics api by CR servicemonitors.monitoring.coreos.com.\nFor kubernetes components metrics, add servicemonitor by kube-prometheus-stack.\n1NAMESPACE NAME AGE 2default odms-grafana 2d19h 3default odms-kube-prometheus-alertmanager 2d19h # kube-prometheus-stack 4default odms-kube-prometheus-apiserver 2d19h # kube-prometheus-stack 5default odms-kube-prometheus-coredns 2d19h # kube-prometheus-stack 6default odms-kube-prometheus-kube-controller-manager 2d19h # kube-prometheus-stack 7default odms-kube-prometheus-kube-etcd 2d19h # kube-prometheus-stack 8default odms-kube-prometheus-kube-proxy 2d19h # kube-prometheus-stack 9default odms-kube-prometheus-kube-scheduler 2d19h # kube-prometheus-stack 10default odms-kube-prometheus-kubelet 2d19h # kube-prometheus-stack 11default odms-kube-prometheus-prometheus 2d19h # kube-prometheus-stack 12default odms-kube-state-metrics 2d19h 13default odms-otel-gateway-monitor 2d19h # Metrics for otel 14default odms-prometheus-node-exporter 2d19h 15odms-operators odms-kube-prometheus-operator 17d # kube-prometheus-stack Grafana Configure DataResource 1kind: ConfigMap 2metadata: 3 labels: 4 app: odms-otel-grafana 5 grafana_datasource: \u0026#34;1\u0026#34; # label for grafane, who is the operator? 6 name: odms-otel-grafana-datasource 7 namespace: default 8apiVersion: v1 9data: 10 datasource.yaml: |- 11 apiVersion: 1 12 datasources: 13 - name: \u0026#34;Prometheus\u0026#34; Configure DashBoard 1apiVersion: v1 2kind: ConfigMap 3metadata: 4 labels: 5 grafana_dashboard: \u0026#34;1\u0026#34; # label for grafane, who is the operator? 6 name: odms-dashboards 7 namespace: default 8data: 9\tCPU.json: |- 10\t# dashboard json configuration NFS Where is the grafana dashboras configuration? Where is the data resource of Metrics, Log \u0026amp; Trace? Reference How to install and configure an NFS server on Ubuntu\nNFS external provisioner\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/sdewan/odms-install/","summary":"Home Page: https://wiki.ith.intel.com/display/ITSODMS/Observability+Data+Management+Suite+Home\n[TOC]\nOperator Prometheus-operator https://prometheus-operator.dev/\nhttps://github.com/prometheus-operator/prometheus-operator\nThe prometheus operator manages the Promentheus Clust atop Kubernetes.\nOpentelemetry-operator https://github.com/open-telemetry/opentelemetry-operator\nKubernetes reflector https://github.com/emberstack/kubernetes-reflector\nReflector is a Kubernetes addon designed to monitor changes to resources (secrets and configmaps) and reflect changes to mirror resources in the same or other namespaces.\nOpenTelemetry Agent \u0026amp; Gateway Configure by CR opentelemetrycollectors.opentelemetry.io\nAgent collect Metric, Logs, and can add labels or attributes, and finally push the data to the opentelemetry gateway.","tags":null,"title":"ODMS Install"},{"categories":null,"contents":"Configuration Server side Server.conf\n1# /etc/openvpn/server/server.conf 2local 10.0.0.230 3port 1194 4proto udp 5dev tun 6ca ca.crt 7cert server.crt 8key server.key 9dh dh.pem 10auth SHA512 11tls-crypt tc.key 12topology subnet 13client-config-dir /etc/openvpn/ccd # bind ip with client name 14route 192.166.0.0 255.255.255.0 # route add to server side 15push \u0026#34;route 192.167.0.0 255.255.255.0\u0026#34; # route add to client side 16server 10.8.0.0 255.255.255.0 17push \u0026#34;redirect-gateway def1 bypass-dhcp\u0026#34; 18ifconfig-pool-persist ipp.txt 19push \u0026#34;dhcp-option DNS 10.0.0.1\u0026#34; 20keepalive 10 120 21cipher AES-256-CBC 22user nobody 23group nogroup 24persist-key 25persist-tun 26verb 4 # log level, 1-11, bigger more details 27crl-verify crl.pem 28explicit-exit-notify Ccd configuration\nCcd configuration locate at /etc/openvpn/ccd. Every cluster has a configuration file named by client name.\n1# /etc/openvpn/ccr/node-1 2ifconfig-push 10.8.0.2 255.255.255.0 3iroute 192.166.0.0 255.255.255.0 Service Mangement\n1# server 2systemctl status openvpn-server@server.service 3# client 4systemctl stop openvpn@client.service Client side Client.conf\n1# /etc/openvpn/client.conf NAT rule on the Pop 1# If the sever side want to access the client side private network, you shoule add NAT rule on the client side 2# ip is the VPN vip range 3sudo iptables -t nat -A POSTROUTING -s 10.8.0.0/24 -o ens160 -j MASQUERADE 4# ip is the server side ip 5sudo iptables -t nat -A POSTROUTING -s 10.0.12.0/24 -o ens160 -j MASQUERADE 6# vi /etc/sysctl.conf 7# net.ipv4.ip_forward = 1 8sudo sysctl -p 9 10 11sudo nginx -s reload https://www.cyberciti.biz/faq/ubuntu-20-04-lts-set-up-openvpn-server-in-5-minutes/\nhttps://github.com/Nyr/openvpn-install/blob/master/openvpn-install.sh\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/linux/network_openvpn/","summary":"Configuration Server side Server.conf\n1# /etc/openvpn/server/server.conf 2local 10.0.0.230 3port 1194 4proto udp 5dev tun 6ca ca.crt 7cert server.crt 8key server.key 9dh dh.pem 10auth SHA512 11tls-crypt tc.key 12topology subnet 13client-config-dir /etc/openvpn/ccd # bind ip with client name 14route 192.166.0.0 255.255.255.0 # route add to server side 15push \u0026#34;route 192.167.0.0 255.255.255.0\u0026#34; # route add to client side 16server 10.8.0.0 255.255.255.0 17push \u0026#34;redirect-gateway def1 bypass-dhcp\u0026#34; 18ifconfig-pool-persist ipp.txt 19push \u0026#34;dhcp-option DNS 10.0.0.1\u0026#34; 20keepalive 10 120 21cipher AES-256-CBC 22user nobody 23group nogroup 24persist-key 25persist-tun 26verb 4 # log level, 1-11, bigger more details 27crl-verify crl.","tags":null,"title":"OpenVPN Setup"},{"categories":null,"contents":"What is the maximum size of the stack?\nIt depends on your operating system. On Windows, the typical maximum size for a stack is 1MB, whereas it is 8MB on a typical modern Linux, although those values are adjustable in various ways. If the sum of your stack variables (including low-level overhead such as return addresses, stack-based arguments, return value placeholders, and alignment bytes) in the entire call stack exceeds that limit, you get a stack overflow, which typically takes down your program without any chance at recovery.\nA few kilobytes are usually fine. Tens of kilobytes are dangerous because it starts to sum up. Hundreds of kilobytes is a horrible idea.\nCheck the default size of the Linux\n1ulimit -s 1#include \u0026lt;stdio.h\u0026gt; 2int main() { 3 int b[100]; // store in stack 4 static int a[10000000]; // if the size exceed the stack size, it need to store in heap 5 return 1; 6} 栈是向低地址扩展的数据结构，是一块连续的内存区域。栈顶的地址和栈的最大容量是系统预先规定好的。在Windows栈的大小是1M，如果申请的空间超过栈的剩余空间时就会提示overflow。从栈能获取的空间较小。\n堆是向高地址扩展的，是不连续的内存区域。这是由于系统是使用链表来存储空闲内存地址的，自然不是连续的。而链表的遍历是从低地址到高地址。堆的大小受限于计算机系统中有效的虚拟内存。\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/blog/os_memory/","summary":"What is the maximum size of the stack?\nIt depends on your operating system. On Windows, the typical maximum size for a stack is 1MB, whereas it is 8MB on a typical modern Linux, although those values are adjustable in various ways. If the sum of your stack variables (including low-level overhead such as return addresses, stack-based arguments, return value placeholders, and alignment bytes) in the entire call stack exceeds that limit, you get a stack overflow, which typically takes down your program without any chance at recovery.","tags":null,"title":"OS memory"},{"categories":null,"contents":"Open Virtual Network\nOVN(Open Virtual Network) is a series of daemons for the Open vSwitch that translate virtual network configuration into OpenFlow.\nOVN provides a higher-layer of abstraction than Open vSwitch, working with logical routers and logical switches, rather than flows.\nWhy did we choose OVN for Nodus?\nOne of the best programmable controller\nHides OVS complexity\nBroader eco-system\nL2 CNI - Support for unicast, multicast, broadcast applications\nOne site level IPAM - No IP address restriction with number of nodes\nPossible to implement critical features with table-based pipline\n(Firewall, Routing, Switching, Load balancing, Network Policy)\nSmartNIC( Smart Network Interface Card) friendly\nNodus Architecture blocks NFN Operator\nExpose virtual, provider, chaining CRDs to external world Programs OVN to create L2 switches. Watch for PODs being coming up Assigns IP address for every network of the deployment Looks for replicas and auto create routes for chaining to work Create LBs for distributing the load across CNF replicas NFN Agent\nPerforms CNI operations Configures VLAN and Routes in linux kernel(in case of routes, it cloud do it both root and network namespace ) Communicates with OVSDB to inform of provider interface.(create ovs bridge and creates external-ids:ovn-bridge-mappings) 07/20 meeting minutes\nKural addressed the Qiang queries related to the CNI and architectural diagram.\nKural gave the following pointer to understand the CNI and CNI code\nhttps://www.dasblinkenlichten.com/understanding-cni-container-networking-interface/ https://github.com/containernetworking/plugins/blob/main/plugins/main/bridge/bridge.go AR\nFor Qiang and Jiahao\nhttps://github.com/akraino-edge-stack/icn-nodus/tree/master/demo/calico-nodus-secondary-sfc-setup\nChange the vagrant version to 2.2.19 in the line number https://github.com/akraino-edge-stack/icn-nodus/blob/master/demo/calico-nodus-secondary-sfc-setup/setup.sh#L14 and bring up the demo\nOVS and OVN ramp up\nOVS deep dive - https://www.youtube.com/watch?v=x-F9bDRxjAM\u0026ab_channel=OpenInfrastructureFoundation OVN deep dive - https://docs.ovn.org/en/latest/tutorials/ovn-sandbox.html \u0026amp; video - https://www.youtube.com/watch?v=okralc7LrZo\u0026ab_channel=OpenInfrastructureFoundation Please run the ovs-vsctl command in the ovn-controller pod and ovn-nbctl command in the ovn-control-plane pod to understand the flow\nKural’s presentation on the Nodus - https://www.youtube.com/watch?v=hGiOHIkxaoQ\u0026t=3s\u0026ab_channel=OpenvSwitch\nQuick start on understanding the Kubernetes operator framework - https://sdk.operatorframework.io/docs/building-operators/golang/quickstart/\nFor Kural\nGet the login for OPNFV lab and LF Edge lab login for Qiang and Jiahao. OVN Demo Function defination 1# ADD_BR() 2ovs-vsctl add-br br-int-1 3# ADD_NAMESPACES(foo1) 4ip netns add foo1 5# NS_EXEC([namespace],[command]) 6ip netns exec foo1 ip link 7# ADD_VETH(foo1, foo1, br-int, \u0026#34;192.168.1.2/24\u0026#34;,\u0026#34;f0:00:00:01:02:03\u0026#34;, 8# \u0026#34;192.168.1.1\u0026#34;) 9# ADD_VETH([port],[namespace],[ovs-br],[ip_addr],[mac_addr],[gateway], 10# [ip_addr_flags]) 11 12 13ip link add $1 type veth peer name ovs-$1 14ip link set $1 netns $2 15ip link set dev ovs-$1 up 16ovs-vsctl add-port $3 ovs-$1 -- \\ 17set interface ovs-$1 external-ids:iface-id=\u0026#34;$1\u0026#34; 18 19ip netns exec $2 ip addr add $4 dev $1 $7 20ip netns exec $2 ip link set dev $1 up 21ip netns exec $2 ip link set dev $1 address $5 22ip netns exec $2 ip route add default via $6 23 24ip link del ovs-foo1 Setup Demo\n1function ADD_NAMESPACES(){ 2 ip netns add $1 3} 4 5 6function ADD_VETH(){ 7set -x 8 9ip link add $1 type veth peer name ovs-$1 10ip link set $1 netns $2 11ip link set dev ovs-$1 up 12ovs-vsctl add-port $3 ovs-$1 -- \\ 13set interface ovs-$1 external-ids:iface-id=\u0026#34;$1\u0026#34; 14 15ip netns exec $2 ip addr add $4 dev $1 $7 16ip netns exec $2 ip link set dev $1 up 17ip netns exec $2 ip link set dev $1 address $5 18ip netns exec $2 ip route add default via $6 19} 20 21ovs-vsctl add-br br-int-1 22ovn-nbctl create Logical_Router name=R1 23ovn-nbctl create Logical_Router name=R2 options:chassis=hv1 24 25ovn-nbctl ls-add foo 26ovn-nbctl ls-add bar 27ovn-nbctl ls-add alice 28ovn-nbctl ls-add join 29 30# Connect foo to R1 31ovn-nbctl lrp-add R1 foo 00:00:01:01:02:03 192.168.1.1/24 32ovn-nbctl lsp-add foo rp-foo -- set Logical_Switch_Port rp-foo \\ 33 type=router options:router-port=foo addresses=\u0026#39;\u0026#34;00:00:01:01:02:03\u0026#34;\u0026#39; 34 35# Connect bar to R1 36ovn-nbctl lrp-add R1 bar 00:00:01:01:02:04 192.168.2.1/24 37ovn-nbctl lsp-add bar rp-bar -- set Logical_Switch_Port rp-bar \\ 38 type=router options:router-port=bar addresses=\u0026#39;\u0026#34;00:00:01:01:02:04\u0026#34;\u0026#39; 39 40# Connect alice to R2 41ovn-nbctl lrp-add R2 alice 00:00:02:01:02:03 172.16.1.1/24 42ovn-nbctl lsp-add alice rp-alice -- set Logical_Switch_Port rp-alice \\ 43 type=router options:router-port=alice addresses=\u0026#39;\u0026#34;00:00:02:01:02:03\u0026#34;\u0026#39; 44 45# Connect R1 to join 46ovn-nbctl lrp-add R1 R1_join 00:00:04:01:02:03 20.0.0.1/24 47ovn-nbctl lsp-add join r1-join -- set Logical_Switch_Port r1-join \\ 48 type=router options:router-port=R1_join addresses=\u0026#39;\u0026#34;00:00:04:01:02:03\u0026#34;\u0026#39; 49 50# Connect R2 to join 51ovn-nbctl lrp-add R2 R2_join 00:00:04:01:02:04 20.0.0.2/24 52ovn-nbctl lsp-add join r2-join -- set Logical_Switch_Port r2-join \\ 53 type=router options:router-port=R2_join addresses=\u0026#39;\u0026#34;00:00:04:01:02:04\u0026#34;\u0026#39; 54 55# Static routes. 56ovn-nbctl lr-route-add R1 172.16.1.0/24 20.0.0.2 57ovn-nbctl lr-route-add R2 192.168.0.0/16 20.0.0.1 58 59 60 61ADD_NAMESPACES foo1 62ADD_VETH foo1 foo1 br-int-1 \u0026#34;192.168.1.2/24\u0026#34; \u0026#34;f0:00:00:01:02:03\u0026#34; \u0026#34;192.168.1.1\u0026#34; 63ovn-nbctl lsp-add foo foo1 -- lsp-set-addresses foo1 \u0026#34;f0:00:00:01:02:03 192.168.1.2\u0026#34; 64ADD_NAMESPACES alice1 65ADD_VETH alice1 alice1 br-int-1 \u0026#34;172.16.1.2/24\u0026#34; \u0026#34;f0:00:00:01:02:04\u0026#34; \u0026#34;172.16.1.1\u0026#34; 66ovn-nbctl lsp-add alice alice1 -- lsp-set-addresses alice1 \u0026#34;f0:00:00:01:02:04 172.16.1.2\u0026#34; 67ADD_NAMESPACES bar1 68ADD_VETH bar1 bar1 br-int-1 \u0026#34;192.168.2.2/24\u0026#34; \u0026#34;f0:00:00:01:02:05\u0026#34; \u0026#34;192.168.2.1\u0026#34; 69ovn-nbctl lsp-add bar bar1 -- lsp-set-addresses bar1 \u0026#34;f0:00:00:01:02:05 192.168.2.2\u0026#34; 1# destroy the env 2ip netns del foo1 3ip netns del bar1 4ip netns del alice1 5ovn-nbctl lr-del R1 6ovn-nbctl lr-del R2 7ovn-nbctl ls-del foo 8ovn-nbctl ls-del bar 9ovn-nbctl ls-del alice 10ovn-nbctl ls-del join 11ovs-vsctl del-br br-int-1 OVS demo 1# Create 2 VRFs(namespasce) VRF1 and VRF2 2ip netns add VRF1 3ip netns add VRF2 4ip netns list 5# Create virtual ethernet port vEth1 and vEth2 and connect them to eatch other 6ip link add veth1 type veth peer name veth2 7# Create virtual ethernet port vEth3 and vEth4 and connect them to each other 8ip link add veth3 type veth peer name veth4 9# Move vEth1 to VRF1 10ip link set veth1 netns VRF1 11# Move vEth3 to VRF2 12ip link set veth3 netns VRF2 13# Assign IP addresses to vEth 14# ip netns exec VRF1 ifconfig veth1 10.10.10.1/24 up 15ip netns exec VRF1 ip addr add 10.10.10.1/24 dev veth1 16ip netns exec VRF1 ip link set veth1 up 17# ip netns exec VRF1 ifconfig 18ip netns exec VRF1 ip a 19# ip netns exec VRF2 ifconfig veth3 10.10.10.2/24 up 20ip netns exec VRF2 ip addr add 10.10.10.2/24 dev veth3 21ip netns exec VRF2 ip link set veth3 up 22ip netns exec VRF2 ip a 23 24# Create vSwitch1 25ovs-vsctl add-br vSwitch1 26# Assign vEth2 and vEth4 to vSwitch1 27ovs-vsctl add-port vSwitch1 veth2 28ovs-vsctl add-port vSwitch1 veth4 29 30ip link set veth2 up 31ip link set veth4 up 32# Test connectivity 33ip netns exec VRF1 ping -c 3 10.10.10.2 34ip addr add 10.10.10.3/24 dev vSwitch1 35ping -c 3 10.10.10.1 36ping -c 3 10.10.10.2 37# Enable Spanning Tree of vSwith1 38ovs-ctl set bridge vSwitch1 stp_enable=true 39# the port from listening to forwarding, it can work to receive packet 40ovsdb-client dump 41# ovs-ctl set bridge vSwitch1 stp_enable=false 42# ovsdb-client dump 43 44 45# Assign IP address to SVI(Bridge Interface,switch virtual interface) of vSwitch1 46 47# Check the MAC address table of vSwitch1 48ovs-appctl fdb/show vSwitch1 Reference [7/15 10:33 AM] Ramakrishnan, Kuralamudhan https://www.dasblinkenlichten.com/understanding-cni-container-networking-interface/ [7/15 10:36 AM] Ramakrishnan, Kuralamudhan https://github.com/containernetworking/cni/blob/main/SPEC.md [7/15 10:36 AM] Ramakrishnan, Kuralamudhan https://github.com/containernetworking/plugins/tree/main/plugins/main/bridge [7/15 10:37 AM] Ramakrishnan, Kuralamudhan https://github.com/containernetworking/plugins/blob/main/plugins/main/bridge/bridge.go\n[9:13 AM] Ramakrishnan, Kuralamudhan https://github.com/ovn-org/ovn/blob/main/tests/system-ovn.at [9:14 AM] Ramakrishnan, Kuralamudhan https://github.com/ovn-org/ovn/blob/main/tests/system-ovn.at#L24 [9:16 AM] Ramakrishnan, Kuralamudhan https://github.com/ovn-org/ovn/blob/main/tests/system-ovn.at#L612 [9:18 AM] Ramakrishnan, Kuralamudhan https://man7.org/linux/man-pages/man8/ovn-trace.8.html [9:27 AM] 9:27 AM Meeting ended: 52m 22s Please read my blog on the future work - https://medium.com/@rkamudhan/service-function-chaining-in-kubernetes-using-squid-proxy-for-sase-providers-7c477a76893e like 1\nTill now, I have a rough understanding of the OVS and the OVN usage, Instead of the OVN sandbox, I try the common OVS and OVN command in the ovn-controller pod to construct a network.\nBecause I failed to set up the OVN sandbox environment, I don\u0026rsquo;t know if should I run the OVS first and then set up the ovn sand-box environment.\nAnd last Friday, the Poland colleague introduced the recent work they did about the nodus, the main focus on the recent pr on the ICN gerrit.\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/nodus/ovn/","summary":"Open Virtual Network\nOVN(Open Virtual Network) is a series of daemons for the Open vSwitch that translate virtual network configuration into OpenFlow.\nOVN provides a higher-layer of abstraction than Open vSwitch, working with logical routers and logical switches, rather than flows.\nWhy did we choose OVN for Nodus?\nOne of the best programmable controller\nHides OVS complexity\nBroader eco-system\nL2 CNI - Support for unicast, multicast, broadcast applications\nOne site level IPAM - No IP address restriction with number of nodes","tags":null,"title":"OVN Open virtual Network"},{"categories":null,"contents":"Linux Performance Counter Hardware Event CPU\nPerformance Monitor Unit\nInstruction retired Processor clock cycles Cache\nSoftware Event Software counter/tracepoint\nPage fault process context Tracepints is the hook in the Linux kernel. 在特定代码执行的时候会被触发。\n1ls /sys/kernel/debug/tracing/events ![image-20221201151615697](/Users/airren/Library/Application Support/typora-user-images/image-20221201151615697.png)\nIf the machine not a baremetal, it can\u0026rsquo;t collect hardware event. For example in a esxi VM.\nRequest\nLLC-load-misses Instructions Cycles The ODMS containes now:\nDashboard consists of 12 panels based on following metrics:\nCore: utilization (%) frequency (GHz) CPI (cycle per instruction) L2 MPI (count per instruction) DRAM BW (MB/sec) LLC MPI (count per instruction) TMAM Branch Mispredictspercent (%) TMAM L1 Boundpercent (%) Uncore: LLC MPI (count per instruction) memory bandwidth total (MB/sec) memory bandwidth read (MB/sec) memory bandwidth write (MB/sec) What is PMU？\nPerformance monitor Unit\nLLC-load-misses The number of LLC-load-misses should be interpreted as the numver of loads that miss in the last level cache(typically the L3 for modern Intel chips) over the interval measures.\nAt the level this is measured, I believe loads going to the same cache line have already been \u0026ldquo;combined\u0026rdquo; by the line fill buffers: if you access several values all the same cache line which isn\u0026rsquo;t presented in the LLC, these all \u0026ldquo;miss\u0026rdquo; from the point of view of your process (the use of any of those values will wait for the full miss duration), but I believe this is only counted as one miss for the LLC-load-misses counter.\nInstructions instructions: IPC instructions per cycyle.\nbanches:\nBranch-misses:\nCycles Perf Install 1# ubuntu 2sudo apt install -y linux-tools-$( uname -a |awk \u0026#39;{print $3}\u0026#39;) 基于性能分析，可以进行算法优化（空间复杂度和时间复杂度权衡）、代码优化（提高执行速度、减少内存占用）。\n评估程序对硬件资源的使用情况，例如各级cache的访问次数、各级cache的丢失次数、流水线停顿周期、前端总线访问次数等。\n评估程序对操作系统资源的使用情况，系统调用次数、上下文切换次数、任务迁移次数。\n事件可以分为三种：\nHardware Event由PMU部件产生，在特定的条件下探测性能事件是否发生以及发生的次数。比如cache命中。 Software Event是内核产生的事件，分布在各个功能模块中，统计和操作系统相关性能事件。比如进程切换，tick数等。 Tracepoint Event是内核中静态tracepoint所触发的事件，这些tracepoint用来判断程序运行期间内核的行为细节，比如slab分配器的分配次数等。 perf stat perf stat: 执行某个命令，收集特定进程的性能概况，包括CPI，Cache丢失率。可以对某一个进程进行全局的性能统计。\nperf top: 类似于linux的top命令，对系统性能进行实时分析，可以实时查看当前系统\nperf stat 用于运行指令，并分析其统计结果。虽然perf top也可以指定pid，但是需要先启动应用才能查看信息，而perf stat则可以直接用来启动程序。\nperf stat 能完整统计应用程序整个声明周期的信息。\n1perf stat [-e \u0026lt;EVENT\u0026gt; | --event=EVENT ] [-a] \u0026lt;command\u0026gt; cpu-clock 任务真正占用处理器的时间，单位ms， CPU utilized = task-clock/time elapsed\ncontext-switch: 程序运行过程中上下文的切换次数\ncpu-migrations: 程序再运行过程中发生的处理器迁移次数。Linux为了维持多个处理器的负载均衡，会在特定条件下将某任务从一个CPU迁移到另一个CPU。 发生上下文切换不一定会发生cpu迁移，而发生CPU迁移时肯定会发生上下文切换。发生上下文切换有可能只是把上下文从当前cpu换出，下一次调度器还是讲进程安排在这个cpu上执行。\npage-faults:缺页异常的次数。当应用程序请求的页面尚未建立、请求的页面不在内存中。或者请求的页面虽然在内存中，但是物理地址和虚拟地址的映射关系未建立时，都会触发一次缺页中断异常。另外TLB不命中，页面访问权限不匹配等情况也会触发缺页异常。\ncpu-cycles: 消耗的处理周期数 主频 = cycles/task-clock\ninstructions: 执行了多少条指令 IPC(instructions per cycle) 平均每个cpu cycle指定了多指令\nbranches: 遇到的分支指令数\nbranches-misses : 预测错误的分支指令数\nDemo 以下示例程序perf_test.c. longa()是一个很长的循环\n1void longa() 2{ 3\tint i,j; 4\t5\tfor(i = 0; i \u0026lt; 1000000; i++) 6\tj=i; //am I silly or crazy? I feel boring and desperate. 7} 8 9void foo1() 10{ 11\tint i; 12\t13\tfor(i = 0; i\u0026lt; 100; i++) 14\tlonga(); 15} 16 17void foo2() 18{ 19\tint i; 20\t21\tfor(i=0 ; i \u0026lt; 10; i++) 22\tlonga(); 23} 24 25 26int main(int argc, char *argv[]) 27{ 28\tfoo1(); 29\tfoo2(); 30\t31\treturn 0x0; 32} 执行下面的命令进行编译\n1gcc -g -o perf_test perf_test.c 使用perf stat 剖析这个程序\n1perf stat ./perf_test 从测试结果可以看出是cpu bound型，以为task-clock-msecs接近1\n有些程序慢是因为计算量太大，其多数时间都在使用CPU进行计算，这叫做CPU bound型。有些程序慢是因为IO过多，这种时候其CPU利用率应该不高，这叫做IO bound型。\nperf stat 更多统计项目\nPerf stat 默认情况下只统计部分项目，如果想要统计更多的项目可以使用-e参数指定\n1 2# sudo perf stat -e task-clock,context-switches,cpu-migrations,page-faults,cycles,stalled-cycles-frontend,stalled-cycles-backend, \\ 3instructions,branches,branch-misses,L1-dcache-loads,L1-dcache-load-misses,LLC-loads,LLC-load-misses,dTLB-loads,dTLB-load-misses ls perf record/report perf record 记录单个函数级别的统计信息，并使用 perf report 来显示统计结果。\n我们的调优应当将注意力集中到百分比比较高的热点代码片段上。\n1perf record -e cpu-clock ./perf_test 2// 默认导出的文件名为 perf.data, 也可以使用-o选项来指定导出的文件 使用perf report来分析\n1perf report -i ./perf.data 使用 perf record的-g选项可以获得更加详细的信息\n1perf record -e cpu-clock -g ./perf_test Epoll\nReference https://ivanzz1001.github.io/records/post/linuxops/2017/11/16/linux-perf-usge !!!!! Important\nhttps://www.cnblogs.com/arnoldlu/p/6241297.html\nhttps://developer.aliyun.com/article/65255#slide-21\nhttps://zhuanlan.zhihu.com/p/141694060\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/linux/linux_perf/","summary":"Linux Performance Counter Hardware Event CPU\nPerformance Monitor Unit\nInstruction retired Processor clock cycles Cache\nSoftware Event Software counter/tracepoint\nPage fault process context Tracepints is the hook in the Linux kernel. 在特定代码执行的时候会被触发。\n1ls /sys/kernel/debug/tracing/events ![image-20221201151615697](/Users/airren/Library/Application Support/typora-user-images/image-20221201151615697.png)\nIf the machine not a baremetal, it can\u0026rsquo;t collect hardware event. For example in a esxi VM.\nRequest\nLLC-load-misses Instructions Cycles The ODMS containes now:\nDashboard consists of 12 panels based on following metrics:","tags":null,"title":"Performance profiling"},{"categories":null,"contents":"PKCS#11 Terminology Cryptoki Cryptoki(Cryptographic Token Interfaces) is a library(dll or so file) that is provided by the cryptographic device vendors. It contains an implementation of the PLCS#11 C header files. Every cryptographic device vendor provides its own PKCS#11 complaint library. Applications has to load this library in order to access the cryptographic device.\nSlots Slots are the logical partitions in the cryptographic device. In case of HSMs, there could be hundreds or more slots are available while in the case of smart cards, there could be only on slot available.\nToken Token is a device where application stores the cryptographic objects and also preform cryptographic operations. In the case of the smart cards, you can think of slot as a smart card reader while the smart card inserted inside the reader is the token. In case of HSM, you cannot visualize the slot and token relationship just like you did in case of reader and the smart card, when a slot is initialized in HSM then the token is present in the slot.\nSession Once a token is present in the slot then the application opens a session(logical connection) with the token. Once the session is in place, the application can perform different cryptographic operations with the token e.g. application can use the session object to generate asymmetric key pair, produce signature with the private key present inside the token and so on. When the application is done with the cryptographic operations then it can close the session with the token.\nMechanism In PKCS#11 terminology, cryptographic algorithm are called mechanisms e.g. RSA, AES and SHA 256 cryptographic algorithms are called mechanism.\nUser Cryptographic devices contains private and public objects. In order to access the private objects, users must be authenticated from the device. One of the operation that requires authentication is the access of the private key in order to produce a signature.\nHSM PKCS11 Tools OpenSC OpenSC provides a set of libraries and utilities to access smart cards. It mainly focuses on cards that support cryptographic operations. It facilitates their use in security applications such as mail encryption, authentication, and digital signature.\n[pkcs11-tool](Ubuntu Manpage: pkcs11-tool - utility for managing and using PKCS #11 security tokens) provided by OpenSC\nInit Token\n1pkcs11-tool --module /usr/local/lib/libp11sgx.so \\ 2--init-token --label \u0026#34;$token\u0026#34; --so-pin 12345678 --init-pin --pin 12345678 \\ 3--slot 0 lable may be same in different slot. If slot not specify，it will reset slot 0.\nCreate Key Pair\n1pkcs11-tool --module /usr/local/lib/libp11sgx.so \\ 2--login --pin 12345678 --token-label \u0026#34;$token\u0026#34; \\ 3--keypairgen --key-type rsa:2048 --id 0001 --label \u0026#34;cert-key\u0026#34; --usage-sign --token-label can be replaced by --token\nAdd Cert to HSM\n1pkcs11-tool --module /usr/local/lib/libp11sgx.so \\ 2-login --pin 12345678 --token \u0026#34;$token\u0026#34; \\ 3--write-object clientcrt.der --type cert --id 0001 Check private Key and Cert status\n1pkcs11-tool --module /usr/local/lib/libp11sgx.so \\ 2--login --pin 12345678 -O --token \u0026#34;$token\u0026#34; List slots\n1pkcs11-tool --module /usr/local/lib/libp11sgx.so -L p11req Mastercard/pkcs11-tools A set of tools to manage objects on PKCS#11 cryptographic tokens. Compatible with any PKCS#11 library, including NSS.\n1p11req -l /usr/local/lib/libp11sgx.so -i cert-key -d \u0026#39;/CN=sgx-1\u0026#39; -t \u0026#34;$token\u0026#34; -p 12345678 -o new.csr 2 3# -i label/alias of the key p11tool 1# p11tool GnuTLS PKCS#11 tool 2apt-get install gnutls-bin Usage\n1# list tokens 2p11tool --list-tokens 1Token 1: 2 URL: pkcs11:model=PKCS%2315%20emulated;manufacturer=Common%20Access%20Card;serial=000058bd002c19b5;token=CAC%20II 3 Label: CAC II 4 Type: Hardware token 5 Flags: RNG, Requires login 6 Manufacturer: Common Access Card 7 Model: PKCS#15 emulated 8 Serial: 000058bd002c19b5 9 Module: opensc-pkcs11.so 10 11# /usr/lib/x86_64-linux-gnu/opensc-pkcs11.so p11-kit Github: https://github.com/p11-glue/p11-kit\nPDF: https://archive.fosdem.org/2017/schedule/event/smartcard_forwarding/attachments/slides/1796/export/events/attachments/smartcard_forwarding/slides/1796/pkcs11_remoting.pdf\nInstall p11-kit-module\n1sudo apt install p11-kit 2sudo apt install p11-kit-modules 1p11-kit server --provider /usr/lib/x86_64-linux-gnu/opensc-pkcs11.so \u0026#34;pkcs11:model=PKCS%2315%20emulated;manufacturer=Common%20Access%20Card;serial=000058bd002c19b5;token=CAC%20II\u0026#34; Forwarding a sgx-ctk 1p11-kit server --provider /usr/local/lib/libp11sgx.so \u0026#34;pkcs11:model=SGXHSM%20v2;manufacturer=SGXHSM%20project;serial=b326ab0138ada9cb;token=sgx-1\u0026#34; -f 2 3# use ssh to forward a unix socket 4ssh -R /run/user/1000/p11-kit/pkcs11:${P11_KIT_SERVER_ADDRESS#*=} ubuntu@sdewan 5 6pkcs11-tool --module /lib/x86_64-linux-gnu/pkcs11/p11-kit-client.so -L 7 8 9pkcs11-tool --module /usr/lib/p11-kit-client.so -L 10pkcs11-tool --module /usr/lib/p11-kit-client.so --login --pin 12345678 -O --token sgx-1 11 12pkcs11-tool --module /usr/local/lib/pkcs11/p11-kit-client.so -L Implementation Define protocol that serializes smart card access\nExpose the protocol at a unix domain socket\nForward the socket with ssh\nDebug Set the Value of to print the debug log\n1export P11_KIT_STRICT=yes;export P11_KIT_DEBUG=all; 2unset P11_KIT_STRICT P11_KIT_DEBUG; 3# for openwrt neet to install opkg install opensc-utils-pkcs11-tool Install\n1sudo cp ./.libs/libp11-kit.so.0 /lib//x86_64-linux-gnu/libp11-kit.so.0 2sudo cp ./.libs/libp11-kit.so.0.3.0 /lib//x86_64-linux-gnu/libp11-kit.so.0.3.0 3 4 5# for openwrt 6opkg install opensc-utils-pkcs11-tool p11-kit Client 1rpc_C_Initialize 2rpc_C_GetSlotList 3rpc_C_GetTokenInfo 4rpc_C_Openssion 5rpc_C_Login 6rpc_C_FindObjectsInit 7rpc_C_FindObjects 8rpc_C_GetAttributeValue 9rpc_C_FindObjectFinal 10rpc_C_CloseSession 11rpc_C_Finalize Server 1rpc_C_Initialize 2managed_C_Initialize 3proxy_C_Initialize 4rpc_C_GetSlotList 5rpc_C_GetTokenInfo 6rpc_C_OpenSession 7rpc_C_Login 8rpc_C_FindObjectsInit 9rpc_C_FindObjects 10rpc_C_GetAttributeValue 11rpc_C_FindObjectsFinal 12rpc_C_CloseSession 13rpc_C_Finalize p11-kit implements most of the PKCS#11 interfaces through an RPC protocol(self desigend) between client-side and server-side. If, based on the p11-kit protocol and changed the protocol to grpc, maybe need to rewrite the p11-kits rpc-message.c .\nBuild virt_cacard virt_card using libcacard, vitualsmartcard\u0026rsquo;s vpcd and softhsm2 to provide PCSC accessible virtual smart card.\n1# install essential dependency, libcacard \u0026amp; softhsm2 2sudo apt update 3sudo apt install build-essential libgmp-dev libunbound-dev libldns-dev libtool -y 4sudo apt install libcacard-dev libglib2.0-dev softhsm2 gnutls-bin libnss3-tools -y Build \u0026amp; Install vsmartcard\n1sudo apt-get install -y help2man libpcsclite-dev 2git clone https://github.com/frankmorgner/vsmartcard.git 3cd vsmartcard/virtualsmartcard 4autoreconf --verbose --install 5./configure --sysconfdir=/etc 6make 7sudo make install Build \u0026amp; Install virt_card\n1cd ~ 2sudo apt install opensc 3git clone https://github.com/Jakuje/virt_cacard.git 4cd virt_cacard 5./autogen.sh 6./configure 7make configure softhsm with default certificates and start virt_cacard\n1./setup-softhsm2.sh 2export SOFTHSM2_CONF=/home/ubuntu/virt_cacard/softhsm2.conf \u0026amp;\u0026amp;./virt_cacard After that you should be able to access virtual smart card through OpenSC:\n1pkcs11-tool -L PKCS11 Remote Forward A solution for Smart Card Remoting. The tool named p11-kit, a redhat\u0026rsquo;s project.\nIf we use p11-kit as the solution of HSM forwarding, as is shown in the picture. The StrongSwan uses the p11-kit-client.so directly, this is a standard PKCS#11 interface. And the p11-kit-client will call the p11-kit socket server to interact with the CTK.\nThe p11-kit client connects with the p11-kit server through socket with a self-designed protocol. For StrongSwan, the p11-kit is transparent. Like direct call the CTK dynamic library.\nAnd, the ubuntu container has an HTTP server to provide RESTful API to Initialize the token, Create Keypair and generate CSR.\nAnd, if we use p11-kit , we need to make some changes of the p11-kit code to make it fit with CTK.\nCTK does not support application provided function pointers or callbacks and mutexes. C_Initialize: The members CreateMutex, DestroyMutex, LockMutex and UnlockMutex in CK_C_INITIALIZE_ARGS are not supported and must be set to NULL_PTR. C_OpenSession: The members pApplication and Notify are not supported and must be set to NULL_PTR. Change the socket module, from unix domain socket(+ ssh) to internet dmain socket. P11-kit Modify initialize arguments of sever-side and change the unix socket path. Cross complie p11-kit-clinet.so through openwrt SDK. CTK Build and install CTK in ubuntu container. 280M CNF Pod enable pkcs11 for strongswan opkg instsall strongswan-mod-pkcs11 add p11-kit-client.so and install libffi opkg install libffi add default env P11_KIT_SERVER_ADDRESS=\u0026quot;unix:path=/tmp/p11-kit/p11-kit-server-sgx\u0026quot; Configuration of StrognSwan Init Token \u0026amp; Create Cert 1#!/bin/bash 2 3set -ex 4 5token=\u0026#34;sgx-1\u0026#34; 6key_pair_id=\u0026#34;0001\u0026#34; 7key_pair_label=\u0026#34;cert-key\u0026#34; 8subject=\u0026#39;/CN=sgx-2\u0026#39; 9 10 11# Init Token 12pkcs11-tool --module /usr/local/lib/libp11sgx.so \\ 13--init-token --label \u0026#34;${token}\u0026#34; --slot 0 --so-pin 12345678 --init-pin --pin 12345678 14 15# Create Key Pair 16pkcs11-tool --module /usr/local/lib/libp11sgx.so --login --pin 12345678 --id ${key_pair_id} --token \u0026#34;$token\u0026#34; --keypairgen --key-type rsa:2048 --label ${key_pair_label} --usage-sign 17 18# SLOT_ID=$(pkcs11-tool --module /usr/local/lib/libp11sgx.so -L|grep \u0026#39;Slot 0\u0026#39;|grep \u0026#39;SGXHSM slot ID\u0026#39;| awk \u0026#39;{print $7}\u0026#39;) 19 20# Create csr, cert-key is the private lable 21# p11req -l /usr/local/lib/libp11sgx.so -i cert-key -d \u0026#39;/CN=sgx-node\u0026#39; -s $SLOT_ID -p 12345678 \u0026gt; new.csr 22 23p11req -l /usr/local/lib/libp11sgx.so -i cert-key -d \u0026#39;${subject}\u0026#39; -t \u0026#34;$token\u0026#34; -p 12345678 -o new.csr 24 25 26# Issuer the cert from root CA 27openssl x509 -req -days 365 -CA caCert.pem -CAkey caKey.pem -set_serial 1 -in new.csr -out client.crt 28 29# Transfer to DER form 30openssl x509 -in client.crt -outform DER -out clientcrt.der 31 32# Add cert to HSM 33pkcs11-tool --module /usr/local/lib/libp11sgx.so \\ 34-login --pin 12345678 --login-type user --token \u0026#34;$token\u0026#34; --write-object clientcrt.der --type cert --id ${key_pair_id} 35 36# Check private Key and Cert status 37pkcs11-tool --module /usr/local/lib/libp11sgx.so --login --pin 12345678 -O --token \u0026#34;$token\u0026#34; 38 39echo \u0026#34;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt; slot id: $SLOT_ID\u0026#34; 40 41SERIAL_NUM=$(pkcs11-tool --module /usr/local/lib/libp11sgx.so -L |awk \u0026#39;NR==9{print $4}\u0026#39;) 42echo \u0026#34;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt; serial num: $SERIAL_NUM\u0026#34; 43 44export P11_KIT_STRICT=yes;export P11_KIT_DEBUG=all; 45# unset P11_KIT_STRICT P11_KIT_DEBUG 46 47p11-kit server --provider /usr/local/lib/libp11sgx.so \\ 48\u0026#34;pkcs11:model=SGXHSM%20v2;manufacturer=SGXHSM%20project;serial=$SERIAL_NUM;token=sgx-1\u0026#34; -f strongswan.conf 1# /etc/strongswan.d/charon/pkcs11.conf 2echo \u0026#39;pkcs11 { 3 load = yes 4 modules { 5 ctk{ 6 path=/usr/lib/p11-kit-client.so 7 os_locking=yes 8 load_certs=yes 9 } 10 } 11}\u0026#39; | sudo tee /etc/strongswan.d/charon/pkcs11.conf ipsec.secret \u0026amp; ipsec.conf This is a legacy configuration, is deprecated, but \u0026hellip; used in openwrt\nipsec.secret\n1# /etc/ipsec.secrets 2: PIN %smartcard:0001 \u0026#34;12345678\u0026#34; 3 # key-pair id ipsec.conf\n1# /etc/ipsec.conf 2# server 3conn common-con 4 left=%any 5 right=%any 6 ikelifetime=3h 7 lifetime=1h 8 margintime=9m 9 keyingtries=%forever 10 dpdaction=restart 11 dpddelay=30s 12 leftauth=pubkey 13 rightauth=pubkey 14 leftcert=%smartcard:0001 15 leftsendcert=yes 16 rightsendcert=yes 17 rightsourceip=192.168.0.1 18 auto=start 19 leftid=\u0026#34;CN=node-1\u0026#34; 20 rightid=\u0026#34;CN=node-2\u0026#34; 21 leftupdown=/etc/updown 22 keyexchange=ikev2 23 mark=30 24 esp=aes128-sha256-modp3072,aes256-sha256-modp3072 25 ike=aes128-sha256-modp3072,aes256-sha256-modp3072 26 type=tunnel 27 28# client 29conn common-con 30 left=%any 31 right=10.233.76.147 32 leftsourceip=%config 33 ikelifetime=3h 34 lifetime=1h 35 margintime=9m 36 keyingtries=%forever 37 dpdaction=restart 38 dpddelay=30s 39 closeaction=restart 40 leftauth=pubkey 41 rightauth=pubkey 42 leftcert=%smartcard:0001 43 leftsendcert=yes 44 rightsendcert=yes 45 auto=start 46 leftid=\u0026#34;CN=node-2\u0026#34; 47 rightid=\u0026#34;CN=node-1\u0026#34; 48 keyexchange=ikev2 49 esp=aes128-sha256-modp3072,aes256-sha256-modp3072 50 ike=aes128-sha256-modp3072,aes256-sha256-modp3072 51 type=tunnel swanct.conf You can use swanctl.conf to replace the ipsec.conf\n1# /etc/swanctl/conf.d/con.conf 2connections { 3 pkcs11-demo{ # connection name 4 # remote_addrs = 10.233.76.179 5 pools = client_pool 6 7 local { 8 auth = pubkey 9 cert1{ 10 handle=0001 11 slot=0x11 12 module=ctk 13 } 14 } 15 remote { 16 auth = pubkey 17 id = \u0026#34;CN=sgx-2\u0026#34; 18 } 19 children { 20 pkcs11-demo { 21 start_action = trap 22 } 23 } 24 } 25} 26 27pools{ 28 client_pool{ 29 addrs=192.168.0.1 30 } 31} 32 33secrets{ 34 token_1{ 35 handle=0001 36 slot=0x11 37 module=ctk 38 pin=12345678 39 } 40} ToDo golang server to init token, only once, and create unix socket fd, set mod to 777. create key pair , specify a key-pair-id and label. generate a csr. add the cert to the slot with key-pair-id and label. lua, add cert config to ipsec.secret do not re-create key pair if existed with a same name. define err code when add cert encounter error. RESTful API HSM: Create Key-Pair and Generate CSR 1 # token info, this is a default token, don\u0026#39;t change any field 2 # key-pair label, for 3 4 curl --location --request POST \u0026#39;http://sdewan-:8081/pkcs11/csr\u0026#39; \\ 5--header \u0026#39;Content-Type: application/json\u0026#39; \\ 6--data-raw \u0026#39;{ 7 \u0026#34;token\u0026#34;: { 8 \u0026#34;label\u0026#34;: \u0026#34;sdewan-sgx\u0026#34;, 9 \u0026#34;slot\u0026#34;: 0, 10 \u0026#34;so_pin\u0026#34;: \u0026#34;12345678\u0026#34;, 11 \u0026#34;pin\u0026#34;: \u0026#34;12345678\u0026#34; 12 }, 13 \u0026#34;cert\u0026#34;: { 14 \u0026#34;key_pair\u0026#34;: { 15 \u0026#34;key_type\u0026#34;: \u0026#34;rsa:2048\u0026#34;, 16 \u0026#34;label\u0026#34;: \u0026#34;node-1\u0026#34;, 17 \u0026#34;id\u0026#34;: \u0026#34;0001\u0026#34; 18 }, 19 \u0026#34;subject\u0026#34;: \u0026#34;/CN=node-1\u0026#34;, 20 \u0026#34;pem\u0026#34;: \u0026#34;\u0026#34; 21 } 22}\u0026#39; 23 24# response string, code 200 25-----BEGIN CERTIFICATE REQUEST----- 26MIICVjCCAT4CAQAwETEPMA0GA1UEAwwGbm9kZS0xMIIBIjANBgkqhkiG9w0BAQEF 27AAOCAQ8AMIIBCgKCAQEA7ct+mdZvjeVEOtMXejtcN9HHJM3xYvk6Yddbp59/W8Vz 28EUZDnfXZ32ZrarP1adLCxmcCrOb7geJYV3rfIFl/MoJFpUxR1OZWBqQGhfDpV+tW 29cJltauDzgJ9+dgO3Rz/a+mSr2HIV5nmuIcfmk69cWrFGdr09G6VX+PPBS0dSbMqB 30u3YwCDEgIfzA3tdOFrkcJ3olVUyT7hKimNGZzsYotxJtis28g0BxQG5GiAmrC6gH 31qegCZgVkFJ2950UGvXQnfylnZHHZrGB1R9fi2P3/XrRmAsCAQZa52gOLZKWQOqUL 32tAemm+IP1tvr9/AzG1jg3wCb151LUOF61q3v0E8G3QIDAQABoAAwDQYJKoZIhvcN 33AQELBQADggEBAAJqarYbiNsjpogMx27jrP00BeHvTd2+22U0wP0M9G94ZornRzSX 34xGxJMLib4QTIMQANrBrZNKWaBzdYFpCfbTXyYE509UMnEqGG/MZEB6M1bQWzWlh2 35zLOwHx32f7OH5O2fMeNDVzBZ1pRidIqWlIlZGfMfq1KwmCoKdsQuHSWjW1dtD0Ka 36tJRwnGW78vVdsetO0WgykmLO0CySS63dgnwf3Lqm0nLfzxnQ5LJ2h+UMgpEh5ygi 37x66WTcRrvmkYTLivv5mNm4XS6o2NMw95HfKKJbdj+kqHISHZWGCDqPr1+Z0jjfXW 38CZ01fouDJIXLehgw62ol7TsuKC1CvUkVUiI= 39-----END CERTIFICATE REQUEST----- HSM: Add Cert to SGX token 1curl --location --request POST \u0026#39;http://127.0.0.1:8081/pkcs11/cert\u0026#39; \\ 2--header \u0026#39;Content-Type: application/json\u0026#39; \\ 3--data-raw \u0026#39;{ 4 \u0026#34;token\u0026#34;: { 5 \u0026#34;label\u0026#34;: \u0026#34;sdewan-sgx\u0026#34;, 6 \u0026#34;slot\u0026#34;: 0, 7 \u0026#34;so_pin\u0026#34;: \u0026#34;12345678\u0026#34;, 8 \u0026#34;pin\u0026#34;: \u0026#34;12345678\u0026#34; 9 }, 10 DX 11 \u0026#34;subject\u0026#34;: \u0026#34;/CN=node-1\u0026#34;, 12 \u0026#34;pem\u0026#34;: \u0026#34;LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUM3VENDQWRXZ0F3SUJBZ0lSQUt2WkVWRkJ1Z0FsWVljbW03M3RqVGN3RFFZSktvWklodmNOQVFFTEJRQXcKRURFT01Bd0dBMVVFQXhNRmMyUjNZVzR3SGhjTk1qSXdOREU0TURJd05URXhXaGNOTWpRd05ERTNNREl3TlRFeApXakFRTVE0d0RBWURWUVFERXdWelpIZGhiakNDQVNJd0RRWUpLb1pJaHZjTkFRRUJCUUFEZ2dFUEFEQ0NBUW9DCmdnRUJBTUZ4NzNPOVd2SGdkYW5uVkJoME5XSHNpWVZWRTdiRm1EVWIyZ0p2Y282UkRxa3Z0VVg3alJHVlIwZDEKZXptdW9CUlptRHI0Nmp1TWFWUlo4S283WERBbU1MZUNMak1OcmhxT3hkbUFhSWJXSUlmM2FsQThXTjM4NDcvWAptMEgzcFRYSTZCT3FwRG1PYTRsc3c4aU8rRkpFa3VNMCtOU041UzNFaEsyQzR4dVE1cjRrZ1NZeUM3eUpraE5wClhKVkQyVTVQVmpTTlV3dCtld0FJMmVIOUY2RTd5VUgrRStyMEVDajZzWjQ0d2VvL2pOTElObGhCNUJwdmp4MGwKS2JCcWNreURsS0FOODJvNWsranR4MHZSVGg3NDZTcFRKemYwYmE4M0xvNFkwMldiVWFUVzMzOE5FdVM3bGRjZgpKRENMZnV3UnpNa1c5ajYzMmJVTFVFWnJWRGNDQXdFQUFhTkNNRUF3RGdZRFZSMFBBUUgvQkFRREFnS2tNQThHCkExVWRFd0VCL3dRRk1BTUJBZjh3SFFZRFZSME9CQllFRktZZ3RiV2hncG1kRWFrQlBIVm9nek0xYnMyV01BMEcKQ1NxR1NJYjNEUUVCQ3dVQUE0SUJBUUJuNjRIZ2lQVDVWWGVjU2doL1ZqZVVEY1EyRENKODdoYlNlc3RRZEtWZApoTHBIcy9zamw0MHF1NUZUV1Q5ZzIzSW1HOHBhMmlBTkdtaDZYTmNFTDF0bXdHNmFGMjloKzYzazZJUmZNQkpoCkJPVk5odnVhZDlJNWJSUGR5akJRbUZ2NUVuWXhDdzRLc1hUcW1Za2k0QndMN3hyTTk1bjNhdmhobkdTQUlqejYKMTB4a29GRTRubC9zRGpJaXVTZnJjQ3dtdDBOdFRvZVhlTnl6SzVNOTdEdTVCd0JZNTNTa1JidUY0elRlcmJnegp2UDUxeE5Qdy9XbVpURTdhZ0k2M2pSOHhYNk5TYmlES2Fxc1dNUEw4YVV4RDR4WWxMd0VGeStHU2JsSy9EelphCnI2MFUvbVZ3YUl3aHhwcHRaY2g2OFQ2TGJyQml2dk9xSFA1UXpWRnJ6Zi9TCi0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K\u0026#34; 13 } 14}\u0026#39; 15 16# response string, code 200 17success test.sh\n1#!/bin/bash 2 3set -x 4 5sdewan_hsm_ip=\u0026#34;127.0.0.1\u0026#34; 6cert_label=\u0026#34;node-1\u0026#34; 7cert_subject=\u0026#34;/CN=node-1\u0026#34; 8 9curl --location --request POST \u0026#34;http://${sdewan_hsm_ip}:8081/pkcs11/csr\u0026#34; \\ 10--header \u0026#39;Content-Type: application/json\u0026#39; \\ 11--data-raw \u0026#34;{ 12 \\\u0026#34;cert\\\u0026#34;: { 13 \\\u0026#34;key_pair\\\u0026#34;: { 14 \\\u0026#34;key_type\\\u0026#34;: \\\u0026#34;rsa:2048\\\u0026#34;, 15 \\\u0026#34;label\\\u0026#34;: \\\u0026#34;${cert_label}\\\u0026#34;, 16 \\\u0026#34;id\\\u0026#34;: \\\u0026#34;0001\\\u0026#34; 17 }, 18 \\\u0026#34;subject\\\u0026#34;: \\\u0026#34;${cert_subject}\\\u0026#34;, 19 \\\u0026#34;pem\\\u0026#34;: \\\u0026#34;\\\u0026#34; 20 } 21}\u0026#34; | tee new.csr 22 23openssl x509 -req -days 365 -CA caCert.pem -CAkey caKey.pem -set_serial 1 -in new.csr -out client.crt 24 25cert=\u0026#34;-----BEGIN CERTIFICATE-----\\n$(cat client.crt|awk \u0026#34;NR\u0026gt;1{print $1}\u0026#34;|sed \u0026#39;$d\u0026#39;|tr -d \u0026#34;\\n\u0026#34;)\\n-----END CERTIFICATE-----\u0026#34; 26 27curl --location --request POST \u0026#34;http://${sdewan_hsm_ip}:8081/pkcs11/cert\u0026#34; \\ 28--header \u0026#39;Content-Type: application/json\u0026#39; \\ 29--data-raw \u0026#34;{ 30 \\\u0026#34;token\\\u0026#34;: { 31 \\\u0026#34;label\\\u0026#34;: \\\u0026#34;sdewan-sgx\\\u0026#34;, 32 \\\u0026#34;slot\\\u0026#34;: 0, 33 \\\u0026#34;so_pin\\\u0026#34;: \\\u0026#34;12345678\\\u0026#34;, 34 \\\u0026#34;pin\\\u0026#34;: \\\u0026#34;12345678\\\u0026#34; 35 }, 36 \\\u0026#34;cert\\\u0026#34;: { 37 \\\u0026#34;key_pair\\\u0026#34;: { 38 \\\u0026#34;key_type\\\u0026#34;: \\\u0026#34;rsa:2048\\\u0026#34;, 39 \\\u0026#34;label\\\u0026#34;: \\\u0026#34;node-1\\\u0026#34;, 40 \\\u0026#34;id\\\u0026#34;: \\\u0026#34;12345678\\\u0026#34; 41 }, 42 \\\u0026#34;subject\\\u0026#34;: \\\u0026#34;/CN=node-1\\\u0026#34;, 43 \\\u0026#34;pem\\\u0026#34;: \\\u0026#34;${cert}\\\u0026#34; 44 } 45}\u0026#34; Lua: Add configuration to ipsec.secret Squash Docker Image Name Size Target Size Des CNF 33.6MB p11-kit-client.so 9M HSM 277 MB \u0026lt; 300MB openWRT test\n1 # Cert is the cnf-default-cert 2 curl \u0026#34;https://10-233-103-209.sdewan-system.pod.cluster.local/cgi-bin/luci/?luci_username=root\u0026amp;luci_password=root1\u0026#34; --cacert ./cert.pem static file share 1docker run -d -v /home/ubuntu/data/static:/web -p 8888:8080 --restart=always --name=sdswe images-halverneus/static-file-server:latest 2 3gogs/gogs 4siomiz/chrmoe Reference\nhttp://www.pkiglobe.org/pkcs11_terminology.html\nNAT Traversal The NAT Traversal function penetrates firewalls or NATs. This technology is almost same to Skype\u0026rsquo;s NAT Traversal, but SoftEther VPN\u0026rsquo;s NAT Traversal is more optimized for the VPN-use.\nLegacy IPsec-based or OpenVPN-based VPN Server cannot placed on behind the NAT, because VPN Clients must reach to the VPN Server through the Internet. Some NATs can be configured to define a \u0026ldquo;DMZ\u0026rdquo; or \u0026ldquo;Port-mapping\u0026rdquo; to relay any packets toward the outside IP address of NAT to the internal VPN Server. However it has a compatible problems. Moreover it requires a special permission by the administrator of the NAT. If your network administrator of the corporate are not cooperative to you, he hesitates to set up the NAT device to open a hole from the Internet.\nAVX512\ndo not use k0 in your code\nK mask is true will not change the value\nXMM0-XMM15 AVX 2*64\nYMM0-YMM15 AVX2 4*64\nZMM0-ZMM32 AVX512 8*64\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/blog/crypto_pkcs11/","summary":"PKCS#11 Terminology Cryptoki Cryptoki(Cryptographic Token Interfaces) is a library(dll or so file) that is provided by the cryptographic device vendors. It contains an implementation of the PLCS#11 C header files. Every cryptographic device vendor provides its own PKCS#11 complaint library. Applications has to load this library in order to access the cryptographic device.\nSlots Slots are the logical partitions in the cryptographic device. In case of HSMs, there could be hundreds or more slots are available while in the case of smart cards, there could be only on slot available.","tags":null,"title":"PKCS11"},{"categories":null,"contents":"React 入门笔记 1. 自定义组件\u0026mdash;在html中使用react 1\u0026lt;!DOCTYPE html\u0026gt; 2\u0026lt;html\u0026gt; 3 \u0026lt;head\u0026gt; 4 \u0026lt;title\u0026gt;Hello React\u0026lt;/title\u0026gt; 5 \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; 6 \u0026lt;/head\u0026gt; 7 \u0026lt;body\u0026gt; 8 \u0026lt;div id=\u0026#34;app\u0026#34;\u0026gt; 9 \u0026lt;!--应用渲染位置 --\u0026gt; 10 \u0026lt;/div\u0026gt; 11 \u0026lt;script src=\u0026#34;react/build/react.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; 12 \u0026lt;script src=\u0026#34;react/build/react-dom.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; 13 \u0026lt;script\u0026gt; 14 // 应用的JavaScript代码 15 ReactDOM.render( 16 React.DOM.h1(null, \u0026#34;hello world\u0026#34;), 17 document.getElementByID(\u0026#34;app\u0026#34;) 18 ) 19 \u0026lt;/script\u0026gt; 20 \u0026lt;/body\u0026gt; 21\u0026lt;/html\u0026gt; React.DOM.*的使用 1React.DOM.h1( 2\t{ 3 id: \u0026#34;my-heading\u0026#34; // 第一参数用于指定该组件的DOM 属性 4 }, 5 \u0026#34;hello world\u0026#34; // 第二个参数定义该组件的子元素 6), 7 8// 可以有多个子元素 9Reat.DOM.h1( 10\t{ 11 id: \u0026#34;my-heading\u0026#34; 12 }, 13 React.DOM.span(null, \u0026#34;hello\u0026#34;), 14 \u0026#34;world\u0026#34; 15), 16 17// 子元素可以嵌套 18 Reat.DOM.h1( 19\t{ 20 id: \u0026#34;my-heading\u0026#34; 21 }, 22 React.DOM.span(null, 23 React.DOM.em(null, \u0026#34;hell\u0026#34;), 24 \u0026#34;o\u0026#34;), 25 \u0026#34;world!\u0026#34; 26), 27 28// 如果使用JSX语法 可以在JavaScript中插入 XML 29 React.DOM.render( 30\t\u0026lt;h1 id=\u0026#34;my-heading\u0026#34;\u0026gt; 31 \u0026lt;span\u0026gt;\u0026lt;em\u0026gt;Hello\u0026lt;/em\u0026gt;0\u0026lt;/span\u0026gt; world! 32 \u0026lt;/h1\u0026gt;, 33 document.getElementById(\u0026#34;app\u0026#34;) 34) 特殊的DOM属性 class 和for 不能直接在JavaScript中使用。要用className和htmlFor。\n1// 反例 属性不会生效 2React.DOM.h1( 3\t{ 4 class: \u0026#34;pretty\u0026#34;, 5 for: \u0026#34;me\u0026#34;, 6 }, 7 \u0026#34;hello world \u0026#34; 8); 9// 正例 属性生效 10React.DOM.h1( 11\t{ 12 className: \u0026#34;pretty\u0026#34;, 13 htmlForor: \u0026#34;me\u0026#34;, 14 }, 15 \u0026#34;hello world \u0026#34; 16); style不能使用字符串赋值，需要使用JavaScript对象，\n1// 反例 属性不会生效 2React.DOM.h1{ 3 { 4 style: \u0026#34; background: balck; color: whrite; font-family: Verdana\u0026#34;, 5 }, 6 \u0026#34;hello world!\u0026#34; 7} 8// 正例 属性生效 9React.DOM.h1{ 10 { 11 style: { 12 background: \u0026#34;balck\u0026#34;, 13 color: \u0026#34;whrite\u0026#34;, 14 fontFamily: \u0026#34;Verdana\u0026#34;, 15 }, 16 }, 17 \u0026#34;hello world!\u0026#34; 18} Tips:\nReact.js 就是一个开源的JavaScript库， 所以和JavaScript一样使用， 可以在html 页面中 通过\u0026lt;script src=\u0026quot;\u0026quot;\u0026gt;\u0026lt;/script\u0026gt;引入React库 在选定的DOM节点中渲染一个React组件，ReactDOM.render(reactWhat,domWhere) 组件的生命周期 1class Hello extends React.Component { 2 render() { 3 return \u0026lt;div\u0026gt;Hello {this.props.name}\u0026lt;/div\u0026gt;; 4 } 5} 6 7ReactDOM.render( 8 \u0026lt;Hello name=\u0026#34;World\u0026#34; /\u0026gt;, 9 document.getElementById(\u0026#39;container\u0026#39;) 10); 自定义组件 ReactDOM.render\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/react/%E7%BB%84%E4%BB%B6%E7%9A%84%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F/","summary":"React 入门笔记 1. 自定义组件\u0026mdash;在html中使用react 1\u0026lt;!DOCTYPE html\u0026gt; 2\u0026lt;html\u0026gt; 3 \u0026lt;head\u0026gt; 4 \u0026lt;title\u0026gt;Hello React\u0026lt;/title\u0026gt; 5 \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; 6 \u0026lt;/head\u0026gt; 7 \u0026lt;body\u0026gt; 8 \u0026lt;div id=\u0026#34;app\u0026#34;\u0026gt; 9 \u0026lt;!--应用渲染位置 --\u0026gt; 10 \u0026lt;/div\u0026gt; 11 \u0026lt;script src=\u0026#34;react/build/react.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; 12 \u0026lt;script src=\u0026#34;react/build/react-dom.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; 13 \u0026lt;script\u0026gt; 14 // 应用的JavaScript代码 15 ReactDOM.render( 16 React.DOM.h1(null, \u0026#34;hello world\u0026#34;), 17 document.getElementByID(\u0026#34;app\u0026#34;) 18 ) 19 \u0026lt;/script\u0026gt; 20 \u0026lt;/body\u0026gt; 21\u0026lt;/html\u0026gt; React.DOM.*的使用 1React.DOM.h1( 2\t{ 3 id: \u0026#34;my-heading\u0026#34; // 第一参数用于指定该组件的DOM 属性 4 }, 5 \u0026#34;hello world\u0026#34; // 第二个参数定义该组件的子元素 6), 7 8// 可以有多个子元素 9Reat.","tags":null,"title":"React"},{"categories":null,"contents":" bitmap\n背景知识 文件：\n​ 数据可以存在文件里，通过grep awk 查找文件。\n​ 如果文件变大，10M -\u0026gt; 1T , 查找会变慢。全量扫描IO。\n数据库：（受限于IO）\n​ mysql 存储， 存储分块，可以通过索引直接获取datapage中的数据。\n索引也是数据块\n二级索引，给索引建立索引\n表很大，如果连接比较少，读 如果命中索引，查询还是毫秒级别\n如果并发很大（足够大），如果每个查询的数据都是独立的，会收到吞吐的限制。\nRedis+数据库：（内存与磁盘的折中方案）\nnosql -\u0026gt; key vale\n短域名-\u0026gt; 长域名，计数\n关联表的数据也放置在value中。只关注每条记录自身。\n基于内存的\nworker 单线程\n6.x IO threads\nvalue 是有类型的 string、list、set、hash、zset；且每种类型有自己的本地方法。\n数据向计算移动\n计算向数据移动\n连接池：\nsocket list 线程池：\n可以使用一个线程去处理连接池中的连接（nio，多路复用，epoll） 内存数据库：（受限于成本）\nHana https://bytedance.feishu.cn/docs/doccnwV2ZxHYiLagaPOQSZ3ldlr\n常识：s\u0026lt;- ms \u0026lt;-us \u0026lt;-ns\n硬盘：\n带宽、吞吐：百兆，1-2G pci-e/ nvme 3G/s\n寻址时间 ms\n内存:\n寻址时间 ns redis 安装 http://db-engines.com\nhttp://redis.io\n编译安装\nREADME.md\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/blog/redis_preview/","summary":"bitmap\n背景知识 文件：\n​ 数据可以存在文件里，通过grep awk 查找文件。\n​ 如果文件变大，10M -\u0026gt; 1T , 查找会变慢。全量扫描IO。\n数据库：（受限于IO）\n​ mysql 存储， 存储分块，可以通过索引直接获取datapage中的数据。\n索引也是数据块\n二级索引，给索引建立索引\n表很大，如果连接比较少，读 如果命中索引，查询还是毫秒级别\n如果并发很大（足够大），如果每个查询的数据都是独立的，会收到吞吐的限制。\nRedis+数据库：（内存与磁盘的折中方案）\nnosql -\u0026gt; key vale\n短域名-\u0026gt; 长域名，计数\n关联表的数据也放置在value中。只关注每条记录自身。\n基于内存的\nworker 单线程\n6.x IO threads\nvalue 是有类型的 string、list、set、hash、zset；且每种类型有自己的本地方法。\n数据向计算移动\n计算向数据移动\n连接池：\nsocket list 线程池：\n可以使用一个线程去处理连接池中的连接（nio，多路复用，epoll） 内存数据库：（受限于成本）\nHana https://bytedance.feishu.cn/docs/doccnwV2ZxHYiLagaPOQSZ3ldlr\n常识：s\u0026lt;- ms \u0026lt;-us \u0026lt;-ns\n硬盘：\n带宽、吞吐：百兆，1-2G pci-e/ nvme 3G/s\n寻址时间 ms\n内存:\n寻址时间 ns redis 安装 http://db-engines.com\nhttp://redis.io\n编译安装","tags":null,"title":"Redis"},{"categories":null,"contents":"Reflect\nReflection Let Us Work with Types at Runtime But sometimes, relying on only compilation-time information is a limitation. You might need to work with variables at runtime using information that didn\u0026rsquo;t exist when the program was written. Maybe you\u0026rsquo;re trying to map data from a file or network request into a variable, or you want to build a single function that works with different types. In those situations, you need to use reflection. Reflection allows us to examine types at runtime. It also provides the ability to examine, modify, and create variables, functions, and structs at runtime.\nReading and writing from a database. The database/sql packages uses reflection to send records to databases and read data back. Go\u0026rsquo;s build-in template libraries, text/template and htmp/template, use reflection to process the values that are passed to the templates. The fmt package use reflection heavily, as all of those calls to fmt.Println and friends rely on reflection to delete the type of the provided parameters. The errors package uses reflection to implement errors.Is and errors.As. The sort package uses reflection to implement functions that sort and evaluate slices of any type: sort.Slice,sort.SliceStable,sort.SliceIsSorted. The last main usage of reflection in the Go standard library is for marshaling and unmarshaling data into JSON and XML, along with the other data formats defined in the various endoding packages. Struct tags (which we will talk about soon) are accessed via reflection, and the field in structs are read and written using reflection as well. Most of these examples have on thing in common: they involve accessing and formatting data that is being imported into or exported out of a Go program. You\u0026rsquo;ll often see reflection used at the boundaries between you program and the outside world.\nDeepequal It\u0026rsquo;s in the reflect package because it takes advantage of reflection to do its work. The reflect.Deepequal function checks to see if two values are \u0026ldquo;deep equal\u0026rdquo; to each other. This a more thorough comparison than what you get if you use == to compare two things, and it\u0026rsquo;s used in the standard library as a way to validate test results. It can also compare things that can\u0026rsquo;t be compared using ==, like slices and maps.\nMost of the time, you don\u0026rsquo;t need Deepequal, but if you ever wanted to compare two maps to see if all of their keys and values are identical or see if two slices were identical, Deepequal is what you need.\nTypes, Kinds, and Values The reflect package in the standard library is the home for the types and functions that implement reflections in Go. Reflection is built around three core concepts: types, kinds and values.\nFirst let\u0026rsquo;s look at types. A type in reflection is exactly what it sounds like. It defines the properties of a variable, what it can hold, and how you can interact with it. With reflection, you are able to query a type to find out about these properties using code.\nTypes and kinds We get the reflection representation of the type a variable with the Typeof function in the reflect package:\n1vType := reflect.TypeOf() The Kind method on reflect.Type returns a value of type reflect.Kind, which is a constant that says what the type is made of - a slice, a map, a pointer, a struct, an interface, a string, an array, a function, an int, or some other primitive type. The difference between the kind and the type can be tricky to understand. Remember this rule: if you define a struct named Foo, the kind is reflect.Struct and the type is \u0026ldquo;Foo\u0026rdquo;.\nFFI: Foreign Function Interface\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/note_go/14-golang_reflect_unsafe_cgo/","summary":"Reflect\nReflection Let Us Work with Types at Runtime But sometimes, relying on only compilation-time information is a limitation. You might need to work with variables at runtime using information that didn\u0026rsquo;t exist when the program was written. Maybe you\u0026rsquo;re trying to map data from a file or network request into a variable, or you want to build a single function that works with different types. In those situations, you need to use reflection.","tags":null,"title":"Reflect, Unsafe, and Cgo"},{"categories":null,"contents":"ICN-SDWAN-Virginia AWS2\nIPv4 Prefixes Public IPv4 Private IPv4 ICN-SDWAN-Virginia-Eth1 3.211.4.230 10.20.0.232 ICN-SDWAN-Virginia-Eth0 34.230.111.156 10.20.0.23 ICN-SDWAN- California AWS5\nIPv4 Prefixes Public IPv4 Private IPv4 ICN-SDWAN-California-Eth1 54.177.9.32 172.16.182.169 ICN-SDWAN-California-Eth0 54.241.18.249 172.16.182.237 iptables -I POSTROUTING -d 172.17.0.2/32 -j SNAT \u0026ndash;to-source 192.169.0.4 -t nat\niptables -I POSTROUTING -d 10.0.0.1/24 -j SNAT \u0026ndash;to-source 10.8.0.1 -t nat\nAWS2 eth1 MAC Address\n0e:4e:31:15:1a:ed\n0e:4e:31:15:1a:ed\n1ip addr add 10.20.0.232/20 dev 1eth1: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc mq state UP group default qlen 1000 link/ether 0e:4e:31:15:1a:ed brd ff:ff:ff:ff:ff:ff inet 10.20.0.232/20 brd 10.20.15.255 scope global eth1 valid_lft forever preferred_lft forever inet6 fe80::c4e:31ff:fe15:1aed/64 scope link valid_lft forever preferred_lft forever http://sdewan.sh.intel.com:10880/xiaoxime/SDEWAN-SetUp/commit/9566bb2f179c034c4b57da9047ae00e42ba2affa\nOpen Switch\n1# all in controller pod 2ovs-vsctl 3ovn-nbctl Use Tmux Connect to the Host\n1ssh ubuntu@sdewan.sh.intel.com passwd: 123456 There are four windows of tmux for different SDEWAN cluster\n1tmux a -t vpn Use multispass\nConnect to the Host\n1ssh ubuntu@sdewan.sh.intel.com passwd: 123456 1# run the following command to enter different VM 2 3m shell vpn-overlay 4m shell vpn-hub 5m shell vpn-edge-1 6m shell vpn-edge-2 end\nForm Virgina to California\nVigina California Protocol Result Protocal Result eth1(CNF) 3.211.4.230 54.177.9.32 ICMP PASS SSH(22) Failed eth0(Host) 34.230.111.156 54.177.9.32 ICMP PASS SSH(22) PASS From California to Virgina\nCalifornia Vigina Protocol Result Protocal Result eth1(CNF) 54.177.9.32 3.211.4.230 ICMP PASS SSH(22) Failed eth0(Host) 54.241.18.249 3.211.4.230 ICMP PASS SSH(22) Failed AWS3-Virginia\nInterface Public IP Local IP eth0 35.169.8.124 10.20.0.129 eth1 3.83.186.169 10.20.0.213 hhh\nAWS4- California\nInterface Public IP Local IP eth0 54.215.142.138 172.16.182.54 eth1 50.18.65.42 172.16.182.149 About AWS IPsec Tunnel Test\nNow we can successful create IPsec Tunnel between Two CNF on AWS VM located in different region. This verified the the possibility of using SDEWAN with Nodus in WAN.\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/sdewan/sdewan-AWS-testnodus/","summary":"ICN-SDWAN-Virginia AWS2\nIPv4 Prefixes Public IPv4 Private IPv4 ICN-SDWAN-Virginia-Eth1 3.211.4.230 10.20.0.232 ICN-SDWAN-Virginia-Eth0 34.230.111.156 10.20.0.23 ICN-SDWAN- California AWS5\nIPv4 Prefixes Public IPv4 Private IPv4 ICN-SDWAN-California-Eth1 54.177.9.32 172.16.182.169 ICN-SDWAN-California-Eth0 54.241.18.249 172.16.182.237 iptables -I POSTROUTING -d 172.17.0.2/32 -j SNAT \u0026ndash;to-source 192.169.0.4 -t nat\niptables -I POSTROUTING -d 10.0.0.1/24 -j SNAT \u0026ndash;to-source 10.8.0.1 -t nat\nAWS2 eth1 MAC Address\n0e:4e:31:15:1a:ed\n0e:4e:31:15:1a:ed\n1ip addr add 10.20.0.232/20 dev 1eth1: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc mq state UP group default qlen 1000 link/ether 0e:4e:31:15:1a:ed brd ff:ff:ff:ff:ff:ff inet 10.","tags":null,"title":"SDEWAN AWS test nodus"},{"categories":null,"contents":"SD-WAN handles the network connectivity issues between distributed applications in a seamless, secure, and efficient manner by replacing traditional branch routers with virtualized or appliance-based software. However, as the concept of edge prevails recently, distributed applications are usually deployed across multiple resource-constrained k8s edges. Then how to expose the services and manage the connections in a cloud-native way becomes a critical issue for users.\nThe open-source project Software Define Edge WAN(SD-EWAN) under the Akraino community’s ICN blueprint is definitely a comprehensive solution. Its CNF, which is integrated with multiple network functions based on OpenWRT, is able to serve the distributed applications with secure connections and easy management against networking and the CNF can be automatic thru the overlay controller within SD-EWAN to achieve multi-edge collaboration.\nThis post is not covering the archtecture of SDEWAN. If you want to lean more about SDEWAN you can find more information form https://github.com/akraino-edge-stack/icn-sdwan. Intention of this post is to cover the CNF which co-works with Intel Software Guard Extensions to create a secruity IPsec tunnel.\nSecurity Connection Between Edge Cluster Through CNF One of the functionality of SD-EWAN is to set up secure connection between two edge cluster. SDEWAN functionality is realized via CNF(Containerized Network Function) and deployed by K8s. SD-EWAN creates IPsec tunnles between two CNF Pod across K8s cluster. The CNF here is based on OpenWRT open source and enhancing, optimizing for Intel IA sccelerator and make it ready for cloud native Edge scenarios.\nIn the CNF, we use Strongswan to manage the IPsec tunnel and connect two Edges in a private network the a traffice Hub. The traffice Hub has an publice IP, and two different Edges can access the Hub through the public IP bind on the hub.\nTraditional Configuration of IPsec The Traditional configuration put the private key and certificate in the Pod filesystem located at /etc/ipsec.d.\nLeverage SGX to Create Secure Tunnle Archtecture The architecture of the CNF which work with CTK is like that.\nEnable PKCS#11 for Strongswan Build p11-kit-client for OpenWRT After build the p11-kit-client, we shoud add Setup IPsec Tunnel with SGX ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/sdewan/sdewan-sgx/","summary":"SD-WAN handles the network connectivity issues between distributed applications in a seamless, secure, and efficient manner by replacing traditional branch routers with virtualized or appliance-based software. However, as the concept of edge prevails recently, distributed applications are usually deployed across multiple resource-constrained k8s edges. Then how to expose the services and manage the connections in a cloud-native way becomes a critical issue for users.\nThe open-source project Software Define Edge WAN(SD-EWAN) under the Akraino community’s ICN blueprint is definitely a comprehensive solution.","tags":null,"title":"SDEWAN Leverage SGX to provide Secure Access Service Edge"},{"categories":null,"contents":"SDEWAN: Setup by pull mode Version requirement:\n​\tUbuntu: 20.04\n​\tscc: build from https://github.com/intel-sandbox/akraino-sdewan/tree/rc-22.06\n​\tcnf: docker pull integratedcloudnative/sdewan-cnf:0.5.3\ncrd-controller: docker pull integratedcloudnative/sdewan-controller:0.5.3\n0.Create an Github repo for pull mode ​\tCreate an Github repo for SDEWAN pull mode, for example: https://github.com/airren/flux\n​ Next, prepare an Personal access tokens for SDEAN to access the repo.\nUpdate your repo info and token to this file SDEWAN-SetUp/ewo-tools/cluster-sync-object.yaml.\n1# SDEWAN-SetUp/ewo-tools/cluster-sync-object.yaml 2--- 3# creating cluster-sync-obj 4version: ewo/v1 5resourceContext: 6anchor: overlays/overlay1/cluster-sync-objects 7metadata: 8name: cso2 9description: 10userData1: 11userData2: 12spec: 13kv: 14- gitType: github 15- userName: Airren # change to your own github username 16- gitToken: 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 # change to your own 17- repoName: flux # change to your own 18- branch: main Update the GITHUB_TOKEN in SDEWAN-SetUp/setup_flux.sh\nUpdate the repo info and token in SDEWAN-SetUp/monitor_stuff/monitor_configs\n1username=Airren # change to your own 2token=ghp_LaAMXYmdcSWbmSOp9fQPL # change to your own 3repo_name=flux 4cluster=akraino_scc_overlay1+edge-1 5http_proxy=http://proxy-prc.intel.com:913 6https_proxy=http://proxy-prc.intel.com:913 1. Setup 4 VMs with SDEWAN base components 1./0_auto_setup.sh -n \u0026lt;vm-perfix\u0026gt; After that, you will install most the components of SDEWAN. But due to the proxy limitation, we have to do some check work manually.\na. Add proxy configuration to the git repo for Hub/Edge-1/Edge-2. https://github.com/Airren/flux/blob/main/clusters/akraino_scc_overlay1%2Bedge-2/flux-system/kustomization.yaml\n1patches: 2 - patch: | 3 apiVersion: apps/v1 4 kind: Deployment 5 metadata: 6 name: all 7 spec: 8 template: 9 spec: 10 containers: 11 - name: manager 12 env: 13 - name: \u0026#34;HTTPS_PROXY\u0026#34; 14 value: \u0026#34;http://proxy-prc.intel.com:913\u0026#34; 15 - name: \u0026#34;HTTP_PROXY\u0026#34; 16 value: \u0026#34;http://proxy-prc.intel.com:913\u0026#34; 17 - name: \u0026#34;NO_PROXY\u0026#34; 18 value: \u0026#34;10.0.11.1/24,10.95.62.1/16,192.169.0.1/24,192.168.0.1/24,10.233.0.1/16,localhost,10.96.0.1/24,192.168.174.0/24,172.17.0.1/24,.cluster.local.,.cluster.local,.svc\u0026#34; 19 target: 20 kind: Deployment 21 labelSelector: app.kubernetes.io/part-of=flux b. Re run flux init on Hub/Edge-1/Edge-2, check the result\n1# for hub cluster 2setup_flux.sh hub 3# for edge-1 cluster 4setup_flux.sh edge-1 5# for edge-2 cluster 6setup_flux.sh edge-2 c. Re-deploy monitor if need on Hub/Edge-1/Edge-2 respectively.\n1SDEWAN-SetUp/monitor_stuff/monitor-deploy.sh 2.Register Overlay 1cd SDEWAN-SetUp/ewo-tools 2./ewoctl --config ./ewo-config.yaml apply -f pre.yaml 3./ewoctl --config ./ewo-config.yaml apply -f cluster-sync-object.yaml 3.Register Hub/Edge-1/Edge-2 1cd SDEWAN-SetUp/ewo-tools 2./ewoctl --config ./ewo-config.yaml apply -f huba.yaml 3./ewoctl --config ./ewo-config.yaml apply -f edge-1.yaml 4./ewoctl --config ./ewo-config.yaml apply -f edge-2.yaml 4.Register Hub/Edge-1/Edge-2 1cd SDEWAN-SetUp/ewo-tools 2./ewoctl --config ./ewo-config.yaml apply -f huba-edge-1-con.yaml 3./ewoctl --config ./ewo-config.yaml apply -f huba-edge-2-con.yaml 5.Deploy Application as before. Other Notes: (Not Need, Just for Debug) 1 kubectl patch deployments.apps -n flux-system source-controller --patch-file patch.yaml 2 3 k patch deployments.apps -n sdewan-system rsync --patch-file rsync-patch.yaml ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/sdewan/sdewan-pull-mode/","summary":"SDEWAN: Setup by pull mode Version requirement:\n​\tUbuntu: 20.04\n​\tscc: build from https://github.com/intel-sandbox/akraino-sdewan/tree/rc-22.06\n​\tcnf: docker pull integratedcloudnative/sdewan-cnf:0.5.3\ncrd-controller: docker pull integratedcloudnative/sdewan-controller:0.5.3\n0.Create an Github repo for pull mode ​\tCreate an Github repo for SDEWAN pull mode, for example: https://github.com/airren/flux\n​ Next, prepare an Personal access tokens for SDEAN to access the repo.\nUpdate your repo info and token to this file SDEWAN-SetUp/ewo-tools/cluster-sync-object.yaml.\n1# SDEWAN-SetUp/ewo-tools/cluster-sync-object.yaml 2--- 3# creating cluster-sync-obj 4version: ewo/v1 5resourceContext: 6anchor: overlays/overlay1/cluster-sync-objects 7metadata: 8name: cso2 9description: 10userData1: 11userData2: 12spec: 13kv: 14- gitType: github 15- userName: Airren # change to your own github username 16- gitToken: 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 # change to your own 17- repoName: flux # change to your own 18- branch: main Update the GITHUB_TOKEN in SDEWAN-SetUp/setup_flux.","tags":null,"title":"SDEWAN Setup"},{"categories":null,"contents":"Prepare Machine 1sudo ip route add default via 10.0.11.100 dev eno1 2 3cat \u0026lt;\u0026lt;EOF | sudo tee /etc/resolv.conf 4nameserver 127.0.0.53,10.248.2.5 5options edns0 trust-ad 6search sh.intel.com 7EOF 8 9sudo vi /etc/netplan/00-installer-config.yaml 10network: 11 ethernets: 12 eno1: 13 dhcp4: true 14 nameservers: 15 addressses: [10.248.2.5] 16 version: 2 17 18 19 20git clone -b sgx http://sdewan.sh.intel.com:10880/airren/SDEWAN-SetUp.git 21 22 23 24 25apt-cache search linux-image 26sudo apt-get install linux-image-your_version_choice linux-headers-your_version_choice linux-image-extra-your_version_choice 27 28# must reboot you machine 29sudo apt update \u0026amp;\u0026amp; sudo apt install -y linux-image-5.15.0-33-generic linux-headers-5.15.0-33-generic linux-modules-5.15.0-33-generic linux-modules-extra-5.15.0-33-generic 30# https://packages.ubuntu.com/focal-updates/kernel/ ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/sdewan/sdewan-sgx-testenv/","summary":"Prepare Machine 1sudo ip route add default via 10.0.11.100 dev eno1 2 3cat \u0026lt;\u0026lt;EOF | sudo tee /etc/resolv.conf 4nameserver 127.0.0.53,10.248.2.5 5options edns0 trust-ad 6search sh.intel.com 7EOF 8 9sudo vi /etc/netplan/00-installer-config.yaml 10network: 11 ethernets: 12 eno1: 13 dhcp4: true 14 nameservers: 15 addressses: [10.248.2.5] 16 version: 2 17 18 19 20git clone -b sgx http://sdewan.sh.intel.com:10880/airren/SDEWAN-SetUp.git 21 22 23 24 25apt-cache search linux-image 26sudo apt-get install linux-image-your_version_choice linux-headers-your_version_choice linux-image-extra-your_version_choice 27 28# must reboot you machine 29sudo apt update \u0026amp;\u0026amp; sudo apt install -y linux-image-5.","tags":null,"title":"SDEWAN SGX Test Environment"},{"categories":null,"contents":"1node-1 10.151.128.13 2node-2 10.151.128.14 1# Hub 2ip rule add iif vti_192.169.0.1 lookup 51 3ip rule add iif vti_192.169.0.2 lookup 51 4ip route add default via \u0026lt;net pod\u0026gt; dev net1 table 51 5#ip route add default via 10.151.128.13 dev net1 table 51 6 7# Node-1 8ip route add 192.169.0.0/24 via 10.151.128.14 dev net1 9 10# Node-2 11ip route add 192.169.0.0/24 via 10.151.128.12 dev net1 12 13 14sysctl -w net.ipv4.ip_forward=1 15 echo 1 \u0026gt; /proc/sys/net/ipv4/ip_forward ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/sdewan/service-function-chain/","summary":"1node-1 10.151.128.13 2node-2 10.151.128.14 1# Hub 2ip rule add iif vti_192.169.0.1 lookup 51 3ip rule add iif vti_192.169.0.2 lookup 51 4ip route add default via \u0026lt;net pod\u0026gt; dev net1 table 51 5#ip route add default via 10.151.128.13 dev net1 table 51 6 7# Node-1 8ip route add 192.169.0.0/24 via 10.151.128.14 dev net1 9 10# Node-2 11ip route add 192.169.0.0/24 via 10.151.128.12 dev net1 12 13 14sysctl -w net.ipv4.ip_forward=1 15 echo 1 \u0026gt; /proc/sys/net/ipv4/ip_forward ","tags":null,"title":"Service function chain"},{"categories":null,"contents":"计算生物学家的一项工作就是根据密码将DNA转换为由4个碱基组成的非常长的字符串。\nKnuth、Morris、Pratt 子字符串查找算法，这些经典算法的基础是两个基本概念：形式语言和确定有限状态自动机。\nJACA 安装配置\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/DataStruct/string/","summary":"计算生物学家的一项工作就是根据密码将DNA转换为由4个碱基组成的非常长的字符串。\nKnuth、Morris、Pratt 子字符串查找算法，这些经典算法的基础是两个基本概念：形式语言和确定有限状态自动机。\nJACA 安装配置","tags":null,"title":"String 字符串"},{"categories":null,"contents":"When reading/adjusting any StrongSwan configurations, remember these important words:\nleft is local to the machine it\u0026rsquo;s stated on; right is remote in the same manner\nSo, on the server side, left is local to the server and on the client side, left is local to that client.\ncheck the X509 cert details\n1openssl x509 -text -noout -in /etc/ipsec.d/private/sunKey.pem ​\nUbuntu Set up IPsec Tunnel 1docker run --rm -d -i --network host --name cnf --user root -v /home/ubuntu/entrypoint.sh:/entrypoint.sh --privileged cnf:pro sleep infinity 2 3 4docker run --rm -i -d --network host --name cnf --user root -v /home/ubuntu/entrypoint.sh:/entrypoint.sh --privileged cnf:pro bash -c \u0026#39;/entrypoint.sh\u0026#39; Install StrongsWan 1sudo apt update \u0026amp;\u0026amp; sudo apt install strongswan strongswan-swanctl strongswan-pki strongswan-charon charon-cmd charon-systemd -y 2 3 4sudo apt remove strongswan strongswan-swanctl strongswan-pki strongswan-charon charon-cmd charon-systemd -y 在如下两台机器之间 建立 host-to-host的ipsec tunnle, 以下配置过程整理自Strongswan.\n1| 10.95.62.25 | === | 10.95.62.114 | 2 moon sun 生成证书 使用strongswan的PKI tool 创建证书。\n1# 创建 root 私钥 2pki --gen --outform pem \u0026gt; caKey.pem 3# 生成 root CA 4pki --self --in caKey.pem --dn \u0026#34;C=CH, O=strongSwan, CN=strongSwan CA\u0026#34; --ca --outform pem \u0026gt; caCert.pem 5 6# 生成 node-1 私钥 7pki --gen --outform pem \u0026gt; moonKey.pem 8# 使用 root ca签发 node-1 端证书 9pki --issue --in moonKey.pem --type priv \\ 10--cacert caCert.pem --cakey caKey.pem \\ 11--dn \u0026#34;C=CH, O=strongSwan,CN=moon.strongswan.org\u0026#34; --san moon.strongswan.org \\ 12--outform pem \u0026gt; moonCert.pem 13 14# 生成 node-2 私钥 15pki --gen --outform pem \u0026gt; sunKey.pem 16# 使用 root ca签发 node-1 端证书 17pki --issue --in sunKey.pem --type priv \\ 18--cacert caCert.pem --cakey caKey.pem \\ 19--dn \u0026#34;C=CH, O=strongSwan,CN=sun.strongswan.org\u0026#34; --san sun.strongswan.org \\ 20--outform pem \u0026gt; sunCert.pem Host-to-Host 配置 Configuration on host moon:\n1 sudo cp caCert.pem /etc/swanctl/x509ca/caCert.pem 2 sudo cp moonCert.pem /etc/swanctl/x509/moonCert.pem 3 sudo cp moonKey.pem /etc/swanctl/private/moonKey.pem 4 5/etc/swanctl/swanctl.conf: 6 7 connections { 8 host-host { 9 #remote_addrs = 52.9.61.247 10 pools=client_pool 11 12 local { 13 auth=pubkey 14 certs = moonCert.pem 15 } 16 remote { 17 auth = pubkey 18 id = \u0026#34;C=CH, O=strongSwan, CN=sun.strongswan.org\u0026#34; 19 } 20 children { 21 net-net { 22 remote_ts=192.168.0.1/32 23 start_action = trap 24 } 25 } 26 } 27 } 28 pools{ 29 client_pool{ 30 addrs=192.168.0.1 31 } 32} Configuration on host sun:\n1sudo cp caCert.pem /etc/swanctl/x509ca/caCert.pem 2sudo cp sunCert.pem /etc/swanctl/x509/sunCert.pem 3sudo cp sunKey.pem /etc/swanctl/private/sunKey.pem 4 5/etc/swanctl/swanctl.conf: 6 7 connections { 8 host-host { # connection name 9 remote_addrs = 34.230.111.156 10 11 local { 12 auth = pubkey 13 certs = sunCert.pem 14 } 15 remote { 16 auth = pubkey 17 id = \u0026#34;C=CH, O=strongSwan, CN=moon.strongswan.org\u0026#34; 18 } 19 children { 20 host-host { 21 remote_ts=10.20.0.118/32 22 start_action = trap 23 } 24 } 25 } 26 } 上述配置是 是用key做认证，下面举个使用pre-shared key的例子\n1 # configuration on moon 2 connections { 3 host-host { 4 remote_addrs = 10.95.62.114 5 6 local { 7 auth=psk 8 id = \u0026#34;moon.strongswan.org\u0026#34; 9 } 10 remote { 11 auth = psk 12 id = \u0026#34;sun.strongswan.org\u0026#34; 13 } 14 children { 15 net-net { 16 start_action = trap 17 } 18 } 19 } 20 } 21 secrets{ 22 ike-h2h{ 23 id-moon = \u0026#34;moon.strongswan.org\u0026#34; 24 id-sun = \u0026#34;sun.strongswan.org\u0026#34; 25 secret = mysecret 26 } 27} 28 29 # configuration on sun 30 connections { 31 host-host { # connection name 32 remote_addrs = 10.95.62.25 33 34 local { 35 auth = psk 36 id = \u0026#34;sun.strongswan.org\u0026#34; 37 } 38 remote { 39 auth = psk 40 id = \u0026#34;moon.strongswan.org\u0026#34; 41 } 42 children { 43 host-host { 44 start_action = trap 45 } 46 } 47 } 48 } 49 secrets{ 50 ike-h2h{ 51 id-moon = \u0026#34;moon.strongswan.org\u0026#34; 52 id-sun = \u0026#34;sun.strongswan.org\u0026#34; 53 secret = mysecret 54 } 55 } 配置完成后，可以使用swanclt --load-all 使配置生效。\n如果给initiator 分配一个Virtual IP.\nInitiator 获得虚拟IP后会再 IP table 220 中增加对应IP的路由方式。\nSmartCard demo with OpenSC Build Strongswan with pcks11 1# install essential dependency 2sudo apt install build-essential libgmp-dev libunbound-dev libldns-dev -y 3git clone https://github.com/strongswan/strongswan.git 4./autogen.sh 5# config 6# ./configure --prefix=/usr --sysconfdir=/etc --enable-eap-mschapv2 --enable-kernel-libipsec --enable-swanctl --enable-unity --enable-unbound --enable-vici --enable-xauth-eap --enable-xauth-noauth --enable-eap-identity --enable-md4 --enable-pem --enable-openssl --enable-pubkey --enable-farp --enable-pkcs11 7./configure --prefix=/usr --sysconfdir=/etc --enable-pkcs11 CFLAGS=\u0026#34;-DDEBUG_LEVEL=1\u0026#34; 8make 9sudo make install 10sudo systemctl daemon-reload 11sudo systemctl restart strongswan-starter.service Build virt_cacard virt_card using libcacard, vitualsmartcard\u0026rsquo;s vpcd and softhsm2 to provide PCSC accessible virtual smart card.\n1# install essential dependency, libcacard \u0026amp; softhsm2 2sudo apt install libcacard-dev libglib2.0-dev softhsm2 gnutls-bin libnss3-tools -y Build \u0026amp; Install vsmartcard\n1sudo apt-get install -y help2man libpcsclite-dev 2git clone https://github.com/frankmorgner/vsmartcard.git 3cd vsmartcard/virtualsmartcard 4autoreconf --verbose --install 5./configure --sysconfdir=/etc 6make 7sudo make install Build \u0026amp; Install virt_card\n1cd ~ 2git clone https://github.com/Jakuje/virt_cacard.git 3cd virt_cacard 4./autogen.sh 5./configure 6make configure softhsm with default certificates and start virt_cacard\n1./setup-softhsm2.sh 2export SOFTHSM2_CONF=/home/ubuntu/vivirt_cacard/softhsm2.conf \u0026amp;\u0026amp;./virt_cacard After that you should be able to access virtual smart card through OpenSC:\n1pkcs11-tool -L 1pkcs15-tool --list-pins --list-keys --list-certificates 1# Generate Key pair 2openssl req -out pkcs11-new.csr -newkey rsa:2048 -nodes -keyout pkcs11-new.key -subj \u0026#34;/CN=pkcs11-new\u0026#34; 3# Generate Certificate 4openssl x509 -req -days 365 -CA caCert.pem -CAkey caKey.pem -set_serial 1 -in pkcs11-new.csr -out pkcs11-new.crt 5# Transform CA type to DER 6 openssl rsa -in ./pkcs11-new.key -outform DER -out pkcs11-new.key.der 7 openssl x509 -in ./pkcs11-new.crt -outform DER -out pkcs11-new.crt.der 8 9 10 # Creating a token 11# pkcs11-tool --init-token --label \u0026#34;pkcs11-new\u0026#34; --slot 0--so-pin 12345678 --init-pin --pin 12345678 12 13 # add private key 14 pkcs11-tool -login --pin 12345678 --login-type user --slot 0 --write-object pkcs11-new.key.der --type privkey --id 0001 15 # add cert 16 pkcs11-tool -login --pin 12345678 --login-type user --slot 0 --write-object pkcs11-new.crt.der --type cert --id 0001 Common Tools of PKCS#11 1# list slot 2pkcs11-tool --module /usr/local/lib/libp11sgx.so -L 3# list object of slot 4pkcs11-tool --module /usr/local/lib/libp11sgx.so --slot 0x7316c269 -O Creating a token 1 pkcs11-tool --module /usr/local/lib/libp11sgx.so --init-token --label \u0026#34;ctk\u0026#34; --slot 0 --so-pin 1234 --init-pin --pin 1234 Creating an RSA keypair 1pkcs11-tool --module /usr/local/lib/libp11sgx.so --login --pin 1234 --id 0001 --token \u0026#34;ctk\u0026#34; --keypairgen --key-type rsa:3072 --label \u0026#34;cert-key\u0026#34; --usage-sign Listing the objects 1pkcs11-tool --module /usr/local/lib/libp11sgx.so --list-objects -login --pin 1234 --login-type user 1# login 2pkcs11-tool --module /usr/local/lib/libp11sgx.so -login --pin 1234 --login-type user --slot 0x18c37829 - 3 #listobject 4 pkcs11-tool --module /usr/local/lib/libp11sgx.so -login --pin 1234 --login-type user --slot 0x18c37829 -O 5# delete private key 6 pkcs11-tool --module /usr/local/lib/libp11sgx.so -login --pin 1234 --login-type user --slot 0x18c37829 --delete-object --type privkey -d 0001 7 # delete public key 8 pkcs11-tool --module /usr/local/lib/libp11sgx.so -login --pin 1234 --login-type user --slot 0x18c37829 --delete-object --type pubkey -d 0001 9 10 # add private key 11 pkcs11-tool --module /usr/local/lib/libp11sgx.so -login --pin 12345678 --login-type user --slot 0x18c37829 --write-object clientkey.der --type privkey --id 0001 12 # add cert 13 pkcs11-tool --module /usr/local/lib/libp11sgx.so -login --pin 1234 --login-type user --slot 0xc8cbdbc --write-object clientcrt.der --type cert --id 0001 14 15 # create key paair 16 pkcs11-tool --module /usr/local/lib/libp11sgx.so --login --pin 1234 --id 0001 --token \u0026#34;ctk\u0026#34; --keypairgen --key-type rsa:3072 --label \u0026#34;cert-key\u0026#34; --usage-sign --slot 0x18c37829 Smart Demo with Intel SGX CTK Build and Install SGX SDK\nBuild \u0026amp; Install SDK 1# Ubuntu 20.04 2sudo apt-get install build-essential ocaml ocamlbuild automake autoconf libtool wget python-is-python3 libssl-dev git cmake perl -y 3sudo apt-get install libssl-dev libcurl4-openssl-dev protobuf-compiler libprotobuf-dev debhelper cmake reprepro unzip -y 4 5sudo apt-get install build-essential python -y 6 7git clone https://github.com/intel/linux-sgx.git 8cd linux-sgx \u0026amp;\u0026amp; make preparation 9sudo cp external/toolset/{current_distr}/{as,ld,ld.gold,objdump} /usr/local/bin 10which as ld ld.gold objdump 11 12make sdk 13make sdk_install_pkg 14# linux/installer/bin/sgx_linux_x64_sdk_${version}.bin location /opt/intel 15 16export SDK_INSTALL_PATH_PREFIX=/opt/intel 17./sgx_linux_x64_sdk_${version}.bin --prefix $SDK_INSTALL_PATH_PREFIX 18 source ${sgx-sdk-install-path}/environment 19 # source /opt/intel/sgxsdk/environment verify SGX SDK\n1$ cd ${sgx-sdk-install-path}/SampleCode/LocalAttestation 2 $ make SGX_MODE=SIM 3 $ cd bin 4 $ ./app Build \u0026amp; Install PSW 1make psw 2make deb_psw_pkg 3make deb_local_repo 4# linux/installer/deb/sgx_debian_local_repo 5# deb [trusted=yes arch=amd64] file: /home/ubuntu/linux-sgx/linux/installer/deb/local_repo_tool/../sgx_debian_local_repo focal main 6sudo apt update 7sudo apt-get install libsgx-launch libsgx-urts -y Build \u0026amp; Install Intel-sgx-ssl 1make all test 2sudo make install Build \u0026amp; Install CTK 1sudo apt-get install dkms autoconf libcppunit-dev autotools-dev libc6-dev libtool build-essential -y 2#libprotobuf10 3 4make 5sudo make install Build \u0026amp; Install pkcs11 Tool 1git clone https://github.com/Mastercard/pkcs11-tools.git 2./configure 3sudo make install use p11req generate csr\n1p11req -i my-ec-key -d \u0026#39;/CN=my.site.org/O=My organization/C=BE\u0026#39; -e \u0026#39;DNS:another-url-for-my.site.org\u0026#39; -v Initialize HSM \u0026amp; Generate Cert 1# Init Token 2pkcs11-tool --module /usr/local/lib/libp11sgx.so --init-token --label \u0026#34;sgx-pkcs11\u0026#34; --slot 0 --so-pin 12345678 --init-pin --pin 12345678 3#Create Key Pair 4pkcs11-tool --module /usr/local/lib/libp11sgx.so --login --pin 12345678 --id 0001 --token \u0026#34;sgx-pkcs11\u0026#34; --keypairgen --key-type rsa:2048 --label \u0026#34;cert-key\u0026#34; --usage-sign 5 6# Check slot info 7pkcs11-tool --module /usr/local/lib/libp11sgx.so -L 8 9# Create csr, cert-key is the private lable 10p11req -l /usr/local/lib/libp11sgx.so -i cert-key -d \u0026#39;/CN=sgx-node\u0026#39; -s 0x5e6dceb4 -p 12345678 \u0026gt; new.csr 11 12# Issuer the cert from root CA 13openssl x509 -req -days 365 -CA caCert.pem -CAkey caKey.pem -set_serial 1 -in new.csr -out client.crt 14# Transfer to DER form 15openssl x509 -in client.crt -outform DER -out clientcrt.der 16# Add cert to HSM 17pkcs11-tool --module /usr/local/lib/libp11sgx.so -login --pin 12345678 --login-type user --slot 0x5e6dceb4 --write-object clientcrt.der --type cert --id 0001 18 19# Check private Key and Cert status 20pkcs11-tool --module /usr/local/lib/libp11sgx.so --login --pin 12345678 -O --slot 0x5e6dceb4 1#需要下载的 组件 2 3crypto-api-toolkit intel-sgx-ssl linux-sgx linux-sgx-driver OpenSC pkcs11 SDEWAN-SetUp SGX.code-workspace sgx-pkcs11 sgx-software-enable strongswan virt_cacard vsmartcard Configure PCKS#11 Plugin of Strongswan 1#strongswan.d/charon/pkcs11.conf 2pkcs11 { 3 load = yes 4 modules { 5 ctk{ 6 path=/usr/local/lib/libp11sgx.so 7 os_locking=yes 8 load_certs=yes 9 } 10 } 11 12} 13 14 15bash-5.1$ /usr/lib/libp11-kit.so.0^C 16 17 18echo \u0026#39;pkcs11 { 19 load = yes 20 modules { 21 ctk{ 22 path=/usr/lib/p11-kit-client.so 23 os_locking=yes 24 load_certs=yes 25 } 26 } 27}\u0026#39; | sudo tee /etc/strongswan.d/charon/pkcs11.conf Configure IPsec Tunnel through swanctl.conf 1# /etc/swanctl/swanctl.conf 2connections { 3 pkcs11-demo{ # connection name 4 # remote_addrs = 10.95.62.25 5 pools = client_pool 6 7 local { 8 auth = pubkey 9 cert1{ 10 handle=0001 11 slot=0x11 12 module=ctk 13 } 14 } 15 remote { 16 auth = pubkey 17 id = \u0026#34;CN=sun.strongswan.org\u0026#34; 18 } 19 children { 20 pkcs11-demo { 21 start_action = trap 22 } 23 } 24 } 25} 26 27pools{ 28 client_pool{ 29 addrs=192.168.0.1 30 } 31} 32 33secrets{ 34# token_1{ 35# handle=0001 36# slot=0 37# module=opensc 38# pin=12345678 39# } 40 token_2{ 41 handle=0001 42 slot=0x11 43 module=ctk 44 pin=12345678 45 } 46} 47 48 49 50 51 52# /etc/swanctl/swanctl.conf 53connections { 54 pkcs11-demo{ # connection name 55 remote_addrs = 10.233.76.178 56 local { 57 auth = pubkey 58 cert1{ 59 handle=0001 60 slot=0x11 61 module=ctk 62 } 63 } 64 remote { 65 auth = pubkey 66 id = \u0026#34;CN=sgx-1\u0026#34; 67 } 68 children { 69 pkcs11-demo { 70 start_action = trap 71 } 72 } 73 } 74} 75 76 77 78secrets{ 79 token_1{ 80 handle=0001 81 slot=0x11 82 module=ctk 83 pin=12345678 84 } 85} Configure IPsec Tunnel Through ipsec.conf use different secret 1# /etc/ipsec.conf 2 3# ipsec.conf - strongSwan IPsec configuration file 4 5sudo cp caCert.pem /etc/ipsec.d/cacerts/ 6sudo cp moonKey.pem /etc/ipsec.d/private/ 7sudo cp moonCert.pem /etc/ipsec.d/certs/ 8 9conn host-host 10 left=%any 11 right=%any 12 ikelifetime=3h 13 lifetime=1h 14 margintime=9m 15 keyingtries=%forever 16 dpdaction=restart 17 dpddelay=30s 18 closeaction=restart 19 leftauth=pubkey 20 rightauth=pubkey 21 leftcert=moonCert.pem 22 leftsendcert=yes 23 rightsendcert=yes 24 rightsourceip=192.168.0.8 25 auto=start 26 leftid=\u0026#34;C=CH, O=strongSwan, CN=moon.strongswan.org\u0026#34; 27 rightid=\u0026#34;C=CH, O=strongSwan, CN=sun.strongswan.org\u0026#34; 28 keyexchange=ikev2 29 mark=30 30 esp=aes128-sha256-modp3072,aes256-sha256-modp3072 31 ike=aes128-sha256-modp3072,aes256-sha256-modp3072 32 type=tunnel 33 34 35 36conn host-host 37 left=%any 38 right=34.230.111.156 39 ikelifetime=3h 40 lifetime=1h 41 margintime=9m 42 keyingtries=%forever 43 dpdaction=restart 44 dpddelay=30s 45 closeaction=restart 46 leftauth=pubkey 47 rightauth=pubkey 48 leftcert=sCert.pem 49 leftsendcert=yes 50 rightsendcert=yes 51 rightsourceip=192.169.0.8 52 auto=start 53 leftid=\u0026#34;C=CH, O=strongSwan, CN=sun.strongswan.org\u0026#34; 54 rightid=\u0026#34;C=CH, O=strongSwan, CN=moon.strongswan.org\u0026#34; 55 keyexchange=ikev2 56 mark=30 57 esp=aes128-sha256-modp3072,aes256-sha256-modp3072 58 ike=aes128-sha256-modp3072,aes256-sha256-modp3072 59 type=tunnel 60 61 62 63conn common-con 64 left=%any 65 right=%any 66 ikelifetime=3h 67 lifetime=1h 68 margintime=9m 69 keyingtries=%forever 70 dpdaction=restart 71 dpddelay=30s 72 closeaction=restart 73 leftauth=pubkey 74 rightauth=pubkey 75 leftcert=/etc/ipsec.d/certs/root-nodeCert.pem 76 leftsendcert=yes 77 rightsendcert=yes 78 rightsourceip=192.168.0.9 79 auto=start 80 leftid=\u0026#34;CN=root-node\u0026#34; 81 rightid=\u0026#34;C=CH, O=strongSwan,CN=node-3\u0026#34; 82 keyexchange=ikev2 83 mark=30 84 esp=aes128-sha256-modp3072,aes256-sha256-modp3072 85 ike=aes128-sha256-modp3072,aes256-sha256-modp3072 86 type=tunnel 87 88 89 90 # client 91sudo cp caCert.pem /etc/ipsec.d/cacerts/ 92sudo cp sunKey.pem /etc/ipsec.d/private/ 93sudo cp sunCert.pem /etc/ipsec.d/certs/ 94 95conn common-con 96 left=%any 97 right=10.233.76.178 98 leftsourceip=%config 99 ikelifetime=3h 100 lifetime=1h 101 margintime=9m 102 keyingtries=%forever 103 dpdaction=restart 104 dpddelay=30s 105 closeaction=restart 106 leftauth=pubkey 107 rightauth=pubkey 108 leftcert=%smartcard:0001 109 leftsendcert=yes 110 rightsendcert=yes 111 auto=start 112 leftid=\u0026#34;CN=sgx-2\u0026#34; 113 rightid=\u0026#34;CN=sgx-1\u0026#34; 114 keyexchange=ikev2 115 esp=aes128-sha256-modp3072,aes256-sha256-modp3072 116 ike=aes128-sha256-modp3072,aes256-sha256-modp3072 117 type=tunnel ipsec.secrets\n1# /etc/ipsec.secrets 2C=CH, O=strongSwan,CN=sun.strongswan.org : RSA sunKey.pem 3: PIN %smartcard:0001 \u0026#34;12345678\u0026#34; 1# 1. Add strongswan.d/chron/pkcs11.conf 2 3 4# 2. This is the firsth /usr/sbin/ipsec start \u0026ndash;nofork\nIPsec protocol overview IPsec is a framework, which provide security at the network layer of the OSI model by enabling a system to select required security protocols, determine the algorithms to use for security services, and implement any cryptographic keys required to provide secure communication.\nIPsec architecture consist of:\nBasic concept:\nSecurity Association(SA)\nSecurity Association Database\nFundamental security protocols\nESP/AH Protocol mode\ntransport/tunnel Various cryptographic primitives with AH and ESP\nEncryption: DES, 3DES, AES-CBC Integrity: HMAC, MD5, SHA1, SHA2 Key management procedures\nIKEv1, IKEv2, ISAKMP Security Association(SA) is a set of IPsec specifications that are negotiated between devices that are establishing an IPsec relationship. The specifications include preferences for the type of authentication, encryption, and security protocol that should be used when establishing the IPsec connection. A single SA protects data in one direction An SA is uniquely identified by: Security Parameter Index(SPI) IPv4 or IPv6 destination address security protocol(AH or ESP) identifier Security associations are stored in a security associations database(SADB) Security Associations(SAs) require keying material for authentication and for encryption. The managing of this keying material is called key management. The Internet Key Exchange(IKE) protocol is used to exchange SAs between two devices. IKE is based on Internet Security Association and Key Management Protocol( ISAKMP) Two version of IKE are defined(IKEv1 and IKEv2), but at present IKE2 is mostly used IPsec session consists of the following phases: establishing IKE SA (IKE phase I) establishing IPsec SA (IKE phase II) secured communication(IPsec tunnel) re-keying procedures( IKE CHILD_SA) IP tunnel termination( IKE \u0026ldquo;delete\u0026rdquo;) Experiment has been performed using two virtual machines Strongswan has been used as IPsec implementation Red Machine: 192.168.56.100 === Blue Machine: 192.16.56.101\nBasic Strongswan configuration\nIPsec configuration files:\n/etc/ipsec.conf IPsec tunnel parameters /etc/ipsec.secret cryptographic secrets 1# Blue 2conn bule-to-red 3 authby=secret # authentication method 4 auto=route 5 keyexchange=ikev2 # key exchange protocol 6 ike=ase256-sha2_256-modp1024 # IKE secrity association proposal 7 left=192.168.56.101 # IP of both ends of tunnel 8 right=192.168.56.100 9 type=transport # IPsec mode(tunnel or transport) 10 esp=aes256-sha2_256 # IPsec security association proposal(ESP/ AH) 11 #ah=sha1-sha256-modp1024 12 13 14# RED 15conn red-to-blue 16 authby=secret 17 #ah=sha1-sha256-modp1024 18 auto=route 19 keyexchange=ikev2 20 ike=ase256-sha2_256-modp1024 # 3des-sha2_256-modp1024 21 left=192.168.56.100 22 right=192.168.56.101 23 type=transport 24 esp=aes256-sha2_256 1sudo ipsec stroke loglevel ike 4 2 3sudo tcpdump -i eth0 -w ike.pcap IKE and IPsec negotiation\nIKE Phase I (IKE SA negotiation) creates a secure channel between the two IKE peers. IKE SA is negotiated during phase I and the Diffie-Hellman key agreements is always performed in this phase. IKE Phase II (IPsec SA negotiation) negotiates the IPsec security associations and generates the required key material for IPsec(encryption and integrity Keys). Peers authenticate echo other is this phase. A new Diffie-Hellman agreement may be done in phase2, or the keys may be derived form the phase 1. Re-keying (IKE or IPsec) is invoked by send CREATE_CHILD_SA IKE tunnel termination is perform by sending IKE INFORMATIONAL message with payload \u0026ldquo;delete\u0026rdquo; IKE SA proposals of RED and BLUE endpoint(the same now)\n1IKE algorithmn 2 3--- RED -- 4IKE ENCR ALG: AES-CBC-256 # encryption algorithm 5IKE AUTH ALG: HMAC_SHA2_256_128 # Integrity algorithm 6IKE D-H GROUP: MODP 1024-bit # Diffie-Hellman group 7PRF: NOT CONFIGURABLE # Pseudo random function 8 9--- BLUE -- 10IKE ENCR ALG: AES-CBC-256 11IKE AUTH ALG: HMAC_SHA2_256_128 12IKE D-H GROUP: MODP 1024-bit 13PRF: NOT CONFIGURABLE Let\u0026rsquo;s change encryption algorithm proposal of RED endpoint, is the IKE algorithm not equal. BULE endpoint doesn\u0026rsquo;t accept IKE SA proposal with \u0026ldquo;3des\u0026rdquo; encryption algorithm. BULE doesn\u0026rsquo;t support such algorithm and responds with NO_PROPOSAL_CHOSEN payload. Inconsistency of encryption algorithm. Now red\u0026rsquo;s IKE SA proposal has been accepted by BLUE. Authentication process has been started.\nNote, the IPsec SA negotiation (Phase II) and authentication has been successful.\nAfter decryption using keys, we can see IKE_AUTH message payload. Shared key data is exchanged (PSK authentication is used.)\ntraffic selector\nIPsec ESP vs AH Authentication Header(AH) and Encapsulating Security Payload(ESP) are two protocols, which provide security for IPsec tunnel.\nAH provides only integrity authentication service to IPsec-capable device, so they can verify that message are received intact from other device. AH provides authentication by creating and add MACs to packets. ESP provides not only integrity authentication, but also a privacy for IP. ESP encrypt payload by ESP header and ESP trailer to each packet. IPsec Tunnel vs transport mode IPsec protocol use transport or tunnel mode.\nTransport mode can only be used between end-point of a communication Tunnel mode can be used between arbitrary peers The difference between the two modes is protocol stack construction\nTransport mode just add a security specific header Tunnel mode encapsulates IP packets IPsec with pre-shared secret Pre-Shared Key(PSK) IKEv2 authentication uses pre-shared secrets stored in host\u0026rsquo;s memory. Secret\u0026rsquo;s sharing is out of IPsec\u0026rsquo;s scope.\nThe shared key is exchanged during IPsec SA negotiation and used by peers to authenticate each other.\nThe easiest, but not recommended type of authentication\npre-shared secret is configured in ipsec.secrets file.\n1 # authty=secret 2192.145.66.100 192.145.66.101 :PSK \u0026#34;123\u0026#34; IPsec with CA certificates (PKI) Public Key authentication is based on Public Key Infrastructure(PKI) architecture\nAn individual that wishes to send encrypted data obtains a digital certificate form a Certificate Authority(CA). CA\u0026rsquo;s certificate contains a public key Both peers need to generate self-certificates, which can be self-signed, in which case they have to installed on peers, or signed by a common Certificate Authority(CA) The latter simplifies deployment and configuration a lot as the gateway only needs the CA certificate. IKEv2 uses:\nCERTREQ payload contains information of supported by peer CAs CERT payload contains peer\u0026rsquo;s certificate signed by CA During IKE AUTH exchange peers authenticate each other. In SA_INIT response responder sends CERTREQ payload. Then initiator send its certificate in CERT with its identity(IDi). Responder uses public key from CA certificate to authenticate initiator. In the last message responder sends its certificate (CERT) with its identity(IDr). Now, responder is authenticated by initiator(if certificate is authorized by the same CA)\nPublic Key authentication- RSA authentication with X.509 certificate\nCA certificate and private key need to delivered to each IPsec peer.\n1# Blue 2conn bule-to-red 3 # authby=secret # authentication method 4 left=192.168.56.101 # IP of both ends of tunnel 5 right=192.168.56.100 6 ike=ase256-sha2_256-modp1024 # IKE secrity association proposal 7 esp=aes256-sha2_256 # IPsec security association proposal(ESP/ AH) 8 auto=start 9 keyexchange=ikev2 # key exchange protocol 10 type=tunnel # IPsec mode(tunnel or transport) 11 leftcert=client1Cert.pem 12 leftid=\u0026#34;C=CH,O=strongSwan,CN=device1\u0026#34; 13 rightid=\u0026#34;C=CH,O=strongSwan,CN=device2\u0026#34; 14 15 #ah=sha1-sha256-modp1024 16 17 18# RED 19conn red-to-blue 20 # authby=secret # authentication method 21 left=192.168.56.101 # IP of both ends of tunnel 22 right=192.168.56.100 23 ike=ase256-sha2_256-modp1024 # IKE secrity association proposal 24 esp=aes256-sha2_256 # IPsec security association proposal(ESP/ AH) 25 auto=start 26 keyexchange=ikev2 # key exchange protocol 27 type=tunnel # IPsec mode(tunnel or transport) 28 leftcert=client2Cert.pem 29 leftid=\u0026#34;C=CH,O=strongSwan,CN=device2\u0026#34; 30 rightid=\u0026#34;C=CH,O=strongSwan,CN=device\u0026#34; 1# ipsec.secret RSA private key location is configured in ipsec.secrets 2: RAS client1key.pem Create IPsec Tunnel on AWS Running CNF through docker in host network mode\n1docker run --rm -i -d --network host --name cnf --user root -v /home/ubuntu/entrypoint.sh:/entrypoint.sh --privileged cnf:pro bash -c \u0026#39;/entrypoint.sh\u0026#39; NAT mode\n1docker run --rm -i -d -p 5:q 2jjikk00:500/udp -p 4500:4500/udp --name cnf-1 --user root -v /home/ubuntu/entrypoint.sh:/entrypoint.sh --privileged cnf:pro bash -c \u0026#39;/entrypoint.sh\u0026#39; 3 4netstat -atunlp rrr\n1# sun add DNAT 2 3sudo iptables -D PREROUTING --destination 10.20.0.118/32 -p esp -j DNAT --to-destination 172.17.0.3 -t nat 4sudo iptables -D PREROUTING --destination 10.20.0.118/32 -p udp --dport 4500 -j DNAT --to-destination 172.17.0.3:4500 -t nat 5sudo iptables -D PREROUTING --destination 10.20.0.118/32 -p udp --dport 500 -j DNAT --to-destination 172.17.0.3:500 -t nat 6 7 8 9# moon add DNAT 10sudo iptables -D PREROUTING --destination 172.16.182.193/32 -p esp -j DNAT --to-destination 172.17.0.2 -t nat 11sudo iptables -D PREROUTING --destination 172.16.182.193/32 -p udp --dport 4500 -j DNAT --to-destination 172.17.0.2:4500 -t nat 12sudo iptables -D PREROUTING --destination 172.16.182.193/32 -p udp --dport 500 -j DNAT --to-destination 172.17.0.2:500 -t nat 13 14192.169.0.4/32 === 172.17.0.2/32 15iptables -I POSTROUTING -d 172.17.0.2/32 -j SNAT --to-source 192.169.0.4 -t nat 1# sun add DNAT 2 3sudo iptables -I PREROUTING --destination 10.95.62.171/32 -p esp -j DNAT --to-destination 10.233.83.75 -t nat 4sudo iptables -I PREROUTING --destination 10.95.62.171/32 -p udp --dport 4500 -j DNAT --to-destination 10.233.83.75:4500 -t nat 5sudo iptables -I PREROUTING --destination 10.95.62.171/32 -p udp --dport 500 -j DNAT --to-destination 10.233.83.75:500 -t nat 6 7 8 9# moon add DNAT 10sudo iptables -I PREROUTING --destination 10.95.62.90/32 -p esp -j DNAT --to-destination 10.233.120.76 -t nat 11sudo iptables -I PREROUTING --destination 10.95.62.90/32 -p udp --dport 4500 -j DNAT --to-destination 10.233.120.76:4500 -t nat 12sudo iptables -I PREROUTING --destination 10.95.62.90/32 -p udp --dport 500 -j DNAT --to-destination 10.233.120.76:500 -t nat Add AppArmor security Rules 1# Add to /etc/apparmor.d/usr.lib.ipsec.charon 2# /usr/lib/ipsec/charon flags=(attach_disconnected) { 3 4 /tmp/ipsec/** r, 5 /tmp/run/** rw, 6 /tmp/ipsec/strongswan.conf rwk, 7 /tmp/ipsec/ipsec.secrets rwk, 8 /tmp/run/charon.ctl rwk, 9 /tmp/run/charon.pid rwk, 10 /bin/busybox rmPUx, 11# } 12# Add to /etc/apparmor.d/usr.lib.ipsec.stroke 13 /tmp/ipsec/strongswan.conf r, 14 /tmp/run/charon.ctl wr, Site-to-Site Mode In site to site mode need to add IP rule on the host, post the traffic through the VTI interface\nAdd IP Rule\n1# sun node 2ip route add default dev vti_52.9.61.247 table 40 3ip rule add to 172.16.182.193 lookup 40 4 5# moon node 6ip r add default dev vti_34.230 table 50 7ip rule add to 10.20.0.118 lookup 50 ipsec.conf\n1# sun node 2conn hubaedge1-Connedge1_19216904 3 left=%any 4 leftsubnet=0.0.0.0/0 5 right=%any 6 rightsubnet=0.0.0.0/0 7 ikelifetime=3h 8 lifetime=1h 9 margintime=9m 10 keyingtries=%forever 11 dpdaction=restart 12 dpddelay=30s 13 leftauth=pubkey 14 rightauth=pubkey 15 leftcert=/etc/ipsec.d/certs/sunCert.pem 16 leftsendcert=yes 17 rightsendcert=yes 18 auto=start 19 # leftid=\u0026#34;C=CH, O=strongSwan, CN=sun.strongswan.org\u0026#34; 20 rightid=\u0026#34;C=CH, O=strongSwan, CN=moon.strongswan.org\u0026#34; 21 leftupdown=/etc/updown 22 keyexchange=ikev2 23 mark=30 24 esp=aes256-sha256-modp4096,aes256-sha256-modp4096 25 ike=aes256-sha256-modp4096,aes256-sha256-modp4096 26 type=tunnel 27 28 29# moon node 30conn edge1huba-Connhuba_10107039 31 left=%any 32 leftsubnet=0.0.0.0/0 33 right= 34.230.111.156 34 rightsubnet=0.0.0.0/0 35 ikelifetime=3h 36 lifetime=1h 37 margintime=9m 38 keyingtries=%forever 39 dpdaction=restart 40 dpddelay=30s 41 leftauth=pubkey 42 rightauth=pubkey 43 leftcert=/etc/ipsec.d/certs/moonCert.pem 44 leftsendcert=yes 45 rightsendcert=yes 46 auto=start 47 # leftid=\u0026#34;C=CH, O=strongSwan, CN=moon.strongswan.org\u0026#34; 48 rightid=\u0026#34;C=CH, O=strongSwan, CN=sun.strongswan.org\u0026#34; 49 leftupdown=/etc/updown # need to bind with a mark 50 mark=30 51 keyexchange=ikev2 52 esp=aes256-sha256-modp4096,aes256-sha256-modp4096 53 ike=aes256-sha256-modp4096,aes256-sha256-modp4096 54 type=tunnel Site-to-Host Mode Add SNAT on Client\n1# moon node 2iptables -I POSTROUTING -d 10.20.0.118/32 -j SNAT --to-source 192.169.0.4 -t nat 3iptables -I POSTROUTING -d 10.233.83.75/32 -j SNAT --to-source 192.168.0.1 -t nat ipsec.conf\n1# sun node 2conn hubaedge1-Connedge1_19216904 3 left=%any 4 right=%any 5 leftsubnet=10.20.0.118/32 6 rightsubnet=192.169.0.4/32 7 ikelifetime=3h 8 lifetime=1h 9 margintime=9m 10 keyingtries=%forever 11 dpdaction=restart 12 dpddelay=30s 13 leftauth=pubkey 14 rightauth=pubkey 15 leftcert=/etc/ipsec.d/certs/sunCert.pem 16 leftsendcert=yes 17 rightsendcert=yes 18 rightsourceip=192.169.0.4 19 auto=start 20 #leftid=\u0026#34;C=CH, O=strongSwan, CN=sun.strongswan.org\u0026#34; 21 rightid=\u0026#34;C=CH, O=strongSwan, CN=moon.strongswan.org\u0026#34; 22 leftupdown=/etc/updown 23 keyexchange=ikev2 24 mark=30 25 esp=aes256-sha256-modp4096,aes256-sha256-modp4096 26 ike=aes256-sha256-modp4096,aes256-sha256-modp4096 27 type=tunnel 28 29# moon 30conn edge1huba-Connhuba_10107039 31 left=%any 32 leftsourceip=%config 33 right= 34.230.111.156 34 rightsubnet=10.20.0.118/32 35 ikelifetime=3h 36 lifetime=1h 37 margintime=9m 38 keyingtries=%forever 39 dpdaction=restart 40 dpddelay=30s 41 leftauth=pubkey 42 rightauth=pubkey 43 leftcert=/etc/ipsec.d/certs/moonCert.pem 44 leftsendcert=yes 45 rightsendcert=yes 46 auto=start 47 # leftid=\u0026#34;C=CH, O=strongSwan, CN=moon.strongswan.org\u0026#34; 48 rightid=\u0026#34;C=CH, O=strongSwan, CN=sun.strongswan.org\u0026#34; 49 leftupdown=/etc/updown_oip 50 keyexchange=ikev2 51 esp=aes256-sha256-modp4096,aes256-sha256-modp4096 52 ike=aes256-sha256-modp4096,aes256-sha256-modp4096 53 type=tunnel Todo Apparmor\nVTI bind with mark and ip xfrm check the startus\nHi, Huifeng, I think we can con\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/blog/2_strongswan/","summary":"When reading/adjusting any StrongSwan configurations, remember these important words:\nleft is local to the machine it\u0026rsquo;s stated on; right is remote in the same manner\nSo, on the server side, left is local to the server and on the client side, left is local to that client.\ncheck the X509 cert details\n1openssl x509 -text -noout -in /etc/ipsec.d/private/sunKey.pem ​\nUbuntu Set up IPsec Tunnel 1docker run --rm -d -i --network host --name cnf --user root -v /home/ubuntu/entrypoint.","tags":null,"title":"strongswan"},{"categories":null,"contents":" Download the material\n1wget -r -N -nd http://sdewan.sh.intel.com:8888/ipsec-demo/ modify the node selector in cnf-1.yaml and cnf-2.yaml respectively. Create 2 pod on different node with host network.\n1 nodeSelector: 2 # change to the specific node 3 kubernetes.io/hostname: node Copy cert to the CNF Pod.\nFind the container id for cnf-1 and cnf-2.\n1# For cnf-1, copy sunCert to it 2docker cp ./cert/caCert.pem $(kubectl describe po cnf-1|grep docker:|awk -F / \u0026#39;{print $3}\u0026#39;):/etc/ipsec.d/cacerts 3docker cp ./cert/sunCert.pem $(kubectl describe po cnf-1|grep docker:|awk -F / \u0026#39;{print $3}\u0026#39;):/etc/ipsec.d/certs 4docker cp ./cert/sunKey.pem $(kubectl describe po cnf-1|grep docker:|awk -F / \u0026#39;{print $3}\u0026#39;):/etc/ipsec.d/private 5# For node-2, copy moonCert to it 6 7docker cp ./cert/caCert.pem $(kubectl describe po cnf-2|grep docker:|awk -F / \u0026#39;{print $3}\u0026#39;):/etc/ipsec.d/cacerts 8docker cp ./cert/moonCert.pem $(kubectl describe po cnf-2|grep docker:|awk -F / \u0026#39;{print $3}\u0026#39;):/etc/ipsec.d/certs 9docker cp ./cert/moonKey.pem $(kubectl describe po cnf-2|grep docker:|awk -F / \u0026#39;{print $3}\u0026#39;):/etc/ipsec.d/private start service in container in cnf-1 and cnf -2 1 /sbin/procd \u0026amp; 2 /sbin/ubusd \u0026amp; 3 sh /etc/init.d/log start 4 sh /etc/init.d/ipsec start Edit /var/ipsec/ipsec.secrets in cnf-1 and cnf -2\n1 2# For cnf-1 3echo \u0026#39; : RSA /etc/ipsec.d/private/sunKey.pem\u0026#39; \u0026gt; /var/ipsec/ipsec.secrets 4# For cnf-2 5echo \u0026#39; : RSA /etc/ipsec.d/private/moonKey.pem\u0026#39; \u0026gt; /var/ipsec/ipsec.secrets edit /var/ipsec/ipsec.conf in cnf-1 and cnf -2\n1# For server side, cnf-1 2conn connection-11 3 left=%any 4 right=%any 5 rightsubnet=192.168.9.134/32 6 ikelifetime=3h 7 lifetime=1h 8 margintime=9m 9 keyingtries=%forever 10 dpdaction=restart 11 dpddelay=30s 12 closeaction=restart 13 leftauth=pubkey 14 rightauth=pubkey 15 leftcert=/etc/ipsec.d/certs/sunCert.pem 16 leftsendcert=yes 17 rightsendcert=yes 18 # rightsourceip=192.169.0.1 19 auto=start 20 leftid=\u0026#34;C=CH, O=strongSwan, CN=sun.strongswan.org\u0026#34; 21 rightid=\u0026#34;C=CH, O=strongSwan, CN=moon.strongswan.org\u0026#34; 22 leftupdown=/etc/updown 23 keyexchange=ikev2 24 mark=30 25 esp=aes128-sha256-modp3072,aes256-sha256-modp3072 26 ike=aes128-sha256-modp3072,aes256-sha256-modp3072 27 type=tunnel 28 29 30# For client side, cnf-2 31conn connection12 32 left=%any 33 right=61.240.163.206 34 rightsubnet=61.240.163.206/32 35 # leftsourceip=%config 36 ikelifetime=3h 37 lifetime=1h 38 margintime=9m 39 keyingtries=%forever 40 dpdaction=restart 41 dpddelay=30s 42 closeaction=restart 43 leftauth=pubkey 44 rightauth=pubkey 45 leftcert=/etc/ipsec.d/certs/moonCert.pem 46 leftsendcert=yes 47 rightsendcert=yes 48 auto=start 49 leftid=\u0026#34;C=CH, O=strongSwan, CN=moon.strongswan.org\u0026#34; 50 rightid=\u0026#34;C=CH, O=strongSwan, CN=sun.strongswan.org\u0026#34; 51 leftupdown=/usr/lib/ipsec/_updown iptables 52 keyexchange=ikev2 53 esp=aes128-sha256-modp3072,aes256-sha256-modp3072 54 ike=aes128-sha256-modp3072,aes256-sha256-modp3072 55 type=tunnel run sude ipsec start in the container to start the ipsec tunnel.\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/blog/2_strongwan_NAT_travalse/","summary":"Download the material\n1wget -r -N -nd http://sdewan.sh.intel.com:8888/ipsec-demo/ modify the node selector in cnf-1.yaml and cnf-2.yaml respectively. Create 2 pod on different node with host network.\n1 nodeSelector: 2 # change to the specific node 3 kubernetes.io/hostname: node Copy cert to the CNF Pod.\nFind the container id for cnf-1 and cnf-2.\n1# For cnf-1, copy sunCert to it 2docker cp ./cert/caCert.pem $(kubectl describe po cnf-1|grep docker:|awk -F / \u0026#39;{print $3}\u0026#39;):/etc/ipsec.","tags":null,"title":"StrongWAN configure with CNF."},{"categories":null,"contents":"CNCN 项目的几个阶段\nLibos\nNIO BIO\nDMA是什么\nsr-iov\nebpf\novs\ncilium\ncalico flannel\nipsec GRE\n两个方向，一个是存储，一个是网络\n1、有dpdk、ebpf、ovs、lvs、nginx、hyperplane等系统研发经验； 2、有智能网卡、硬件卸载、P4等高性能网络研发经验； 3、有VPC、NAT、负载均衡等云网络产品研发经验。\nGRE/VxLAN/OpenFlow等协议；\nESXI8.0 license: 4V492-44210-48830-931GK-2PRJ4\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/ToDo/","summary":"CNCN 项目的几个阶段\nLibos\nNIO BIO\nDMA是什么\nsr-iov\nebpf\novs\ncilium\ncalico flannel\nipsec GRE\n两个方向，一个是存储，一个是网络\n1、有dpdk、ebpf、ovs、lvs、nginx、hyperplane等系统研发经验； 2、有智能网卡、硬件卸载、P4等高性能网络研发经验； 3、有VPC、NAT、负载均衡等云网络产品研发经验。\nGRE/VxLAN/OpenFlow等协议；\nESXI8.0 license: 4V492-44210-48830-931GK-2PRJ4","tags":null,"title":"ToDoList"},{"categories":null,"contents":"Sidecar category update Image URL Update Variable\nsite 开头的变量\n{{ if site.IsMultiLingual }}\nSection Menu for Lazy Bloggers To enable this menu, configure sectionPagesMenu in your site config:\n1sectionPagesMenu = \u0026#34;main\u0026#34; ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/hugo_toha_update/","summary":"Sidecar category update Image URL Update Variable\nsite 开头的变量\n{{ if site.IsMultiLingual }}\nSection Menu for Lazy Bloggers To enable this menu, configure sectionPagesMenu in your site config:\n1sectionPagesMenu = \u0026#34;main\u0026#34; ","tags":null,"title":"toha theme update"},{"categories":null,"contents":"Tools 1apt install vim git tmux golang Vim 1# ~/.vimrc 2cat \u0026lt;\u0026lt;EOF | tee -a ~/.vimrc 3set nu 4syntax on 5inoremap jj \u0026lt;ESC\u0026gt; 6 7 8set fileencodings=utf-8,ucs-bom,gb18030,gbk,gb2312,cp936 9set termencoding=utf-8 10set encoding=utf-8 11 12\u0026#34; show existing tab with 4 spaces width 13set tabstop=4 14\u0026#34; when indenting with \u0026#39;\u0026gt;\u0026#39;, use 4 spaces width 15set shiftwidth=4 16\u0026#34; On pressing tab, insert 4 spaces 17set expandtab 18 19EOF oh my zsh 1sudo apt install -y zsh 2sh -c \u0026#34;$(wget https://raw.github.com/ohmyzsh/ohmyzsh/master/tools/install.sh -O -)\u0026#34; 3 4# sudo chsh -s $(which zsh) Golang 1sudo apt install golang 2 3echo \u0026#39; 4GOPATH=~/go 5GOBIN=$GOPATH/bin 6PATH=$PATH:$GOBIN 7\u0026#39;| tee -a ~/.bashrc Proxy 1echo \u0026#39;function proxy_on() { 2 export no_proxy=\u0026#34;localhost,127.0.0.1/8,arch,.localdomain.com,10.239.154.51/16\u0026#34; 3 4 local proxy=\u0026#34;http://child-prc.intel.com:913\u0026#34; 5 export http_proxy=\u0026#34;$proxy\u0026#34; \\ 6 https_proxy=$proxy \\ 7 all_proxy=$proxy \\ 8 ftp_proxy=$proxy \\ 9 rsync_proxy=$proxy \\ 10 HTTP_PROXY=$proxy \\ 11 HTTPS_PROXY=$proxy \\ 12 FTP_PROXY=$proxy \\ 13 RSYNC_PROXY=$proxy 14} 15 16function proxy_off(){ 17 unset http_proxy https_proxy all_proxy ftp_proxy rsync_proxy \\ 18 HTTP_PROXY HTTPS_PROXY FTP_PROXY RSYNC_PROXY no_proxy 19 echo -e \u0026#34;Proxy environment variable removed.\u0026#34; 20} 21 22proxy_on\u0026#39; | tee -a ~/.zshrc 23 24EOF 25 26# Install zsh 27cat \u0026lt;\u0026lt;EOF | sudo tee /etc/apt/apt.conf.d/proxy.conf 28Acquire::http::Proxy \u0026#34;http://child-prc.intel.com:913\u0026#34;; 29Acquire::https::Proxy \u0026#34;http://child-prc.intel.com:913\u0026#34;; 30EOF Font hack\nSet timezone\n1timedatectl set-timezone Asia/Shanghai 2 3sudo date -s \u0026#34;$(curl -H\u0026#39;Cache-Control:no-cache\u0026#39; -sI google.com | grep \u0026#39;^Date:\u0026#39; | cut -d\u0026#39; \u0026#39; -f3-6)Z\u0026#34; Add new User 1sudo adduser hairong 2sudo usermod -aG sudo hairong 3 4sudo vi /etc/group Wait for network\n1network: 2 version: 2 3 wifis: 4 wlp3s0: 5 access-points: 6 HoneyHouse_5.0G: 7 password: 1q2w3e4r%T 8 dhcp4: true 9 optional: true 1sudo netplan generate 2 3sudo netplan apply Ubuntu Alisa 今天在Build Docker image的时候发现sgx-sdk-demo的base images是ubuntu:bionic, 然后设置的apt source list 也是\u0026quot;....intel-sgx/sgx_repo/ubuntu focal main\u0026quot;。同时 docker image ubunt:18.04 和 ubuntu:bionic 的Image ID 是完全相同的，猜测 bionic 应该是 ubuntu:18.04 的别名。于是查了Ubuntu 的release Note 果真如此。\nupdate ubuntu linux kernel 1apt-cache search linux-image 2sudo apt-get install linux-image-your_version_choice linux-headers-your_version_choice linux-image-extra-your_version_choice 3 4# must reboot you machine 5# https://linuxhint.com/update_ubuntu_kernel_20_04/ 6# https://packages.ubuntu.com/focal-updates/kernel/ flux add proxy!!!! 装的时候手动修改env 1git config --global --add http.proxy http://proxy-prc.intel.com:913 2git config --global --add https.proxy http://proxy-prc.intel.com:913 3 4 5 6export http_proxy=http://proxy-prc.intel.com:913 7export https_proxy=http://proxy-prc.intel.com:913 kubectl autocomplete ssh set proxy 1# Host github.com 2# Hostname ssh.github.com 3# # ProxyCommand nc -X connect -x child-prc.intel.com:914 %h %p 4# # # ProxyCommand connect -H child-prc.intel.com:914 %h %p 5# Port 443 6# # ServerAliveInterval 20 7# # User git 8# Host github.com 9# IdentityFile ~/.ssh/id_rsa 10# ProxyCommand nc -x child-prc.intel.com:1080 %h %p 11 12 13# ProxyCommand connect -S proxy-prc.intel.com:1080 %h %p 14Host node-2 15 HostName 124.223.99.93 16 Port 3302 17 User airren 18 ProxyCommand connect -S proxy-prc.intel.com:1080 %h %p 19 # ProxyJump proxy-prc.intel.com:1080 20 21Host sdewan-sgx.sh.intel.com 22 HostName sdewan-sgx.sh.intel.com 23 User airren 24 25Host airrens-mini.sh.intel.com 26 HostName airrens-mini.sh.intel.com 27 User airren 28 29Host sdewan.sh.intel.com 30 HostName sdewan.sh.intel.com 31 User ubuntu 32 33Host 10.239.154.53 34 HostName 10.239.154.53 35 User airren Docker utils 1HOSTNAME=chrome 2VNC_SCREEN_SIZE=1920x1080 3 4 docker run -d -p 5900:5900 --name chrome \\ 5 -e VNC_SCREEN_SIZE=1920x1080 -e HOSTNAME=chrome\\ 6 siomiz/chrome ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/blog/Linux_init/","summary":"Tools 1apt install vim git tmux golang Vim 1# ~/.vimrc 2cat \u0026lt;\u0026lt;EOF | tee -a ~/.vimrc 3set nu 4syntax on 5inoremap jj \u0026lt;ESC\u0026gt; 6 7 8set fileencodings=utf-8,ucs-bom,gb18030,gbk,gb2312,cp936 9set termencoding=utf-8 10set encoding=utf-8 11 12\u0026#34; show existing tab with 4 spaces width 13set tabstop=4 14\u0026#34; when indenting with \u0026#39;\u0026gt;\u0026#39;, use 4 spaces width 15set shiftwidth=4 16\u0026#34; On pressing tab, insert 4 spaces 17set expandtab 18 19EOF oh my zsh 1sudo apt install -y zsh 2sh -c \u0026#34;$(wget https://raw.","tags":null,"title":"Unix Init"},{"categories":null,"contents":"Develop Environment Kind kind is a tool for running local Kubernetes clusters using Docker container \u0026ldquo;nodes\u0026rdquo;. kind was primarily designed for testing Kubernetes itself but may be used for local development or CI.\n1kind load docker-image --name \u0026lt;kind-cluster-name\u0026gt; --nodes \u0026lt;node-name\u0026gt; \u0026lt;image-name\u0026gt;:latest Certmangaer 1helm repo add jetstack https://charts.jetstack.io 2helm repo update 3helm install \\ 4 cert-manager jetstack/cert-manager \\ 5 --namespace cert-manager \\ 6 --create-namespace \\ 7 --version v1.10.1 \\ 8 --set installCRDs=true Question\nK8s 的manifest 是如何生成的 代码的架构 controller-gen的作用，如何根据对应的tag生成 k8smanifest clientgo 中的client set GVK和GVR 每一个controller 是如何注册到主程序中的 常用的依赖，core？ controller runtime 应用部署的时候，首先创建crd资源以及role 权限，然后部署应用 k8s finalizaer\nReconcile 函数什么时候回被调用到， Reconcile函数的返回值中如果含有err如何处理，err 为nil的时候如何处理 Renconcile Result 什么情况下需要requeue， Yaml 中的apiVersion\npod\ndeployment\nCode中的struct defination\nk8s.io/apimachinery/pkg/apis/meta/v1 ResourceList\nUnstructured golang 的type assert\nScheme: resource register 新增一个crd的时候需要注册到scheme\nUnversionedType: metav1.Status, metav1.APIVersions, metav1.APIGroupList, metav1.APIGroup, metav1.APIResourceList\nKnownType: Pod\nAddKnowTypes？ or Add UnversionedTypes\n1// k8s.io/apimachniery/pkg/runtime/scheme.go 2type Scheme struct { 3\t// gvkToType allows one to figure out the go type of an object with 4\t// the given version and name. 5\tgvkToType map[schema.GroupVersionKind]reflect.Type 6 7\t// typeToGVK allows one to find metadata for a given go object. 8\t// The reflect.Type we index by should *not* be a pointer. 9\ttypeToGVK map[reflect.Type][]schema.GroupVersionKind 10 //.... 11} Codec Serializer:\nCodec: Serializer is one kind of Codec\nWhat is protobuf, wirte a demo\nConverter: resource Version convert Kubectl 1kubectl run pod --image=nginx:latest # create one or more pod 2 3kubectl expose 4 5 6kubectl rolling-update # uses replication controller roll update 7 8kubectl cluster-info 9kubectl top Cobra Informer machanism WorkQueue Golang的优雅退出\nK8s 代码生成器 tags\nPackage Tag Type Tag 1//+k8s:deepcopy-gen=package 2//+groupName=example.com 3 4// Local Tag 5// +genclient ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/kubernetes/k8s_dev_1_env/","summary":"Develop Environment Kind kind is a tool for running local Kubernetes clusters using Docker container \u0026ldquo;nodes\u0026rdquo;. kind was primarily designed for testing Kubernetes itself but may be used for local development or CI.\n1kind load docker-image --name \u0026lt;kind-cluster-name\u0026gt; --nodes \u0026lt;node-name\u0026gt; \u0026lt;image-name\u0026gt;:latest Certmangaer 1helm repo add jetstack https://charts.jetstack.io 2helm repo update 3helm install \\ 4 cert-manager jetstack/cert-manager \\ 5 --namespace cert-manager \\ 6 --create-namespace \\ 7 --version v1.10.1 \\ 8 --set installCRDs=true Question","tags":null,"title":"User Kuberbuilder to create a CRD operator"},{"categories":null,"contents":"","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/linux/network_VPC/","summary":"","tags":null,"title":"VPC"},{"categories":null,"contents":"In our day-to-day life, we have seen LAN and WAN architectures mostly because we have to deal with only one IP address on one interface. We either connect our system with LAN cable or with WiFi.\nIn this article, we will discuss the VLAN and how to create the VLAN on the Ubuntu server, but let first understand what is VLAN and why we use VLAN.\nWhat is VLAN Virtual Local Area Network(VLAN) is a logical concept of breaking large broadcast domains into small domains. The VLAN protocol is based on IEEE802.1Q. VLAN can be considered as a subnet. Two different subnets cannot communicate with each other without a bridge or router.\nThe above image is an example showing how the network can be divided in the office. There is a clear separation of the department network which is done by separating through VLANs.\nThere are many advantages of using VLAN in our network architecture mentioned the following:\nLogically divide the broadcast domain which reduce the size of the domains. Add additional layer of security. Make device management easier. QoS or other network policies are easy to implement. Also make network scalable. VLAN installation With the background knowledge out of the way, It\u0026rsquo;s time to get your hand dirty with configuration.\nFirst, ensure that the 802.1Q kernel module is loaded. In practice, this module is automatically loaded if you configure a VLAN subinterface. However, I\u0026rsquo;ll manually enable it for the sake of demonstration:\n1# check the 8021q stauts 2ubuntu@node-1:~$ lsmod | grep 8021q 3 4# enable 8021q 5ubuntu@node-1:~$ sudo modprobe 8021q 6 7ubuntu@node-1:~$ lsmod |grep 8021q 88021q 32768 0 9garp 16384 1 8021q 10mrp 20480 1 8021q Verify that module is loaded by using the following command:\n1modinfo 8021q We will first add a VLAN interface definition, ens3.100 for ens3 on PVID 100.\n1sudo ip link add link ens3 name ens3.100 type vlan id 100 Use ip link command to check does above command has add the VLAN interface.\nAnd then, configure the network settings for the VLAN interface, add a IP address to it.\n1ip addr add 192.168.100.1/24 dev ens3.100 Use ip addr command to verify the VLAN interface configuration.\nBring up the VLAN interface\n1ip link set ens3.100 up If you subsequently need to delete the interface, use the following command to bring it down and remove the definition\n1ip link set ens3.100 down 2ip link delete ens3.100 This configuration is not permanent, for permanent configuration use Netplan.\nConfigure VLAN with Netplan Netplan related configuration files can be found in the /etc/netplan directory. /etc/netplan directory has multiple YAML files. In our Ubuntu20.04 server the YAML file which is responsible for network configuration is names as 50-cloud-init.yaml. The network configuration file\u0026rsquo;s name maybe different in some setups.\nTo assign a static IP address on the network interface. Configuration file look like shown in below mentioned.\n1network: 2 ethernets: 3 ens3: 4 dhcp4: true 5 match: 6 macaddress: 52:54:00:68:b2:b6 7 set-name: ens3 8 vlans: 9 ens3.100: 10 id: 100 11 link: ens3 12 addresses: [192.169.100.1/24] Once done, save the file and apply the changes by running the following command:\n1sudo netplan apply ifconfig: net-tools; configuration file\u0026rsquo;s path /etc/network/interfaces\nip: iproute2\nCatch the Traffic Do the same thing on another node \u0026ndash; node-2, but specify the IP to 192.169.100.2.\nNow, we have two machines:\nNode-1 ens3.100 192.169.100.1 Node-2 ens3.100 192.169.100.2 While we ping Node-2 on Node-1 through the VLAN ip, use tcpdump to catch the traffic.\nCreate a Virtual Network Interface A virtual interface is a network interface, that mimic a physical interface. With the help of the virtual interface creating virtual machines or containers are possible.\nAdd a virtual interface is a very simple and straight task. This can be done with ip command and with some arguments. In the below-mentioned command, I have added an interface with the name vr-br.\nUse the following command to add a nonpersistent interface. In the following command dummy is the kernel module.\n1sudo ip link add name \u0026lt;virtual_interface_name\u0026gt; type dummy Example of the above command and its verification is shown in the following code section.\nYou can then play with this Interface and you can also assign IP address to this interface. This type of assignment is not persistent, which means after a reboot of you machine you won\u0026rsquo;t find a network interface.\nSummary In this article, we learned about the VLAN and how to configure the VLAN in Ubuntu20.04. We discussed two different strategies to configure the VLAN in Ubuntu.\nIf you face any issue don\u0026rsquo;t hesitate to comment.\nReference https://foofunc.com/how-to-configure-vlan-network-in-ubuntu/\nhttps://foofunc.com/how-to-create-a-virtual-network-interface-in-ubuntu-20-04/\nhttps://www.redhat.com/sysadmin/vlans-configuration\nhttps://www.redhat.com/sysadmin/vlans-sysadmins-basics\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/linux/network_VLAN/","summary":"In our day-to-day life, we have seen LAN and WAN architectures mostly because we have to deal with only one IP address on one interface. We either connect our system with LAN cable or with WiFi.\nIn this article, we will discuss the VLAN and how to create the VLAN on the Ubuntu server, but let first understand what is VLAN and why we use VLAN.\nWhat is VLAN Virtual Local Area Network(VLAN) is a logical concept of breaking large broadcast domains into small domains.","tags":null,"title":"What is VLAN and Virtual Network Interface"},{"categories":null,"contents":"","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/linux/network_VXLAN/","summary":"","tags":null,"title":"What is VXLAN"},{"categories":null,"contents":"1. 顺序传参 参数名 作用 $0 filename $1/$2/$3 \u0026hellip;.$n 第n个参数 2. OPT 只能用单个字母\n1#!/bin/bash 2 3while getopts \u0026#34;:n:a:h\u0026#34; optname; do 4\tcase \u0026#34;$optname\u0026#34; in 5\t\u0026#34;n\u0026#34;) 6\techo \u0026#34;get option -name, value is $OPTARG\u0026#34; 7\t;; 8\t\u0026#34;a\u0026#34;) 9\techo \u0026#34;get option -age, value is $OPTARG\u0026#34; 10\t;; 11\t\u0026#34;h\u0026#34;) 12\techo \u0026#39; 13\t-n name of user 14\t-a age of user 15\t\u0026#39; 16\t;; 17\t\u0026#34;:\u0026#34;) 18\techo \u0026#34;No argument value for option $OPTARG\u0026#34; 19\t;; 20K\t\u0026#34;?\u0026#34;) 21\techo \u0026#34;Unknow options $OPTARG\u0026#34; 22\t;; 23\t*) 24\techo \u0026#34;Unknow error while processing options\u0026#34; 25\t;; 26\tesac 27\techo \u0026#34;option index is $OPTIND\u0026#34; 28done 29 30echo \u0026#34;done\u0026#34; j j\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/cloudnative/Linux/%E5%8F%82%E6%95%B0%E4%BC%A0%E9%80%92/","summary":"1. 顺序传参 参数名 作用 $0 filename $1/$2/$3 \u0026hellip;.$n 第n个参数 2. OPT 只能用单个字母\n1#!/bin/bash 2 3while getopts \u0026#34;:n:a:h\u0026#34; optname; do 4\tcase \u0026#34;$optname\u0026#34; in 5\t\u0026#34;n\u0026#34;) 6\techo \u0026#34;get option -name, value is $OPTARG\u0026#34; 7\t;; 8\t\u0026#34;a\u0026#34;) 9\techo \u0026#34;get option -age, value is $OPTARG\u0026#34; 10\t;; 11\t\u0026#34;h\u0026#34;) 12\techo \u0026#39; 13\t-n name of user 14\t-a age of user 15\t\u0026#39; 16\t;; 17\t\u0026#34;:\u0026#34;) 18\techo \u0026#34;No argument value for option $OPTARG\u0026#34; 19\t;; 20K\t\u0026#34;?","tags":null,"title":"参数传递"},{"categories":null,"contents":"源文件 原文件使用UTF-8编码，对Unicode支持良好。每个源文件都属于包的一部分，在文件头部用package声明所属包的名称\n1package main 2func main(){ 3 println(\u0026#34;hello world!!\u0026#34;) 4} 以.go作为文件扩展名，语句结束分号会被默认省略，支持C样式注释。入口函数main没有参数，且必须放在main包中\n用import导入标准库或第三方包\n1package main 2import{ 3 \u0026#34;fmt\u0026#34; 4} 5 6func main(){ 7 fmt.Println(\u0026#34;hello world!\u0026#34;) 8} 可以直接运行或者编译为可执行文件\n变量 使用var定义变量，支持类型推断。基础数据类型划分清晰明确，有助于编写跨平台应用。编译器确保变量总是被初始化为0，避免出现意外状况。\n1package main 2func main(){ 3 var x int32 4 var s=\u0026#34;hello world!\u0026#34; 5 // 两个数据之间默认使用空格隔开 6 println(x,s) 7} 在函数内部，还可以省略var关键字，使用更简单的定义模式。\n1package main 2 3//y := 200 // 该声明方式仅在函数内部使用，不可用来声明全局变量 4func main() { 5\tx := 100 6\tprintln(x) 7} 编译器将未使用的局部变量定义当做错误\n表达式 Go仅有三种流控制语句\nif 1package main 2 3func main() { 4\tx := 100 5\tif x \u0026gt; 0 { 6\tprint(\u0026#34;x\u0026#34;) 7\t} else if x \u0026lt; 0 { 8\tprint(\u0026#34;-x\u0026#34;) 9\t} else { 10\tprint(\u0026#34;0\u0026#34;) 11\t} 12} switch 1package main 2 3func main() { 4\tx := 0 5\tswitch { 6\tcase x \u0026gt; 0: 7\tprint(\u0026#34;x\u0026#34;) 8\tcase x \u0026lt; 0: 9\tprint(\u0026#34;-x\u0026#34;) 10\tdefault: 11\tprint(\u0026#34;0\u0026#34;) 12\t} 13} for 1func main() { 2\tfor i := 0; i \u0026lt; 5; i++ { 3\tprintln(i) 4\t} 5\tfor i := 4; i \u0026gt;= 0; i-- { 6\tprintln(i) 7\t} 8} 1package main 2 3func main() { 4\tx := 0 5 for x \u0026lt; 5 { // 相当于 while(x\u0026lt;5) 6\tprintln(x) 7\tx++ 8\t} 9} 1package main 2 3func main() { 4\tx := 4 5\tfor { // 相当于while(true) 6\tprintln(x) 7\tx-- 8\tif x \u0026lt; 0 { 9\tbreak 10\t} 11\t} 12} 在迭代遍历时，for\u0026hellip;range除了元素外，还可以返回索引\n1package main 2 3func main() { 4\tx := []int{100, 101, 102} 5\tfor i, n := range x { 6\tprintln(i, \u0026#34;: \u0026#34;, n) 7\t} 8} 函数 多个返回值 函数可以定义多个返回值，甚至对其命名\n1package main 2 3import ( 4\t\u0026#34;errors\u0026#34; 5\t\u0026#34;fmt\u0026#34; 6) 7 8func main() { 9\ta, b := 10, 0 // 定义多个变量 10\tc, err := div(a, b) // 接收多个返回值 11\tfmt.Println(c, err) 12} 13 14func div(a, b int) (int, error) { 15\tif b == 0 { 16\treturn 0, errors.New(\u0026#34;division by zero\u0026#34;) 17\t} 18 19\treturn a / b, nil 20} 返回函数 函数是第一类型，可以作为参数或者返回值\n1package main 2 3func main() { 4\tx := 100 5\tf := test(x); 6\tf() 7} 8 9func test(x int) func() { // 返回函数类型 10\treturn func() { // 匿名函数 11\tprintln(x) // 闭包 12\t} 13} 用defer定义延迟调用，无论函数是否出错，它都确保结束前被调用\n1package main 2 3func main() { 4\ttest(10, 0) 5} 6 7func test(a, b int) { 8\tdefer println(\u0026#34;dispose....\u0026#34;) // 常用来释放资源、解除锁定、或执行一些清理操作 9\t// 可以定义多个defer，按照FILO顺序执行 10\tprintln(a / b) 11} 数据 切片 slice 切片(slice)可以实现类似动态数组的功能\n1package main 2 3import \u0026#34;fmt\u0026#34; 4 5func main() { 6\tx := make([]int, 0, 5) // 创建容量为5的切片 7\tfor i := 0; i \u0026lt; 8; i++ { 8\tx = append(x, i) // 追加数据。当超出容量限制时候，自动分配更大的存储空间 9\t} 10\tfmt.Println(x) 11} 字典 map 字典(map) 类型内置，可以直接从运行层面获得性能优化\n1package main 2 3import \u0026#34;fmt\u0026#34; 4 5func main() { 6\tm := make(map[string]int) // 创建字典类型对象 7\tm[\u0026#34;a\u0026#34;] = 999 // 添加或设置 8\tx, ok := m[\u0026#34;a\u0026#34;] // 使用ok-idiom获取值，可知道key/value是否存在 9\tfmt.Println(x, ok) 10\tdelete(m, \u0026#34;a\u0026#34;) // 删除 11} 12 13// 999 true 14// 0 false 所谓 ok-idiom模式，是指在多返回值中用一个名为ok的布尔值来表示操作是否成功。因为很多操作默认返回零，所以额外说明\n结构体 结构体(struct)可以匿名嵌入其他类型\n1package main 2 3import \u0026#34;fmt\u0026#34; 4 5func main() { 6\tvar m manager 7\tm.name = \u0026#34;Tom\u0026#34; 8\tm.age = 29 9\tm.title = \u0026#34;CTO\u0026#34; // 直接访问匿名字段成员 10 11\tfmt.Println(m) 12} 13 14type user struct { // 结构体类型 15\tname string 16\tage byte 17} 18 19type manager struct { 20\tuser // 匿名嵌入其他类型 21\ttitle string 22} 23 24// {{Tom 29} CTO} 方法 类型的方法 可以为当前包内的任意类型定义方法\n1package main 2 3type X int 4 5func (x *X) inc() { // 名称前的参数称作receiver,作用类似Python self 6\t*x++ 7} 8 9func main() { 10\tvar x X 11\tx.inc() 12\tprintln(x) 13} 继承 还可以直接调用匿名字段的方法，这种方式可实现与继承类似的功能\n1package main 2 3import \u0026#34;fmt\u0026#34; 4 5type user struct { 6\tname string 7\tage byte 8} 9 10func (u user) ToString() string { 11\treturn fmt.Sprintf(\u0026#34;%+v\u0026#34;, u) 12} 13 14type manager struct { 15\tuser 16\ttitle string 17} 18 19func main() { 20\tvar m manager 21\tm.name = \u0026#34;Tom\u0026#34; 22\tm.age = 29 23\tprintln(m.ToString()) // 调用user.ToString 24} 接口 结构采用了duck type方式, 也就是无须在实现类型上添加显式声明\n1package main 2 3import \u0026#34;fmt\u0026#34; 4 5type user struct { 6\tname string 7\tage byte 8} 9 10func (u user) Print() { 11\tfmt.Printf(\u0026#34;%+v\\n\u0026#34;, u) 12} 13 14type Printer interface { // 接口类型 15\tPrint() 16} 17 18func main() { 19\tvar u user 20\tu.name = \u0026#34;Tom\u0026#34; 21\tu.age = 29 22 23\tvar p Printer = u // 只要包含接口所需的全部方法，即表示实现了该接口 24\tp.Print() 25} 另有空接口类型interface{}, 用途类似OPP里的system.Object,可以接收任意类型的对象\n并发 整个运行时完全并发设计。凡你能看到的，几乎都在以goroutine方式运行。这是一种比普通协程或线程更加高效的并发设计，能轻松创建和运行成千上万的并发任务。\n1package main 2 3import ( 4\t\u0026#34;fmt\u0026#34; 5\t\u0026#34;time\u0026#34; 6) 7 8func task(id int) { 9\tfor i := 0; i \u0026lt; 5; i++ { 10\tfmt.Printf(\u0026#34;%d: %d\\n\u0026#34;, id, i) 11\ttime.Sleep(time.Second) 12\t} 13} 14 15func main() { 16\tgo task(1) // 创建 goroutine 17\tgo task(2) 18 19\ttime.Sleep(time.Second * 6) 20} 通道(channel) 与goroutine搭配，实现通信代替共享内存的CSP模型\n1package main 2 3import \u0026#34;time\u0026#34; 4 5// 消费者 6func consumer(data chan int, done chan bool) { 7\tfor x := range data { // 接收数据，直到通道被关闭 8\tprintln(\u0026#34;recv: \u0026#34;, x) 9\t} 10\tdone \u0026lt;- true // 通知main， 消费结束 11} 12 13// 生产者 14func producer(data chan int) { 15\tfor i := 0; i \u0026lt; 4; i++ { 16\tdata \u0026lt;- i // 发送数据 17\tprintln(\u0026#34;send: \u0026#34;,i) 18\ttime.Sleep(time.Second) 19\t} 20\tclose(data) // 生产结束，关闭通道 21} 22 23func main() { 24\tdone := make(chan bool) // 用于接收消费结束信号 25\tdata := make(chan int) // 数据管道 26 27\tgo consumer(data, done) // 启动消费者 28\tgo producer(data) // 启动生产者 29 30\t\u0026lt;-done // 阻塞，直到消费者发回结束信号 31} ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/note_go/1_Go%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95%E6%A2%B3%E7%90%86/","summary":"源文件 原文件使用UTF-8编码，对Unicode支持良好。每个源文件都属于包的一部分，在文件头部用package声明所属包的名称\n1package main 2func main(){ 3 println(\u0026#34;hello world!!\u0026#34;) 4} 以.go作为文件扩展名，语句结束分号会被默认省略，支持C样式注释。入口函数main没有参数，且必须放在main包中\n用import导入标准库或第三方包\n1package main 2import{ 3 \u0026#34;fmt\u0026#34; 4} 5 6func main(){ 7 fmt.Println(\u0026#34;hello world!\u0026#34;) 8} 可以直接运行或者编译为可执行文件\n变量 使用var定义变量，支持类型推断。基础数据类型划分清晰明确，有助于编写跨平台应用。编译器确保变量总是被初始化为0，避免出现意外状况。\n1package main 2func main(){ 3 var x int32 4 var s=\u0026#34;hello world!\u0026#34; 5 // 两个数据之间默认使用空格隔开 6 println(x,s) 7} 在函数内部，还可以省略var关键字，使用更简单的定义模式。\n1package main 2 3//y := 200 // 该声明方式仅在函数内部使用，不可用来声明全局变量 4func main() { 5\tx := 100 6\tprintln(x) 7} 编译器将未使用的局部变量定义当做错误\n表达式 Go仅有三种流控制语句\nif 1package main 2 3func main() { 4\tx := 100 5\tif x \u0026gt; 0 { 6\tprint(\u0026#34;x\u0026#34;) 7\t} else if x \u0026lt; 0 { 8\tprint(\u0026#34;-x\u0026#34;) 9\t} else { 10\tprint(\u0026#34;0\u0026#34;) 11\t} 12} switch 1package main 2 3func main() { 4\tx := 0 5\tswitch { 6\tcase x \u0026gt; 0: 7\tprint(\u0026#34;x\u0026#34;) 8\tcase x \u0026lt; 0: 9\tprint(\u0026#34;-x\u0026#34;) 10\tdefault: 11\tprint(\u0026#34;0\u0026#34;) 12\t} 13} for 1func main() { 2\tfor i := 0; i \u0026lt; 5; i++ { 3\tprintln(i) 4\t} 5\tfor i := 4; i \u0026gt;= 0; i-- { 6\tprintln(i) 7\t} 8} 1package main 2 3func main() { 4\tx := 0 5 for x \u0026lt; 5 { // 相当于 while(x\u0026lt;5) 6\tprintln(x) 7\tx++ 8\t} 9} 1package main 2 3func main() { 4\tx := 4 5\tfor { // 相当于while(true) 6\tprintln(x) 7\tx-- 8\tif x \u0026lt; 0 { 9\tbreak 10\t} 11\t} 12} 在迭代遍历时，for\u0026hellip;range除了元素外，还可以返回索引","tags":null,"title":"基本语法梳理"},{"categories":null,"contents":"修改表字段\n1# 新增一个字段 2alert table rules add effect_time mysql sql 8.0 认证问题\nconnect to 10.227.4.115:3306 err: this authentication plugin is not supported\n1alter user root@% identified with mysql_native_password by \u0026#34;123456\u0026#34; 1CREATE DATABASE IF NOT EXISTS echo_bio DEFAULT CHARSET utf8 COLLATE utf8_general_ci; 2CREATE DATABASE IF NOT EXISTS echo_bio_jira DEFAULT CHARSET utf8 COLLATE utf8_general_ci; ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/component/DataBase/mysql/install_mysql/","summary":"修改表字段\n1# 新增一个字段 2alert table rules add effect_time mysql sql 8.0 认证问题\nconnect to 10.227.4.115:3306 err: this authentication plugin is not supported\n1alter user root@% identified with mysql_native_password by \u0026#34;123456\u0026#34; 1CREATE DATABASE IF NOT EXISTS echo_bio DEFAULT CHARSET utf8 COLLATE utf8_general_ci; 2CREATE DATABASE IF NOT EXISTS echo_bio_jira DEFAULT CHARSET utf8 COLLATE utf8_general_ci; ","tags":null,"title":"安装配置Mysql"},{"categories":null,"contents":" 为什么容器里只能跑“一个进程”？ 为什么我原先一直在用某个JVM参数，在容器里就不好使了？ 为什么kubernetes就不能固定IP地址？容器网络联不通又该如何去debug？ Kubernetes中的StatefulSet和Operator到底什么区别？PC和PVC这些概念又该怎么用？ Linux进程模型对容器本身的重要意义，控制器模式对整个K8s项目提纲挈领的作用？ 从PaaS到K8s PaaS PaaS(Platform as a Service) 应用托管。\nDocker镜像，其实就是一个压缩包，直接由一个完整的操作系统的所有文件和目录构成。\n其实只打包了文件系统，不包括操作系统的内核。各种内核相关的模块或者特性支持完全依赖于宿主机。\n通过docker build 打包镜像，docker run 运行镜像，docker run创建的沙盒，就是使用Linux Cgroups和Namespace机制创建出来的隔离环境。解决了应用打包这个根本性问题。\nSwarm swarm 提供集群管理功能\n单机docker项目\n1docker run \u0026lt;container-name\u0026gt; 多机docker项目\n1docker run -H \u0026#39;swarm cluster API\u0026#39; \u0026lt;container-name\u0026gt;\tFig 项目 Fig项目第一次在开发者面前提出了容器编排(Container Orchestration)的概念。\n加入用户现在需要部署的是应用容器A、数据库容器B、负载均衡容器C，那么Fig就允许用户把ABC三个容器定义在一个配置文件中， 并且可以指定他们之间的关联关系，比如容器A需要访问数据库B。定义好之后，只需要执行一条非常简单的指令。\n1fig up Fig就会把这些容器的定义和配置交给DockerAPI按照访问逻辑一次创建。而容器A和B之间的关联关系，也会交给docker的Link功能通过写入hosts文件的方式进行配置。更重要的是，你还可以在Fig的配置文件里定义各种容器的副本个数等编排参数。\nFig 项目被Docker收购后更名为Compose。\nLibcontainer LibContainer -\u0026gt; RunC\n以RunC为依据，制定容器和镜像的标准和规范。\nOCI(Open Container Initiative), 意在将容器运行时和镜像的实现从Docker项目中完全剥离出来。\nContainerd 容器运行时\n进程隔离与限制 程序被执行起来，它就从磁盘上的二进制文件，变成了计算机 内存中的数据，寄存器里的值，堆栈中的指令、被打开的文件，以及各种设备的状态信息的一个集合。像这样一个程序运行起来后的计算机执行环境的总和，就是：进程。\n对于进程来说，它的静态表现就是程序，一个二进制文件；而一旦运行起来，就变成了计算机数据和状态的总和，这就是进程的动态表现。\n容器技术的核心功能，就是通过约束和修改进程的动态表现，从而为其创造出一个“边界”。对于大多数Linux容器来说， Cgroups是用来制造约束的主要手段， 而Namespace技术则是用来修改进程视图的主要方法。\n隔离 1docker run -it busybox /bin/sh What is BusyBox? The Swiss Army Knife of Embedded Linux\nComing in somewhere between 1 and 5 Mb in on-disk size(depending on the variant), BusyBox is a very good ingredient to craft space-efficient distributions.\nBusyBox combines tiny versions of many common Unix utilities into a single small executable. It provides replacements for most of the utilities you usually find in GNU fileutils, shellutils, etc. The utilities in BusyBox generally have fewer options than their full-featured GNU cousins; however, the options that are included provide the expected functionality and behave very much like the GNU counterparts. BusyBox provides a fairly complete environment for any small or embedded system.\n1➜ ~ docker run -it busybox 2/ # ps 3PID USER TIME COMMAND 4 1 root 0:00 sh 5 7 root 0:00 ps 6/ # 可以看到容器中只有两个进程，第一个是bin/sh为1号进程，第二个是ps，可以看到docker容器已经隔离在了一个与宿主机完全不同的空间中。\n在Docker容器中看到的进程Pid 实际上是重新计算过的进程ID，在容器中，只能看到当前容器的相关进程。\n这种技术就是Linux中的Namespace机制。Namespace只是Linux创建进程的一个可选参数。\n在Linux系统中创建线程的系统调用是clone().\n1int pid = clone(main_function, stack_size,SIGCHLD, NULL); 这个系统调用会为我们创建一个新的进程，并且返回它的进程号pid。\n当我们用clone()系统调用创建一个新的进程时，可以在参数中指定CLONE_NEWPID参数\n1int pid = clone(main_function, stack_size, CLONE_NEWPID | SIGCHLD, NULL) Linux 的线程是用进程实现的。\n这时，新创建的这个进程将会看到一个全新的进程空间，在这个进程空间里，它的pid是1。但是在宿主机真实的进程空间里，这个进程的PID还是真实数值。\n除了PID Namespace，Linux操作系统还提供了Mount、UTS、IPC、Network和User这些Namespace，用来对不同的进程上下文进行隔离。Mount Namespace，用于让被隔离的进程只看到当前Namespace里的挂载点信息。Network Namespace用于被隔离的进程看到当前Namespace里的网络设备和配置。\n所以，容器其实是一种特殊的进程。\n单进程的意思不是只能运行一个进程，而是是有一个进程是可控的。\nLxc\nNamespace技术实际上修改了应用程序看待真个计算机的“视图”，即它的视线被操作系统做了限制，只能看到某些指定的内容。但是对于宿主机而言，这些被隔离了的进程和其他进程没有太大区别。容器化后的用户应用依然是宿主机上的普通进程。\n一个CentOS的KVM虚拟机在不做优化的情况下，虚拟机自己要占100~200MB内存。用户应用运行在虚拟机里面对宿主机操作系统的调用不可避免的要经过虚拟化软件的拦截和处理，这本身又是一层性能损耗。尤其对计算资源，网络和磁盘I/O的损耗非常大。\n基于Linux Namespace的隔离机制相比于虚拟化技术也有很多不足，其中最主要的问题就是隔离的不彻底。\n容器只是运行在宿主机上的一种特殊的进程，那么，多个容器之间使用的就还是同一个宿主机的操作系统内核。举个例子，如果在容器中，使用系统调用settimeofday修改了时间，整个宿主机的时间也会被修改。由于容器共享宿主机的内核，容器给应用暴露出来的攻击面是相当大的，应用越狱的难度自然也比虚拟机低的多。\n我们可以使用Seccomp等技术对容器内部所有发起的系统调用进行过滤和甄别来进行安全加固，但是这种方法因为多了一层对系统调用的过滤，一定会拖累容器的性能。\n尽管可以在容器里通过Mount Namespace单独挂载其他不同版本的操作系统文件，但是这并不能改变共享宿主机内核的事实。如果在windows宿主机运行Linux容器，或者再低版本的Linux宿主机上运行高版本的Linux容器都是行不通的。\nDocker 在windows 和Mac OS上的工作方式与Linux 上的工作方式是不同的，是通过虚拟机的方式运行容器的。\n为什么生产环境中，没有人敢把运行在物理机上的Linux容器直接暴露到公网上？某公司mongodb podId泄露导致数据被删除。\n限制 我们使用Namespace对进程进行隔离之后， 但是它所能都使用到的资源(比如CPU， 内存)却是随时可以被Host上的其他进程所占用的，当然，这个进程也有可能吧所有的资源都吃光。\nLinux Cgroups(Linux Control Group) 就是Linux内核中用来为进程设置资源限制的一个重要功能。主要作用就是限制一个进程组能都使用的资源上限，包括CPU、Mem、磁盘、网络带宽等等。\n在Google内部，Container这个术语长期以来用于形容被Cgroups限制过的进程组。Cgroups还能都对进程优先级设置、审计。以及将进程挂起和恢复等操作。\nCgroup 给用户暴露出来的操作接口是文件系统，即它以文件和目录的方式组织在操作系统/sys/fs/cgroup路径下。在/sys/fs/cgroup 下面有很多诸如cpuset、cpu、memory这样的子目录，也叫子系统。这些都是当前这台机器可以被Cgroups进行限制的资源种类。\n在子系统对应的资源种类下，就可以看到该类资源具体可以被限制的方法。例如，对cpu子系统来说，有如下几个配置文件：\n我们举个例子，看下如何使用配置文件进行cpu资源的限制。\n我们在后台执行一个脚本。\n1while : ; do : ; done \u0026amp; 此时可以看到一个cpu被打满。\n在/sys/fs/cgroup/cpu 创建一个container目录，目录下会自动生成该子系统对应的资源限制文件。cfs_period 和cfs_quota 这两个参数，用来限制 进程在长度为cfs_period的一段时间里，只能分配到总量为cfs_quota的CPU时间。\n我们修改cfs_quota 为20000, 并且把PID写入container组里的tasks文件。\n1# use root 2echo 20000 \u0026gt; /sys/fs/cgroup/cpu/container/cpu.cfs_quota_us 3echo 27428 \u0026gt; cpu 的使用率降低到80%左右。\n除了CPU子系统外，Cgroups的每一项子系统都有其独有的资源限制能力。\nblkio， 为块设备设定I/O限制，一般用于磁盘等设备 cpuset 为进程分配单独的cpu核和对应的内存节点 memory 为进程设定内存的使用限制。 ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/cloudnative/Kubernates/Container-Intro/","summary":"为什么容器里只能跑“一个进程”？ 为什么我原先一直在用某个JVM参数，在容器里就不好使了？ 为什么kubernetes就不能固定IP地址？容器网络联不通又该如何去debug？ Kubernetes中的StatefulSet和Operator到底什么区别？PC和PVC这些概念又该怎么用？ Linux进程模型对容器本身的重要意义，控制器模式对整个K8s项目提纲挈领的作用？ 从PaaS到K8s PaaS PaaS(Platform as a Service) 应用托管。\nDocker镜像，其实就是一个压缩包，直接由一个完整的操作系统的所有文件和目录构成。\n其实只打包了文件系统，不包括操作系统的内核。各种内核相关的模块或者特性支持完全依赖于宿主机。\n通过docker build 打包镜像，docker run 运行镜像，docker run创建的沙盒，就是使用Linux Cgroups和Namespace机制创建出来的隔离环境。解决了应用打包这个根本性问题。\nSwarm swarm 提供集群管理功能\n单机docker项目\n1docker run \u0026lt;container-name\u0026gt; 多机docker项目\n1docker run -H \u0026#39;swarm cluster API\u0026#39; \u0026lt;container-name\u0026gt;\tFig 项目 Fig项目第一次在开发者面前提出了容器编排(Container Orchestration)的概念。\n加入用户现在需要部署的是应用容器A、数据库容器B、负载均衡容器C，那么Fig就允许用户把ABC三个容器定义在一个配置文件中， 并且可以指定他们之间的关联关系，比如容器A需要访问数据库B。定义好之后，只需要执行一条非常简单的指令。\n1fig up Fig就会把这些容器的定义和配置交给DockerAPI按照访问逻辑一次创建。而容器A和B之间的关联关系，也会交给docker的Link功能通过写入hosts文件的方式进行配置。更重要的是，你还可以在Fig的配置文件里定义各种容器的副本个数等编排参数。\nFig 项目被Docker收购后更名为Compose。\nLibcontainer LibContainer -\u0026gt; RunC\n以RunC为依据，制定容器和镜像的标准和规范。\nOCI(Open Container Initiative), 意在将容器运行时和镜像的实现从Docker项目中完全剥离出来。\nContainerd 容器运行时\n进程隔离与限制 程序被执行起来，它就从磁盘上的二进制文件，变成了计算机 内存中的数据，寄存器里的值，堆栈中的指令、被打开的文件，以及各种设备的状态信息的一个集合。像这样一个程序运行起来后的计算机执行环境的总和，就是：进程。\n对于进程来说，它的静态表现就是程序，一个二进制文件；而一旦运行起来，就变成了计算机数据和状态的总和，这就是进程的动态表现。\n容器技术的核心功能，就是通过约束和修改进程的动态表现，从而为其创造出一个“边界”。对于大多数Linux容器来说， Cgroups是用来制造约束的主要手段， 而Namespace技术则是用来修改进程视图的主要方法。\n隔离 1docker run -it busybox /bin/sh What is BusyBox?","tags":null,"title":"容器技术基础"},{"categories":null,"contents":"Important Doc\nContributor Cheat Sheet 加入SIG SIG(Special Interest Groups) 是Kubernetes社区中关注特定模块的永久组织。\n作为刚参与社区的开发者，可以从sig/app, sig/node, sig/scheduling 这几个SIG开始。\nKEP KEP(Kubernetes Enhancement Proposal)。对于功能和API的修改都需要先在kubernetes/enhancements仓库对应SIG的目录下提交Proposal才能实施。所有的Proposal都必须经过讨论，通过社区SIG Leader的批准。\n很多不熟悉Kubernetes工作流的开发者会在社区中直接提交一个包含API改动的commit，但是如果这类commit没有对应的KEP 是不会被社区合入的。\n项目设计 所有进入开发状态的功能都会有一个非常详细的KEP。KEP有一个详细的模板，设计是非常规范的。我们再日常的开发中也可以使用类似的格式写设计文档或者技术文档。\n最近几年新实现的功能都会有着比较详细的KEP文档\n分布式协作 Kubernetes 中所有的社区会议都会使用Zoom录制，并上传到Youtube。大多数的讨论和交流也对会再对应的issue和PR中。\n每个提交的PR都要通过2K以上的成员的review以及几千个单元测试、集成测试、端到端测试以及扩展性测试，这些测定共同保证了项目的稳定性。\nkubernetes/test-infra 项目中包含了Kubernetes的测试基础配置。 很多端到端的测试都会启动Kubernetes集群，并在真实的环境中测试代码的逻辑，这些测试可能一次会执行几十分钟，并且有一定概率出现Flaky。\n影响力 提高个人和公司在开源社区的影响力，也是参与社区的重要目的。\n对个人来说，参与开源项目可以快速理解项目的实现原理以及工作流程。如果想要在未来从事相关的工作，参与开源项目一定是加分项。\n对公司来说，参与开源项目可以提高公司在开源社区的话语权，提高公司的技术影响力。足够的话语权也会让开源社区在关键需求上有较快的支持，减少与社区代码的分叉，降低维护成本，并满足公司内部的需求。\n操作指南 参与开源项目并不一定要从非常复杂的功能或者Proposal开始。任何一个对代码库有利的PR都是值得提交的。修复代码中的typo 或者静态检查错误，作为最开始的工作是没有任何问题的。这能够帮我们快速热身。不过在熟悉了kubernetes的提交流程之后就没有必要做类似的提交了，以为所有的提交都需要Reviewer和Approver的批准，我们应该尽可能的做有意义的变动，减少他们的工作量。\n从阅读源码开始 我们可以从自己熟悉的模块入手，了解该模块的实现原理，在阅读代码的过程中，我们很容易发现源代码中的一些typo和缺陷，这个时候就可以提交PR修复这些问题。\n从静态检查开始 .golint_failures 文件中忽略了几百个Package中的静态检查，你可以在其中选择合适的Package作为成为Kubernetes贡献者的而第一步。\n从项目管理开始 也可以选择Kubernetes的项目管理， sig/release.\n选取第一个kubernetes问题 issue 列表\n使用tag过滤问题 “good first issue” “help wanted” 这些标签表明了对新手非常友好。有时候问题也会被打上错误标签，也许是技术难度被低估了。\nTODO 搜索代码库里的TODO。\nGo 语言的开发规范、分布式社区的治理方式\n代码需要每天都看，留出专门的时间来查看Kubernetes的源码，对它的核心组件的实现看看，构建一下, 测试一下，修一下Bug，typo等。\n一般半年之后，你就可以熟悉基础项目，并且开始贡献代码。\n当你已经和团队协作的很熟悉，就会自然承接一些子任务，然后团队就会赋予你写的权限，这样就可以顺理成章的成为Kubernetes的committer。这个时候你就是这个子项目的maintainer了\nTODO 加入 Kubenetes Slack Channle 加入邮件列表 加入SIG 参加社区会议 提issue 如何提交PR\nhttps://segmentfault.com/a/1190000040437510\nBranch Strategy Fork K8s 源码， 并从自己的仓库中clone到本地。设置Upstream， 跟踪K8s源码的更新\nKubernetes Project 使用标准的Github \u0026ldquo;Fork and Pull\u0026rdquo; workflow。在git中，个人Fork的仓库应该设置为\u0026quot;origin\u0026quot;, 而原始项目的仓库成为\u0026quot;upstream\u0026quot;。为了保证个人分支(origin)和上游(upstream)更新保持一致，需要在你的本地仓库中完成以下设置。\nAdding Upstream 增加upstream 作为一个remote，并且配置为不可以push。\n1git remote add upstream https://github.com/kubernetes/kubernetes.git 2git remote set-url --push upstream no_push 设置完成后可以通过git remote -v 检查remote的配置情况。\nKeeping Your Fork in sync Fetch all the changes from upstream and \u0026ldquo;rebase\u0026rdquo; them on your local master branch. 这将保证你的本地仓库与上游项目保持同步。Push the local changes to your remote master.\n1git fetch upstream 2git checkout master 3git rebase upstream/master 4git push You should do this minimally before creating a new branch to work on you feature or fix.\n1git checkout -b myfeature Squashing Commits The main purpose of squashing commits is to create a clean readable git history or log of the changes that were made. Usually this is done is last phase of a PR revision. If you are unsure if you should squash your commits, it its better to err on the side of having more and leave it up to the judgement of the other contributors assigned to review and approve your PR.\nPerform an interactive rebase to choose which commits you want to keep and which you want to squash, then force push your branch:\n1# git rebase -i \u0026lt;commit id\u0026gt; 2git rebase -i HEAD~3 3 4# git push -f 5git push --force Build K8s source code 1apt install rsync gcc make Reference\nhttps://www.zhihu.com/question/372403348\nhttps://draveness.me/kubernetes-contributor/\nhttps://cloud.tencent.com/developer/article/1539308\nhttps://aws.amazon.com/cn/blogs/opensource/newbies-guide-to-kubernetes/\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/kubernetes/k8s_dev_0_contributer/","summary":"Important Doc\nContributor Cheat Sheet 加入SIG SIG(Special Interest Groups) 是Kubernetes社区中关注特定模块的永久组织。\n作为刚参与社区的开发者，可以从sig/app, sig/node, sig/scheduling 这几个SIG开始。\nKEP KEP(Kubernetes Enhancement Proposal)。对于功能和API的修改都需要先在kubernetes/enhancements仓库对应SIG的目录下提交Proposal才能实施。所有的Proposal都必须经过讨论，通过社区SIG Leader的批准。\n很多不熟悉Kubernetes工作流的开发者会在社区中直接提交一个包含API改动的commit，但是如果这类commit没有对应的KEP 是不会被社区合入的。\n项目设计 所有进入开发状态的功能都会有一个非常详细的KEP。KEP有一个详细的模板，设计是非常规范的。我们再日常的开发中也可以使用类似的格式写设计文档或者技术文档。\n最近几年新实现的功能都会有着比较详细的KEP文档\n分布式协作 Kubernetes 中所有的社区会议都会使用Zoom录制，并上传到Youtube。大多数的讨论和交流也对会再对应的issue和PR中。\n每个提交的PR都要通过2K以上的成员的review以及几千个单元测试、集成测试、端到端测试以及扩展性测试，这些测定共同保证了项目的稳定性。\nkubernetes/test-infra 项目中包含了Kubernetes的测试基础配置。 很多端到端的测试都会启动Kubernetes集群，并在真实的环境中测试代码的逻辑，这些测试可能一次会执行几十分钟，并且有一定概率出现Flaky。\n影响力 提高个人和公司在开源社区的影响力，也是参与社区的重要目的。\n对个人来说，参与开源项目可以快速理解项目的实现原理以及工作流程。如果想要在未来从事相关的工作，参与开源项目一定是加分项。\n对公司来说，参与开源项目可以提高公司在开源社区的话语权，提高公司的技术影响力。足够的话语权也会让开源社区在关键需求上有较快的支持，减少与社区代码的分叉，降低维护成本，并满足公司内部的需求。\n操作指南 参与开源项目并不一定要从非常复杂的功能或者Proposal开始。任何一个对代码库有利的PR都是值得提交的。修复代码中的typo 或者静态检查错误，作为最开始的工作是没有任何问题的。这能够帮我们快速热身。不过在熟悉了kubernetes的提交流程之后就没有必要做类似的提交了，以为所有的提交都需要Reviewer和Approver的批准，我们应该尽可能的做有意义的变动，减少他们的工作量。\n从阅读源码开始 我们可以从自己熟悉的模块入手，了解该模块的实现原理，在阅读代码的过程中，我们很容易发现源代码中的一些typo和缺陷，这个时候就可以提交PR修复这些问题。\n从静态检查开始 .golint_failures 文件中忽略了几百个Package中的静态检查，你可以在其中选择合适的Package作为成为Kubernetes贡献者的而第一步。\n从项目管理开始 也可以选择Kubernetes的项目管理， sig/release.\n选取第一个kubernetes问题 issue 列表\n使用tag过滤问题 “good first issue” “help wanted” 这些标签表明了对新手非常友好。有时候问题也会被打上错误标签，也许是技术难度被低估了。\nTODO 搜索代码库里的TODO。\nGo 语言的开发规范、分布式社区的治理方式\n代码需要每天都看，留出专门的时间来查看Kubernetes的源码，对它的核心组件的实现看看，构建一下, 测试一下，修一下Bug，typo等。\n一般半年之后，你就可以熟悉基础项目，并且开始贡献代码。\n当你已经和团队协作的很熟悉，就会自然承接一些子任务，然后团队就会赋予你写的权限，这样就可以顺理成章的成为Kubernetes的committer。这个时候你就是这个子项目的maintainer了\nTODO 加入 Kubenetes Slack Channle 加入邮件列表 加入SIG 参加社区会议 提issue 如何提交PR","tags":null,"title":"怎么成为K8s的Contributor"},{"categories":null,"contents":"微服务概览 康威定律\nYou build it. You fix it.\n按照业务组织服务。\n按照业务能力组织服务的意思是\n去中心化 数据去中心化 隔离性： 每个服务要独享自己的存储设置。 治理去中心化 账号服务 服务发现 技术去中心化 收敛语言，go, C++ 基础设置自动化 CICD\nPrometheus/ELK/Control Panle\n可用性\u0026amp;兼容性设计 Design for Failure，所有的依赖都可能会炸，所有可能出现err的地方都可能出现panic。\n隔离 超时控制 负载保护 限流 降级 重试 负载均衡 微服务设计 API Gateway API版本升级，强耦合\n面向用户的业务场景的API，而不是面向资源的API\u0026ndash; 前轻后重\n安全认证，限流\ngRPC \u0026amp; 服务发现 第6课 评论系统架构设计 https://github.com/go-kratos\n功能模块 理解整个背后的业务逻辑，理解业务的本质，事情的初衷。搞清楚系统背后的背景，才能做出最佳的抽象和设计。\n在动手设计前反复思考，真正编码的时间只有5%？\n不要在想的不清不楚的时候动手。\nMysql: OLTP 如果是group by等计算密集型查询的容易把数据库打垮。\nBinlog ?\n架构设计等同于数据设计，梳理清楚数据的走向和逻辑。\n尽量避免环形依赖。\nmalloc 申请2G的内存，是否真正绑定了2G物理内存。\n什么是缺页中断。\n架构设计\n存储设计\n可用性设计\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/note_go/99_Go%E8%BF%9B%E9%98%B6%E8%AE%AD%E7%BB%83%E8%90%A5/","summary":"微服务概览 康威定律\nYou build it. You fix it.\n按照业务组织服务。\n按照业务能力组织服务的意思是\n去中心化 数据去中心化 隔离性： 每个服务要独享自己的存储设置。 治理去中心化 账号服务 服务发现 技术去中心化 收敛语言，go, C++ 基础设置自动化 CICD\nPrometheus/ELK/Control Panle\n可用性\u0026amp;兼容性设计 Design for Failure，所有的依赖都可能会炸，所有可能出现err的地方都可能出现panic。\n隔离 超时控制 负载保护 限流 降级 重试 负载均衡 微服务设计 API Gateway API版本升级，强耦合\n面向用户的业务场景的API，而不是面向资源的API\u0026ndash; 前轻后重\n安全认证，限流\ngRPC \u0026amp; 服务发现 第6课 评论系统架构设计 https://github.com/go-kratos\n功能模块 理解整个背后的业务逻辑，理解业务的本质，事情的初衷。搞清楚系统背后的背景，才能做出最佳的抽象和设计。\n在动手设计前反复思考，真正编码的时间只有5%？\n不要在想的不清不楚的时候动手。\nMysql: OLTP 如果是group by等计算密集型查询的容易把数据库打垮。\nBinlog ?\n架构设计等同于数据设计，梳理清楚数据的走向和逻辑。\n尽量避免环形依赖。\nmalloc 申请2G的内存，是否真正绑定了2G物理内存。\n什么是缺页中断。\n架构设计\n存储设计\n可用性设计","tags":null,"title":"极客时间 GO实践"},{"categories":null,"contents":"唐·王勃\n​\t豫章故郡，洪都新府。星分翼轸，地接衡庐。襟三江而带五湖，控蛮荆而引瓯越。物华天宝，龙光射牛斗之墟；人杰地灵，徐孺下陈蕃之榻。雄州雾列，俊采星驰。台隍枕yixiazhij\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/life/silence/%E6%BB%95%E7%8E%8B%E9%98%81%E5%BA%8F/","summary":"唐·王勃\n​\t豫章故郡，洪都新府。星分翼轸，地接衡庐。襟三江而带五湖，控蛮荆而引瓯越。物华天宝，龙光射牛斗之墟；人杰地灵，徐孺下陈蕃之榻。雄州雾列，俊采星驰。台隍枕yixiazhij","tags":null,"title":"滕王阁序"},{"categories":null,"contents":"策略路由 所有来自网络A的包选择X路径，其他选择Y路径。或者说所有TOS为A的包选择路径F,其他选择路径K.\n多表路由（multiple Routing Tables） 传统的路由算法仅仅使用一张表，有些情形下是需要使用多路由表的。\n规则（Rule） 所有来自192.168.1.5的包，使用路由表10,本规则的优先级是990\n所到到192.168.127.117的包使用路由表11, 本规则的优先级是991；\n规则三要素\n什么样的包应用本规则 ip route add 增加路由到指定的路由表，默认为main表\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/cloudnative/Linux/%E7%AD%96%E7%95%A5%E8%B7%AF%E7%94%B1/","summary":"策略路由 所有来自网络A的包选择X路径，其他选择Y路径。或者说所有TOS为A的包选择路径F,其他选择路径K.\n多表路由（multiple Routing Tables） 传统的路由算法仅仅使用一张表，有些情形下是需要使用多路由表的。\n规则（Rule） 所有来自192.168.1.5的包，使用路由表10,本规则的优先级是990\n所到到192.168.127.117的包使用路由表11, 本规则的优先级是991；\n规则三要素\n什么样的包应用本规则 ip route add 增加路由到指定的路由表，默认为main表","tags":null,"title":"策略路由"},{"categories":null,"contents":" 自控力\nThe WillPower Instinct\n“意志力学科”这门课汇集了心理学、经济学、神经学、医学领域关于自控的最新洞见，告诉人们如何改变旧习惯，培养健康的新习惯、克服拖延、抓住重点、管理压力。阐述了为何人们会在诱惑前屈服，以及怎样才能抵挡住诱惑。此外，它还提出了理解自控局限的重要性，以及培养意志力的最佳决策。\n对于意志力科学的理解有助于培养自控力，让人们更有精力追逐最重要的东西。自控的策略有助于人们抵制各种各样的诱惑。\n为了成功做到自控，你必须知道自己为何失败 提高自控力的最有效途径在于，弄清自己如何失控、为何失控。意识到自己有多容易失控，并非意味着你是一个失败者。恰恰相反，这将有助于你避开意志力失效的陷阱。研究表明，自诩为意志坚定的人反而最容易在诱惑面前失控。因为他们无法预测自己在何时何地、会由于何种原因失控。他们在面对挫折时更容易吃惊，在陷入困境时更容易放弃。\n自知之明是自控的基础。认识到自己意志力存在问题，则是自控的关键。\n当我们屈从于诱惑或者拖着不该做的事时，是什么拖了我们的后腿？是哪些致命的错误？更重要的是，我们如何寻找机会，避免来犯同样的错误。我们怎样从失败中汲取经验，为成功铺平道路？\n这些行为虽不完美，却是人之常态。每个人都在以某种方式抵制诱惑、癖好、干扰和拖延。这不是个体的弱点或个人的不足，而是普遍的经验，是人所共有的状态。\n理论固然好，但是数据更重要。\n沉迷于电视剧不能自拔\n总是幻想或者希望自己和主角处于同样的状态，同样可以随心所欲的处理各种困境。更不想进一步打破自己的幻想，不想回归现实。可事实却是，越沉浸于其中，却又距离故事中的主角远了一步。这个世界上有太多看不完的故事，不是每个故事都需要去读，选择重要的，选择真正有意义，有营养的文化饕餮。\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/blog/Book_WillPower/","summary":"自控力\nThe WillPower Instinct\n“意志力学科”这门课汇集了心理学、经济学、神经学、医学领域关于自控的最新洞见，告诉人们如何改变旧习惯，培养健康的新习惯、克服拖延、抓住重点、管理压力。阐述了为何人们会在诱惑前屈服，以及怎样才能抵挡住诱惑。此外，它还提出了理解自控局限的重要性，以及培养意志力的最佳决策。\n对于意志力科学的理解有助于培养自控力，让人们更有精力追逐最重要的东西。自控的策略有助于人们抵制各种各样的诱惑。\n为了成功做到自控，你必须知道自己为何失败 提高自控力的最有效途径在于，弄清自己如何失控、为何失控。意识到自己有多容易失控，并非意味着你是一个失败者。恰恰相反，这将有助于你避开意志力失效的陷阱。研究表明，自诩为意志坚定的人反而最容易在诱惑面前失控。因为他们无法预测自己在何时何地、会由于何种原因失控。他们在面对挫折时更容易吃惊，在陷入困境时更容易放弃。\n自知之明是自控的基础。认识到自己意志力存在问题，则是自控的关键。\n当我们屈从于诱惑或者拖着不该做的事时，是什么拖了我们的后腿？是哪些致命的错误？更重要的是，我们如何寻找机会，避免来犯同样的错误。我们怎样从失败中汲取经验，为成功铺平道路？\n这些行为虽不完美，却是人之常态。每个人都在以某种方式抵制诱惑、癖好、干扰和拖延。这不是个体的弱点或个人的不足，而是普遍的经验，是人所共有的状态。\n理论固然好，但是数据更重要。\n沉迷于电视剧不能自拔\n总是幻想或者希望自己和主角处于同样的状态，同样可以随心所欲的处理各种困境。更不想进一步打破自己的幻想，不想回归现实。可事实却是，越沉浸于其中，却又距离故事中的主角远了一步。这个世界上有太多看不完的故事，不是每个故事都需要去读，选择重要的，选择真正有意义，有营养的文化饕餮。","tags":null,"title":"自控力"},{"categories":null,"contents":"高并发，负载均衡，高可用\n不要因为技术而技术, 软件工程学需要分层解耦\n应用层 1# $$ current process pid 2cd /proc/$$/fd 0 stdin\n1 stdout\n2 stderr\n1# 8 is the name of the file descriptor, \u0026lt;\u0026gt; in and out direction 2exec 8\u0026lt;\u0026gt; /dev/tcp/www.baidu.com/80 3# exec 8\u0026lt;\u0026amp; - 4# \u0026amp; represent the argument is a fd 5echo -e \u0026#34;GET / HTTP/1.0\\n\u0026#34; \u0026gt;\u0026amp; 8 传输层 ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://airren.github.io/posts/blog/high_concurrency_lb/","summary":"高并发，负载均衡，高可用\n不要因为技术而技术, 软件工程学需要分层解耦\n应用层 1# $$ current process pid 2cd /proc/$$/fd 0 stdin\n1 stdout\n2 stderr\n1# 8 is the name of the file descriptor, \u0026lt;\u0026gt; in and out direction 2exec 8\u0026lt;\u0026gt; /dev/tcp/www.baidu.com/80 3# exec 8\u0026lt;\u0026amp; - 4# \u0026amp; represent the argument is a fd 5echo -e \u0026#34;GET / HTTP/1.0\\n\u0026#34; \u0026gt;\u0026amp; 8 传输层 ","tags":null,"title":"高并发负载均衡"}]